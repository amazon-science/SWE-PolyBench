{"instance_id": "apache__dubbo-3093", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ClassHelper.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ClassHelper.java\nindex b5aa79f2fc..5eba2e6d39 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ClassHelper.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ClassHelper.java\n@@ -265,8 +265,11 @@ public class ClassHelper {\n     }\n \n     public static Object convertPrimitive(Class<?> type, String value) {\n+        if (value == null || value.length() == 0) {\n+            return null;\n+        }\n         if (type == char.class || type == Character.class) {\n-            return value.length() > 0 ? value.charAt(0) : '\\0';\n+            return value.charAt(0);\n         } else if (type == boolean.class || type == Boolean.class) {\n             return Boolean.valueOf(value);\n         } else if (type == byte.class || type == Byte.class) {\n"}
{"instance_id": "apache__dubbo-4515", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/io/Bytes.java b/dubbo-common/src/main/java/org/apache/dubbo/common/io/Bytes.java\nindex 263e7b9f67..5112dcf73a 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/io/Bytes.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/io/Bytes.java\n@@ -730,8 +730,12 @@ public class Bytes {\n             char pc = code[64];\n             if (str.charAt(off + len - 2) == pc) {\n                 size -= 2;\n+                --num;\n+                rem = 2;\n             } else if (str.charAt(off + len - 1) == pc) {\n                 size--;\n+                --num;\n+                rem = 3;\n             }\n         } else {\n             if (rem == 2) {\n"}
{"instance_id": "apache__dubbo-3317", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-registry/dubbo-registry-multicast/src/main/java/org/apache/dubbo/registry/multicast/MulticastRegistry.java b/dubbo-registry/dubbo-registry-multicast/src/main/java/org/apache/dubbo/registry/multicast/MulticastRegistry.java\nindex 5498e9efbf..fbe0e8ba6b 100644\n--- a/dubbo-registry/dubbo-registry-multicast/src/main/java/org/apache/dubbo/registry/multicast/MulticastRegistry.java\n+++ b/dubbo-registry/dubbo-registry-multicast/src/main/java/org/apache/dubbo/registry/multicast/MulticastRegistry.java\n@@ -1,437 +1,447 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.registry.multicast;\r\n-\r\n-import org.apache.dubbo.common.Constants;\r\n-import org.apache.dubbo.common.URL;\r\n-import org.apache.dubbo.common.logger.Logger;\r\n-import org.apache.dubbo.common.logger.LoggerFactory;\r\n-import org.apache.dubbo.common.utils.ConcurrentHashSet;\r\n-import org.apache.dubbo.common.utils.ExecutorUtil;\r\n-import org.apache.dubbo.common.utils.NamedThreadFactory;\r\n-import org.apache.dubbo.common.utils.NetUtils;\r\n-import org.apache.dubbo.common.utils.UrlUtils;\r\n-import org.apache.dubbo.common.utils.CollectionUtils;\r\n-import org.apache.dubbo.registry.NotifyListener;\r\n-import org.apache.dubbo.registry.support.FailbackRegistry;\r\n-\r\n-import java.io.IOException;\r\n-import java.net.DatagramPacket;\r\n-import java.net.InetAddress;\r\n-import java.net.InetSocketAddress;\r\n-import java.net.MulticastSocket;\r\n-import java.net.Socket;\r\n-import java.util.ArrayList;\r\n-import java.util.Arrays;\r\n-import java.util.HashSet;\r\n-import java.util.List;\r\n-import java.util.Map;\r\n-import java.util.Set;\r\n-import java.util.concurrent.ConcurrentHashMap;\r\n-import java.util.concurrent.ConcurrentMap;\r\n-import java.util.concurrent.Executors;\r\n-import java.util.concurrent.ScheduledExecutorService;\r\n-import java.util.concurrent.ScheduledFuture;\r\n-import java.util.concurrent.TimeUnit;\r\n-\r\n-/**\r\n- * MulticastRegistry\r\n- */\r\n-public class MulticastRegistry extends FailbackRegistry {\r\n-\r\n-    // logging output\r\n-    private static final Logger logger = LoggerFactory.getLogger(MulticastRegistry.class);\r\n-\r\n-    private static final int DEFAULT_MULTICAST_PORT = 1234;\r\n-\r\n-    private final InetAddress multicastAddress;\r\n-\r\n-    private final MulticastSocket multicastSocket;\r\n-\r\n-    private final int multicastPort;\r\n-\r\n-    private final ConcurrentMap<URL, Set<URL>> received = new ConcurrentHashMap<URL, Set<URL>>();\r\n-\r\n-    private final ScheduledExecutorService cleanExecutor = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"DubboMulticastRegistryCleanTimer\", true));\r\n-\r\n-    private final ScheduledFuture<?> cleanFuture;\r\n-\r\n-    private final int cleanPeriod;\r\n-\r\n-    private volatile boolean admin = false;\r\n-\r\n-    public MulticastRegistry(URL url) {\r\n-        super(url);\r\n-        if (url.isAnyHost()) {\r\n-            throw new IllegalStateException(\"registry address == null\");\r\n-        }\r\n-        try {\r\n-            multicastAddress = InetAddress.getByName(url.getHost());\r\n-            if (!multicastAddress.isMulticastAddress()) {\r\n-                throw new IllegalArgumentException(\"Invalid multicast address \" + url.getHost() +\r\n-                        \", ipv4 multicast address scope: 224.0.0.0 - 239.255.255.255.\");\r\n-            }\r\n-            multicastPort = url.getPort() <= 0 ? DEFAULT_MULTICAST_PORT : url.getPort();\r\n-            multicastSocket = new MulticastSocket(multicastPort);\r\n-            multicastSocket.setLoopbackMode(false);\r\n-            multicastSocket.joinGroup(multicastAddress);\r\n-            Thread thread = new Thread(new Runnable() {\r\n-                @Override\r\n-                public void run() {\r\n-                    byte[] buf = new byte[2048];\r\n-                    DatagramPacket recv = new DatagramPacket(buf, buf.length);\r\n-                    while (!multicastSocket.isClosed()) {\r\n-                        try {\r\n-                            multicastSocket.receive(recv);\r\n-                            String msg = new String(recv.getData()).trim();\r\n-                            int i = msg.indexOf('\\n');\r\n-                            if (i > 0) {\r\n-                                msg = msg.substring(0, i).trim();\r\n-                            }\r\n-                            MulticastRegistry.this.receive(msg, (InetSocketAddress) recv.getSocketAddress());\r\n-                            Arrays.fill(buf, (byte) 0);\r\n-                        } catch (Throwable e) {\r\n-                            if (!multicastSocket.isClosed()) {\r\n-                                logger.error(e.getMessage(), e);\r\n-                            }\r\n-                        }\r\n-                    }\r\n-                }\r\n-            }, \"DubboMulticastRegistryReceiver\");\r\n-            thread.setDaemon(true);\r\n-            thread.start();\r\n-        } catch (IOException e) {\r\n-            throw new IllegalStateException(e.getMessage(), e);\r\n-        }\r\n-        this.cleanPeriod = url.getParameter(Constants.SESSION_TIMEOUT_KEY, Constants.DEFAULT_SESSION_TIMEOUT);\r\n-        if (url.getParameter(\"clean\", true)) {\r\n-            this.cleanFuture = cleanExecutor.scheduleWithFixedDelay(new Runnable() {\r\n-                @Override\r\n-                public void run() {\r\n-                    try {\r\n-                        clean(); // Remove the expired\r\n-                    } catch (Throwable t) { // Defensive fault tolerance\r\n-                        logger.error(\"Unexpected exception occur at clean expired provider, cause: \" + t.getMessage(), t);\r\n-                    }\r\n-                }\r\n-            }, cleanPeriod, cleanPeriod, TimeUnit.MILLISECONDS);\r\n-        } else {\r\n-            this.cleanFuture = null;\r\n-        }\r\n-    }\r\n-\r\n-    /**\r\n-     * Remove the expired providers, only when \"clean\" parameter is true.\r\n-     */\r\n-    private void clean() {\r\n-        if (admin) {\r\n-            for (Set<URL> providers : new HashSet<Set<URL>>(received.values())) {\r\n-                for (URL url : new HashSet<URL>(providers)) {\r\n-                    if (isExpired(url)) {\r\n-                        if (logger.isWarnEnabled()) {\r\n-                            logger.warn(\"Clean expired provider \" + url);\r\n-                        }\r\n-                        doUnregister(url);\r\n-                    }\r\n-                }\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    private boolean isExpired(URL url) {\r\n-        if (!url.getParameter(Constants.DYNAMIC_KEY, true)\r\n-                || url.getPort() <= 0\r\n-                || Constants.CONSUMER_PROTOCOL.equals(url.getProtocol())\r\n-                || Constants.ROUTE_PROTOCOL.equals(url.getProtocol())\r\n-                || Constants.OVERRIDE_PROTOCOL.equals(url.getProtocol())) {\r\n-            return false;\r\n-        }\r\n-        Socket socket = null;\r\n-        try {\r\n-            socket = new Socket(url.getHost(), url.getPort());\r\n-        } catch (Throwable e) {\r\n-            try {\r\n-                Thread.sleep(100);\r\n-            } catch (Throwable e2) {\r\n-            }\r\n-            Socket socket2 = null;\r\n-            try {\r\n-                socket2 = new Socket(url.getHost(), url.getPort());\r\n-            } catch (Throwable e2) {\r\n-                return true;\r\n-            } finally {\r\n-                if (socket2 != null) {\r\n-                    try {\r\n-                        socket2.close();\r\n-                    } catch (Throwable e2) {\r\n-                    }\r\n-                }\r\n-            }\r\n-        } finally {\r\n-            if (socket != null) {\r\n-                try {\r\n-                    socket.close();\r\n-                } catch (Throwable e) {\r\n-                }\r\n-            }\r\n-        }\r\n-        return false;\r\n-    }\r\n-\r\n-    private void receive(String msg, InetSocketAddress remoteAddress) {\r\n-        if (logger.isInfoEnabled()) {\r\n-            logger.info(\"Receive multicast message: \" + msg + \" from \" + remoteAddress);\r\n-        }\r\n-        if (msg.startsWith(Constants.REGISTER)) {\r\n-            URL url = URL.valueOf(msg.substring(Constants.REGISTER.length()).trim());\r\n-            registered(url);\r\n-        } else if (msg.startsWith(Constants.UNREGISTER)) {\r\n-            URL url = URL.valueOf(msg.substring(Constants.UNREGISTER.length()).trim());\r\n-            unregistered(url);\r\n-        } else if (msg.startsWith(Constants.SUBSCRIBE)) {\r\n-            URL url = URL.valueOf(msg.substring(Constants.SUBSCRIBE.length()).trim());\r\n-            Set<URL> urls = getRegistered();\r\n-            if (CollectionUtils.isNotEmpty(urls)) {\r\n-                for (URL u : urls) {\r\n-                    if (UrlUtils.isMatch(url, u)) {\r\n-                        String host = remoteAddress != null && remoteAddress.getAddress() != null\r\n-                                ? remoteAddress.getAddress().getHostAddress() : url.getIp();\r\n-                        if (url.getParameter(\"unicast\", true) // Whether the consumer's machine has only one process\r\n-                                && !NetUtils.getLocalHost().equals(host)) { // Multiple processes in the same machine cannot be unicast with unicast or there will be only one process receiving information\r\n-                            unicast(Constants.REGISTER + \" \" + u.toFullString(), host);\r\n-                        } else {\r\n-                            multicast(Constants.REGISTER + \" \" + u.toFullString());\r\n-                        }\r\n-                    }\r\n-                }\r\n-            }\r\n-        }/* else if (msg.startsWith(UNSUBSCRIBE)) {\r\n-        }*/\r\n-    }\r\n-\r\n-    private void multicast(String msg) {\r\n-        if (logger.isInfoEnabled()) {\r\n-            logger.info(\"Send multicast message: \" + msg + \" to \" + multicastAddress + \":\" + multicastPort);\r\n-        }\r\n-        try {\r\n-            byte[] data = (msg + \"\\n\").getBytes();\r\n-            DatagramPacket hi = new DatagramPacket(data, data.length, multicastAddress, multicastPort);\r\n-            multicastSocket.send(hi);\r\n-        } catch (Exception e) {\r\n-            throw new IllegalStateException(e.getMessage(), e);\r\n-        }\r\n-    }\r\n-\r\n-    private void unicast(String msg, String host) {\r\n-        if (logger.isInfoEnabled()) {\r\n-            logger.info(\"Send unicast message: \" + msg + \" to \" + host + \":\" + multicastPort);\r\n-        }\r\n-        try {\r\n-            byte[] data = (msg + \"\\n\").getBytes();\r\n-            DatagramPacket hi = new DatagramPacket(data, data.length, InetAddress.getByName(host), multicastPort);\r\n-            multicastSocket.send(hi);\r\n-        } catch (Exception e) {\r\n-            throw new IllegalStateException(e.getMessage(), e);\r\n-        }\r\n-    }\r\n-\r\n-    @Override\r\n-    public void doRegister(URL url) {\r\n-        multicast(Constants.REGISTER + \" \" + url.toFullString());\r\n-    }\r\n-\r\n-    @Override\r\n-    public void doUnregister(URL url) {\r\n-        multicast(Constants.UNREGISTER + \" \" + url.toFullString());\r\n-    }\r\n-\r\n-    @Override\r\n-    public void doSubscribe(URL url, NotifyListener listener) {\r\n-        if (Constants.ANY_VALUE.equals(url.getServiceInterface())) {\r\n-            admin = true;\r\n-        }\r\n-        multicast(Constants.SUBSCRIBE + \" \" + url.toFullString());\r\n-        synchronized (listener) {\r\n-            try {\r\n-                listener.wait(url.getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT));\r\n-            } catch (InterruptedException e) {\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    @Override\r\n-    public void doUnsubscribe(URL url, NotifyListener listener) {\r\n-        if (!Constants.ANY_VALUE.equals(url.getServiceInterface())\r\n-                && url.getParameter(Constants.REGISTER_KEY, true)) {\r\n-            unregister(url);\r\n-        }\r\n-        multicast(Constants.UNSUBSCRIBE + \" \" + url.toFullString());\r\n-    }\r\n-\r\n-    @Override\r\n-    public boolean isAvailable() {\r\n-        try {\r\n-            return multicastSocket != null;\r\n-        } catch (Throwable t) {\r\n-            return false;\r\n-        }\r\n-    }\r\n-\r\n-    /**\r\n-     * Remove the expired providers(if clean is true), leave the multicast group and close the multicast socket.\r\n-     */\r\n-    @Override\r\n-    public void destroy() {\r\n-        super.destroy();\r\n-        try {\r\n-            ExecutorUtil.cancelScheduledFuture(cleanFuture);\r\n-        } catch (Throwable t) {\r\n-            logger.warn(t.getMessage(), t);\r\n-        }\r\n-        try {\r\n-            multicastSocket.leaveGroup(multicastAddress);\r\n-            multicastSocket.close();\r\n-        } catch (Throwable t) {\r\n-            logger.warn(t.getMessage(), t);\r\n-        }\r\n-        ExecutorUtil.gracefulShutdown(cleanExecutor, cleanPeriod);\r\n-    }\r\n-\r\n-    protected void registered(URL url) {\r\n-        for (Map.Entry<URL, Set<NotifyListener>> entry : getSubscribed().entrySet()) {\r\n-            URL key = entry.getKey();\r\n-            if (UrlUtils.isMatch(key, url)) {\r\n-                Set<URL> urls = received.get(key);\r\n-                if (urls == null) {\r\n-                    received.putIfAbsent(key, new ConcurrentHashSet<URL>());\r\n-                    urls = received.get(key);\r\n-                }\r\n-                urls.add(url);\r\n-                List<URL> list = toList(urls);\r\n-                for (NotifyListener listener : entry.getValue()) {\r\n-                    notify(key, listener, list);\r\n-                    synchronized (listener) {\r\n-                        listener.notify();\r\n-                    }\r\n-                }\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    protected void unregistered(URL url) {\r\n-        for (Map.Entry<URL, Set<NotifyListener>> entry : getSubscribed().entrySet()) {\r\n-            URL key = entry.getKey();\r\n-            if (UrlUtils.isMatch(key, url)) {\r\n-                Set<URL> urls = received.get(key);\r\n-                if (urls != null) {\r\n-                    urls.remove(url);\r\n-                }\r\n-                if (urls == null || urls.isEmpty()) {\r\n-                    if (urls == null) {\r\n-                        urls = new ConcurrentHashSet<URL>();\r\n-                    }\r\n-                    URL empty = url.setProtocol(Constants.EMPTY_PROTOCOL);\r\n-                    urls.add(empty);\r\n-                }\r\n-                List<URL> list = toList(urls);\r\n-                for (NotifyListener listener : entry.getValue()) {\r\n-                    notify(key, listener, list);\r\n-                }\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    protected void subscribed(URL url, NotifyListener listener) {\r\n-        List<URL> urls = lookup(url);\r\n-        notify(url, listener, urls);\r\n-    }\r\n-\r\n-    private List<URL> toList(Set<URL> urls) {\r\n-        List<URL> list = new ArrayList<URL>();\r\n-        if (CollectionUtils.isNotEmpty(urls)) {\r\n-            for (URL url : urls) {\r\n-                list.add(url);\r\n-            }\r\n-        }\r\n-        return list;\r\n-    }\r\n-\r\n-    @Override\r\n-    public void register(URL url) {\r\n-        super.register(url);\r\n-        registered(url);\r\n-    }\r\n-\r\n-    @Override\r\n-    public void unregister(URL url) {\r\n-        super.unregister(url);\r\n-        unregistered(url);\r\n-    }\r\n-\r\n-    @Override\r\n-    public void subscribe(URL url, NotifyListener listener) {\r\n-        super.subscribe(url, listener);\r\n-        subscribed(url, listener);\r\n-    }\r\n-\r\n-    @Override\r\n-    public void unsubscribe(URL url, NotifyListener listener) {\r\n-        super.unsubscribe(url, listener);\r\n-        received.remove(url);\r\n-    }\r\n-\r\n-    @Override\r\n-    public List<URL> lookup(URL url) {\r\n-        List<URL> urls = new ArrayList<URL>();\r\n-        Map<String, List<URL>> notifiedUrls = getNotified().get(url);\r\n-        if (notifiedUrls != null && notifiedUrls.size() > 0) {\r\n-            for (List<URL> values : notifiedUrls.values()) {\r\n-                urls.addAll(values);\r\n-            }\r\n-        }\r\n-        if (urls.isEmpty()) {\r\n-            List<URL> cacheUrls = getCacheUrls(url);\r\n-            if (CollectionUtils.isNotEmpty(cacheUrls)) {\r\n-                urls.addAll(cacheUrls);\r\n-            }\r\n-        }\r\n-        if (urls.isEmpty()) {\r\n-            for (URL u : getRegistered()) {\r\n-                if (UrlUtils.isMatch(url, u)) {\r\n-                    urls.add(u);\r\n-                }\r\n-            }\r\n-        }\r\n-        if (Constants.ANY_VALUE.equals(url.getServiceInterface())) {\r\n-            for (URL u : getSubscribed().keySet()) {\r\n-                if (UrlUtils.isMatch(url, u)) {\r\n-                    urls.add(u);\r\n-                }\r\n-            }\r\n-        }\r\n-        return urls;\r\n-    }\r\n-\r\n-    public MulticastSocket getMulticastSocket() {\r\n-        return multicastSocket;\r\n-    }\r\n-\r\n-    public Map<URL, Set<URL>> getReceived() {\r\n-        return received;\r\n-    }\r\n-\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.registry.multicast;\n+\n+import org.apache.dubbo.common.Constants;\n+import org.apache.dubbo.common.URL;\n+import org.apache.dubbo.common.logger.Logger;\n+import org.apache.dubbo.common.logger.LoggerFactory;\n+import org.apache.dubbo.common.utils.ConcurrentHashSet;\n+import org.apache.dubbo.common.utils.ExecutorUtil;\n+import org.apache.dubbo.common.utils.NamedThreadFactory;\n+import org.apache.dubbo.common.utils.NetUtils;\n+import org.apache.dubbo.common.utils.UrlUtils;\n+import org.apache.dubbo.common.utils.CollectionUtils;\n+import org.apache.dubbo.registry.NotifyListener;\n+import org.apache.dubbo.registry.support.FailbackRegistry;\n+\n+import java.io.IOException;\n+import java.net.DatagramPacket;\n+import java.net.InetAddress;\n+import java.net.InetSocketAddress;\n+import java.net.MulticastSocket;\n+import java.net.NetworkInterface;\n+import java.net.Socket;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * MulticastRegistry\n+ */\n+public class MulticastRegistry extends FailbackRegistry {\n+\n+    // logging output\n+    private static final Logger logger = LoggerFactory.getLogger(MulticastRegistry.class);\n+\n+    private static final int DEFAULT_MULTICAST_PORT = 1234;\n+\n+    private final InetAddress multicastAddress;\n+\n+    private final MulticastSocket multicastSocket;\n+\n+    private final int multicastPort;\n+\n+    private final ConcurrentMap<URL, Set<URL>> received = new ConcurrentHashMap<URL, Set<URL>>();\n+\n+    private final ScheduledExecutorService cleanExecutor = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"DubboMulticastRegistryCleanTimer\", true));\n+\n+    private final ScheduledFuture<?> cleanFuture;\n+\n+    private final int cleanPeriod;\n+\n+    private volatile boolean admin = false;\n+\n+    public MulticastRegistry(URL url) {\n+        super(url);\n+        if (url.isAnyHost()) {\n+            throw new IllegalStateException(\"registry address == null\");\n+        }\n+        try {\n+            multicastAddress = InetAddress.getByName(url.getHost());\n+            if (!multicastAddress.isMulticastAddress()) {\n+                throw new IllegalArgumentException(\"Invalid multicast address \" + url.getHost() +\n+                        \", ipv4 multicast address scope: 224.0.0.0 - 239.255.255.255.\");\n+            }\n+            multicastPort = url.getPort() <= 0 ? DEFAULT_MULTICAST_PORT : url.getPort();\n+            multicastSocket = new MulticastSocket(multicastPort);\n+            multicastSocket.setLoopbackMode(false);\n+            // setting the interface to use for multicast packets\n+            // to fix the issue of \"Can't assign requested address\" on macOS\n+            InetAddress localAddress = NetUtils.getLocalAddress();\n+            if (localAddress != null) {\n+                NetworkInterface networkInterface = NetworkInterface.getByInetAddress(localAddress);\n+                if (networkInterface != null) {\n+                    multicastSocket.setNetworkInterface(networkInterface);\n+                }\n+            }\n+            multicastSocket.joinGroup(multicastAddress);\n+            Thread thread = new Thread(new Runnable() {\n+                @Override\n+                public void run() {\n+                    byte[] buf = new byte[2048];\n+                    DatagramPacket recv = new DatagramPacket(buf, buf.length);\n+                    while (!multicastSocket.isClosed()) {\n+                        try {\n+                            multicastSocket.receive(recv);\n+                            String msg = new String(recv.getData()).trim();\n+                            int i = msg.indexOf('\\n');\n+                            if (i > 0) {\n+                                msg = msg.substring(0, i).trim();\n+                            }\n+                            MulticastRegistry.this.receive(msg, (InetSocketAddress) recv.getSocketAddress());\n+                            Arrays.fill(buf, (byte) 0);\n+                        } catch (Throwable e) {\n+                            if (!multicastSocket.isClosed()) {\n+                                logger.error(e.getMessage(), e);\n+                            }\n+                        }\n+                    }\n+                }\n+            }, \"DubboMulticastRegistryReceiver\");\n+            thread.setDaemon(true);\n+            thread.start();\n+        } catch (IOException e) {\n+            throw new IllegalStateException(e.getMessage(), e);\n+        }\n+        this.cleanPeriod = url.getParameter(Constants.SESSION_TIMEOUT_KEY, Constants.DEFAULT_SESSION_TIMEOUT);\n+        if (url.getParameter(\"clean\", true)) {\n+            this.cleanFuture = cleanExecutor.scheduleWithFixedDelay(new Runnable() {\n+                @Override\n+                public void run() {\n+                    try {\n+                        clean(); // Remove the expired\n+                    } catch (Throwable t) { // Defensive fault tolerance\n+                        logger.error(\"Unexpected exception occur at clean expired provider, cause: \" + t.getMessage(), t);\n+                    }\n+                }\n+            }, cleanPeriod, cleanPeriod, TimeUnit.MILLISECONDS);\n+        } else {\n+            this.cleanFuture = null;\n+        }\n+    }\n+\n+    /**\n+     * Remove the expired providers, only when \"clean\" parameter is true.\n+     */\n+    private void clean() {\n+        if (admin) {\n+            for (Set<URL> providers : new HashSet<Set<URL>>(received.values())) {\n+                for (URL url : new HashSet<URL>(providers)) {\n+                    if (isExpired(url)) {\n+                        if (logger.isWarnEnabled()) {\n+                            logger.warn(\"Clean expired provider \" + url);\n+                        }\n+                        doUnregister(url);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean isExpired(URL url) {\n+        if (!url.getParameter(Constants.DYNAMIC_KEY, true)\n+                || url.getPort() <= 0\n+                || Constants.CONSUMER_PROTOCOL.equals(url.getProtocol())\n+                || Constants.ROUTE_PROTOCOL.equals(url.getProtocol())\n+                || Constants.OVERRIDE_PROTOCOL.equals(url.getProtocol())) {\n+            return false;\n+        }\n+        Socket socket = null;\n+        try {\n+            socket = new Socket(url.getHost(), url.getPort());\n+        } catch (Throwable e) {\n+            try {\n+                Thread.sleep(100);\n+            } catch (Throwable e2) {\n+            }\n+            Socket socket2 = null;\n+            try {\n+                socket2 = new Socket(url.getHost(), url.getPort());\n+            } catch (Throwable e2) {\n+                return true;\n+            } finally {\n+                if (socket2 != null) {\n+                    try {\n+                        socket2.close();\n+                    } catch (Throwable e2) {\n+                    }\n+                }\n+            }\n+        } finally {\n+            if (socket != null) {\n+                try {\n+                    socket.close();\n+                } catch (Throwable e) {\n+                }\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private void receive(String msg, InetSocketAddress remoteAddress) {\n+        if (logger.isInfoEnabled()) {\n+            logger.info(\"Receive multicast message: \" + msg + \" from \" + remoteAddress);\n+        }\n+        if (msg.startsWith(Constants.REGISTER)) {\n+            URL url = URL.valueOf(msg.substring(Constants.REGISTER.length()).trim());\n+            registered(url);\n+        } else if (msg.startsWith(Constants.UNREGISTER)) {\n+            URL url = URL.valueOf(msg.substring(Constants.UNREGISTER.length()).trim());\n+            unregistered(url);\n+        } else if (msg.startsWith(Constants.SUBSCRIBE)) {\n+            URL url = URL.valueOf(msg.substring(Constants.SUBSCRIBE.length()).trim());\n+            Set<URL> urls = getRegistered();\n+            if (CollectionUtils.isNotEmpty(urls)) {\n+                for (URL u : urls) {\n+                    if (UrlUtils.isMatch(url, u)) {\n+                        String host = remoteAddress != null && remoteAddress.getAddress() != null\n+                                ? remoteAddress.getAddress().getHostAddress() : url.getIp();\n+                        if (url.getParameter(\"unicast\", true) // Whether the consumer's machine has only one process\n+                                && !NetUtils.getLocalHost().equals(host)) { // Multiple processes in the same machine cannot be unicast with unicast or there will be only one process receiving information\n+                            unicast(Constants.REGISTER + \" \" + u.toFullString(), host);\n+                        } else {\n+                            multicast(Constants.REGISTER + \" \" + u.toFullString());\n+                        }\n+                    }\n+                }\n+            }\n+        }/* else if (msg.startsWith(UNSUBSCRIBE)) {\n+        }*/\n+    }\n+\n+    private void multicast(String msg) {\n+        if (logger.isInfoEnabled()) {\n+            logger.info(\"Send multicast message: \" + msg + \" to \" + multicastAddress + \":\" + multicastPort);\n+        }\n+        try {\n+            byte[] data = (msg + \"\\n\").getBytes();\n+            DatagramPacket hi = new DatagramPacket(data, data.length, multicastAddress, multicastPort);\n+            multicastSocket.send(hi);\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e.getMessage(), e);\n+        }\n+    }\n+\n+    private void unicast(String msg, String host) {\n+        if (logger.isInfoEnabled()) {\n+            logger.info(\"Send unicast message: \" + msg + \" to \" + host + \":\" + multicastPort);\n+        }\n+        try {\n+            byte[] data = (msg + \"\\n\").getBytes();\n+            DatagramPacket hi = new DatagramPacket(data, data.length, InetAddress.getByName(host), multicastPort);\n+            multicastSocket.send(hi);\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e.getMessage(), e);\n+        }\n+    }\n+\n+    @Override\n+    public void doRegister(URL url) {\n+        multicast(Constants.REGISTER + \" \" + url.toFullString());\n+    }\n+\n+    @Override\n+    public void doUnregister(URL url) {\n+        multicast(Constants.UNREGISTER + \" \" + url.toFullString());\n+    }\n+\n+    @Override\n+    public void doSubscribe(URL url, NotifyListener listener) {\n+        if (Constants.ANY_VALUE.equals(url.getServiceInterface())) {\n+            admin = true;\n+        }\n+        multicast(Constants.SUBSCRIBE + \" \" + url.toFullString());\n+        synchronized (listener) {\n+            try {\n+                listener.wait(url.getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT));\n+            } catch (InterruptedException e) {\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void doUnsubscribe(URL url, NotifyListener listener) {\n+        if (!Constants.ANY_VALUE.equals(url.getServiceInterface())\n+                && url.getParameter(Constants.REGISTER_KEY, true)) {\n+            unregister(url);\n+        }\n+        multicast(Constants.UNSUBSCRIBE + \" \" + url.toFullString());\n+    }\n+\n+    @Override\n+    public boolean isAvailable() {\n+        try {\n+            return multicastSocket != null;\n+        } catch (Throwable t) {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Remove the expired providers(if clean is true), leave the multicast group and close the multicast socket.\n+     */\n+    @Override\n+    public void destroy() {\n+        super.destroy();\n+        try {\n+            ExecutorUtil.cancelScheduledFuture(cleanFuture);\n+        } catch (Throwable t) {\n+            logger.warn(t.getMessage(), t);\n+        }\n+        try {\n+            multicastSocket.leaveGroup(multicastAddress);\n+            multicastSocket.close();\n+        } catch (Throwable t) {\n+            logger.warn(t.getMessage(), t);\n+        }\n+        ExecutorUtil.gracefulShutdown(cleanExecutor, cleanPeriod);\n+    }\n+\n+    protected void registered(URL url) {\n+        for (Map.Entry<URL, Set<NotifyListener>> entry : getSubscribed().entrySet()) {\n+            URL key = entry.getKey();\n+            if (UrlUtils.isMatch(key, url)) {\n+                Set<URL> urls = received.get(key);\n+                if (urls == null) {\n+                    received.putIfAbsent(key, new ConcurrentHashSet<URL>());\n+                    urls = received.get(key);\n+                }\n+                urls.add(url);\n+                List<URL> list = toList(urls);\n+                for (NotifyListener listener : entry.getValue()) {\n+                    notify(key, listener, list);\n+                    synchronized (listener) {\n+                        listener.notify();\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    protected void unregistered(URL url) {\n+        for (Map.Entry<URL, Set<NotifyListener>> entry : getSubscribed().entrySet()) {\n+            URL key = entry.getKey();\n+            if (UrlUtils.isMatch(key, url)) {\n+                Set<URL> urls = received.get(key);\n+                if (urls != null) {\n+                    urls.remove(url);\n+                }\n+                if (urls == null || urls.isEmpty()) {\n+                    if (urls == null) {\n+                        urls = new ConcurrentHashSet<URL>();\n+                    }\n+                    URL empty = url.setProtocol(Constants.EMPTY_PROTOCOL);\n+                    urls.add(empty);\n+                }\n+                List<URL> list = toList(urls);\n+                for (NotifyListener listener : entry.getValue()) {\n+                    notify(key, listener, list);\n+                }\n+            }\n+        }\n+    }\n+\n+    protected void subscribed(URL url, NotifyListener listener) {\n+        List<URL> urls = lookup(url);\n+        notify(url, listener, urls);\n+    }\n+\n+    private List<URL> toList(Set<URL> urls) {\n+        List<URL> list = new ArrayList<URL>();\n+        if (CollectionUtils.isNotEmpty(urls)) {\n+            for (URL url : urls) {\n+                list.add(url);\n+            }\n+        }\n+        return list;\n+    }\n+\n+    @Override\n+    public void register(URL url) {\n+        super.register(url);\n+        registered(url);\n+    }\n+\n+    @Override\n+    public void unregister(URL url) {\n+        super.unregister(url);\n+        unregistered(url);\n+    }\n+\n+    @Override\n+    public void subscribe(URL url, NotifyListener listener) {\n+        super.subscribe(url, listener);\n+        subscribed(url, listener);\n+    }\n+\n+    @Override\n+    public void unsubscribe(URL url, NotifyListener listener) {\n+        super.unsubscribe(url, listener);\n+        received.remove(url);\n+    }\n+\n+    @Override\n+    public List<URL> lookup(URL url) {\n+        List<URL> urls = new ArrayList<URL>();\n+        Map<String, List<URL>> notifiedUrls = getNotified().get(url);\n+        if (notifiedUrls != null && notifiedUrls.size() > 0) {\n+            for (List<URL> values : notifiedUrls.values()) {\n+                urls.addAll(values);\n+            }\n+        }\n+        if (urls.isEmpty()) {\n+            List<URL> cacheUrls = getCacheUrls(url);\n+            if (CollectionUtils.isNotEmpty(cacheUrls)) {\n+                urls.addAll(cacheUrls);\n+            }\n+        }\n+        if (urls.isEmpty()) {\n+            for (URL u : getRegistered()) {\n+                if (UrlUtils.isMatch(url, u)) {\n+                    urls.add(u);\n+                }\n+            }\n+        }\n+        if (Constants.ANY_VALUE.equals(url.getServiceInterface())) {\n+            for (URL u : getSubscribed().keySet()) {\n+                if (UrlUtils.isMatch(url, u)) {\n+                    urls.add(u);\n+                }\n+            }\n+        }\n+        return urls;\n+    }\n+\n+    public MulticastSocket getMulticastSocket() {\n+        return multicastSocket;\n+    }\n+\n+    public Map<URL, Set<URL>> getReceived() {\n+        return received;\n+    }\n+\n+}\n"}
{"instance_id": "apache__dubbo-4026", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/PojoUtils.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/PojoUtils.java\nindex 37aa5ddaa6..64ebc70d43 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/PojoUtils.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/PojoUtils.java\n@@ -1,610 +1,636 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.common.utils;\r\n-\r\n-import org.apache.dubbo.common.logger.Logger;\r\n-import org.apache.dubbo.common.logger.LoggerFactory;\r\n-\r\n-import java.lang.reflect.Array;\r\n-import java.lang.reflect.Constructor;\r\n-import java.lang.reflect.Field;\r\n-import java.lang.reflect.InvocationHandler;\r\n-import java.lang.reflect.InvocationTargetException;\r\n-import java.lang.reflect.Method;\r\n-import java.lang.reflect.Modifier;\r\n-import java.lang.reflect.ParameterizedType;\r\n-import java.lang.reflect.Proxy;\r\n-import java.lang.reflect.Type;\r\n-import java.util.ArrayList;\r\n-import java.util.Collection;\r\n-import java.util.Collections;\r\n-import java.util.HashMap;\r\n-import java.util.HashSet;\r\n-import java.util.Hashtable;\r\n-import java.util.IdentityHashMap;\r\n-import java.util.LinkedHashMap;\r\n-import java.util.List;\r\n-import java.util.Map;\r\n-import java.util.Properties;\r\n-import java.util.TreeMap;\r\n-import java.util.WeakHashMap;\r\n-import java.util.concurrent.ConcurrentHashMap;\r\n-import java.util.concurrent.ConcurrentMap;\r\n-import java.util.concurrent.ConcurrentSkipListMap;\r\n-\r\n-/**\r\n- * PojoUtils. Travel object deeply, and convert complex type to simple type.\r\n- * <p/>\r\n- * Simple type below will be remained:\r\n- * <ul>\r\n- * <li> Primitive Type, also include <b>String</b>, <b>Number</b>(Integer, Long), <b>Date</b>\r\n- * <li> Array of Primitive Type\r\n- * <li> Collection, eg: List, Map, Set etc.\r\n- * </ul>\r\n- * <p/>\r\n- * Other type will be covert to a map which contains the attributes and value pair of object.\r\n- */\r\n-public class PojoUtils {\r\n-\r\n-    private static final Logger logger = LoggerFactory.getLogger(PojoUtils.class);\r\n-    private static final ConcurrentMap<String, Method> NAME_METHODS_CACHE = new ConcurrentHashMap<String, Method>();\r\n-    private static final ConcurrentMap<Class<?>, ConcurrentMap<String, Field>> CLASS_FIELD_CACHE = new ConcurrentHashMap<Class<?>, ConcurrentMap<String, Field>>();\r\n-\r\n-    public static Object[] generalize(Object[] objs) {\r\n-        Object[] dests = new Object[objs.length];\r\n-        for (int i = 0; i < objs.length; i++) {\r\n-            dests[i] = generalize(objs[i]);\r\n-        }\r\n-        return dests;\r\n-    }\r\n-\r\n-    public static Object[] realize(Object[] objs, Class<?>[] types) {\r\n-        if (objs.length != types.length) {\r\n-            throw new IllegalArgumentException(\"args.length != types.length\");\r\n-        }\r\n-\r\n-        Object[] dests = new Object[objs.length];\r\n-        for (int i = 0; i < objs.length; i++) {\r\n-            dests[i] = realize(objs[i], types[i]);\r\n-        }\r\n-\r\n-        return dests;\r\n-    }\r\n-\r\n-    public static Object[] realize(Object[] objs, Class<?>[] types, Type[] gtypes) {\r\n-        if (objs.length != types.length || objs.length != gtypes.length) {\r\n-            throw new IllegalArgumentException(\"args.length != types.length\");\r\n-        }\r\n-        Object[] dests = new Object[objs.length];\r\n-        for (int i = 0; i < objs.length; i++) {\r\n-            dests[i] = realize(objs[i], types[i], gtypes[i]);\r\n-        }\r\n-        return dests;\r\n-    }\r\n-\r\n-    public static Object generalize(Object pojo) {\r\n-        return generalize(pojo, new IdentityHashMap<Object, Object>());\r\n-    }\r\n-\r\n-    @SuppressWarnings(\"unchecked\")\r\n-    private static Object generalize(Object pojo, Map<Object, Object> history) {\r\n-        if (pojo == null) {\r\n-            return null;\r\n-        }\r\n-\r\n-        if (pojo instanceof Enum<?>) {\r\n-            return ((Enum<?>) pojo).name();\r\n-        }\r\n-        if (pojo.getClass().isArray() && Enum.class.isAssignableFrom(pojo.getClass().getComponentType())) {\r\n-            int len = Array.getLength(pojo);\r\n-            String[] values = new String[len];\r\n-            for (int i = 0; i < len; i++) {\r\n-                values[i] = ((Enum<?>) Array.get(pojo, i)).name();\r\n-            }\r\n-            return values;\r\n-        }\r\n-\r\n-        if (ReflectUtils.isPrimitives(pojo.getClass())) {\r\n-            return pojo;\r\n-        }\r\n-\r\n-        if (pojo instanceof Class) {\r\n-            return ((Class) pojo).getName();\r\n-        }\r\n-\r\n-        Object o = history.get(pojo);\r\n-        if (o != null) {\r\n-            return o;\r\n-        }\r\n-        history.put(pojo, pojo);\r\n-\r\n-        if (pojo.getClass().isArray()) {\r\n-            int len = Array.getLength(pojo);\r\n-            Object[] dest = new Object[len];\r\n-            history.put(pojo, dest);\r\n-            for (int i = 0; i < len; i++) {\r\n-                Object obj = Array.get(pojo, i);\r\n-                dest[i] = generalize(obj, history);\r\n-            }\r\n-            return dest;\r\n-        }\r\n-        if (pojo instanceof Collection<?>) {\r\n-            Collection<Object> src = (Collection<Object>) pojo;\r\n-            int len = src.size();\r\n-            Collection<Object> dest = (pojo instanceof List<?>) ? new ArrayList<Object>(len) : new HashSet<Object>(len);\r\n-            history.put(pojo, dest);\r\n-            for (Object obj : src) {\r\n-                dest.add(generalize(obj, history));\r\n-            }\r\n-            return dest;\r\n-        }\r\n-        if (pojo instanceof Map<?, ?>) {\r\n-            Map<Object, Object> src = (Map<Object, Object>) pojo;\r\n-            Map<Object, Object> dest = createMap(src);\r\n-            history.put(pojo, dest);\r\n-            for (Map.Entry<Object, Object> obj : src.entrySet()) {\r\n-                dest.put(generalize(obj.getKey(), history), generalize(obj.getValue(), history));\r\n-            }\r\n-            return dest;\r\n-        }\r\n-        Map<String, Object> map = new HashMap<String, Object>();\r\n-        history.put(pojo, map);\r\n-        map.put(\"class\", pojo.getClass().getName());\r\n-        for (Method method : pojo.getClass().getMethods()) {\r\n-            if (ReflectUtils.isBeanPropertyReadMethod(method)) {\r\n-                try {\r\n-                    map.put(ReflectUtils.getPropertyNameFromBeanReadMethod(method), generalize(method.invoke(pojo), history));\r\n-                } catch (Exception e) {\r\n-                    throw new RuntimeException(e.getMessage(), e);\r\n-                }\r\n-            }\r\n-        }\r\n-        // public field\r\n-        for (Field field : pojo.getClass().getFields()) {\r\n-            if (ReflectUtils.isPublicInstanceField(field)) {\r\n-                try {\r\n-                    Object fieldValue = field.get(pojo);\r\n-                    if (history.containsKey(pojo)) {\r\n-                        Object pojoGeneralizedValue = history.get(pojo);\r\n-                        if (pojoGeneralizedValue instanceof Map\r\n-                                && ((Map) pojoGeneralizedValue).containsKey(field.getName())) {\r\n-                            continue;\r\n-                        }\r\n-                    }\r\n-                    if (fieldValue != null) {\r\n-                        map.put(field.getName(), generalize(fieldValue, history));\r\n-                    }\r\n-                } catch (Exception e) {\r\n-                    throw new RuntimeException(e.getMessage(), e);\r\n-                }\r\n-            }\r\n-        }\r\n-        return map;\r\n-    }\r\n-\r\n-    public static Object realize(Object pojo, Class<?> type) {\r\n-        return realize0(pojo, type, null, new IdentityHashMap<Object, Object>());\r\n-    }\r\n-\r\n-    public static Object realize(Object pojo, Class<?> type, Type genericType) {\r\n-        return realize0(pojo, type, genericType, new IdentityHashMap<Object, Object>());\r\n-    }\r\n-\r\n-    private static class PojoInvocationHandler implements InvocationHandler {\r\n-\r\n-        private Map<Object, Object> map;\r\n-\r\n-        public PojoInvocationHandler(Map<Object, Object> map) {\r\n-            this.map = map;\r\n-        }\r\n-\r\n-        @Override\r\n-        @SuppressWarnings(\"unchecked\")\r\n-        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\r\n-            if (method.getDeclaringClass() == Object.class) {\r\n-                return method.invoke(map, args);\r\n-            }\r\n-            String methodName = method.getName();\r\n-            Object value = null;\r\n-            if (methodName.length() > 3 && methodName.startsWith(\"get\")) {\r\n-                value = map.get(methodName.substring(3, 4).toLowerCase() + methodName.substring(4));\r\n-            } else if (methodName.length() > 2 && methodName.startsWith(\"is\")) {\r\n-                value = map.get(methodName.substring(2, 3).toLowerCase() + methodName.substring(3));\r\n-            } else {\r\n-                value = map.get(methodName.substring(0, 1).toLowerCase() + methodName.substring(1));\r\n-            }\r\n-            if (value instanceof Map<?, ?> && !Map.class.isAssignableFrom(method.getReturnType())) {\r\n-                value = realize0((Map<String, Object>) value, method.getReturnType(), null, new IdentityHashMap<Object, Object>());\r\n-            }\r\n-            return value;\r\n-        }\r\n-    }\r\n-\r\n-    @SuppressWarnings(\"unchecked\")\r\n-    private static Collection<Object> createCollection(Class<?> type, int len) {\r\n-        if (type.isAssignableFrom(ArrayList.class)) {\r\n-            return new ArrayList<Object>(len);\r\n-        }\r\n-        if (type.isAssignableFrom(HashSet.class)) {\r\n-            return new HashSet<Object>(len);\r\n-        }\r\n-        if (!type.isInterface() && !Modifier.isAbstract(type.getModifiers())) {\r\n-            try {\r\n-                return (Collection<Object>) type.newInstance();\r\n-            } catch (Exception e) {\r\n-                // ignore\r\n-            }\r\n-        }\r\n-        return new ArrayList<Object>();\r\n-    }\r\n-\r\n-    private static Map createMap(Map src) {\r\n-        Class<? extends Map> cl = src.getClass();\r\n-        Map result = null;\r\n-        if (HashMap.class == cl) {\r\n-            result = new HashMap();\r\n-        } else if (Hashtable.class == cl) {\r\n-            result = new Hashtable();\r\n-        } else if (IdentityHashMap.class == cl) {\r\n-            result = new IdentityHashMap();\r\n-        } else if (LinkedHashMap.class == cl) {\r\n-            result = new LinkedHashMap();\r\n-        } else if (Properties.class == cl) {\r\n-            result = new Properties();\r\n-        } else if (TreeMap.class == cl) {\r\n-            result = new TreeMap();\r\n-        } else if (WeakHashMap.class == cl) {\r\n-            return new WeakHashMap();\r\n-        } else if (ConcurrentHashMap.class == cl) {\r\n-            result = new ConcurrentHashMap();\r\n-        } else if (ConcurrentSkipListMap.class == cl) {\r\n-            result = new ConcurrentSkipListMap();\r\n-        } else {\r\n-            try {\r\n-                result = cl.newInstance();\r\n-            } catch (Exception e) { /* ignore */ }\r\n-\r\n-            if (result == null) {\r\n-                try {\r\n-                    Constructor<?> constructor = cl.getConstructor(Map.class);\r\n-                    result = (Map) constructor.newInstance(Collections.EMPTY_MAP);\r\n-                } catch (Exception e) { /* ignore */ }\r\n-            }\r\n-        }\r\n-\r\n-        if (result == null) {\r\n-            result = new HashMap<Object, Object>();\r\n-        }\r\n-\r\n-        return result;\r\n-    }\r\n-\r\n-    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\r\n-    private static Object realize0(Object pojo, Class<?> type, Type genericType, final Map<Object, Object> history) {\r\n-        if (pojo == null) {\r\n-            return null;\r\n-        }\r\n-\r\n-        if (type != null && type.isEnum() && pojo.getClass() == String.class) {\r\n-            return Enum.valueOf((Class<Enum>) type, (String) pojo);\r\n-        }\r\n-\r\n-        if (ReflectUtils.isPrimitives(pojo.getClass())\r\n-                && !(type != null && type.isArray()\r\n-                && type.getComponentType().isEnum()\r\n-                && pojo.getClass() == String[].class)) {\r\n-            return CompatibleTypeUtils.compatibleTypeConvert(pojo, type);\r\n-        }\r\n-\r\n-        Object o = history.get(pojo);\r\n-\r\n-        if (o != null) {\r\n-            return o;\r\n-        }\r\n-\r\n-        history.put(pojo, pojo);\r\n-\r\n-        if (pojo.getClass().isArray()) {\r\n-            if (Collection.class.isAssignableFrom(type)) {\r\n-                Class<?> ctype = pojo.getClass().getComponentType();\r\n-                int len = Array.getLength(pojo);\r\n-                Collection dest = createCollection(type, len);\r\n-                history.put(pojo, dest);\r\n-                for (int i = 0; i < len; i++) {\r\n-                    Object obj = Array.get(pojo, i);\r\n-                    Object value = realize0(obj, ctype, null, history);\r\n-                    dest.add(value);\r\n-                }\r\n-                return dest;\r\n-            } else {\r\n-                Class<?> ctype = (type != null && type.isArray() ? type.getComponentType() : pojo.getClass().getComponentType());\r\n-                int len = Array.getLength(pojo);\r\n-                Object dest = Array.newInstance(ctype, len);\r\n-                history.put(pojo, dest);\r\n-                for (int i = 0; i < len; i++) {\r\n-                    Object obj = Array.get(pojo, i);\r\n-                    Object value = realize0(obj, ctype, null, history);\r\n-                    Array.set(dest, i, value);\r\n-                }\r\n-                return dest;\r\n-            }\r\n-        }\r\n-\r\n-        if (pojo instanceof Collection<?>) {\r\n-            if (type.isArray()) {\r\n-                Class<?> ctype = type.getComponentType();\r\n-                Collection<Object> src = (Collection<Object>) pojo;\r\n-                int len = src.size();\r\n-                Object dest = Array.newInstance(ctype, len);\r\n-                history.put(pojo, dest);\r\n-                int i = 0;\r\n-                for (Object obj : src) {\r\n-                    Object value = realize0(obj, ctype, null, history);\r\n-                    Array.set(dest, i, value);\r\n-                    i++;\r\n-                }\r\n-                return dest;\r\n-            } else {\r\n-                Collection<Object> src = (Collection<Object>) pojo;\r\n-                int len = src.size();\r\n-                Collection<Object> dest = createCollection(type, len);\r\n-                history.put(pojo, dest);\r\n-                for (Object obj : src) {\r\n-                    Type keyType = getGenericClassByIndex(genericType, 0);\r\n-                    Class<?> keyClazz = obj.getClass();\r\n-                    if (keyType instanceof Class) {\r\n-                        keyClazz = (Class<?>) keyType;\r\n-                    }\r\n-                    Object value = realize0(obj, keyClazz, keyType, history);\r\n-                    dest.add(value);\r\n-                }\r\n-                return dest;\r\n-            }\r\n-        }\r\n-\r\n-        if (pojo instanceof Map<?, ?> && type != null) {\r\n-            Object className = ((Map<Object, Object>) pojo).get(\"class\");\r\n-            if (className instanceof String) {\r\n-                try {\r\n-                    type = ClassUtils.forName((String) className);\r\n-                } catch (ClassNotFoundException e) {\r\n-                    // ignore\r\n-                }\r\n-            }\r\n-\r\n-            // special logic for enum\r\n-            if (type.isEnum()) {\r\n-                Object name = ((Map<Object, Object>) pojo).get(\"name\");\r\n-                if (name != null) {\r\n-                    return Enum.valueOf((Class<Enum>) type, name.toString());\r\n-                }\r\n-            }\r\n-            Map<Object, Object> map;\r\n-            // when return type is not the subclass of return type from the signature and not an interface\r\n-            if (!type.isInterface() && !type.isAssignableFrom(pojo.getClass())) {\r\n-                try {\r\n-                    map = (Map<Object, Object>) type.newInstance();\r\n-                    Map<Object, Object> mapPojo = (Map<Object, Object>) pojo;\r\n-                    map.putAll(mapPojo);\r\n-                    map.remove(\"class\");\r\n-                } catch (Exception e) {\r\n-                    //ignore error\r\n-                    map = (Map<Object, Object>) pojo;\r\n-                }\r\n-            } else {\r\n-                map = (Map<Object, Object>) pojo;\r\n-            }\r\n-\r\n-            if (Map.class.isAssignableFrom(type) || type == Object.class) {\r\n-                final Map<Object, Object> result = createMap(map);\r\n-                history.put(pojo, result);\r\n-                for (Map.Entry<Object, Object> entry : map.entrySet()) {\r\n-                    Type keyType = getGenericClassByIndex(genericType, 0);\r\n-                    Type valueType = getGenericClassByIndex(genericType, 1);\r\n-                    Class<?> keyClazz;\r\n-                    if (keyType instanceof Class) {\r\n-                        keyClazz = (Class<?>) keyType;\r\n-                    } else if (keyType instanceof ParameterizedType) {\r\n-                        keyClazz = (Class<?>) ((ParameterizedType) keyType).getRawType();\r\n-                    } else {\r\n-                        keyClazz = entry.getKey() == null ? null : entry.getKey().getClass();\r\n-                    }\r\n-                    Class<?> valueClazz;\r\n-                    if (valueType instanceof Class) {\r\n-                        valueClazz = (Class<?>) valueType;\r\n-                    } else if (valueType instanceof ParameterizedType) {\r\n-                        valueClazz = (Class<?>) ((ParameterizedType) valueType).getRawType();\r\n-                    } else {\r\n-                        valueClazz = entry.getValue() == null ? null : entry.getValue().getClass();\r\n-                    }\r\n-\r\n-                    Object key = keyClazz == null ? entry.getKey() : realize0(entry.getKey(), keyClazz, keyType, history);\r\n-                    Object value = valueClazz == null ? entry.getValue() : realize0(entry.getValue(), valueClazz, valueType, history);\r\n-                    result.put(key, value);\r\n-                }\r\n-                return result;\r\n-            } else if (type.isInterface()) {\r\n-                Object dest = Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), new Class<?>[]{type}, new PojoInvocationHandler(map));\r\n-                history.put(pojo, dest);\r\n-                return dest;\r\n-            } else {\r\n-                Object dest = newInstance(type);\r\n-                history.put(pojo, dest);\r\n-                for (Map.Entry<Object, Object> entry : map.entrySet()) {\r\n-                    Object key = entry.getKey();\r\n-                    if (key instanceof String) {\r\n-                        String name = (String) key;\r\n-                        Object value = entry.getValue();\r\n-                        if (value != null) {\r\n-                            Method method = getSetterMethod(dest.getClass(), name, value.getClass());\r\n-                            Field field = getField(dest.getClass(), name);\r\n-                            if (method != null) {\r\n-                                if (!method.isAccessible()) {\r\n-                                    method.setAccessible(true);\r\n-                                }\r\n-                                Type ptype = method.getGenericParameterTypes()[0];\r\n-                                value = realize0(value, method.getParameterTypes()[0], ptype, history);\r\n-                                try {\r\n-                                    method.invoke(dest, value);\r\n-                                } catch (Exception e) {\r\n-                                    String exceptionDescription = \"Failed to set pojo \" + dest.getClass().getSimpleName() + \" property \" + name\r\n-                                            + \" value \" + value + \"(\" + value.getClass() + \"), cause: \" + e.getMessage();\r\n-                                    logger.error(exceptionDescription, e);\r\n-                                    throw new RuntimeException(exceptionDescription, e);\r\n-                                }\r\n-                            } else if (field != null) {\r\n-                                value = realize0(value, field.getType(), field.getGenericType(), history);\r\n-                                try {\r\n-                                    field.set(dest, value);\r\n-                                } catch (IllegalAccessException e) {\r\n-                                    throw new RuntimeException(\"Failed to set field \" + name + \" of pojo \" + dest.getClass().getName() + \" : \" + e.getMessage(), e);\r\n-                                }\r\n-                            }\r\n-                        }\r\n-                    }\r\n-                }\r\n-                if (dest instanceof Throwable) {\r\n-                    Object message = map.get(\"message\");\r\n-                    if (message instanceof String) {\r\n-                        try {\r\n-                            Field field = Throwable.class.getDeclaredField(\"detailMessage\");\r\n-                            if (!field.isAccessible()) {\r\n-                                field.setAccessible(true);\r\n-                            }\r\n-                            field.set(dest, message);\r\n-                        } catch (Exception e) {\r\n-                        }\r\n-                    }\r\n-                }\r\n-                return dest;\r\n-            }\r\n-        }\r\n-        return pojo;\r\n-    }\r\n-\r\n-    /**\r\n-     * Get parameterized type\r\n-     *\r\n-     * @param genericType generic type\r\n-     * @param index       index of the target parameterized type\r\n-     * @return Return Person.class for List<Person>, return Person.class for Map<String, Person> when index=0\r\n-     */\r\n-    private static Type getGenericClassByIndex(Type genericType, int index) {\r\n-        Type clazz = null;\r\n-        // find parameterized type\r\n-        if (genericType instanceof ParameterizedType) {\r\n-            ParameterizedType t = (ParameterizedType) genericType;\r\n-            Type[] types = t.getActualTypeArguments();\r\n-            clazz = types[index];\r\n-        }\r\n-        return clazz;\r\n-    }\r\n-\r\n-    private static Object newInstance(Class<?> cls) {\r\n-        try {\r\n-            return cls.newInstance();\r\n-        } catch (Throwable t) {\r\n-            try {\r\n-                Constructor<?>[] constructors = cls.getDeclaredConstructors();\r\n-                /**\r\n-                 * From Javadoc java.lang.Class#getDeclaredConstructors\r\n-                 * This method returns an array of Constructor objects reflecting all the constructors\r\n-                 * declared by the class represented by this Class object.\r\n-                 * This method returns an array of length 0,\r\n-                 * if this Class object represents an interface, a primitive type, an array class, or void.\r\n-                 */\r\n-                if (constructors.length == 0) {\r\n-                    throw new RuntimeException(\"Illegal constructor: \" + cls.getName());\r\n-                }\r\n-                Constructor<?> constructor = constructors[0];\r\n-                if (constructor.getParameterTypes().length > 0) {\r\n-                    for (Constructor<?> c : constructors) {\r\n-                        if (c.getParameterTypes().length < constructor.getParameterTypes().length) {\r\n-                            constructor = c;\r\n-                            if (constructor.getParameterTypes().length == 0) {\r\n-                                break;\r\n-                            }\r\n-                        }\r\n-                    }\r\n-                }\r\n-                constructor.setAccessible(true);\r\n-                return constructor.newInstance(new Object[constructor.getParameterTypes().length]);\r\n-            } catch (InstantiationException e) {\r\n-                throw new RuntimeException(e.getMessage(), e);\r\n-            } catch (IllegalAccessException e) {\r\n-                throw new RuntimeException(e.getMessage(), e);\r\n-            } catch (InvocationTargetException e) {\r\n-                throw new RuntimeException(e.getMessage(), e);\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    private static Method getSetterMethod(Class<?> cls, String property, Class<?> valueCls) {\r\n-        String name = \"set\" + property.substring(0, 1).toUpperCase() + property.substring(1);\r\n-        Method method = NAME_METHODS_CACHE.get(cls.getName() + \".\" + name + \"(\" + valueCls.getName() + \")\");\r\n-        if (method == null) {\r\n-            try {\r\n-                method = cls.getMethod(name, valueCls);\r\n-            } catch (NoSuchMethodException e) {\r\n-                for (Method m : cls.getMethods()) {\r\n-                    if (ReflectUtils.isBeanPropertyWriteMethod(m) && m.getName().equals(name)) {\r\n-                        method = m;\r\n-                    }\r\n-                }\r\n-            }\r\n-            if (method != null) {\r\n-                NAME_METHODS_CACHE.put(cls.getName() + \".\" + name + \"(\" + valueCls.getName() + \")\", method);\r\n-            }\r\n-        }\r\n-        return method;\r\n-    }\r\n-\r\n-    private static Field getField(Class<?> cls, String fieldName) {\r\n-        Field result = null;\r\n-        if (CLASS_FIELD_CACHE.containsKey(cls) && CLASS_FIELD_CACHE.get(cls).containsKey(fieldName)) {\r\n-            return CLASS_FIELD_CACHE.get(cls).get(fieldName);\r\n-        }\r\n-        try {\r\n-            result = cls.getDeclaredField(fieldName);\r\n-            result.setAccessible(true);\r\n-        } catch (NoSuchFieldException e) {\r\n-            for (Field field : cls.getFields()) {\r\n-                if (fieldName.equals(field.getName()) && ReflectUtils.isPublicInstanceField(field)) {\r\n-                    result = field;\r\n-                    break;\r\n-                }\r\n-            }\r\n-        }\r\n-        if (result != null) {\r\n-            ConcurrentMap<String, Field> fields = CLASS_FIELD_CACHE.get(cls);\r\n-            if (fields == null) {\r\n-                fields = new ConcurrentHashMap<String, Field>();\r\n-                CLASS_FIELD_CACHE.putIfAbsent(cls, fields);\r\n-            }\r\n-            fields = CLASS_FIELD_CACHE.get(cls);\r\n-            fields.putIfAbsent(fieldName, result);\r\n-        }\r\n-        return result;\r\n-    }\r\n-\r\n-    public static boolean isPojo(Class<?> cls) {\r\n-        return !ReflectUtils.isPrimitives(cls)\r\n-                && !Collection.class.isAssignableFrom(cls)\r\n-                && !Map.class.isAssignableFrom(cls);\r\n-    }\r\n-\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.common.utils;\n+\n+import org.apache.dubbo.common.logger.Logger;\n+import org.apache.dubbo.common.logger.LoggerFactory;\n+\n+import java.lang.reflect.Array;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.InvocationHandler;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.ParameterizedType;\n+import java.lang.reflect.Proxy;\n+import java.lang.reflect.Type;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Hashtable;\n+import java.util.IdentityHashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.TreeMap;\n+import java.util.WeakHashMap;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+/**\n+ * PojoUtils. Travel object deeply, and convert complex type to simple type.\n+ * <p/>\n+ * Simple type below will be remained:\n+ * <ul>\n+ * <li> Primitive Type, also include <b>String</b>, <b>Number</b>(Integer, Long), <b>Date</b>\n+ * <li> Array of Primitive Type\n+ * <li> Collection, eg: List, Map, Set etc.\n+ * </ul>\n+ * <p/>\n+ * Other type will be covert to a map which contains the attributes and value pair of object.\n+ */\n+public class PojoUtils {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(PojoUtils.class);\n+    private static final ConcurrentMap<String, Method> NAME_METHODS_CACHE = new ConcurrentHashMap<String, Method>();\n+    private static final ConcurrentMap<Class<?>, ConcurrentMap<String, Field>> CLASS_FIELD_CACHE = new ConcurrentHashMap<Class<?>, ConcurrentMap<String, Field>>();\n+\n+    public static Object[] generalize(Object[] objs) {\n+        Object[] dests = new Object[objs.length];\n+        for (int i = 0; i < objs.length; i++) {\n+            dests[i] = generalize(objs[i]);\n+        }\n+        return dests;\n+    }\n+\n+    public static Object[] realize(Object[] objs, Class<?>[] types) {\n+        if (objs.length != types.length) {\n+            throw new IllegalArgumentException(\"args.length != types.length\");\n+        }\n+\n+        Object[] dests = new Object[objs.length];\n+        for (int i = 0; i < objs.length; i++) {\n+            dests[i] = realize(objs[i], types[i]);\n+        }\n+\n+        return dests;\n+    }\n+\n+    public static Object[] realize(Object[] objs, Class<?>[] types, Type[] gtypes) {\n+        if (objs.length != types.length || objs.length != gtypes.length) {\n+            throw new IllegalArgumentException(\"args.length != types.length\");\n+        }\n+        Object[] dests = new Object[objs.length];\n+        for (int i = 0; i < objs.length; i++) {\n+            dests[i] = realize(objs[i], types[i], gtypes[i]);\n+        }\n+        return dests;\n+    }\n+\n+    public static Object generalize(Object pojo) {\n+        return generalize(pojo, new IdentityHashMap<Object, Object>());\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static Object generalize(Object pojo, Map<Object, Object> history) {\n+        if (pojo == null) {\n+            return null;\n+        }\n+\n+        if (pojo instanceof Enum<?>) {\n+            return ((Enum<?>) pojo).name();\n+        }\n+        if (pojo.getClass().isArray() && Enum.class.isAssignableFrom(pojo.getClass().getComponentType())) {\n+            int len = Array.getLength(pojo);\n+            String[] values = new String[len];\n+            for (int i = 0; i < len; i++) {\n+                values[i] = ((Enum<?>) Array.get(pojo, i)).name();\n+            }\n+            return values;\n+        }\n+\n+        if (ReflectUtils.isPrimitives(pojo.getClass())) {\n+            return pojo;\n+        }\n+\n+        if (pojo instanceof Class) {\n+            return ((Class) pojo).getName();\n+        }\n+\n+        Object o = history.get(pojo);\n+        if (o != null) {\n+            return o;\n+        }\n+        history.put(pojo, pojo);\n+\n+        if (pojo.getClass().isArray()) {\n+            int len = Array.getLength(pojo);\n+            Object[] dest = new Object[len];\n+            history.put(pojo, dest);\n+            for (int i = 0; i < len; i++) {\n+                Object obj = Array.get(pojo, i);\n+                dest[i] = generalize(obj, history);\n+            }\n+            return dest;\n+        }\n+        if (pojo instanceof Collection<?>) {\n+            Collection<Object> src = (Collection<Object>) pojo;\n+            int len = src.size();\n+            Collection<Object> dest = (pojo instanceof List<?>) ? new ArrayList<Object>(len) : new HashSet<Object>(len);\n+            history.put(pojo, dest);\n+            for (Object obj : src) {\n+                dest.add(generalize(obj, history));\n+            }\n+            return dest;\n+        }\n+        if (pojo instanceof Map<?, ?>) {\n+            Map<Object, Object> src = (Map<Object, Object>) pojo;\n+            Map<Object, Object> dest = createMap(src);\n+            history.put(pojo, dest);\n+            for (Map.Entry<Object, Object> obj : src.entrySet()) {\n+                dest.put(generalize(obj.getKey(), history), generalize(obj.getValue(), history));\n+            }\n+            return dest;\n+        }\n+        Map<String, Object> map = new HashMap<String, Object>();\n+        history.put(pojo, map);\n+        map.put(\"class\", pojo.getClass().getName());\n+        for (Method method : pojo.getClass().getMethods()) {\n+            if (ReflectUtils.isBeanPropertyReadMethod(method)) {\n+                try {\n+                    map.put(ReflectUtils.getPropertyNameFromBeanReadMethod(method), generalize(method.invoke(pojo), history));\n+                } catch (Exception e) {\n+                    throw new RuntimeException(e.getMessage(), e);\n+                }\n+            }\n+        }\n+        // public field\n+        for (Field field : pojo.getClass().getFields()) {\n+            if (ReflectUtils.isPublicInstanceField(field)) {\n+                try {\n+                    Object fieldValue = field.get(pojo);\n+                    if (history.containsKey(pojo)) {\n+                        Object pojoGeneralizedValue = history.get(pojo);\n+                        if (pojoGeneralizedValue instanceof Map\n+                                && ((Map) pojoGeneralizedValue).containsKey(field.getName())) {\n+                            continue;\n+                        }\n+                    }\n+                    if (fieldValue != null) {\n+                        map.put(field.getName(), generalize(fieldValue, history));\n+                    }\n+                } catch (Exception e) {\n+                    throw new RuntimeException(e.getMessage(), e);\n+                }\n+            }\n+        }\n+        return map;\n+    }\n+\n+    public static Object realize(Object pojo, Class<?> type) {\n+        return realize0(pojo, type, null, new IdentityHashMap<Object, Object>());\n+    }\n+\n+    public static Object realize(Object pojo, Class<?> type, Type genericType) {\n+        return realize0(pojo, type, genericType, new IdentityHashMap<Object, Object>());\n+    }\n+\n+    private static class PojoInvocationHandler implements InvocationHandler {\n+\n+        private Map<Object, Object> map;\n+\n+        public PojoInvocationHandler(Map<Object, Object> map) {\n+            this.map = map;\n+        }\n+\n+        @Override\n+        @SuppressWarnings(\"unchecked\")\n+        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n+            if (method.getDeclaringClass() == Object.class) {\n+                return method.invoke(map, args);\n+            }\n+            String methodName = method.getName();\n+            Object value = null;\n+            if (methodName.length() > 3 && methodName.startsWith(\"get\")) {\n+                value = map.get(methodName.substring(3, 4).toLowerCase() + methodName.substring(4));\n+            } else if (methodName.length() > 2 && methodName.startsWith(\"is\")) {\n+                value = map.get(methodName.substring(2, 3).toLowerCase() + methodName.substring(3));\n+            } else {\n+                value = map.get(methodName.substring(0, 1).toLowerCase() + methodName.substring(1));\n+            }\n+            if (value instanceof Map<?, ?> && !Map.class.isAssignableFrom(method.getReturnType())) {\n+                value = realize0((Map<String, Object>) value, method.getReturnType(), null, new IdentityHashMap<Object, Object>());\n+            }\n+            return value;\n+        }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static Collection<Object> createCollection(Class<?> type, int len) {\n+        if (type.isAssignableFrom(ArrayList.class)) {\n+            return new ArrayList<Object>(len);\n+        }\n+        if (type.isAssignableFrom(HashSet.class)) {\n+            return new HashSet<Object>(len);\n+        }\n+        if (!type.isInterface() && !Modifier.isAbstract(type.getModifiers())) {\n+            try {\n+                return (Collection<Object>) type.newInstance();\n+            } catch (Exception e) {\n+                // ignore\n+            }\n+        }\n+        return new ArrayList<Object>();\n+    }\n+\n+    private static Map createMap(Map src) {\n+        Class<? extends Map> cl = src.getClass();\n+        Map result = null;\n+        if (HashMap.class == cl) {\n+            result = new HashMap();\n+        } else if (Hashtable.class == cl) {\n+            result = new Hashtable();\n+        } else if (IdentityHashMap.class == cl) {\n+            result = new IdentityHashMap();\n+        } else if (LinkedHashMap.class == cl) {\n+            result = new LinkedHashMap();\n+        } else if (Properties.class == cl) {\n+            result = new Properties();\n+        } else if (TreeMap.class == cl) {\n+            result = new TreeMap();\n+        } else if (WeakHashMap.class == cl) {\n+            return new WeakHashMap();\n+        } else if (ConcurrentHashMap.class == cl) {\n+            result = new ConcurrentHashMap();\n+        } else if (ConcurrentSkipListMap.class == cl) {\n+            result = new ConcurrentSkipListMap();\n+        } else {\n+            try {\n+                result = cl.newInstance();\n+            } catch (Exception e) { /* ignore */ }\n+\n+            if (result == null) {\n+                try {\n+                    Constructor<?> constructor = cl.getConstructor(Map.class);\n+                    result = (Map) constructor.newInstance(Collections.EMPTY_MAP);\n+                } catch (Exception e) { /* ignore */ }\n+            }\n+        }\n+\n+        if (result == null) {\n+            result = new HashMap<Object, Object>();\n+        }\n+\n+        return result;\n+    }\n+\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    private static Object realize0(Object pojo, Class<?> type, Type genericType, final Map<Object, Object> history) {\n+        if (pojo == null) {\n+            return null;\n+        }\n+\n+        if (type != null && type.isEnum() && pojo.getClass() == String.class) {\n+            return Enum.valueOf((Class<Enum>) type, (String) pojo);\n+        }\n+\n+        if (ReflectUtils.isPrimitives(pojo.getClass())\n+                && !(type != null && type.isArray()\n+                && type.getComponentType().isEnum()\n+                && pojo.getClass() == String[].class)) {\n+            return CompatibleTypeUtils.compatibleTypeConvert(pojo, type);\n+        }\n+\n+        Object o = history.get(pojo);\n+\n+        if (o != null) {\n+            return o;\n+        }\n+\n+        history.put(pojo, pojo);\n+\n+        if (pojo.getClass().isArray()) {\n+            if (Collection.class.isAssignableFrom(type)) {\n+                Class<?> ctype = pojo.getClass().getComponentType();\n+                int len = Array.getLength(pojo);\n+                Collection dest = createCollection(type, len);\n+                history.put(pojo, dest);\n+                for (int i = 0; i < len; i++) {\n+                    Object obj = Array.get(pojo, i);\n+                    Object value = realize0(obj, ctype, null, history);\n+                    dest.add(value);\n+                }\n+                return dest;\n+            } else {\n+                Class<?> ctype = (type != null && type.isArray() ? type.getComponentType() : pojo.getClass().getComponentType());\n+                int len = Array.getLength(pojo);\n+                Object dest = Array.newInstance(ctype, len);\n+                history.put(pojo, dest);\n+                for (int i = 0; i < len; i++) {\n+                    Object obj = Array.get(pojo, i);\n+                    Object value = realize0(obj, ctype, null, history);\n+                    Array.set(dest, i, value);\n+                }\n+                return dest;\n+            }\n+        }\n+\n+        if (pojo instanceof Collection<?>) {\n+            if (type.isArray()) {\n+                Class<?> ctype = type.getComponentType();\n+                Collection<Object> src = (Collection<Object>) pojo;\n+                int len = src.size();\n+                Object dest = Array.newInstance(ctype, len);\n+                history.put(pojo, dest);\n+                int i = 0;\n+                for (Object obj : src) {\n+                    Object value = realize0(obj, ctype, null, history);\n+                    Array.set(dest, i, value);\n+                    i++;\n+                }\n+                return dest;\n+            } else {\n+                Collection<Object> src = (Collection<Object>) pojo;\n+                int len = src.size();\n+                Collection<Object> dest = createCollection(type, len);\n+                history.put(pojo, dest);\n+                for (Object obj : src) {\n+                    Type keyType = getGenericClassByIndex(genericType, 0);\n+                    Class<?> keyClazz = obj.getClass();\n+                    if (keyType instanceof Class) {\n+                        keyClazz = (Class<?>) keyType;\n+                    }\n+                    Object value = realize0(obj, keyClazz, keyType, history);\n+                    dest.add(value);\n+                }\n+                return dest;\n+            }\n+        }\n+\n+        if (pojo instanceof Map<?, ?> && type != null) {\n+            Object className = ((Map<Object, Object>) pojo).get(\"class\");\n+            if (className instanceof String) {\n+                try {\n+                    type = ClassUtils.forName((String) className);\n+                } catch (ClassNotFoundException e) {\n+                    // ignore\n+                }\n+            }\n+\n+            // special logic for enum\n+            if (type.isEnum()) {\n+                Object name = ((Map<Object, Object>) pojo).get(\"name\");\n+                if (name != null) {\n+                    return Enum.valueOf((Class<Enum>) type, name.toString());\n+                }\n+            }\n+            Map<Object, Object> map;\n+            // when return type is not the subclass of return type from the signature and not an interface\n+            if (!type.isInterface() && !type.isAssignableFrom(pojo.getClass())) {\n+                try {\n+                    map = (Map<Object, Object>) type.newInstance();\n+                    Map<Object, Object> mapPojo = (Map<Object, Object>) pojo;\n+                    map.putAll(mapPojo);\n+                    map.remove(\"class\");\n+                } catch (Exception e) {\n+                    //ignore error\n+                    map = (Map<Object, Object>) pojo;\n+                }\n+            } else {\n+                map = (Map<Object, Object>) pojo;\n+            }\n+\n+            if (Map.class.isAssignableFrom(type) || type == Object.class) {\n+                final Map<Object, Object> result = createMap(map);\n+                history.put(pojo, result);\n+                for (Map.Entry<Object, Object> entry : map.entrySet()) {\n+                    Type keyType = getGenericClassByIndex(genericType, 0);\n+                    Type valueType = getGenericClassByIndex(genericType, 1);\n+                    Class<?> keyClazz;\n+                    if (keyType instanceof Class) {\n+                        keyClazz = (Class<?>) keyType;\n+                    } else if (keyType instanceof ParameterizedType) {\n+                        keyClazz = (Class<?>) ((ParameterizedType) keyType).getRawType();\n+                    } else {\n+                        keyClazz = entry.getKey() == null ? null : entry.getKey().getClass();\n+                    }\n+                    Class<?> valueClazz;\n+                    if (valueType instanceof Class) {\n+                        valueClazz = (Class<?>) valueType;\n+                    } else if (valueType instanceof ParameterizedType) {\n+                        valueClazz = (Class<?>) ((ParameterizedType) valueType).getRawType();\n+                    } else {\n+                        valueClazz = entry.getValue() == null ? null : entry.getValue().getClass();\n+                    }\n+\n+                    Object key = keyClazz == null ? entry.getKey() : realize0(entry.getKey(), keyClazz, keyType, history);\n+                    Object value = valueClazz == null ? entry.getValue() : realize0(entry.getValue(), valueClazz, valueType, history);\n+                    result.put(key, value);\n+                }\n+                return result;\n+            } else if (type.isInterface()) {\n+                Object dest = Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), new Class<?>[]{type}, new PojoInvocationHandler(map));\n+                history.put(pojo, dest);\n+                return dest;\n+            } else {\n+                Object dest = newInstance(type);\n+                history.put(pojo, dest);\n+                for (Map.Entry<Object, Object> entry : map.entrySet()) {\n+                    Object key = entry.getKey();\n+                    if (key instanceof String) {\n+                        String name = (String) key;\n+                        Object value = entry.getValue();\n+                        if (value != null) {\n+                            Method method = getSetterMethod(dest.getClass(), name, value.getClass());\n+                            Field field = getField(dest.getClass(), name);\n+                            if (method != null) {\n+                                if (!method.isAccessible()) {\n+                                    method.setAccessible(true);\n+                                }\n+                                Type ptype = method.getGenericParameterTypes()[0];\n+                                value = realize0(value, method.getParameterTypes()[0], ptype, history);\n+                                try {\n+                                    method.invoke(dest, value);\n+                                } catch (Exception e) {\n+                                    String exceptionDescription = \"Failed to set pojo \" + dest.getClass().getSimpleName() + \" property \" + name\n+                                            + \" value \" + value + \"(\" + value.getClass() + \"), cause: \" + e.getMessage();\n+                                    logger.error(exceptionDescription, e);\n+                                    throw new RuntimeException(exceptionDescription, e);\n+                                }\n+                            } else if (field != null) {\n+                                value = realize0(value, field.getType(), field.getGenericType(), history);\n+                                try {\n+                                    field.set(dest, value);\n+                                } catch (IllegalAccessException e) {\n+                                    throw new RuntimeException(\"Failed to set field \" + name + \" of pojo \" + dest.getClass().getName() + \" : \" + e.getMessage(), e);\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+                if (dest instanceof Throwable) {\n+                    Object message = map.get(\"message\");\n+                    if (message instanceof String) {\n+                        try {\n+                            Field field = Throwable.class.getDeclaredField(\"detailMessage\");\n+                            if (!field.isAccessible()) {\n+                                field.setAccessible(true);\n+                            }\n+                            field.set(dest, message);\n+                        } catch (Exception e) {\n+                        }\n+                    }\n+                }\n+                return dest;\n+            }\n+        }\n+        return pojo;\n+    }\n+\n+    /**\n+     * Get parameterized type\n+     *\n+     * @param genericType generic type\n+     * @param index       index of the target parameterized type\n+     * @return Return Person.class for List<Person>, return Person.class for Map<String, Person> when index=0\n+     */\n+    private static Type getGenericClassByIndex(Type genericType, int index) {\n+        Type clazz = null;\n+        // find parameterized type\n+        if (genericType instanceof ParameterizedType) {\n+            ParameterizedType t = (ParameterizedType) genericType;\n+            Type[] types = t.getActualTypeArguments();\n+            clazz = types[index];\n+        }\n+        return clazz;\n+    }\n+\n+    private static Object newInstance(Class<?> cls) {\n+        try {\n+            return cls.newInstance();\n+        } catch (Throwable t) {\n+            try {\n+                Constructor<?>[] constructors = cls.getDeclaredConstructors();\n+                /**\n+                 * From Javadoc java.lang.Class#getDeclaredConstructors\n+                 * This method returns an array of Constructor objects reflecting all the constructors\n+                 * declared by the class represented by this Class object.\n+                 * This method returns an array of length 0,\n+                 * if this Class object represents an interface, a primitive type, an array class, or void.\n+                 */\n+                if (constructors.length == 0) {\n+                    throw new RuntimeException(\"Illegal constructor: \" + cls.getName());\n+                }\n+                Constructor<?> constructor = constructors[0];\n+                if (constructor.getParameterTypes().length > 0) {\n+                    for (Constructor<?> c : constructors) {\n+                        if (c.getParameterTypes().length < constructor.getParameterTypes().length) {\n+                            constructor = c;\n+                            if (constructor.getParameterTypes().length == 0) {\n+                                break;\n+                            }\n+                        }\n+                    }\n+                }\n+                constructor.setAccessible(true);\n+                Class<?>[] parameterTypes = constructor.getParameterTypes();\n+                Object[] parameters = new Object[parameterTypes.length];\n+                for (int i = 0; i < parameterTypes.length; i++) {\n+                    parameters[i] = getDefaultValue(parameterTypes[i]);\n+                }\n+                return constructor.newInstance(parameters);\n+            } catch (InstantiationException e) {\n+                throw new RuntimeException(e.getMessage(), e);\n+            } catch (IllegalAccessException e) {\n+                throw new RuntimeException(e.getMessage(), e);\n+            } catch (InvocationTargetException e) {\n+                throw new RuntimeException(e.getMessage(), e);\n+            }\n+        }\n+    }\n+\n+    private static Object getDefaultValue(Class<?> parameterType) {\n+        if (parameterType == byte.class) {\n+            return (byte) 0;\n+        } else if (parameterType == short.class) {\n+            return (short) 0;\n+        } else if (parameterType == int.class) {\n+            return 0;\n+        } else if (parameterType == long.class) {\n+            return 0L;\n+        } else if (parameterType == float.class) {\n+            return 0F;\n+        } else if (parameterType == double.class) {\n+            return 0D;\n+        } else if (parameterType == char.class) {\n+            return (char) 0;\n+        } else if (parameterType == boolean.class) {\n+            return false;\n+        }\n+        return null;\n+    }\n+\n+    private static Method getSetterMethod(Class<?> cls, String property, Class<?> valueCls) {\n+        String name = \"set\" + property.substring(0, 1).toUpperCase() + property.substring(1);\n+        Method method = NAME_METHODS_CACHE.get(cls.getName() + \".\" + name + \"(\" + valueCls.getName() + \")\");\n+        if (method == null) {\n+            try {\n+                method = cls.getMethod(name, valueCls);\n+            } catch (NoSuchMethodException e) {\n+                for (Method m : cls.getMethods()) {\n+                    if (ReflectUtils.isBeanPropertyWriteMethod(m) && m.getName().equals(name)) {\n+                        method = m;\n+                    }\n+                }\n+            }\n+            if (method != null) {\n+                NAME_METHODS_CACHE.put(cls.getName() + \".\" + name + \"(\" + valueCls.getName() + \")\", method);\n+            }\n+        }\n+        return method;\n+    }\n+\n+    private static Field getField(Class<?> cls, String fieldName) {\n+        Field result = null;\n+        if (CLASS_FIELD_CACHE.containsKey(cls) && CLASS_FIELD_CACHE.get(cls).containsKey(fieldName)) {\n+            return CLASS_FIELD_CACHE.get(cls).get(fieldName);\n+        }\n+        try {\n+            result = cls.getDeclaredField(fieldName);\n+            result.setAccessible(true);\n+        } catch (NoSuchFieldException e) {\n+            for (Field field : cls.getFields()) {\n+                if (fieldName.equals(field.getName()) && ReflectUtils.isPublicInstanceField(field)) {\n+                    result = field;\n+                    break;\n+                }\n+            }\n+        }\n+        if (result != null) {\n+            ConcurrentMap<String, Field> fields = CLASS_FIELD_CACHE.get(cls);\n+            if (fields == null) {\n+                fields = new ConcurrentHashMap<String, Field>();\n+                CLASS_FIELD_CACHE.putIfAbsent(cls, fields);\n+            }\n+            fields = CLASS_FIELD_CACHE.get(cls);\n+            fields.putIfAbsent(fieldName, result);\n+        }\n+        return result;\n+    }\n+\n+    public static boolean isPojo(Class<?> cls) {\n+        return !ReflectUtils.isPrimitives(cls)\n+                && !Collection.class.isAssignableFrom(cls)\n+                && !Map.class.isAssignableFrom(cls);\n+    }\n+\n+}\n"}
{"instance_id": "Significant-Gravitas__AutoGPT-4652", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/autogpt/commands/file_operations.py b/autogpt/commands/file_operations.py\nindex 5d9649be5..be9e64c50 100644\n--- a/autogpt/commands/file_operations.py\n+++ b/autogpt/commands/file_operations.py\n@@ -22,6 +22,9 @@ from autogpt.utils import readable_file_size\n \n Operation = Literal[\"write\", \"append\", \"delete\"]\n \n+# Maximum number of files to return from list_files to avoid exceeding token limits\n+FILE_LISTING_LIMIT = 100\n+\n \n def text_checksum(text: str) -> str:\n     \"\"\"Get the hex checksum for the given text.\"\"\"\n@@ -359,6 +362,11 @@ def list_files(directory: str, agent: Agent) -> list[str]:\n                 os.path.join(root, file), agent.config.workspace_path\n             )\n             found_files.append(relative_path)\n+            if len(found_files) >= FILE_LISTING_LIMIT:\n+                found_files.append(\n+                    f\"... (File listing truncated. {FILE_LISTING_LIMIT} files shown.)\"\n+                )\n+                return found_files\n \n     return found_files\n \n"}
{"instance_id": "apache__dubbo-3855", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/support/RpcUtils.java b/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/support/RpcUtils.java\nindex 5e9e74a9a6..fb6c311ac5 100644\n--- a/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/support/RpcUtils.java\n+++ b/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/support/RpcUtils.java\n@@ -165,8 +165,9 @@ public class RpcUtils {\n             }\n         }\n \n-        if (Boolean.TRUE.toString().equals(inv.getAttachment(ASYNC_KEY))) {\n-            isAsync = true;\n+        String value = inv.getAttachment(ASYNC_KEY);\n+        if (value != null) {\n+            isAsync = Boolean.TRUE.toString().equals(value);\n         } else {\n             isAsync = url.getMethodParameter(getMethodName(inv), ASYNC_KEY, false);\n         }\n@@ -216,8 +217,9 @@ public class RpcUtils {\n \n     public static boolean isOneway(URL url, Invocation inv) {\n         boolean isOneway;\n-        if (Boolean.FALSE.toString().equals(inv.getAttachment(RETURN_KEY))) {\n-            isOneway = true;\n+        String value = inv.getAttachment(RETURN_KEY);\n+        if (value != null) {\n+            isOneway = !Boolean.parseBoolean(value);\n         } else {\n             isOneway = !url.getMethodParameter(getMethodName(inv), RETURN_KEY, true);\n         }\n"}
{"instance_id": "apache__dubbo-4567", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/Version.java b/dubbo-common/src/main/java/org/apache/dubbo/common/Version.java\nindex a015b44e9e..b67d32caac 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/Version.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/Version.java\n@@ -100,7 +100,7 @@ public final class Version {\n         // for previous dubbo version(2.0.10/020010~2.6.2/020602), this version is the jar's version, so they need to\n         // be ignore\n         int iVersion = getIntVersion(version);\n-        if (iVersion >= 2001000 && iVersion <= 2060200) {\n+        if (iVersion >= 2001000 && iVersion < 2060300) {\n             return false;\n         }\n \n"}
{"instance_id": "apache__dubbo-5783", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/CompatibleTypeUtils.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/CompatibleTypeUtils.java\nindex cce01c9c84..057a70a466 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/CompatibleTypeUtils.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/CompatibleTypeUtils.java\n@@ -1,210 +1,240 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.common.utils;\r\n-\r\n-import java.lang.reflect.Array;\r\n-import java.math.BigDecimal;\r\n-import java.math.BigInteger;\r\n-import java.text.ParseException;\r\n-import java.text.SimpleDateFormat;\r\n-import java.util.ArrayList;\r\n-import java.util.Collection;\r\n-import java.util.Date;\r\n-import java.util.HashSet;\r\n-import java.util.List;\r\n-import java.util.Set;\r\n-\r\n-public class CompatibleTypeUtils {\r\n-\r\n-    private static final String DATE_FORMAT = \"yyyy-MM-dd HH:mm:ss\";\r\n-\r\n-    private CompatibleTypeUtils() {\r\n-    }\r\n-\r\n-    /**\r\n-     * Compatible type convert. Null value is allowed to pass in. If no conversion is needed, then the original value\r\n-     * will be returned.\r\n-     * <p>\r\n-     * Supported compatible type conversions include (primary types and corresponding wrappers are not listed):\r\n-     * <ul>\r\n-     * <li> String -> char, enum, Date\r\n-     * <li> byte, short, int, long -> byte, short, int, long\r\n-     * <li> float, double -> float, double\r\n-     * </ul>\r\n-     */\r\n-    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\r\n-    public static Object compatibleTypeConvert(Object value, Class<?> type) {\r\n-        if (value == null || type == null || type.isAssignableFrom(value.getClass())) {\r\n-            return value;\r\n-        }\r\n-\r\n-        if (value instanceof String) {\r\n-            String string = (String) value;\r\n-            if (char.class.equals(type) || Character.class.equals(type)) {\r\n-                if (string.length() != 1) {\r\n-                    throw new IllegalArgumentException(String.format(\"CAN NOT convert String(%s) to char!\" +\r\n-                            \" when convert String to char, the String MUST only 1 char.\", string));\r\n-                }\r\n-                return string.charAt(0);\r\n-            }\r\n-            if (type.isEnum()) {\r\n-                return Enum.valueOf((Class<Enum>) type, string);\r\n-            }\r\n-            if (type == BigInteger.class) {\r\n-                return new BigInteger(string);\r\n-            }\r\n-            if (type == BigDecimal.class) {\r\n-                return new BigDecimal(string);\r\n-            }\r\n-            if (type == Short.class || type == short.class) {\r\n-                return new Short(string);\r\n-            }\r\n-            if (type == Integer.class || type == int.class) {\r\n-                return new Integer(string);\r\n-            }\r\n-            if (type == Long.class || type == long.class) {\r\n-                return new Long(string);\r\n-            }\r\n-            if (type == Double.class || type == double.class) {\r\n-                return new Double(string);\r\n-            }\r\n-            if (type == Float.class || type == float.class) {\r\n-                return new Float(string);\r\n-            }\r\n-            if (type == Byte.class || type == byte.class) {\r\n-                return new Byte(string);\r\n-            }\r\n-            if (type == Boolean.class || type == boolean.class) {\r\n-                return Boolean.valueOf(string);\r\n-            }\r\n-            if (type == Date.class || type == java.sql.Date.class || type == java.sql.Timestamp.class\r\n-                    || type == java.sql.Time.class) {\r\n-                try {\r\n-                    Date date = new SimpleDateFormat(DATE_FORMAT).parse(string);\r\n-                    if (type == java.sql.Date.class) {\r\n-                        return new java.sql.Date(date.getTime());\r\n-                    }\r\n-                    if (type == java.sql.Timestamp.class) {\r\n-                        return new java.sql.Timestamp(date.getTime());\r\n-                    }\r\n-                    if (type == java.sql.Time.class) {\r\n-                        return new java.sql.Time(date.getTime());\r\n-                    }\r\n-                    return date;\r\n-                } catch (ParseException e) {\r\n-                    throw new IllegalStateException(\"Failed to parse date \" + value + \" by format \"\r\n-                            + DATE_FORMAT + \", cause: \" + e.getMessage(), e);\r\n-                }\r\n-            }\r\n-            if (type == Class.class) {\r\n-                try {\r\n-                    return ReflectUtils.name2class(string);\r\n-                } catch (ClassNotFoundException e) {\r\n-                    throw new RuntimeException(e.getMessage(), e);\r\n-                }\r\n-            }\r\n-            if (char[].class.equals(type)) {\r\n-                // Process string to char array for generic invoke\r\n-                // See\r\n-                // - https://github.com/apache/dubbo/issues/2003\r\n-                int len = string.length();\r\n-                char[] chars = new char[len];\r\n-                string.getChars(0, len, chars, 0);\r\n-                return chars;\r\n-            }\r\n-        }\r\n-        if (value instanceof Number) {\r\n-            Number number = (Number) value;\r\n-            if (type == byte.class || type == Byte.class) {\r\n-                return number.byteValue();\r\n-            }\r\n-            if (type == short.class || type == Short.class) {\r\n-                return number.shortValue();\r\n-            }\r\n-            if (type == int.class || type == Integer.class) {\r\n-                return number.intValue();\r\n-            }\r\n-            if (type == long.class || type == Long.class) {\r\n-                return number.longValue();\r\n-            }\r\n-            if (type == float.class || type == Float.class) {\r\n-                return number.floatValue();\r\n-            }\r\n-            if (type == double.class || type == Double.class) {\r\n-                return number.doubleValue();\r\n-            }\r\n-            if (type == BigInteger.class) {\r\n-                return BigInteger.valueOf(number.longValue());\r\n-            }\r\n-            if (type == BigDecimal.class) {\r\n-                return BigDecimal.valueOf(number.doubleValue());\r\n-            }\r\n-            if (type == Date.class) {\r\n-                return new Date(number.longValue());\r\n-            }\r\n-            if (type == boolean.class || type == Boolean.class) {\r\n-                return 0 != number.intValue();\r\n-            }\r\n-        }\r\n-        if (value instanceof Collection) {\r\n-            Collection collection = (Collection) value;\r\n-            if (type.isArray()) {\r\n-                int length = collection.size();\r\n-                Object array = Array.newInstance(type.getComponentType(), length);\r\n-                int i = 0;\r\n-                for (Object item : collection) {\r\n-                    Array.set(array, i++, item);\r\n-                }\r\n-                return array;\r\n-            }\r\n-            if (!type.isInterface()) {\r\n-                try {\r\n-                    Collection result = (Collection) type.newInstance();\r\n-                    result.addAll(collection);\r\n-                    return result;\r\n-                } catch (Throwable ignored) {\r\n-                }\r\n-            }\r\n-            if (type == List.class) {\r\n-                return new ArrayList<Object>(collection);\r\n-            }\r\n-            if (type == Set.class) {\r\n-                return new HashSet<Object>(collection);\r\n-            }\r\n-        }\r\n-        if (value.getClass().isArray() && Collection.class.isAssignableFrom(type)) {\r\n-            Collection collection;\r\n-            if (!type.isInterface()) {\r\n-                try {\r\n-                    collection = (Collection) type.newInstance();\r\n-                } catch (Throwable e) {\r\n-                    collection = new ArrayList<Object>();\r\n-                }\r\n-            } else if (type == Set.class) {\r\n-                collection = new HashSet<Object>();\r\n-            } else {\r\n-                collection = new ArrayList<Object>();\r\n-            }\r\n-            int length = Array.getLength(value);\r\n-            for (int i = 0; i < length; i++) {\r\n-                collection.add(Array.get(value, i));\r\n-            }\r\n-            return collection;\r\n-        }\r\n-        return value;\r\n-    }\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.common.utils;\n+\n+import java.lang.reflect.Array;\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.time.format.DateTimeFormatter;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+public class CompatibleTypeUtils {\n+\n+    private static final String DATE_FORMAT = \"yyyy-MM-dd HH:mm:ss\";\n+    private static final DateTimeFormatter DATE_TIME_FORMATTER = DateTimeFormatter.ofPattern(DATE_FORMAT);\n+    private static final String DATE_ONLY_FORMAT = \"yyyy-MM-dd\";\n+    private static final DateTimeFormatter DATE_FORMATTER = DateTimeFormatter.ofPattern(DATE_ONLY_FORMAT);\n+    private static final String TIME_ONLY_FORMAT = \"HH:mm:ss\";\n+    private static final DateTimeFormatter TIME_FORMATTER = DateTimeFormatter.ofPattern(TIME_ONLY_FORMAT);\n+\n+    private CompatibleTypeUtils() {\n+    }\n+\n+    /**\n+     * Compatible type convert. Null value is allowed to pass in. If no conversion is needed, then the original value\n+     * will be returned.\n+     * <p>\n+     * Supported compatible type conversions include (primary types and corresponding wrappers are not listed):\n+     * <ul>\n+     * <li> String -> char, enum, Date, LocalDateTime, LocalDate, LocalTime\n+     * <li> byte, short, int, long -> byte, short, int, long\n+     * <li> float, double -> float, double\n+     * </ul>\n+     */\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    public static Object compatibleTypeConvert(Object value, Class<?> type) {\n+        if (value == null || type == null || type.isAssignableFrom(value.getClass())) {\n+            return value;\n+        }\n+\n+        if (value instanceof String) {\n+            String string = (String) value;\n+            if (char.class.equals(type) || Character.class.equals(type)) {\n+                if (string.length() != 1) {\n+                    throw new IllegalArgumentException(String.format(\"CAN NOT convert String(%s) to char!\" +\n+                            \" when convert String to char, the String MUST only 1 char.\", string));\n+                }\n+                return string.charAt(0);\n+            }\n+            if (type.isEnum()) {\n+                return Enum.valueOf((Class<Enum>) type, string);\n+            }\n+            if (type == BigInteger.class) {\n+                return new BigInteger(string);\n+            }\n+            if (type == BigDecimal.class) {\n+                return new BigDecimal(string);\n+            }\n+            if (type == Short.class || type == short.class) {\n+                return new Short(string);\n+            }\n+            if (type == Integer.class || type == int.class) {\n+                return new Integer(string);\n+            }\n+            if (type == Long.class || type == long.class) {\n+                return new Long(string);\n+            }\n+            if (type == Double.class || type == double.class) {\n+                return new Double(string);\n+            }\n+            if (type == Float.class || type == float.class) {\n+                return new Float(string);\n+            }\n+            if (type == Byte.class || type == byte.class) {\n+                return new Byte(string);\n+            }\n+            if (type == Boolean.class || type == boolean.class) {\n+                return Boolean.valueOf(string);\n+            }\n+            if (type == Date.class || type == java.sql.Date.class || type == java.sql.Timestamp.class\n+                    || type == java.sql.Time.class) {\n+                try {\n+                    Date date = new SimpleDateFormat(DATE_FORMAT).parse(string);\n+                    if (type == java.sql.Date.class) {\n+                        return new java.sql.Date(date.getTime());\n+                    }\n+                    if (type == java.sql.Timestamp.class) {\n+                        return new java.sql.Timestamp(date.getTime());\n+                    }\n+                    if (type == java.sql.Time.class) {\n+                        return new java.sql.Time(date.getTime());\n+                    }\n+                    return date;\n+                } catch (ParseException e) {\n+                    throw new IllegalStateException(\"Failed to parse date \" + value + \" by format \"\n+                            + DATE_FORMAT + \", cause: \" + e.getMessage(), e);\n+                }\n+            }\n+            if (type == LocalDateTime.class) {\n+                if (string.length() == DATE_ONLY_FORMAT.length()) {\n+                    // Only date part provided, append time part\n+                    return LocalDateTime.parse(string + \" 00:00:00\", DATE_TIME_FORMATTER);\n+                }\n+                return LocalDateTime.parse(string, DATE_TIME_FORMATTER);\n+            }\n+            if (type == LocalDate.class) {\n+                if (string.length() > DATE_ONLY_FORMAT.length()) {\n+                    // Full datetime provided, extract date part\n+                    return LocalDate.parse(string.substring(0, DATE_ONLY_FORMAT.length()), DATE_FORMATTER);\n+                }\n+                return LocalDate.parse(string, DATE_FORMATTER);\n+            }\n+            if (type == LocalTime.class) {\n+                if (string.length() > TIME_ONLY_FORMAT.length()) {\n+                    // Full datetime provided, extract time part\n+                    return LocalTime.parse(string.substring(DATE_ONLY_FORMAT.length() + 1), TIME_FORMATTER);\n+                }\n+                return LocalTime.parse(string, TIME_FORMATTER);\n+            }\n+            if (type == Class.class) {\n+                try {\n+                    return ReflectUtils.name2class(string);\n+                } catch (ClassNotFoundException e) {\n+                    throw new RuntimeException(e.getMessage(), e);\n+                }\n+            }\n+            if (char[].class.equals(type)) {\n+                // Process string to char array for generic invoke\n+                // See\n+                // - https://github.com/apache/dubbo/issues/2003\n+                int len = string.length();\n+                char[] chars = new char[len];\n+                string.getChars(0, len, chars, 0);\n+                return chars;\n+            }\n+        }\n+        if (value instanceof Number) {\n+            Number number = (Number) value;\n+            if (type == byte.class || type == Byte.class) {\n+                return number.byteValue();\n+            }\n+            if (type == short.class || type == Short.class) {\n+                return number.shortValue();\n+            }\n+            if (type == int.class || type == Integer.class) {\n+                return number.intValue();\n+            }\n+            if (type == long.class || type == Long.class) {\n+                return number.longValue();\n+            }\n+            if (type == float.class || type == Float.class) {\n+                return number.floatValue();\n+            }\n+            if (type == double.class || type == Double.class) {\n+                return number.doubleValue();\n+            }\n+            if (type == BigInteger.class) {\n+                return BigInteger.valueOf(number.longValue());\n+            }\n+            if (type == BigDecimal.class) {\n+                return BigDecimal.valueOf(number.doubleValue());\n+            }\n+            if (type == Date.class) {\n+                return new Date(number.longValue());\n+            }\n+            if (type == boolean.class || type == Boolean.class) {\n+                return 0 != number.intValue();\n+            }\n+        }\n+        if (value instanceof Collection) {\n+            Collection collection = (Collection) value;\n+            if (type.isArray()) {\n+                int length = collection.size();\n+                Object array = Array.newInstance(type.getComponentType(), length);\n+                int i = 0;\n+                for (Object item : collection) {\n+                    Array.set(array, i++, item);\n+                }\n+                return array;\n+            }\n+            if (!type.isInterface()) {\n+                try {\n+                    Collection result = (Collection) type.newInstance();\n+                    result.addAll(collection);\n+                    return result;\n+                } catch (Throwable ignored) {\n+                }\n+            }\n+            if (type == List.class) {\n+                return new ArrayList<Object>(collection);\n+            }\n+            if (type == Set.class) {\n+                return new HashSet<Object>(collection);\n+            }\n+        }\n+        if (value.getClass().isArray() && Collection.class.isAssignableFrom(type)) {\n+            Collection collection;\n+            if (!type.isInterface()) {\n+                try {\n+                    collection = (Collection) type.newInstance();\n+                } catch (Throwable e) {\n+                    collection = new ArrayList<Object>();\n+                }\n+            } else if (type == Set.class) {\n+                collection = new HashSet<Object>();\n+            } else {\n+                collection = new ArrayList<Object>();\n+            }\n+            int length = Array.getLength(value);\n+            for (int i = 0; i < length; i++) {\n+                collection.add(Array.get(value, i));\n+            }\n+            return collection;\n+        }\n+        return value;\n+    }\n+}\n"}
{"instance_id": "apache__dubbo-8126", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/api/Connection.java b/dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/api/Connection.java\nindex 3f058292d0..eec4d79fb2 100644\n--- a/dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/api/Connection.java\n+++ b/dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/api/Connection.java\n@@ -222,6 +222,7 @@ public class Connection extends AbstractReferenceCounted implements ReferenceCou\n         @Override\n         public void operationComplete(ChannelFuture future) {\n             if (future.isSuccess()) {\n+                onConnected(future.channel());\n                 return;\n             }\n             final Connection conn = Connection.this;\n"}
{"instance_id": "apache__dubbo-3622", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/Invoker.java b/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/Invoker.java\nindex 55a948083f..d9509ab14c 100644\n--- a/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/Invoker.java\n+++ b/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/Invoker.java\n@@ -22,8 +22,12 @@ import org.apache.dubbo.common.URL;\n @Deprecated\n public interface Invoker<T> extends org.apache.dubbo.rpc.Invoker<T> {\n \n+    Result invoke(Invocation invocation) throws RpcException;\n+\n     @Override\n-    Result invoke(org.apache.dubbo.rpc.Invocation invocation) throws RpcException;\n+    default Result invoke(org.apache.dubbo.rpc.Invocation invocation) throws RpcException {\n+        return invoke(new Invocation.CompatibleInvocation(invocation));\n+    }\n \n     default org.apache.dubbo.rpc.Invoker<T> getOriginal() {\n         return null;\n@@ -43,8 +47,8 @@ public interface Invoker<T> extends org.apache.dubbo.rpc.Invoker<T> {\n         }\n \n         @Override\n-        public Result invoke(org.apache.dubbo.rpc.Invocation invocation) throws RpcException {\n-            return new Result.CompatibleResult(invoker.invoke(((Invocation) invocation).getOriginal()));\n+        public Result invoke(Invocation invocation) throws RpcException {\n+            return new Result.CompatibleResult(invoker.invoke(invocation.getOriginal()));\n         }\n \n         @Override\n"}
{"instance_id": "apache__dubbo-5356", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/config/configcenter/file/FileSystemDynamicConfiguration.java b/dubbo-common/src/main/java/org/apache/dubbo/common/config/configcenter/file/FileSystemDynamicConfiguration.java\nindex ff2432f2e2..458670b051 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/config/configcenter/file/FileSystemDynamicConfiguration.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/config/configcenter/file/FileSystemDynamicConfiguration.java\n@@ -124,7 +124,7 @@ public class FileSystemDynamicConfiguration extends AbstractDynamicConfiguration\n      *\n      * @see #detectPoolingBasedWatchService(Optional)\n      */\n-    private static final boolean basedPoolingWatchService;\n+    private static final boolean BASED_POOLING_WATCH_SERVICE;\n \n     private static final WatchEvent.Modifier[] modifiers;\n \n@@ -144,7 +144,7 @@ public class FileSystemDynamicConfiguration extends AbstractDynamicConfiguration\n     // static initialization\n     static {\n         watchService = newWatchService();\n-        basedPoolingWatchService = detectPoolingBasedWatchService(watchService);\n+        BASED_POOLING_WATCH_SERVICE = detectPoolingBasedWatchService(watchService);\n         modifiers = initWatchEventModifiers();\n         delay = initDelay(modifiers);\n         watchEventsLoopThreadPool = newWatchEventsLoopThreadPool();\n@@ -497,7 +497,7 @@ public class FileSystemDynamicConfiguration extends AbstractDynamicConfiguration\n      * @see #detectPoolingBasedWatchService(Optional)\n      */\n     protected static boolean isBasedPoolingWatchService() {\n-        return basedPoolingWatchService;\n+        return BASED_POOLING_WATCH_SERVICE;\n     }\n \n     protected static ThreadPoolExecutor getWatchEventsLoopThreadPool() {\ndiff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/json/GenericJSONConverter.java b/dubbo-common/src/main/java/org/apache/dubbo/common/json/GenericJSONConverter.java\nindex 9082eb155c..e7e0e6a0a7 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/json/GenericJSONConverter.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/json/GenericJSONConverter.java\n@@ -36,8 +36,8 @@ import java.util.concurrent.atomic.AtomicLong;\n @Deprecated\n public class GenericJSONConverter implements JSONConverter {\n     private static final String DATE_FORMAT = \"yyyy-MM-dd HH:mm:ss\";\n-    private static final Map<Class<?>, Encoder> GlobalEncoderMap = new HashMap<Class<?>, Encoder>();\n-    private static final Map<Class<?>, Decoder> GlobalDecoderMap = new HashMap<Class<?>, Decoder>();\n+    private static final Map<Class<?>, Encoder> GLOBAL_ENCODER_MAP = new HashMap<Class<?>, Encoder>();\n+    private static final Map<Class<?>, Decoder> GLOBAL_DECODER_MAP = new HashMap<Class<?>, Decoder>();\n \n     static {\n         // init encoder map.\n@@ -47,8 +47,8 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueBoolean((Boolean) obj);\n             }\n         };\n-        GlobalEncoderMap.put(boolean.class, e);\n-        GlobalEncoderMap.put(Boolean.class, e);\n+        GLOBAL_ENCODER_MAP.put(boolean.class, e);\n+        GLOBAL_ENCODER_MAP.put(Boolean.class, e);\n \n         e = new Encoder() {\n             @Override\n@@ -56,13 +56,13 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueInt(((Number) obj).intValue());\n             }\n         };\n-        GlobalEncoderMap.put(int.class, e);\n-        GlobalEncoderMap.put(Integer.class, e);\n-        GlobalEncoderMap.put(short.class, e);\n-        GlobalEncoderMap.put(Short.class, e);\n-        GlobalEncoderMap.put(byte.class, e);\n-        GlobalEncoderMap.put(Byte.class, e);\n-        GlobalEncoderMap.put(AtomicInteger.class, e);\n+        GLOBAL_ENCODER_MAP.put(int.class, e);\n+        GLOBAL_ENCODER_MAP.put(Integer.class, e);\n+        GLOBAL_ENCODER_MAP.put(short.class, e);\n+        GLOBAL_ENCODER_MAP.put(Short.class, e);\n+        GLOBAL_ENCODER_MAP.put(byte.class, e);\n+        GLOBAL_ENCODER_MAP.put(Byte.class, e);\n+        GLOBAL_ENCODER_MAP.put(AtomicInteger.class, e);\n \n         e = new Encoder() {\n             @Override\n@@ -70,8 +70,8 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueString(Character.toString((Character) obj));\n             }\n         };\n-        GlobalEncoderMap.put(char.class, e);\n-        GlobalEncoderMap.put(Character.class, e);\n+        GLOBAL_ENCODER_MAP.put(char.class, e);\n+        GLOBAL_ENCODER_MAP.put(Character.class, e);\n \n         e = new Encoder() {\n             @Override\n@@ -79,10 +79,10 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueLong(((Number) obj).longValue());\n             }\n         };\n-        GlobalEncoderMap.put(long.class, e);\n-        GlobalEncoderMap.put(Long.class, e);\n-        GlobalEncoderMap.put(AtomicLong.class, e);\n-        GlobalEncoderMap.put(BigInteger.class, e);\n+        GLOBAL_ENCODER_MAP.put(long.class, e);\n+        GLOBAL_ENCODER_MAP.put(Long.class, e);\n+        GLOBAL_ENCODER_MAP.put(AtomicLong.class, e);\n+        GLOBAL_ENCODER_MAP.put(BigInteger.class, e);\n \n         e = new Encoder() {\n             @Override\n@@ -90,8 +90,8 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueFloat(((Number) obj).floatValue());\n             }\n         };\n-        GlobalEncoderMap.put(float.class, e);\n-        GlobalEncoderMap.put(Float.class, e);\n+        GLOBAL_ENCODER_MAP.put(float.class, e);\n+        GLOBAL_ENCODER_MAP.put(Float.class, e);\n \n         e = new Encoder() {\n             @Override\n@@ -99,9 +99,9 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueDouble(((Number) obj).doubleValue());\n             }\n         };\n-        GlobalEncoderMap.put(double.class, e);\n-        GlobalEncoderMap.put(Double.class, e);\n-        GlobalEncoderMap.put(BigDecimal.class, e);\n+        GLOBAL_ENCODER_MAP.put(double.class, e);\n+        GLOBAL_ENCODER_MAP.put(Double.class, e);\n+        GLOBAL_ENCODER_MAP.put(BigDecimal.class, e);\n \n         e = new Encoder() {\n             @Override\n@@ -109,9 +109,9 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueString(obj.toString());\n             }\n         };\n-        GlobalEncoderMap.put(String.class, e);\n-        GlobalEncoderMap.put(StringBuilder.class, e);\n-        GlobalEncoderMap.put(StringBuffer.class, e);\n+        GLOBAL_ENCODER_MAP.put(String.class, e);\n+        GLOBAL_ENCODER_MAP.put(StringBuilder.class, e);\n+        GLOBAL_ENCODER_MAP.put(StringBuffer.class, e);\n \n         e = new Encoder() {\n             @Override\n@@ -119,7 +119,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueString(Bytes.bytes2base64((byte[]) obj));\n             }\n         };\n-        GlobalEncoderMap.put(byte[].class, e);\n+        GLOBAL_ENCODER_MAP.put(byte[].class, e);\n \n         e = new Encoder() {\n             @Override\n@@ -127,11 +127,11 @@ public class GenericJSONConverter implements JSONConverter {\n                 jb.valueString(new SimpleDateFormat(DATE_FORMAT).format((Date) obj));\n             }\n         };\n-        GlobalEncoderMap.put(Date.class, e);\n+        GLOBAL_ENCODER_MAP.put(Date.class, e);\n \n         // init decoder map.\n         Decoder d = Object::toString;\n-        GlobalDecoderMap.put(String.class, d);\n+        GLOBAL_DECODER_MAP.put(String.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -142,7 +142,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return false;\n             }\n         };\n-        GlobalDecoderMap.put(boolean.class, d);\n+        GLOBAL_DECODER_MAP.put(boolean.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -153,7 +153,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Boolean) null;\n             }\n         };\n-        GlobalDecoderMap.put(Boolean.class, d);\n+        GLOBAL_DECODER_MAP.put(Boolean.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -164,7 +164,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (char) 0;\n             }\n         };\n-        GlobalDecoderMap.put(char.class, d);\n+        GLOBAL_DECODER_MAP.put(char.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -175,7 +175,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Character) null;\n             }\n         };\n-        GlobalDecoderMap.put(Character.class, d);\n+        GLOBAL_DECODER_MAP.put(Character.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -186,7 +186,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return 0;\n             }\n         };\n-        GlobalDecoderMap.put(int.class, d);\n+        GLOBAL_DECODER_MAP.put(int.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -197,7 +197,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Integer) null;\n             }\n         };\n-        GlobalDecoderMap.put(Integer.class, d);\n+        GLOBAL_DECODER_MAP.put(Integer.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -208,7 +208,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (short) 0;\n             }\n         };\n-        GlobalDecoderMap.put(short.class, d);\n+        GLOBAL_DECODER_MAP.put(short.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -219,7 +219,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Short) null;\n             }\n         };\n-        GlobalDecoderMap.put(Short.class, d);\n+        GLOBAL_DECODER_MAP.put(Short.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -230,7 +230,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (long) 0;\n             }\n         };\n-        GlobalDecoderMap.put(long.class, d);\n+        GLOBAL_DECODER_MAP.put(long.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -241,7 +241,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Long) null;\n             }\n         };\n-        GlobalDecoderMap.put(Long.class, d);\n+        GLOBAL_DECODER_MAP.put(Long.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -252,7 +252,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (float) 0;\n             }\n         };\n-        GlobalDecoderMap.put(float.class, d);\n+        GLOBAL_DECODER_MAP.put(float.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -263,7 +263,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Float) null;\n             }\n         };\n-        GlobalDecoderMap.put(Float.class, d);\n+        GLOBAL_DECODER_MAP.put(Float.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -274,7 +274,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (double) 0;\n             }\n         };\n-        GlobalDecoderMap.put(double.class, d);\n+        GLOBAL_DECODER_MAP.put(double.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -285,7 +285,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Double) null;\n             }\n         };\n-        GlobalDecoderMap.put(Double.class, d);\n+        GLOBAL_DECODER_MAP.put(Double.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -296,7 +296,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (byte) 0;\n             }\n         };\n-        GlobalDecoderMap.put(byte.class, d);\n+        GLOBAL_DECODER_MAP.put(byte.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -307,7 +307,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Byte) null;\n             }\n         };\n-        GlobalDecoderMap.put(Byte.class, d);\n+        GLOBAL_DECODER_MAP.put(Byte.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -318,7 +318,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (byte[]) null;\n             }\n         };\n-        GlobalDecoderMap.put(byte[].class, d);\n+        GLOBAL_DECODER_MAP.put(byte[].class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -326,7 +326,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return new StringBuilder(jv.toString());\n             }\n         };\n-        GlobalDecoderMap.put(StringBuilder.class, d);\n+        GLOBAL_DECODER_MAP.put(StringBuilder.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -334,7 +334,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return new StringBuffer(jv.toString());\n             }\n         };\n-        GlobalDecoderMap.put(StringBuffer.class, d);\n+        GLOBAL_DECODER_MAP.put(StringBuffer.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -345,7 +345,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (BigInteger) null;\n             }\n         };\n-        GlobalDecoderMap.put(BigInteger.class, d);\n+        GLOBAL_DECODER_MAP.put(BigInteger.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -356,7 +356,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (BigDecimal) null;\n             }\n         };\n-        GlobalDecoderMap.put(BigDecimal.class, d);\n+        GLOBAL_DECODER_MAP.put(BigDecimal.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -367,7 +367,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (AtomicInteger) null;\n             }\n         };\n-        GlobalDecoderMap.put(AtomicInteger.class, d);\n+        GLOBAL_DECODER_MAP.put(AtomicInteger.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -378,7 +378,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (AtomicLong) null;\n             }\n         };\n-        GlobalDecoderMap.put(AtomicLong.class, d);\n+        GLOBAL_DECODER_MAP.put(AtomicLong.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -396,7 +396,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Date) null;\n             }\n         };\n-        GlobalDecoderMap.put(Date.class, d);\n+        GLOBAL_DECODER_MAP.put(Date.class, d);\n \n         d = new Decoder() {\n             @Override\n@@ -414,7 +414,7 @@ public class GenericJSONConverter implements JSONConverter {\n                 return (Locale)null;\n             }\n         };\n-        GlobalDecoderMap.put(Locale.class, d);\n+        GLOBAL_DECODER_MAP.put(Locale.class, d);\n     }\n \n     @Override\n@@ -425,7 +425,7 @@ public class GenericJSONConverter implements JSONConverter {\n             return;\n         }\n         Class<?> c = obj.getClass();\n-        Encoder encoder = GlobalEncoderMap.get(c);\n+        Encoder encoder = GLOBAL_ENCODER_MAP.get(c);\n \n         if (encoder != null) {\n             encoder.encode(obj, jb);\n@@ -508,7 +508,7 @@ public class GenericJSONConverter implements JSONConverter {\n         if (jv == null) {\n             return null;\n         }\n-        Decoder decoder = GlobalDecoderMap.get(c);\n+        Decoder decoder = GLOBAL_DECODER_MAP.get(c);\n         if (decoder != null) {\n             return decoder.decode(jv);\n         }\ndiff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ReflectUtils.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ReflectUtils.java\nindex 7bb9256006..4b8440c9ff 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ReflectUtils.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ReflectUtils.java\n@@ -134,20 +134,20 @@ public final class ReflectUtils {\n \n     private static final ConcurrentMap<String, Class<?>> NAME_CLASS_CACHE = new ConcurrentHashMap<String, Class<?>>();\n \n-    private static final ConcurrentMap<String, Method> Signature_METHODS_CACHE = new ConcurrentHashMap<String, Method>();\n+    private static final ConcurrentMap<String, Method> SIGNATURE_METHODS_CACHE = new ConcurrentHashMap<String, Method>();\n \n-    private static Map<Class<?>, Object> primitiveDefaults = new HashMap<>();\n+    private static Map<Class<?>, Object> PRIMITIVE_DEFAULTS = new HashMap<>();\n \n     static {\n-        primitiveDefaults.put(int.class, 0);\n-        primitiveDefaults.put(long.class, 0L);\n-        primitiveDefaults.put(byte.class, (byte) 0);\n-        primitiveDefaults.put(char.class, (char) 0);\n-        primitiveDefaults.put(short.class, (short) 0);\n-        primitiveDefaults.put(float.class, (float) 0);\n-        primitiveDefaults.put(double.class, (double) 0);\n-        primitiveDefaults.put(boolean.class, false);\n-        primitiveDefaults.put(void.class, null);\n+        PRIMITIVE_DEFAULTS.put(int.class, 0);\n+        PRIMITIVE_DEFAULTS.put(long.class, 0L);\n+        PRIMITIVE_DEFAULTS.put(byte.class, (byte) 0);\n+        PRIMITIVE_DEFAULTS.put(char.class, (char) 0);\n+        PRIMITIVE_DEFAULTS.put(short.class, (short) 0);\n+        PRIMITIVE_DEFAULTS.put(float.class, (float) 0);\n+        PRIMITIVE_DEFAULTS.put(double.class, (double) 0);\n+        PRIMITIVE_DEFAULTS.put(boolean.class, false);\n+        PRIMITIVE_DEFAULTS.put(void.class, null);\n     }\n \n     private ReflectUtils() {\n@@ -911,7 +911,7 @@ public final class ReflectUtils {\n         if (parameterTypes != null && parameterTypes.length > 0) {\n             signature += StringUtils.join(parameterTypes);\n         }\n-        Method method = Signature_METHODS_CACHE.get(signature);\n+        Method method = SIGNATURE_METHODS_CACHE.get(signature);\n         if (method != null) {\n             return method;\n         }\n@@ -939,7 +939,7 @@ public final class ReflectUtils {\n             method = clazz.getMethod(methodName, types);\n \n         }\n-        Signature_METHODS_CACHE.put(signature, method);\n+        SIGNATURE_METHODS_CACHE.put(signature, method);\n         return method;\n     }\n \n@@ -1082,7 +1082,7 @@ public final class ReflectUtils {\n \n     public static Object defaultReturn(Method m) {\n         if (m.getReturnType().isPrimitive()) {\n-            return primitiveDefaults.get(m.getReturnType());\n+            return PRIMITIVE_DEFAULTS.get(m.getReturnType());\n         } else {\n             return null;\n         }\n@@ -1090,7 +1090,7 @@ public final class ReflectUtils {\n \n     public static Object defaultReturn(Class<?> classType) {\n         if (classType != null && classType.isPrimitive()) {\n-            return primitiveDefaults.get(classType);\n+            return PRIMITIVE_DEFAULTS.get(classType);\n         } else {\n             return null;\n         }\ndiff --git a/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java b/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java\nindex 8cdd9c0adb..735ea7eb3a 100644\n--- a/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java\n+++ b/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/ServiceConfig.java\n@@ -114,7 +114,7 @@ public class ServiceConfig<T> extends ServiceConfigBase<T> {\n      */\n     private static final ScheduledExecutorService DELAY_EXPORT_EXECUTOR = Executors.newSingleThreadScheduledExecutor(new NamedThreadFactory(\"DubboServiceDelayExporter\", true));\n \n-    private static final Protocol protocol = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();\n+    private static final Protocol PROTOCOL = ExtensionLoader.getExtensionLoader(Protocol.class).getAdaptiveExtension();\n \n     /**\n      * A {@link ProxyFactory} implementation that will generate a exported service proxy,the JavassistProxyFactory is its\n@@ -480,7 +480,7 @@ public class ServiceConfig<T> extends ServiceConfigBase<T> {\n                         Invoker<?> invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, registryURL.addParameterAndEncoded(EXPORT_KEY, url.toFullString()));\n                         DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this);\n \n-                        Exporter<?> exporter = protocol.export(wrapperInvoker);\n+                        Exporter<?> exporter = PROTOCOL.export(wrapperInvoker);\n                         exporters.add(exporter);\n                     }\n                 } else {\n@@ -490,7 +490,7 @@ public class ServiceConfig<T> extends ServiceConfigBase<T> {\n                     Invoker<?> invoker = PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, url);\n                     DelegateProviderMetaDataInvoker wrapperInvoker = new DelegateProviderMetaDataInvoker(invoker, this);\n \n-                    Exporter<?> exporter = protocol.export(wrapperInvoker);\n+                    Exporter<?> exporter = PROTOCOL.export(wrapperInvoker);\n                     exporters.add(exporter);\n                 }\n                 /**\n@@ -516,7 +516,7 @@ public class ServiceConfig<T> extends ServiceConfigBase<T> {\n                 .setHost(LOCALHOST_VALUE)\n                 .setPort(0)\n                 .build();\n-        Exporter<?> exporter = protocol.export(\n+        Exporter<?> exporter = PROTOCOL.export(\n                 PROXY_FACTORY.getInvoker(ref, (Class) interfaceClass, local));\n         exporters.add(exporter);\n         logger.info(\"Export dubbo service \" + interfaceClass.getName() + \" to local registry url : \" + local);\ndiff --git a/dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java b/dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java\nindex be15230c4f..5e9008f284 100644\n--- a/dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java\n+++ b/dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/report/support/AbstractMetadataReport.java\n@@ -81,8 +81,8 @@ public abstract class AbstractMetadataReport implements MetadataReport {\n \n     protected final static String DEFAULT_ROOT = \"dubbo\";\n \n-    private static final int ONE_DAY_IN_MIll = 60 * 24 * 60 * 1000;\n-    private static final int FOUR_HOURS_IN_MIll = 60 * 4 * 60 * 1000;\n+    private static final int ONE_DAY_IN_MILL = 60 * 24 * 60 * 1000;\n+    private static final int FOUR_HOURS_IN_MILL = 60 * 4 * 60 * 1000;\n     // Log output\n     protected final Logger logger = LoggerFactory.getLogger(getClass());\n \n@@ -126,7 +126,7 @@ public abstract class AbstractMetadataReport implements MetadataReport {\n         // cycle report the data switch\n         if (reportServerURL.getParameter(CYCLE_REPORT_KEY, DEFAULT_METADATA_REPORT_CYCLE_REPORT)) {\n             ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor(new NamedThreadFactory(\"DubboMetadataReportTimer\", true));\n-            scheduler.scheduleAtFixedRate(this::publishAll, calculateStartTime(), ONE_DAY_IN_MIll, TimeUnit.MILLISECONDS);\n+            scheduler.scheduleAtFixedRate(this::publishAll, calculateStartTime(), ONE_DAY_IN_MILL, TimeUnit.MILLISECONDS);\n         }\n     }\n \n@@ -385,8 +385,8 @@ public abstract class AbstractMetadataReport implements MetadataReport {\n         calendar.set(Calendar.MINUTE, 0);\n         calendar.set(Calendar.SECOND, 0);\n         calendar.set(Calendar.MILLISECOND, 0);\n-        long subtract = calendar.getTimeInMillis() + ONE_DAY_IN_MIll - nowMill;\n-        return subtract + (FOUR_HOURS_IN_MIll / 2) + ThreadLocalRandom.current().nextInt(FOUR_HOURS_IN_MIll);\n+        long subtract = calendar.getTimeInMillis() + ONE_DAY_IN_MILL - nowMill;\n+        return subtract + (FOUR_HOURS_IN_MILL / 2) + ThreadLocalRandom.current().nextInt(FOUR_HOURS_IN_MILL);\n     }\n \n     class MetadataReportRetry {\ndiff --git a/dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/store/BaseWritableMetadataService.java b/dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/store/BaseWritableMetadataService.java\nindex 0e5ac34b74..f84c9c6c92 100644\n--- a/dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/store/BaseWritableMetadataService.java\n+++ b/dubbo-metadata/dubbo-metadata-api/src/main/java/org/apache/dubbo/metadata/store/BaseWritableMetadataService.java\n@@ -37,7 +37,7 @@ public class BaseWritableMetadataService {\n      * All exported {@link URL urls} {@link Map} whose key is the return value of {@link URL#getServiceKey()} method\n      * and value is the {@link SortedSet sorted set} of the {@link URL URLs}\n      */\n-    static ConcurrentNavigableMap<String, SortedSet<URL>> exportedServiceURLs = new ConcurrentSkipListMap<>();\n+    static ConcurrentNavigableMap<String, SortedSet<URL>> EXPORTED_SERVICE_URLS = new ConcurrentSkipListMap<>();\n \n     // ==================================================================================== //\n \n@@ -48,9 +48,9 @@ public class BaseWritableMetadataService {\n      * whose key is the return value of {@link URL#getServiceKey()} method and value is\n      * the {@link SortedSet sorted set} of the {@link URL URLs}\n      */\n-    final static ConcurrentNavigableMap<String, SortedSet<URL>> subscribedServiceURLs = new ConcurrentSkipListMap<>();\n+    final static ConcurrentNavigableMap<String, SortedSet<URL>> SUBSCRIBED_SERVICE_URLS = new ConcurrentSkipListMap<>();\n \n-    final static ConcurrentNavigableMap<String, String> serviceDefinitions = new ConcurrentSkipListMap<>();\n+    final static ConcurrentNavigableMap<String, String> SERVICE_DEFINITIONS = new ConcurrentSkipListMap<>();\n \n \n     boolean throwableAction(Consumer<URL> consumer, URL url) {\n@@ -64,7 +64,7 @@ public class BaseWritableMetadataService {\n     }\n \n     public SortedSet<String> getSubscribedURLs() {\n-        return getAllUnmodifiableServiceURLs(subscribedServiceURLs);\n+        return getAllUnmodifiableServiceURLs(SUBSCRIBED_SERVICE_URLS);\n     }\n \n     static SortedSet<String> getAllUnmodifiableServiceURLs(Map<String, SortedSet<URL>> serviceURLs) {\ndiff --git a/dubbo-monitor/dubbo-monitor-api/src/main/java/org/apache/dubbo/monitor/support/AbstractMonitorFactory.java b/dubbo-monitor/dubbo-monitor-api/src/main/java/org/apache/dubbo/monitor/support/AbstractMonitorFactory.java\nindex 7b921e6fdf..9a1b0ae19d 100644\n--- a/dubbo-monitor/dubbo-monitor-api/src/main/java/org/apache/dubbo/monitor/support/AbstractMonitorFactory.java\n+++ b/dubbo-monitor/dubbo-monitor-api/src/main/java/org/apache/dubbo/monitor/support/AbstractMonitorFactory.java\n@@ -1,125 +1,125 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.monitor.support;\r\n-\r\n-import org.apache.dubbo.common.URL;\r\n-import org.apache.dubbo.common.logger.Logger;\r\n-import org.apache.dubbo.common.logger.LoggerFactory;\r\n-import org.apache.dubbo.common.utils.NamedThreadFactory;\r\n-import org.apache.dubbo.monitor.Monitor;\r\n-import org.apache.dubbo.monitor.MonitorFactory;\r\n-import org.apache.dubbo.monitor.MonitorService;\r\n-\r\n-import java.util.Collection;\r\n-import java.util.Collections;\r\n-import java.util.Map;\r\n-import java.util.concurrent.CompletableFuture;\r\n-import java.util.concurrent.ConcurrentHashMap;\r\n-import java.util.concurrent.ExecutionException;\r\n-import java.util.concurrent.ExecutorService;\r\n-import java.util.concurrent.Future;\r\n-import java.util.concurrent.SynchronousQueue;\r\n-import java.util.concurrent.ThreadPoolExecutor;\r\n-import java.util.concurrent.TimeUnit;\r\n-import java.util.concurrent.locks.ReentrantLock;\r\n-\r\n-import static org.apache.dubbo.common.constants.CommonConstants.INTERFACE_KEY;\r\n-\r\n-/**\r\n- * AbstractMonitorFactory. (SPI, Singleton, ThreadSafe)\r\n- */\r\n-public abstract class AbstractMonitorFactory implements MonitorFactory {\r\n-    private static final Logger logger = LoggerFactory.getLogger(AbstractMonitorFactory.class);\r\n-\r\n-    /**\r\n-     * The lock for getting monitor center\r\n-     */\r\n-    private static final ReentrantLock LOCK = new ReentrantLock();\r\n-\r\n-    /**\r\n-     * The monitor centers Map<RegistryAddress, Registry>\r\n-     */\r\n-    private static final Map<String, Monitor> MONITORS = new ConcurrentHashMap<String, Monitor>();\r\n-\r\n-    private static final Map<String, CompletableFuture<Monitor>> FUTURES = new ConcurrentHashMap<String, CompletableFuture<Monitor>>();\r\n-\r\n-    /**\r\n-     * The monitor create executor\r\n-     */\r\n-    private static final ExecutorService executor = new ThreadPoolExecutor(0, 10, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>(), new NamedThreadFactory(\"DubboMonitorCreator\", true));\r\n-\r\n-    public static Collection<Monitor> getMonitors() {\r\n-        return Collections.unmodifiableCollection(MONITORS.values());\r\n-    }\r\n-\r\n-    @Override\r\n-    public Monitor getMonitor(URL url) {\r\n-        url = url.setPath(MonitorService.class.getName()).addParameter(INTERFACE_KEY, MonitorService.class.getName());\r\n-        String key = url.toServiceStringWithoutResolving();\r\n-        Monitor monitor = MONITORS.get(key);\r\n-        Future<Monitor> future = FUTURES.get(key);\r\n-        if (monitor != null || future != null) {\r\n-            return monitor;\r\n-        }\r\n-\r\n-        LOCK.lock();\r\n-        try {\r\n-            monitor = MONITORS.get(key);\r\n-            future = FUTURES.get(key);\r\n-            if (monitor != null || future != null) {\r\n-                return monitor;\r\n-            }\r\n-\r\n-            final URL monitorUrl = url;\r\n-            final CompletableFuture<Monitor> completableFuture = CompletableFuture.supplyAsync(() -> AbstractMonitorFactory.this.createMonitor(monitorUrl));\r\n-            FUTURES.put(key, completableFuture);\r\n-            completableFuture.thenRunAsync(new MonitorListener(key), executor);\r\n-\r\n-            return null;\r\n-        } finally {\r\n-            // unlock\r\n-            LOCK.unlock();\r\n-        }\r\n-    }\r\n-\r\n-    protected abstract Monitor createMonitor(URL url);\r\n-\r\n-\r\n-    class MonitorListener implements Runnable {\r\n-\r\n-        private String key;\r\n-\r\n-        public MonitorListener(String key) {\r\n-            this.key = key;\r\n-        }\r\n-\r\n-        @Override\r\n-        public void run() {\r\n-            try {\r\n-                CompletableFuture<Monitor> completableFuture = AbstractMonitorFactory.FUTURES.get(key);\r\n-                AbstractMonitorFactory.MONITORS.put(key, completableFuture.get());\r\n-                AbstractMonitorFactory.FUTURES.remove(key);\r\n-            } catch (InterruptedException e) {\r\n-                logger.warn(\"Thread was interrupted unexpectedly, monitor will never be got.\");\r\n-                AbstractMonitorFactory.FUTURES.remove(key);\r\n-            } catch (ExecutionException e) {\r\n-                logger.warn(\"Create monitor failed, monitor data will not be collected until you fix this problem. \", e);\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.monitor.support;\n+\n+import org.apache.dubbo.common.URL;\n+import org.apache.dubbo.common.logger.Logger;\n+import org.apache.dubbo.common.logger.LoggerFactory;\n+import org.apache.dubbo.common.utils.NamedThreadFactory;\n+import org.apache.dubbo.monitor.Monitor;\n+import org.apache.dubbo.monitor.MonitorFactory;\n+import org.apache.dubbo.monitor.MonitorService;\n+\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.Map;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.SynchronousQueue;\n+import java.util.concurrent.ThreadPoolExecutor;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.locks.ReentrantLock;\n+\n+import static org.apache.dubbo.common.constants.CommonConstants.INTERFACE_KEY;\n+\n+/**\n+ * AbstractMonitorFactory. (SPI, Singleton, ThreadSafe)\n+ */\n+public abstract class AbstractMonitorFactory implements MonitorFactory {\n+    private static final Logger logger = LoggerFactory.getLogger(AbstractMonitorFactory.class);\n+\n+    /**\n+     * The lock for getting monitor center\n+     */\n+    private static final ReentrantLock LOCK = new ReentrantLock();\n+\n+    /**\n+     * The monitor centers Map<RegistryAddress, Registry>\n+     */\n+    private static final Map<String, Monitor> MONITORS = new ConcurrentHashMap<String, Monitor>();\n+\n+    private static final Map<String, CompletableFuture<Monitor>> FUTURES = new ConcurrentHashMap<String, CompletableFuture<Monitor>>();\n+\n+    /**\n+     * The monitor create executor\n+     */\n+    private static final ExecutorService EXECUTOR = new ThreadPoolExecutor(0, 10, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>(), new NamedThreadFactory(\"DubboMonitorCreator\", true));\n+\n+    public static Collection<Monitor> getMonitors() {\n+        return Collections.unmodifiableCollection(MONITORS.values());\n+    }\n+\n+    @Override\n+    public Monitor getMonitor(URL url) {\n+        url = url.setPath(MonitorService.class.getName()).addParameter(INTERFACE_KEY, MonitorService.class.getName());\n+        String key = url.toServiceStringWithoutResolving();\n+        Monitor monitor = MONITORS.get(key);\n+        Future<Monitor> future = FUTURES.get(key);\n+        if (monitor != null || future != null) {\n+            return monitor;\n+        }\n+\n+        LOCK.lock();\n+        try {\n+            monitor = MONITORS.get(key);\n+            future = FUTURES.get(key);\n+            if (monitor != null || future != null) {\n+                return monitor;\n+            }\n+\n+            final URL monitorUrl = url;\n+            final CompletableFuture<Monitor> completableFuture = CompletableFuture.supplyAsync(() -> AbstractMonitorFactory.this.createMonitor(monitorUrl));\n+            FUTURES.put(key, completableFuture);\n+            completableFuture.thenRunAsync(new MonitorListener(key), EXECUTOR);\n+\n+            return null;\n+        } finally {\n+            // unlock\n+            LOCK.unlock();\n+        }\n+    }\n+\n+    protected abstract Monitor createMonitor(URL url);\n+\n+\n+    class MonitorListener implements Runnable {\n+\n+        private String key;\n+\n+        public MonitorListener(String key) {\n+            this.key = key;\n+        }\n+\n+        @Override\n+        public void run() {\n+            try {\n+                CompletableFuture<Monitor> completableFuture = AbstractMonitorFactory.FUTURES.get(key);\n+                AbstractMonitorFactory.MONITORS.put(key, completableFuture.get());\n+                AbstractMonitorFactory.FUTURES.remove(key);\n+            } catch (InterruptedException e) {\n+                logger.warn(\"Thread was interrupted unexpectedly, monitor will never be got.\");\n+                AbstractMonitorFactory.FUTURES.remove(key);\n+            } catch (ExecutionException e) {\n+                logger.warn(\"Create monitor failed, monitor data will not be collected until you fix this problem. \", e);\n+            }\n+        }\n+    }\n+\n+}\ndiff --git a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/DubboLogo.java b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/DubboLogo.java\nindex 7bb86c7d4e..9ef98b37a1 100644\n--- a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/DubboLogo.java\n+++ b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/DubboLogo.java\n@@ -17,7 +17,7 @@\n package org.apache.dubbo.qos.server;\n \n public class DubboLogo {\n-    public static final String dubbo =\n+    public static final String DUBBO =\n                     \"   ___   __  __ ___   ___   ____     \" + System.lineSeparator() +\n                     \"  / _ \\\\ / / / // _ ) / _ ) / __ \\\\  \" + System.lineSeparator() +\n                     \" / // // /_/ // _  |/ _  |/ /_/ /    \" + System.lineSeparator() +\ndiff --git a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/Server.java b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/Server.java\nindex 70b1dd3158..0f33ae38ad 100644\n--- a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/Server.java\n+++ b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/Server.java\n@@ -60,7 +60,7 @@ public class Server {\n     private EventLoopGroup worker;\n \n     private Server() {\n-        this.welcome = DubboLogo.dubbo;\n+        this.welcome = DubboLogo.DUBBO;\n     }\n \n     private String welcome;\ndiff --git a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/handler/QosProcessHandler.java b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/handler/QosProcessHandler.java\nindex 0341f50999..245b820d7e 100644\n--- a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/handler/QosProcessHandler.java\n+++ b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/handler/QosProcessHandler.java\n@@ -43,7 +43,7 @@ public class QosProcessHandler extends ByteToMessageDecoder {\n     // true means to accept foreign IP\n     private boolean acceptForeignIp;\n \n-    public static final String prompt = \"dubbo>\";\n+    public static final String PROMPT = \"dubbo>\";\n \n     public QosProcessHandler(String welcome, boolean acceptForeignIp) {\n         this.welcome = welcome;\n@@ -58,7 +58,7 @@ public class QosProcessHandler extends ByteToMessageDecoder {\n             public void run() {\n                 if (welcome != null) {\n                     ctx.write(Unpooled.wrappedBuffer(welcome.getBytes()));\n-                    ctx.writeAndFlush(Unpooled.wrappedBuffer(prompt.getBytes()));\n+                    ctx.writeAndFlush(Unpooled.wrappedBuffer(PROMPT.getBytes()));\n                 }\n             }\n \ndiff --git a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/handler/TelnetProcessHandler.java b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/handler/TelnetProcessHandler.java\nindex 2faffa04e7..f19f727f14 100644\n--- a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/handler/TelnetProcessHandler.java\n+++ b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/server/handler/TelnetProcessHandler.java\n@@ -35,33 +35,33 @@ import io.netty.channel.SimpleChannelInboundHandler;\n  */\n public class TelnetProcessHandler extends SimpleChannelInboundHandler<String> {\n \n-    private static final Logger log = LoggerFactory.getLogger(TelnetProcessHandler.class);\n-    private static CommandExecutor commandExecutor = new DefaultCommandExecutor();\n+    private static final Logger LOGGER = LoggerFactory.getLogger(TelnetProcessHandler.class);\n+    private static CommandExecutor COMMAND_EXECUTOR = new DefaultCommandExecutor();\n \n     @Override\n     protected void channelRead0(ChannelHandlerContext ctx, String msg) throws Exception {\n \n         if (StringUtils.isBlank(msg)) {\n-            ctx.writeAndFlush(QosProcessHandler.prompt);\n+            ctx.writeAndFlush(QosProcessHandler.PROMPT);\n         } else {\n             CommandContext commandContext = TelnetCommandDecoder.decode(msg);\n             commandContext.setRemote(ctx.channel());\n \n             try {\n-                String result = commandExecutor.execute(commandContext);\n+                String result = COMMAND_EXECUTOR.execute(commandContext);\n                 if (StringUtils.isEquals(QosConstants.CLOSE, result)) {\n                     ctx.writeAndFlush(getByeLabel()).addListener(ChannelFutureListener.CLOSE);\n                 } else {\n-                    ctx.writeAndFlush(result + QosConstants.BR_STR + QosProcessHandler.prompt);\n+                    ctx.writeAndFlush(result + QosConstants.BR_STR + QosProcessHandler.PROMPT);\n                 }\n             } catch (NoSuchCommandException ex) {\n                 ctx.writeAndFlush(msg + \" :no such command\");\n-                ctx.writeAndFlush(QosConstants.BR_STR + QosProcessHandler.prompt);\n-                log.error(\"can not found command \" + commandContext, ex);\n+                ctx.writeAndFlush(QosConstants.BR_STR + QosProcessHandler.PROMPT);\n+                LOGGER.error(\"can not found command \" + commandContext, ex);\n             } catch (Exception ex) {\n                 ctx.writeAndFlush(msg + \" :fail to execute commandContext by \" + ex.getMessage());\n-                ctx.writeAndFlush(QosConstants.BR_STR + QosProcessHandler.prompt);\n-                log.error(\"execute commandContext got exception \" + commandContext, ex);\n+                ctx.writeAndFlush(QosConstants.BR_STR + QosProcessHandler.PROMPT);\n+                LOGGER.error(\"execute commandContext got exception \" + commandContext, ex);\n             }\n         }\n     }\ndiff --git a/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/DispatcherServlet.java b/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/DispatcherServlet.java\nindex bf75230fb3..3500f05e0f 100644\n--- a/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/DispatcherServlet.java\n+++ b/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/DispatcherServlet.java\n@@ -1,65 +1,65 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.remoting.http.servlet;\r\n-\r\n-import org.apache.dubbo.remoting.http.HttpHandler;\r\n-\r\n-import javax.servlet.ServletException;\r\n-import javax.servlet.http.HttpServlet;\r\n-import javax.servlet.http.HttpServletRequest;\r\n-import javax.servlet.http.HttpServletResponse;\r\n-import java.io.IOException;\r\n-import java.util.Map;\r\n-import java.util.concurrent.ConcurrentHashMap;\r\n-\r\n-/**\r\n- * Service dispatcher Servlet.\r\n- */\r\n-public class DispatcherServlet extends HttpServlet {\r\n-\r\n-    private static final long serialVersionUID = 5766349180380479888L;\r\n-    private static final Map<Integer, HttpHandler> handlers = new ConcurrentHashMap<Integer, HttpHandler>();\r\n-    private static DispatcherServlet INSTANCE;\r\n-\r\n-    public DispatcherServlet() {\r\n-        DispatcherServlet.INSTANCE = this;\r\n-    }\r\n-\r\n-    public static void addHttpHandler(int port, HttpHandler processor) {\r\n-        handlers.put(port, processor);\r\n-    }\r\n-\r\n-    public static void removeHttpHandler(int port) {\r\n-        handlers.remove(port);\r\n-    }\r\n-\r\n-    public static DispatcherServlet getInstance() {\r\n-        return INSTANCE;\r\n-    }\r\n-\r\n-    @Override\r\n-    protected void service(HttpServletRequest request, HttpServletResponse response)\r\n-            throws ServletException, IOException {\r\n-        HttpHandler handler = handlers.get(request.getLocalPort());\r\n-        if (handler == null) {// service not found.\r\n-            response.sendError(HttpServletResponse.SC_NOT_FOUND, \"Service not found.\");\r\n-        } else {\r\n-            handler.handle(request, response);\r\n-        }\r\n-    }\r\n-\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.remoting.http.servlet;\n+\n+import org.apache.dubbo.remoting.http.HttpHandler;\n+\n+import javax.servlet.ServletException;\n+import javax.servlet.http.HttpServlet;\n+import javax.servlet.http.HttpServletRequest;\n+import javax.servlet.http.HttpServletResponse;\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Service dispatcher Servlet.\n+ */\n+public class DispatcherServlet extends HttpServlet {\n+\n+    private static final long serialVersionUID = 5766349180380479888L;\n+    private static final Map<Integer, HttpHandler> HANDLERS = new ConcurrentHashMap<Integer, HttpHandler>();\n+    private static DispatcherServlet INSTANCE;\n+\n+    public DispatcherServlet() {\n+        DispatcherServlet.INSTANCE = this;\n+    }\n+\n+    public static void addHttpHandler(int port, HttpHandler processor) {\n+        HANDLERS.put(port, processor);\n+    }\n+\n+    public static void removeHttpHandler(int port) {\n+        HANDLERS.remove(port);\n+    }\n+\n+    public static DispatcherServlet getInstance() {\n+        return INSTANCE;\n+    }\n+\n+    @Override\n+    protected void service(HttpServletRequest request, HttpServletResponse response)\n+            throws ServletException, IOException {\n+        HttpHandler handler = HANDLERS.get(request.getLocalPort());\n+        if (handler == null) {// service not found.\n+            response.sendError(HttpServletResponse.SC_NOT_FOUND, \"Service not found.\");\n+        } else {\n+            handler.handle(request, response);\n+        }\n+    }\n+\n+}\ndiff --git a/dubbo-remoting/dubbo-remoting-netty4/src/main/java/org/apache/dubbo/remoting/transport/netty4/NettyClient.java b/dubbo-remoting/dubbo-remoting-netty4/src/main/java/org/apache/dubbo/remoting/transport/netty4/NettyClient.java\nindex 697a79a6b6..6f91cfd6b0 100644\n--- a/dubbo-remoting/dubbo-remoting-netty4/src/main/java/org/apache/dubbo/remoting/transport/netty4/NettyClient.java\n+++ b/dubbo-remoting/dubbo-remoting-netty4/src/main/java/org/apache/dubbo/remoting/transport/netty4/NettyClient.java\n@@ -55,7 +55,7 @@ public class NettyClient extends AbstractClient {\n     /**\n      * netty client bootstrap\n      */\n-    private static final EventLoopGroup eventLoopGroup = eventLoopGroup(Constants.DEFAULT_IO_THREADS, \"NettyClientWorker\");\n+    private static final EventLoopGroup EVENT_LOOP_GROUP = eventLoopGroup(Constants.DEFAULT_IO_THREADS, \"NettyClientWorker\");\n \n     private static final String SOCKS_PROXY_HOST = \"socksProxyHost\";\n \n@@ -91,7 +91,7 @@ public class NettyClient extends AbstractClient {\n     protected void doOpen() throws Throwable {\n         final NettyClientHandler nettyClientHandler = new NettyClientHandler(getUrl(), this);\n         bootstrap = new Bootstrap();\n-        bootstrap.group(eventLoopGroup)\n+        bootstrap.group(EVENT_LOOP_GROUP)\n                 .option(ChannelOption.SO_KEEPALIVE, true)\n                 .option(ChannelOption.TCP_NODELAY, true)\n                 .option(ChannelOption.ALLOCATOR, PooledByteBufAllocator.DEFAULT)\ndiff --git a/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/filter/DeprecatedFilter.java b/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/filter/DeprecatedFilter.java\nindex 59fe7c4e18..c4f5695d8e 100644\n--- a/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/filter/DeprecatedFilter.java\n+++ b/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/filter/DeprecatedFilter.java\n@@ -1,78 +1,78 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.rpc.filter;\r\n-\r\n-import org.apache.dubbo.common.constants.CommonConstants;\r\n-import org.apache.dubbo.common.extension.Activate;\r\n-import org.apache.dubbo.common.logger.Logger;\r\n-import org.apache.dubbo.common.logger.LoggerFactory;\r\n-import org.apache.dubbo.common.utils.ConcurrentHashSet;\r\n-import org.apache.dubbo.rpc.Filter;\r\n-import org.apache.dubbo.rpc.Invocation;\r\n-import org.apache.dubbo.rpc.Invoker;\r\n-import org.apache.dubbo.rpc.Result;\r\n-import org.apache.dubbo.rpc.RpcException;\r\n-\r\n-import java.util.Set;\r\n-\r\n-import static org.apache.dubbo.rpc.Constants.DEPRECATED_KEY;\r\n-\r\n-/**\r\n- * DeprecatedFilter logs error message if a invoked method has been marked as deprecated. To check whether a method\r\n- * is deprecated or not it looks for <b>deprecated</b> attribute value and consider it is deprecated it value is <b>true</b>\r\n- *\r\n- * @see Filter\r\n- */\r\n-@Activate(group = CommonConstants.CONSUMER, value = DEPRECATED_KEY)\r\n-public class DeprecatedFilter implements Filter {\r\n-\r\n-    private static final Logger LOGGER = LoggerFactory.getLogger(DeprecatedFilter.class);\r\n-\r\n-    private static final Set<String> logged = new ConcurrentHashSet<String>();\r\n-\r\n-    @Override\r\n-    public Result invoke(Invoker<?> invoker, Invocation invocation) throws RpcException {\r\n-        String key = invoker.getInterface().getName() + \".\" + invocation.getMethodName();\r\n-        if (!logged.contains(key)) {\r\n-            logged.add(key);\r\n-            if (invoker.getUrl().getMethodParameter(invocation.getMethodName(), DEPRECATED_KEY, false)) {\r\n-                LOGGER.error(\"The service method \" + invoker.getInterface().getName() + \".\" + getMethodSignature(invocation) + \" is DEPRECATED! Declare from \" + invoker.getUrl());\r\n-            }\r\n-        }\r\n-        return invoker.invoke(invocation);\r\n-    }\r\n-\r\n-    private String getMethodSignature(Invocation invocation) {\r\n-        StringBuilder buf = new StringBuilder(invocation.getMethodName());\r\n-        buf.append(\"(\");\r\n-        Class<?>[] types = invocation.getParameterTypes();\r\n-        if (types != null && types.length > 0) {\r\n-            boolean first = true;\r\n-            for (Class<?> type : types) {\r\n-                if (first) {\r\n-                    first = false;\r\n-                } else {\r\n-                    buf.append(\", \");\r\n-                }\r\n-                buf.append(type.getSimpleName());\r\n-            }\r\n-        }\r\n-        buf.append(\")\");\r\n-        return buf.toString();\r\n-    }\r\n-\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.rpc.filter;\n+\n+import org.apache.dubbo.common.constants.CommonConstants;\n+import org.apache.dubbo.common.extension.Activate;\n+import org.apache.dubbo.common.logger.Logger;\n+import org.apache.dubbo.common.logger.LoggerFactory;\n+import org.apache.dubbo.common.utils.ConcurrentHashSet;\n+import org.apache.dubbo.rpc.Filter;\n+import org.apache.dubbo.rpc.Invocation;\n+import org.apache.dubbo.rpc.Invoker;\n+import org.apache.dubbo.rpc.Result;\n+import org.apache.dubbo.rpc.RpcException;\n+\n+import java.util.Set;\n+\n+import static org.apache.dubbo.rpc.Constants.DEPRECATED_KEY;\n+\n+/**\n+ * DeprecatedFilter logs error message if a invoked method has been marked as deprecated. To check whether a method\n+ * is deprecated or not it looks for <b>deprecated</b> attribute value and consider it is deprecated it value is <b>true</b>\n+ *\n+ * @see Filter\n+ */\n+@Activate(group = CommonConstants.CONSUMER, value = DEPRECATED_KEY)\n+public class DeprecatedFilter implements Filter {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(DeprecatedFilter.class);\n+\n+    private static final Set<String> LOGGED = new ConcurrentHashSet<String>();\n+\n+    @Override\n+    public Result invoke(Invoker<?> invoker, Invocation invocation) throws RpcException {\n+        String key = invoker.getInterface().getName() + \".\" + invocation.getMethodName();\n+        if (!LOGGED.contains(key)) {\n+            LOGGED.add(key);\n+            if (invoker.getUrl().getMethodParameter(invocation.getMethodName(), DEPRECATED_KEY, false)) {\n+                LOGGER.error(\"The service method \" + invoker.getInterface().getName() + \".\" + getMethodSignature(invocation) + \" is DEPRECATED! Declare from \" + invoker.getUrl());\n+            }\n+        }\n+        return invoker.invoke(invocation);\n+    }\n+\n+    private String getMethodSignature(Invocation invocation) {\n+        StringBuilder buf = new StringBuilder(invocation.getMethodName());\n+        buf.append(\"(\");\n+        Class<?>[] types = invocation.getParameterTypes();\n+        if (types != null && types.length > 0) {\n+            boolean first = true;\n+            for (Class<?> type : types) {\n+                if (first) {\n+                    first = false;\n+                } else {\n+                    buf.append(\", \");\n+                }\n+                buf.append(type.getSimpleName());\n+            }\n+        }\n+        buf.append(\")\");\n+        return buf.toString();\n+    }\n+\n+}\ndiff --git a/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/CallbackServiceCodec.java b/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/CallbackServiceCodec.java\nindex 98facee2f6..52373e4f20 100644\n--- a/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/CallbackServiceCodec.java\n+++ b/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/CallbackServiceCodec.java\n@@ -56,7 +56,7 @@ class CallbackServiceCodec {\n     private static final Logger logger = LoggerFactory.getLogger(CallbackServiceCodec.class);\n \n     private static final ProxyFactory PROXY_FACTORY = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();\n-    private static final DubboProtocol protocol = DubboProtocol.getDubboProtocol();\n+    private static final DubboProtocol PROTOCOL = DubboProtocol.getDubboProtocol();\n     private static final byte CALLBACK_NONE = 0x0;\n     private static final byte CALLBACK_CREATE = 0x1;\n     private static final byte CALLBACK_DESTROY = 0x2;\n@@ -119,7 +119,7 @@ class CallbackServiceCodec {\n                 if (!isInstancesOverLimit(channel, url, clazz.getName(), instid, false)) {\n                     Invoker<?> invoker = PROXY_FACTORY.getInvoker(inst, clazz, exportUrl);\n                     // should destroy resource?\n-                    Exporter<?> exporter = protocol.export(invoker);\n+                    Exporter<?> exporter = PROTOCOL.export(invoker);\n                     // this is used for tracing if instid has published service or not.\n                     channel.setAttribute(cacheKey, exporter);\n                     logger.info(\"Export a callback service :\" + exportUrl + \", on \" + channel + \", url is: \" + url);\ndiff --git a/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/filter/TraceFilter.java b/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/filter/TraceFilter.java\nindex 9d922fc86c..25d390ee3f 100644\n--- a/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/filter/TraceFilter.java\n+++ b/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/filter/TraceFilter.java\n@@ -51,13 +51,13 @@ public class TraceFilter implements Filter {\n \n     private static final String TRACE_COUNT = \"trace.count\";\n \n-    private static final ConcurrentMap<String, Set<Channel>> tracers = new ConcurrentHashMap<>();\n+    private static final ConcurrentMap<String, Set<Channel>> TRACERS = new ConcurrentHashMap<>();\n \n     public static void addTracer(Class<?> type, String method, Channel channel, int max) {\n         channel.setAttribute(TRACE_MAX, max);\n         channel.setAttribute(TRACE_COUNT, new AtomicInteger());\n         String key = method != null && method.length() > 0 ? type.getName() + \".\" + method : type.getName();\n-        Set<Channel> channels = tracers.computeIfAbsent(key, k -> new ConcurrentHashSet<>());\n+        Set<Channel> channels = TRACERS.computeIfAbsent(key, k -> new ConcurrentHashSet<>());\n         channels.add(channel);\n     }\n \n@@ -65,7 +65,7 @@ public class TraceFilter implements Filter {\n         channel.removeAttribute(TRACE_MAX);\n         channel.removeAttribute(TRACE_COUNT);\n         String key = method != null && method.length() > 0 ? type.getName() + \".\" + method : type.getName();\n-        Set<Channel> channels = tracers.get(key);\n+        Set<Channel> channels = TRACERS.get(key);\n         if (channels != null) {\n             channels.remove(channel);\n         }\n@@ -76,12 +76,12 @@ public class TraceFilter implements Filter {\n         long start = System.currentTimeMillis();\n         Result result = invoker.invoke(invocation);\n         long end = System.currentTimeMillis();\n-        if (tracers.size() > 0) {\n+        if (TRACERS.size() > 0) {\n             String key = invoker.getInterface().getName() + \".\" + invocation.getMethodName();\n-            Set<Channel> channels = tracers.get(key);\n+            Set<Channel> channels = TRACERS.get(key);\n             if (channels == null || channels.isEmpty()) {\n                 key = invoker.getInterface().getName();\n-                channels = tracers.get(key);\n+                channels = TRACERS.get(key);\n             }\n             if (CollectionUtils.isNotEmpty(channels)) {\n                 for (Channel channel : new ArrayList<>(channels)) {\ndiff --git a/dubbo-rpc/dubbo-rpc-native-thrift/src/main/java/org/apache/dubbo/rpc/protocol/nativethrift/ThriftProtocol.java b/dubbo-rpc/dubbo-rpc-native-thrift/src/main/java/org/apache/dubbo/rpc/protocol/nativethrift/ThriftProtocol.java\nindex c5b729bda3..8250151f27 100644\n--- a/dubbo-rpc/dubbo-rpc-native-thrift/src/main/java/org/apache/dubbo/rpc/protocol/nativethrift/ThriftProtocol.java\n+++ b/dubbo-rpc/dubbo-rpc-native-thrift/src/main/java/org/apache/dubbo/rpc/protocol/nativethrift/ThriftProtocol.java\n@@ -55,7 +55,7 @@ public class ThriftProtocol extends AbstractProxyProtocol {\n     public static final String THRIFT_PROCESSOR = \"$Processor\";\n     public static final String THRIFT_CLIENT = \"$Client\";\n \n-    private static final Map<String, TServer> serverMap = new HashMap<>();\n+    private static final Map<String, TServer> SERVER_MAP = new HashMap<>();\n     private TMultiplexedProcessor processor = new TMultiplexedProcessor();\n \n     public ThriftProtocol() {\n@@ -95,7 +95,7 @@ public class ThriftProtocol extends AbstractProxyProtocol {\n                     TProcessor tprocessor = (TProcessor) constructor.newInstance(impl);\n                     processor.registerProcessor(typeName, tprocessor);\n \n-                    if (serverMap.get(url.getAddress()) == null) {\n+                    if (SERVER_MAP.get(url.getAddress()) == null) {\n \n                         /**Solve the problem of only 50 of the default number of concurrent connections*/\n                         TNonblockingServerSocket.NonblockingAbstractServerSocketArgs args = new TNonblockingServerSocket.NonblockingAbstractServerSocketArgs();\n@@ -139,7 +139,7 @@ public class ThriftProtocol extends AbstractProxyProtocol {\n             throw new RpcException(\"Fail to create nativethrift server(\" + url + \") due to null args\");\n         }\n         final TServer thriftServer = new TThreadedSelectorServer(tArgs);\n-        serverMap.put(url.getAddress(), thriftServer);\n+        SERVER_MAP.put(url.getAddress(), thriftServer);\n \n         new Thread(() -> {\n             logger.info(\"Start Thrift ThreadedSelectorServer\");\ndiff --git a/dubbo-serialization/dubbo-serialization-fst/src/main/java/org/apache/dubbo/common/serialize/fst/FstFactory.java b/dubbo-serialization/dubbo-serialization-fst/src/main/java/org/apache/dubbo/common/serialize/fst/FstFactory.java\nindex e41c358b43..f73259ff3b 100644\n--- a/dubbo-serialization/dubbo-serialization-fst/src/main/java/org/apache/dubbo/common/serialize/fst/FstFactory.java\n+++ b/dubbo-serialization/dubbo-serialization-fst/src/main/java/org/apache/dubbo/common/serialize/fst/FstFactory.java\n@@ -30,13 +30,13 @@ import java.io.OutputStream;\n  */\n public class FstFactory {\n \n-    private static final FstFactory factory = new FstFactory();\n+    private static final FstFactory FACTORY = new FstFactory();\n \n     private final FSTConfiguration conf = FSTConfiguration.createDefaultConfiguration();\n \n \n     public static FstFactory getDefaultFactory() {\n-        return factory;\n+        return FACTORY;\n     }\n \n     public FstFactory() {\n"}
{"instance_id": "apache__dubbo-6498", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-rpc/dubbo-rpc-webservice/src/main/java/org/apache/dubbo/rpc/protocol/webservice/WebServiceProtocol.java b/dubbo-rpc/dubbo-rpc-webservice/src/main/java/org/apache/dubbo/rpc/protocol/webservice/WebServiceProtocol.java\nindex dff3bd1e13..0d8dceda0d 100644\n--- a/dubbo-rpc/dubbo-rpc-webservice/src/main/java/org/apache/dubbo/rpc/protocol/webservice/WebServiceProtocol.java\n+++ b/dubbo-rpc/dubbo-rpc-webservice/src/main/java/org/apache/dubbo/rpc/protocol/webservice/WebServiceProtocol.java\n@@ -105,7 +105,7 @@ public class WebServiceProtocol extends AbstractProxyProtocol {\n             serverMap.put(addr, new ProxyProtocolServer(remotingServer));\n         }\n         serverFactoryBean = new ServerFactoryBean();\n-        serverFactoryBean.setAddress(url.getAbsolutePath());\n+        serverFactoryBean.setAddress(\"/\" + url.getServiceInterface());\n         serverFactoryBean.setServiceClass(type);\n         serverFactoryBean.setServiceBean(impl);\n         serverFactoryBean.setBus(bus);\n"}
{"instance_id": "apache__dubbo-5708", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/legacy/SelectTelnetHandler.java b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/legacy/SelectTelnetHandler.java\nindex 700b6ae841..2db7f54da3 100644\n--- a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/legacy/SelectTelnetHandler.java\n+++ b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/legacy/SelectTelnetHandler.java\n@@ -51,7 +51,7 @@ public class SelectTelnetHandler implements TelnetHandler {\n         if (!StringUtils.isInteger(message) || Integer.parseInt(message) < 1 || Integer.parseInt(message) > methodList.size()) {\n             return \"Illegal index ,please input select 1~\" + methodList.size();\n         }\n-        Method method = methodList.get(Integer.parseInt(message));\n+        Method method = methodList.get(Integer.parseInt(message) - 1);\n         channel.setAttribute(SELECT_METHOD_KEY, method);\n         channel.setAttribute(SELECT_KEY, Boolean.TRUE);\n         String invokeMessage = (String) channel.getAttribute(InvokeTelnetHandler.INVOKE_MESSAGE_KEY);\n"}
{"instance_id": "apache__rocketmq-1636", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/AbstractSendMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/AbstractSendMessageProcessor.java\nindex b0668d49f..0bf28dc19 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/AbstractSendMessageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/AbstractSendMessageProcessor.java\n@@ -142,7 +142,7 @@ public abstract class AbstractSendMessageProcessor implements NettyRequestProces\n     protected RemotingCommand msgContentCheck(final ChannelHandlerContext ctx,\n         final SendMessageRequestHeader requestHeader, RemotingCommand request,\n         final RemotingCommand response) {\n-        if (requestHeader.getTopic().length() > Byte.MAX_VALUE) {\n+        if (requestHeader.getTopic().length() > 255) {\n             log.warn(\"putMessage message topic length too long {}\", requestHeader.getTopic().length());\n             response.setCode(ResponseCode.MESSAGE_ILLEGAL);\n             return response;\ndiff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/SendMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/SendMessageProcessor.java\nindex 2589a7547..14ec2f2a9 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/SendMessageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/SendMessageProcessor.java\n@@ -510,7 +510,7 @@ public class SendMessageProcessor extends AbstractSendMessageProcessor implement\n             queueIdInt = Math.abs(this.random.nextInt() % 99999999) % topicConfig.getWriteQueueNums();\n         }\n \n-        if (requestHeader.getTopic().length() > Byte.MAX_VALUE) {\n+        if (requestHeader.getTopic().length() > 255) {\n             response.setCode(ResponseCode.MESSAGE_ILLEGAL);\n             response.setRemark(\"message topic length too long \" + requestHeader.getTopic().length());\n             return response;\ndiff --git a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\nindex d5ba5692a..ddf31dec2 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\n@@ -377,7 +377,7 @@ public class DefaultMessageStore implements MessageStore {\n             this.printTimes.set(0);\n         }\n \n-        if (msg.getTopic().length() > Byte.MAX_VALUE) {\n+        if (msg.getTopic().length() > 255) {\n             log.warn(\"putMessage message topic length too long \" + msg.getTopic().length());\n             return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);\n         }\n@@ -433,7 +433,7 @@ public class DefaultMessageStore implements MessageStore {\n             this.printTimes.set(0);\n         }\n \n-        if (messageExtBatch.getTopic().length() > Byte.MAX_VALUE) {\n+        if (messageExtBatch.getTopic().length() > 255) {\n             log.warn(\"PutMessages topic length too long \" + messageExtBatch.getTopic().length());\n             return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);\n         }\n"}
{"instance_id": "apache__dubbo-4678", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java b/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java\nindex d557624a66..caf9220ffb 100644\n--- a/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java\n+++ b/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java\n@@ -507,6 +507,16 @@ public abstract class AbstractConfig implements Serializable {\n                         metaData.put(key, null);\n                         continue;\n                     }\n+\n+                    /**\n+                     * Exclude methods annotated with @Parameter(excluded = true).\n+                     * This is important for cases like isGeneric()/getGeneric() where both methods\n+                     * map to the same key \"generic\", but isGeneric() is a derived/computed property\n+                     * that should not be included in metadata.\n+                     */\n+                    if (parameter != null && parameter.excluded()) {\n+                        continue;\n+                    }\n                     Object value = method.invoke(this);\n                     String str = String.valueOf(value).trim();\n                     if (value != null && str.length() > 0) {\n"}
{"instance_id": "angular__angular-37561", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/core/src/render3/di.ts b/packages/core/src/render3/di.ts\nindex 14a40667cd..980b7a21d8 100644\n--- a/packages/core/src/render3/di.ts\n+++ b/packages/core/src/render3/di.ts\n@@ -657,16 +657,54 @@ export function \u0275\u0275getFactoryOf<T>(type: Type<any>): FactoryFn<T>|null {\n  */\n export function \u0275\u0275getInheritedFactory<T>(type: Type<any>): (type: Type<T>) => T {\n   return noSideEffects(() => {\n-    const proto = Object.getPrototypeOf(type.prototype).constructor as Type<any>;\n-    const factory = (proto as any)[NG_FACTORY_DEF] || \u0275\u0275getFactoryOf<T>(proto);\n-    if (factory !== null) {\n-      return factory;\n-    } else {\n-      // There is no factory defined. Either this was improper usage of inheritance\n-      // (no Angular decorator on the superclass) or there is no constructor at all\n-      // in the inheritance chain. Since the two cases cannot be distinguished, the\n-      // latter has to be assumed.\n-      return (t) => new t();\n+    const ownConstructor = type.prototype.constructor;\n+    const ownFactory = ownConstructor.hasOwnProperty(NG_FACTORY_DEF) ?\n+        (ownConstructor as any)[NG_FACTORY_DEF] :\n+        null;\n+\n+    // Walk up the prototype chain to find a factory that is different from the current type's\n+    // factory. We use hasOwnProperty to check each level to avoid picking up factories from\n+    // the prototype chain that belong to the current type (which would cause infinite recursion).\n+    let currentProto = Object.getPrototypeOf(type.prototype);\n+\n+    while (currentProto) {\n+      const currentConstructor = currentProto.constructor as Type<any>;\n+\n+      // If we've reached the top of the inheritance chain (Object), stop.\n+      if (currentConstructor === ownConstructor || currentConstructor === Object) {\n+        break;\n+      }\n+\n+      // Check if this level has its own factory (not inherited from further up the chain)\n+      if (currentConstructor.hasOwnProperty(NG_FACTORY_DEF)) {\n+        const factory = (currentConstructor as any)[NG_FACTORY_DEF];\n+        // Make sure it's not the same factory as the current type's factory\n+        if (factory !== ownFactory) {\n+          return factory;\n+        }\n+      }\n+\n+      // Move up the prototype chain\n+      currentProto = Object.getPrototypeOf(currentProto);\n     }\n+\n+    // If we didn't find a factory with hasOwnProperty, try using \u0275\u0275getFactoryOf\n+    // which may find a factory through other means (e.g., injector def)\n+    const proto = Object.getPrototypeOf(type.prototype);\n+    if (proto) {\n+      const parentConstructor = proto.constructor as Type<any>;\n+      if (parentConstructor !== ownConstructor && parentConstructor !== Object) {\n+        const factory = \u0275\u0275getFactoryOf<T>(parentConstructor);\n+        if (factory !== null) {\n+          return factory;\n+        }\n+      }\n+    }\n+\n+    // There is no factory defined. Either this was improper usage of inheritance\n+    // (no Angular decorator on the superclass) or there is no constructor at all\n+    // in the inheritance chain. Since the two cases cannot be distinguished, the\n+    // latter has to be assumed.\n+    return (t) => new t();\n   });\n }\n"}
{"instance_id": "apache__rocketmq-5008", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetAssigner.java b/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetAssigner.java\nindex 55614ccba..fb24deb0a 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetAssigner.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetAssigner.java\n@@ -22,6 +22,7 @@ import java.util.concurrent.ConcurrentMap;\n import org.apache.rocketmq.common.constant.LoggerName;\n import org.apache.rocketmq.logging.InternalLogger;\n import org.apache.rocketmq.logging.InternalLoggerFactory;\n+import org.apache.rocketmq.srvutil.ConcurrentHashMapUtil;\n \n /**\n  * QueueOffsetAssigner is a component for assigning offsets for queues.\n@@ -35,7 +36,7 @@ public class QueueOffsetAssigner {\n     private ConcurrentMap<String/* topic-queueid */, Long/* offset */> lmqTopicQueueTable = new ConcurrentHashMap<>(1024);\n \n     public long assignQueueOffset(String topicQueueKey, short messageNum) {\n-        long queueOffset = this.topicQueueTable.computeIfAbsent(topicQueueKey, k -> 0L);\n+        Long queueOffset = ConcurrentHashMapUtil.computeIfAbsent(this.topicQueueTable, topicQueueKey, k -> 0L);\n         this.topicQueueTable.put(topicQueueKey, queueOffset + messageNum);\n         return queueOffset;\n     }\n@@ -45,13 +46,13 @@ public class QueueOffsetAssigner {\n     }\n \n     public long assignBatchQueueOffset(String topicQueueKey, short messageNum) {\n-        Long topicOffset = this.batchTopicQueueTable.computeIfAbsent(topicQueueKey, k -> 0L);\n+        Long topicOffset = ConcurrentHashMapUtil.computeIfAbsent(this.batchTopicQueueTable, topicQueueKey, k -> 0L);\n         this.batchTopicQueueTable.put(topicQueueKey, topicOffset + messageNum);\n         return topicOffset;\n     }\n \n     public long assignLmqOffset(String topicQueueKey, short messageNum) {\n-        long topicOffset = this.lmqTopicQueueTable.computeIfAbsent(topicQueueKey, k -> 0L);\n+        Long topicOffset = ConcurrentHashMapUtil.computeIfAbsent(this.lmqTopicQueueTable, topicQueueKey, k -> 0L);\n         this.lmqTopicQueueTable.put(topicQueueKey, topicOffset + messageNum);\n         return topicOffset;\n     }\n"}
{"instance_id": "apache__dubbo-8623", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-rpc/dubbo-rpc-api/src/main/java/com/alibaba/dubbo/rpc/support/MockInvoker.java b/dubbo-rpc/dubbo-rpc-api/src/main/java/com/alibaba/dubbo/rpc/support/MockInvoker.java\nindex fc99bdcd1e..49c3096e2e 100644\n--- a/dubbo-rpc/dubbo-rpc-api/src/main/java/com/alibaba/dubbo/rpc/support/MockInvoker.java\n+++ b/dubbo-rpc/dubbo-rpc-api/src/main/java/com/alibaba/dubbo/rpc/support/MockInvoker.java\n@@ -1,255 +1,260 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package com.alibaba.dubbo.rpc.support;\r\n-\r\n-import com.alibaba.dubbo.common.Constants;\r\n-import com.alibaba.dubbo.common.URL;\r\n-import com.alibaba.dubbo.common.extension.ExtensionLoader;\r\n-import com.alibaba.dubbo.common.utils.ConfigUtils;\r\n-import com.alibaba.dubbo.common.utils.PojoUtils;\r\n-import com.alibaba.dubbo.common.utils.ReflectUtils;\r\n-import com.alibaba.dubbo.common.utils.StringUtils;\r\n-import com.alibaba.dubbo.rpc.Invocation;\r\n-import com.alibaba.dubbo.rpc.Invoker;\r\n-import com.alibaba.dubbo.rpc.ProxyFactory;\r\n-import com.alibaba.dubbo.rpc.Result;\r\n-import com.alibaba.dubbo.rpc.RpcException;\r\n-import com.alibaba.dubbo.rpc.RpcInvocation;\r\n-import com.alibaba.dubbo.rpc.RpcResult;\r\n-import com.alibaba.fastjson.JSON;\r\n-\r\n-import java.lang.reflect.Constructor;\r\n-import java.lang.reflect.Type;\r\n-import java.util.List;\r\n-import java.util.Map;\r\n-import java.util.concurrent.ConcurrentHashMap;\r\n-\r\n-final public class MockInvoker<T> implements Invoker<T> {\r\n-    private final static ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();\r\n-    private final static Map<String, Invoker<?>> mocks = new ConcurrentHashMap<String, Invoker<?>>();\r\n-    private final static Map<String, Throwable> throwables = new ConcurrentHashMap<String, Throwable>();\r\n-\r\n-    private final URL url;\r\n-\r\n-    public MockInvoker(URL url) {\r\n-        this.url = url;\r\n-    }\r\n-\r\n-    public static Object parseMockValue(String mock) throws Exception {\r\n-        return parseMockValue(mock, null);\r\n-    }\r\n-\r\n-    public static Object parseMockValue(String mock, Type[] returnTypes) throws Exception {\r\n-        Object value = null;\r\n-        if (\"empty\".equals(mock)) {\r\n-            value = ReflectUtils.getEmptyObject(returnTypes != null && returnTypes.length > 0 ? (Class<?>) returnTypes[0] : null);\r\n-        } else if (\"null\".equals(mock)) {\r\n-            value = null;\r\n-        } else if (\"true\".equals(mock)) {\r\n-            value = true;\r\n-        } else if (\"false\".equals(mock)) {\r\n-            value = false;\r\n-        } else if (mock.length() >= 2 && (mock.startsWith(\"\\\"\") && mock.endsWith(\"\\\"\")\r\n-                || mock.startsWith(\"\\'\") && mock.endsWith(\"\\'\"))) {\r\n-            value = mock.subSequence(1, mock.length() - 1);\r\n-        } else if (returnTypes != null && returnTypes.length > 0 && returnTypes[0] == String.class) {\r\n-            value = mock;\r\n-        } else if (StringUtils.isNumeric(mock)) {\r\n-            value = JSON.parse(mock);\r\n-        } else if (mock.startsWith(\"{\")) {\r\n-            value = JSON.parseObject(mock, Map.class);\r\n-        } else if (mock.startsWith(\"[\")) {\r\n-            value = JSON.parseObject(mock, List.class);\r\n-        } else {\r\n-            value = mock;\r\n-        }\r\n-        if (returnTypes != null && returnTypes.length > 0) {\r\n-            value = PojoUtils.realize(value, (Class<?>) returnTypes[0], returnTypes.length > 1 ? returnTypes[1] : null);\r\n-        }\r\n-        return value;\r\n-    }\r\n-\r\n-    @Override\r\n-    public Result invoke(Invocation invocation) throws RpcException {\r\n-        String mock = getUrl().getParameter(invocation.getMethodName() + \".\" + Constants.MOCK_KEY);\r\n-        if (invocation instanceof RpcInvocation) {\r\n-            ((RpcInvocation) invocation).setInvoker(this);\r\n-        }\r\n-        if (StringUtils.isBlank(mock)) {\r\n-            mock = getUrl().getParameter(Constants.MOCK_KEY);\r\n-        }\r\n-\r\n-        if (StringUtils.isBlank(mock)) {\r\n-            throw new RpcException(new IllegalAccessException(\"mock can not be null. url :\" + url));\r\n-        }\r\n-        mock = normalizeMock(URL.decode(mock));\r\n-        if (mock.startsWith(Constants.RETURN_PREFIX)) {\r\n-            mock = mock.substring(Constants.RETURN_PREFIX.length()).trim();\r\n-            try {\r\n-                Type[] returnTypes = RpcUtils.getReturnTypes(invocation);\r\n-                Object value = parseMockValue(mock, returnTypes);\r\n-                return new RpcResult(value);\r\n-            } catch (Exception ew) {\r\n-                throw new RpcException(\"mock return invoke error. method :\" + invocation.getMethodName()\r\n-                        + \", mock:\" + mock + \", url: \" + url, ew);\r\n-            }\r\n-        } else if (mock.startsWith(Constants.THROW_PREFIX)) {\r\n-            mock = mock.substring(Constants.THROW_PREFIX.length()).trim();\r\n-            if (StringUtils.isBlank(mock)) {\r\n-                throw new RpcException(\"mocked exception for service degradation.\");\r\n-            } else { // user customized class\r\n-                Throwable t = getThrowable(mock);\r\n-                throw new RpcException(RpcException.BIZ_EXCEPTION, t);\r\n-            }\r\n-        } else { //impl mock\r\n-            try {\r\n-                Invoker<T> invoker = getInvoker(mock);\r\n-                return invoker.invoke(invocation);\r\n-            } catch (Throwable t) {\r\n-                throw new RpcException(\"Failed to create mock implementation class \" + mock, t);\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    public static Throwable getThrowable(String throwstr) {\r\n-        Throwable throwable = throwables.get(throwstr);\r\n-        if (throwable != null) {\r\n-            return throwable;\r\n-        }\r\n-\r\n-        try {\r\n-            Throwable t;\r\n-            Class<?> bizException = ReflectUtils.forName(throwstr);\r\n-            Constructor<?> constructor;\r\n-            constructor = ReflectUtils.findConstructor(bizException, String.class);\r\n-            t = (Throwable) constructor.newInstance(new Object[]{\"mocked exception for service degradation.\"});\r\n-            if (throwables.size() < 1000) {\r\n-                throwables.put(throwstr, t);\r\n-            }\r\n-            return t;\r\n-        } catch (Exception e) {\r\n-            throw new RpcException(\"mock throw error :\" + throwstr + \" argument error.\", e);\r\n-        }\r\n-    }\r\n-\r\n-    @SuppressWarnings(\"unchecked\")\r\n-    private Invoker<T> getInvoker(String mockService) {\r\n-        Invoker<T> invoker = (Invoker<T>) mocks.get(mockService);\r\n-        if (invoker != null) {\r\n-            return invoker;\r\n-        }\r\n-\r\n-        Class<T> serviceType = (Class<T>) ReflectUtils.forName(url.getServiceInterface());\r\n-        T mockObject = (T) getMockObject(mockService, serviceType);\r\n-        invoker = proxyFactory.getInvoker(mockObject, serviceType, url);\r\n-        if (mocks.size() < 10000) {\r\n-            mocks.put(mockService, invoker);\r\n-        }\r\n-        return invoker;\r\n-    }\r\n-\r\n-    @SuppressWarnings(\"unchecked\")\r\n-    public static Object getMockObject(String mockService, Class serviceType) {\r\n-        if (ConfigUtils.isDefault(mockService)) {\r\n-            mockService = serviceType.getName() + \"Mock\";\r\n-        }\r\n-\r\n-        Class<?> mockClass = ReflectUtils.forName(mockService);\r\n-        if (!serviceType.isAssignableFrom(mockClass)) {\r\n-            throw new IllegalStateException(\"The mock class \" + mockClass.getName() +\r\n-                    \" not implement interface \" + serviceType.getName());\r\n-        }\r\n-\r\n-        try {\r\n-            return mockClass.newInstance();\r\n-        } catch (InstantiationException e) {\r\n-            throw new IllegalStateException(\"No default constructor from mock class \" + mockClass.getName(), e);\r\n-        } catch (IllegalAccessException e) {\r\n-            throw new IllegalStateException(e);\r\n-        }\r\n-    }\r\n-\r\n-\r\n-    /**\r\n-     * Normalize mock string:\r\n-     *\r\n-     * <ol>\r\n-     * <li>return => return null</li>\r\n-     * <li>fail => default</li>\r\n-     * <li>force => default</li>\r\n-     * <li>fail:throw/return foo => throw/return foo</li>\r\n-     * <li>force:throw/return foo => throw/return foo</li>\r\n-     * </ol>\r\n-     *\r\n-     * @param mock mock string\r\n-     * @return normalized mock string\r\n-     */\r\n-    public static String normalizeMock(String mock) {\r\n-        if (mock == null) {\r\n-            return mock;\r\n-        }\r\n-\r\n-        mock = mock.trim();\r\n-\r\n-        if (mock.length() == 0) {\r\n-            return mock;\r\n-        }\r\n-\r\n-        if (Constants.RETURN_KEY.equalsIgnoreCase(mock)) {\r\n-            return Constants.RETURN_PREFIX + \"null\";\r\n-        }\r\n-\r\n-        if (ConfigUtils.isDefault(mock) || \"fail\".equalsIgnoreCase(mock) || \"force\".equalsIgnoreCase(mock)) {\r\n-            return \"default\";\r\n-        }\r\n-\r\n-        if (mock.startsWith(Constants.FAIL_PREFIX)) {\r\n-            mock = mock.substring(Constants.FAIL_PREFIX.length()).trim();\r\n-        }\r\n-\r\n-        if (mock.startsWith(Constants.FORCE_PREFIX)) {\r\n-            mock = mock.substring(Constants.FORCE_PREFIX.length()).trim();\r\n-        }\r\n-\r\n-        if (mock.startsWith(Constants.RETURN_PREFIX) || mock.startsWith(Constants.THROW_PREFIX)) {\r\n-            mock = mock.replace('`', '\"');\r\n-        }\r\n-\r\n-        return mock;\r\n-    }\r\n-\r\n-    @Override\r\n-    public URL getUrl() {\r\n-        return this.url;\r\n-    }\r\n-\r\n-    @Override\r\n-    public boolean isAvailable() {\r\n-        return true;\r\n-    }\r\n-\r\n-    @Override\r\n-    public void destroy() {\r\n-        //do nothing\r\n-    }\r\n-\r\n-    @Override\r\n-    public Class<T> getInterface() {\r\n-        //FIXME\r\n-        return null;\r\n-    }\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.alibaba.dubbo.rpc.support;\n+\n+import com.alibaba.dubbo.common.Constants;\n+import com.alibaba.dubbo.common.URL;\n+import com.alibaba.dubbo.common.extension.ExtensionLoader;\n+import com.alibaba.dubbo.common.utils.ConfigUtils;\n+import com.alibaba.dubbo.common.utils.PojoUtils;\n+import com.alibaba.dubbo.common.utils.ReflectUtils;\n+import com.alibaba.dubbo.common.utils.StringUtils;\n+import com.alibaba.dubbo.rpc.Invocation;\n+import com.alibaba.dubbo.rpc.Invoker;\n+import com.alibaba.dubbo.rpc.ProxyFactory;\n+import com.alibaba.dubbo.rpc.Result;\n+import com.alibaba.dubbo.rpc.RpcException;\n+import com.alibaba.dubbo.rpc.RpcInvocation;\n+import com.alibaba.dubbo.rpc.RpcResult;\n+import com.alibaba.fastjson.JSON;\n+\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.Type;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+final public class MockInvoker<T> implements Invoker<T> {\n+    private final static ProxyFactory proxyFactory = ExtensionLoader.getExtensionLoader(ProxyFactory.class).getAdaptiveExtension();\n+    private final static Map<String, Invoker<?>> mocks = new ConcurrentHashMap<String, Invoker<?>>();\n+    private final static Map<String, Throwable> throwables = new ConcurrentHashMap<String, Throwable>();\n+\n+    private final URL url;\n+\n+    public MockInvoker(URL url) {\n+        this.url = url;\n+    }\n+\n+    public static Object parseMockValue(String mock) throws Exception {\n+        return parseMockValue(mock, null);\n+    }\n+\n+    public static Object parseMockValue(String mock, Type[] returnTypes) throws Exception {\n+        Object value = null;\n+        if (\"empty\".equals(mock)) {\n+            value = ReflectUtils.getEmptyObject(returnTypes != null && returnTypes.length > 0 ? (Class<?>) returnTypes[0] : null);\n+        } else if (\"null\".equals(mock)) {\n+            value = null;\n+        } else if (\"true\".equals(mock)) {\n+            value = true;\n+        } else if (\"false\".equals(mock)) {\n+            value = false;\n+        } else if (mock.length() >= 2 && (mock.startsWith(\"\\\"\") && mock.endsWith(\"\\\"\")\n+                || mock.startsWith(\"\\'\") && mock.endsWith(\"\\'\"))) {\n+            value = mock.subSequence(1, mock.length() - 1);\n+        } else if (returnTypes != null && returnTypes.length > 0 && returnTypes[0] == String.class) {\n+            value = mock;\n+        } else if (StringUtils.isNumeric(mock)) {\n+            value = JSON.parse(mock);\n+        } else if (mock.startsWith(\"{\")) {\n+            value = JSON.parseObject(mock, Map.class);\n+        } else if (mock.startsWith(\"[\")) {\n+            value = JSON.parseObject(mock, List.class);\n+        } else {\n+            value = mock;\n+        }\n+        if (returnTypes != null && returnTypes.length > 0) {\n+            value = PojoUtils.realize(value, (Class<?>) returnTypes[0], returnTypes.length > 1 ? returnTypes[1] : null);\n+        }\n+        return value;\n+    }\n+\n+    @Override\n+    public Result invoke(Invocation invocation) throws RpcException {\n+        String mock = getUrl().getParameter(invocation.getMethodName() + \".\" + Constants.MOCK_KEY);\n+        if (invocation instanceof RpcInvocation) {\n+            ((RpcInvocation) invocation).setInvoker(this);\n+        }\n+        if (StringUtils.isBlank(mock)) {\n+            mock = getUrl().getParameter(Constants.MOCK_KEY);\n+        }\n+\n+        if (StringUtils.isBlank(mock)) {\n+            throw new RpcException(new IllegalAccessException(\"mock can not be null. url :\" + url));\n+        }\n+        mock = normalizeMock(URL.decode(mock));\n+        if (mock.startsWith(Constants.RETURN_PREFIX)) {\n+            mock = mock.substring(Constants.RETURN_PREFIX.length()).trim();\n+            try {\n+                Type[] returnTypes = RpcUtils.getReturnTypes(invocation);\n+                Object value = parseMockValue(mock, returnTypes);\n+                return new RpcResult(value);\n+            } catch (Exception ew) {\n+                throw new RpcException(\"mock return invoke error. method :\" + invocation.getMethodName()\n+                        + \", mock:\" + mock + \", url: \" + url, ew);\n+            }\n+        } else if (mock.startsWith(Constants.THROW_PREFIX)) {\n+            mock = mock.substring(Constants.THROW_PREFIX.length()).trim();\n+            if (StringUtils.isBlank(mock)) {\n+                throw new RpcException(\"mocked exception for service degradation.\");\n+            } else { // user customized class\n+                Throwable t = getThrowable(mock);\n+                throw new RpcException(RpcException.BIZ_EXCEPTION, t);\n+            }\n+        } else { //impl mock\n+            try {\n+                Invoker<T> invoker = getInvoker(mock);\n+                return invoker.invoke(invocation);\n+            } catch (Throwable t) {\n+                throw new RpcException(\"Failed to create mock implementation class \" + mock, t);\n+            }\n+        }\n+    }\n+\n+    public static Throwable getThrowable(String throwstr) {\n+        Throwable throwable = throwables.get(throwstr);\n+        if (throwable != null) {\n+            return throwable;\n+        }\n+\n+        try {\n+            Throwable t;\n+            Class<?> bizException = ReflectUtils.forName(throwstr);\n+            Constructor<?> constructor;\n+            constructor = ReflectUtils.findConstructor(bizException, String.class);\n+            t = (Throwable) constructor.newInstance(new Object[]{\"mocked exception for service degradation.\"});\n+            if (throwables.size() < 1000) {\n+                throwables.put(throwstr, t);\n+            }\n+            return t;\n+        } catch (Exception e) {\n+            throw new RpcException(\"mock throw error :\" + throwstr + \" argument error.\", e);\n+        }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private Invoker<T> getInvoker(String mockService) {\n+        Class<T> serviceType = (Class<T>) ReflectUtils.forName(url.getServiceInterface());\n+        String mockServiceName = mockService;\n+        if (ConfigUtils.isDefault(mockService)) {\n+            mockServiceName = serviceType.getName() + \"Mock\";\n+        }\n+\n+        Invoker<T> invoker = (Invoker<T>) mocks.get(mockServiceName);\n+        if (invoker != null) {\n+            return invoker;\n+        }\n+\n+        T mockObject = (T) getMockObject(mockService, serviceType);\n+        invoker = proxyFactory.getInvoker(mockObject, serviceType, url);\n+        if (mocks.size() < 10000) {\n+            mocks.put(mockServiceName, invoker);\n+        }\n+        return invoker;\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    public static Object getMockObject(String mockService, Class serviceType) {\n+        if (ConfigUtils.isDefault(mockService)) {\n+            mockService = serviceType.getName() + \"Mock\";\n+        }\n+\n+        Class<?> mockClass = ReflectUtils.forName(mockService);\n+        if (!serviceType.isAssignableFrom(mockClass)) {\n+            throw new IllegalStateException(\"The mock class \" + mockClass.getName() +\n+                    \" not implement interface \" + serviceType.getName());\n+        }\n+\n+        try {\n+            return mockClass.newInstance();\n+        } catch (InstantiationException e) {\n+            throw new IllegalStateException(\"No default constructor from mock class \" + mockClass.getName(), e);\n+        } catch (IllegalAccessException e) {\n+            throw new IllegalStateException(e);\n+        }\n+    }\n+\n+\n+    /**\n+     * Normalize mock string:\n+     *\n+     * <ol>\n+     * <li>return => return null</li>\n+     * <li>fail => default</li>\n+     * <li>force => default</li>\n+     * <li>fail:throw/return foo => throw/return foo</li>\n+     * <li>force:throw/return foo => throw/return foo</li>\n+     * </ol>\n+     *\n+     * @param mock mock string\n+     * @return normalized mock string\n+     */\n+    public static String normalizeMock(String mock) {\n+        if (mock == null) {\n+            return mock;\n+        }\n+\n+        mock = mock.trim();\n+\n+        if (mock.length() == 0) {\n+            return mock;\n+        }\n+\n+        if (Constants.RETURN_KEY.equalsIgnoreCase(mock)) {\n+            return Constants.RETURN_PREFIX + \"null\";\n+        }\n+\n+        if (ConfigUtils.isDefault(mock) || \"fail\".equalsIgnoreCase(mock) || \"force\".equalsIgnoreCase(mock)) {\n+            return \"default\";\n+        }\n+\n+        if (mock.startsWith(Constants.FAIL_PREFIX)) {\n+            mock = mock.substring(Constants.FAIL_PREFIX.length()).trim();\n+        }\n+\n+        if (mock.startsWith(Constants.FORCE_PREFIX)) {\n+            mock = mock.substring(Constants.FORCE_PREFIX.length()).trim();\n+        }\n+\n+        if (mock.startsWith(Constants.RETURN_PREFIX) || mock.startsWith(Constants.THROW_PREFIX)) {\n+            mock = mock.replace('`', '\"');\n+        }\n+\n+        return mock;\n+    }\n+\n+    @Override\n+    public URL getUrl() {\n+        return this.url;\n+    }\n+\n+    @Override\n+    public boolean isAvailable() {\n+        return true;\n+    }\n+\n+    @Override\n+    public void destroy() {\n+        //do nothing\n+    }\n+\n+    @Override\n+    public Class<T> getInterface() {\n+        //FIXME\n+        return null;\n+    }\n+}\n"}
{"instance_id": "apache__rocketmq-4122", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java b/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java\nindex 12b8ec7f8..c837e32e1 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java\n@@ -88,6 +88,7 @@ public class DLedgerCommitLog extends CommitLog {\n         dLedgerConfig.setGroup(defaultMessageStore.getMessageStoreConfig().getdLegerGroup());\n         dLedgerConfig.setPeers(defaultMessageStore.getMessageStoreConfig().getdLegerPeers());\n         dLedgerConfig.setStoreBaseDir(defaultMessageStore.getMessageStoreConfig().getStorePathRootDir());\n+        dLedgerConfig.setDataStorePath(defaultMessageStore.getMessageStoreConfig().getStorePathCommitLog());\n         dLedgerConfig.setMappedFileSizeForEntryData(defaultMessageStore.getMessageStoreConfig().getMappedFileSizeCommitLog());\n         dLedgerConfig.setDeleteWhen(defaultMessageStore.getMessageStoreConfig().getDeleteWhen());\n         dLedgerConfig.setFileReservedHours(defaultMessageStore.getMessageStoreConfig().getFileReservedTime() + 1);\n"}
{"instance_id": "apache__rocketmq-5037", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/common/src/main/java/org/apache/rocketmq/common/protocol/ResponseCode.java b/common/src/main/java/org/apache/rocketmq/common/protocol/ResponseCode.java\nindex 65c367d3c..a10bb6150 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/protocol/ResponseCode.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/protocol/ResponseCode.java\n@@ -115,4 +115,6 @@ public class ResponseCode extends RemotingSysResponseCode {\n \n     public static final int CONTROLLER_INVALID_CLEAN_BROKER_METADATA = 2009;\n \n+    public static final int CONTROLLER_ELECT_MASTER_FAILED = 2010;\n+\n }\ndiff --git a/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java b/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\nindex 683a17d4e..6116de755 100644\n--- a/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\n+++ b/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\n@@ -137,7 +137,7 @@ public class ReplicasInfoManager {\n             if (!newSyncStateSet.contains(syncStateInfo.getMasterAddress())) {\n                 String err = String.format(\"Rejecting alter syncStateSet request because the newSyncStateSet don't contains origin leader {%s}\", syncStateInfo.getMasterAddress());\n                 log.error(err);\n-                result.setCodeAndRemark(ResponseCode.CONTROLLER_INVALID_REQUEST, err);\n+                result.setCodeAndRemark(ResponseCode.CONTROLLER_INVALID_REPLICAS, err);\n                 return result;\n             }\n \n@@ -149,7 +149,7 @@ public class ReplicasInfoManager {\n             result.addEvent(event);\n             return result;\n         }\n-        result.setCodeAndRemark(ResponseCode.CONTROLLER_INVALID_REQUEST, \"Broker metadata is not existed\");\n+        result.setCodeAndRemark(ResponseCode.CONTROLLER_BROKER_METADATA_NOT_EXIST, \"Broker metadata is not existed\");\n         return result;\n     }\n \n@@ -171,7 +171,7 @@ public class ReplicasInfoManager {\n                 // old master still valid, change nothing\n                 String err = String.format(\"The old master %s is still alive, not need to elect new master for broker %s\", oldMaster, brokerInfo.getBrokerName());\n                 log.warn(\"{}\", err);\n-                result.setCodeAndRemark(ResponseCode.CONTROLLER_INVALID_REQUEST, err);\n+                result.setCodeAndRemark(ResponseCode.CONTROLLER_ELECT_MASTER_FAILED, err);\n                 return result;\n             }\n             // a new master is elected\n@@ -198,7 +198,7 @@ public class ReplicasInfoManager {\n             result.setCodeAndRemark(ResponseCode.CONTROLLER_MASTER_NOT_AVAILABLE, \"Failed to elect a new broker master\");\n             return result;\n         }\n-        result.setCodeAndRemark(ResponseCode.CONTROLLER_INVALID_REQUEST, \"Broker metadata is not existed\");\n+        result.setCodeAndRemark(ResponseCode.CONTROLLER_BROKER_METADATA_NOT_EXIST, \"Broker metadata is not existed\");\n         return result;\n     }\n \n@@ -271,7 +271,7 @@ public class ReplicasInfoManager {\n         }\n \n         response.setMasterAddress(\"\");\n-        result.setCodeAndRemark(ResponseCode.CONTROLLER_INVALID_REQUEST, \"The broker has not master, and this new registered broker can't not be elected as master\");\n+        result.setCodeAndRemark(ResponseCode.CONTROLLER_MASTER_NOT_AVAILABLE, \"The broker has not master, and this new registered broker can't not be elected as master\");\n         return result;\n     }\n \n"}
{"instance_id": "apache__rocketmq-516", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/common/src/main/java/org/apache/rocketmq/common/stats/MomentStatsItemSet.java b/common/src/main/java/org/apache/rocketmq/common/stats/MomentStatsItemSet.java\nindex d3b559661..a38b53ffd 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/stats/MomentStatsItemSet.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/stats/MomentStatsItemSet.java\n@@ -79,10 +79,10 @@ public class MomentStatsItemSet {\n         if (null == statsItem) {\n             statsItem =\n                 new MomentStatsItem(this.statsName, statsKey, this.scheduledExecutorService, this.log);\n-            MomentStatsItem prev = this.statsItemTable.put(statsKey, statsItem);\n-\n-            if (null == prev) {\n+            MomentStatsItem prev = this.statsItemTable.putIfAbsent(statsKey, statsItem);\n \n+            if (null != prev) {\n+                statsItem = prev;\n                 // statsItem.init();\n             }\n         }\ndiff --git a/common/src/main/java/org/apache/rocketmq/common/stats/StatsItemSet.java b/common/src/main/java/org/apache/rocketmq/common/stats/StatsItemSet.java\nindex 9a0caaa11..b36865161 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/stats/StatsItemSet.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/stats/StatsItemSet.java\n@@ -162,10 +162,10 @@ public class StatsItemSet {\n         StatsItem statsItem = this.statsItemTable.get(statsKey);\n         if (null == statsItem) {\n             statsItem = new StatsItem(this.statsName, statsKey, this.scheduledExecutorService, this.log);\n-            StatsItem prev = this.statsItemTable.put(statsKey, statsItem);\n-\n-            if (null == prev) {\n+            StatsItem prev = this.statsItemTable.putIfAbsent(statsKey, statsItem);\n \n+            if (null != prev) {\n+                statsItem = prev;\n                 // statsItem.init();\n             }\n         }\n"}
{"instance_id": "apache__rocketmq-5062", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/broker/src/main/java/org/apache/rocketmq/broker/failover/EscapeBridge.java b/broker/src/main/java/org/apache/rocketmq/broker/failover/EscapeBridge.java\nindex 25d449170..8db08783b 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/failover/EscapeBridge.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/failover/EscapeBridge.java\n@@ -330,4 +330,49 @@ public class EscapeBridge {\n         return null;\n     }\n \n+    /**\n+     * Put half message to master broker for escaping transactional messages in slave-acting-master mode.\n+     * <p>\n+     * If sent to a local master, just append it to half topic.\n+     * If sent to a remote master, the half message should be restored to original real message,\n+     * because sending messages to a system topic is forbidden.\n+     *\n+     * @param messageExt the half message to escape\n+     * @return put message result\n+     */\n+    public PutMessageResult putHalfMessage(MessageExtBrokerInner messageExt) {\n+        BrokerController masterBroker = this.brokerController.peekMasterBroker();\n+        if (masterBroker != null) {\n+            // Local master is available, just append to half topic directly\n+            return masterBroker.getMessageStore().putMessage(messageExt);\n+        } else if (this.brokerController.getBrokerConfig().isEnableSlaveActingMaster()\n+            && this.brokerController.getBrokerConfig().isEnableRemoteEscape()) {\n+            // Remote escape: restore half message to original real message\n+            // because sending messages to a system topic is forbidden\n+            try {\n+                messageExt.setWaitStoreMsgOK(false);\n+\n+                // Restore the original topic and queueId from properties\n+                String realTopic = messageExt.getProperty(MessageConst.PROPERTY_REAL_TOPIC);\n+                String realQueueIdStr = messageExt.getProperty(MessageConst.PROPERTY_REAL_QUEUE_ID);\n+\n+                if (realTopic != null && realQueueIdStr != null) {\n+                    // Restore the message to its original topic\n+                    messageExt.setTopic(realTopic);\n+                    messageExt.setQueueId(Integer.parseInt(realQueueIdStr));\n+                }\n+\n+                final SendResult sendResult = putMessageToRemoteBroker(messageExt);\n+                return transformSendResult2PutResult(sendResult);\n+            } catch (Exception e) {\n+                LOG.error(\"putHalfMessage to remote failed\", e);\n+                return new PutMessageResult(PutMessageStatus.PUT_TO_REMOTE_BROKER_FAIL, null, true);\n+            }\n+        } else {\n+            LOG.warn(\"Put half message failed, enableSlaveActingMaster={}, enableRemoteEscape={}.\",\n+                this.brokerController.getBrokerConfig().isEnableSlaveActingMaster(), this.brokerController.getBrokerConfig().isEnableRemoteEscape());\n+            return new PutMessageResult(PutMessageStatus.SERVICE_NOT_AVAILABLE, null);\n+        }\n+    }\n+\n }\ndiff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/EndTransactionProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/EndTransactionProcessor.java\nindex 6da4a4a8a..5b180f3bd 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/EndTransactionProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/EndTransactionProcessor.java\n@@ -62,6 +62,16 @@ public class EndTransactionProcessor implements NettyRequestProcessor {\n             return response;\n         }\n \n+        if (brokerController.getBrokerConfig().isEnableSlaveActingMaster()) {\n+            // If slave is acting as master, deny EndTransaction requests\n+            // because the slave should keep read-only semantics\n+            if (brokerController.peekMasterBroker() == null) {\n+                response.setCode(ResponseCode.SLAVE_NOT_AVAILABLE);\n+                LOGGER.warn(\"Slave is acting as master, so end transaction is forbidden. \");\n+                return response;\n+            }\n+        }\n+\n         if (requestHeader.getFromTransactionCheck()) {\n             switch (requestHeader.getCommitOrRollback()) {\n                 case MessageSysFlag.TRANSACTION_NOT_TYPE: {\ndiff --git a/broker/src/main/java/org/apache/rocketmq/broker/transaction/AbstractTransactionalMessageCheckListener.java b/broker/src/main/java/org/apache/rocketmq/broker/transaction/AbstractTransactionalMessageCheckListener.java\nindex 2ed0d9d1c..569742bd9 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/transaction/AbstractTransactionalMessageCheckListener.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/transaction/AbstractTransactionalMessageCheckListener.java\n@@ -20,8 +20,11 @@ import io.netty.channel.Channel;\n import org.apache.rocketmq.broker.BrokerController;\n import org.apache.rocketmq.common.ThreadFactoryImpl;\n import org.apache.rocketmq.common.constant.LoggerName;\n+import org.apache.rocketmq.common.message.MessageAccessor;\n import org.apache.rocketmq.common.message.MessageConst;\n+import org.apache.rocketmq.common.message.MessageDecoder;\n import org.apache.rocketmq.common.message.MessageExt;\n+import org.apache.rocketmq.common.message.MessageExtBrokerInner;\n import org.apache.rocketmq.common.protocol.header.CheckTransactionStateRequestHeader;\n import org.apache.rocketmq.logging.InternalLogger;\n import org.apache.rocketmq.logging.InternalLoggerFactory;\n@@ -68,6 +71,57 @@ public abstract class AbstractTransactionalMessageCheckListener {\n         }\n     }\n \n+    /**\n+     * Escape half message to an available master directly in slave-acting-master mode,\n+     * without checking transaction status actually.\n+     * <p>\n+     * This keeps read-only semantics of slaves, so that no new half messages or op messages\n+     * will be created in slave acting as master, all actual checking processes of half messages\n+     * are delivered to master.\n+     *\n+     * @param msgExt the half message to escape\n+     */\n+    public void escapeHalfMessage(final MessageExt msgExt) {\n+        if (executorService != null) {\n+            executorService.execute(new Runnable() {\n+                @Override\n+                public void run() {\n+                    try {\n+                        brokerController.getEscapeBridge().putHalfMessage(convertToHalfMessage(msgExt));\n+                    } catch (Exception e) {\n+                        LOGGER.error(\"Escape half message error!\", e);\n+                    }\n+                }\n+            });\n+        } else {\n+            LOGGER.error(\"TransactionalMessageCheckListener not init, cannot escape half message\");\n+        }\n+    }\n+\n+    /**\n+     * Convert MessageExt to MessageExtBrokerInner for escaping.\n+     *\n+     * @param msgExt the message to convert\n+     * @return the converted MessageExtBrokerInner\n+     */\n+    private MessageExtBrokerInner convertToHalfMessage(MessageExt msgExt) {\n+        MessageExtBrokerInner msgInner = new MessageExtBrokerInner();\n+        msgInner.setTopic(msgExt.getTopic());\n+        msgInner.setBody(msgExt.getBody());\n+        msgInner.setQueueId(msgExt.getQueueId());\n+        msgInner.setMsgId(msgExt.getMsgId());\n+        msgInner.setSysFlag(msgExt.getSysFlag());\n+        msgInner.setTags(msgExt.getTags());\n+        msgInner.setTagsCode(MessageExtBrokerInner.tagsString2tagsCode(msgInner.getTags()));\n+        MessageAccessor.setProperties(msgInner, msgExt.getProperties());\n+        msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgExt.getProperties()));\n+        msgInner.setBornTimestamp(msgExt.getBornTimestamp());\n+        msgInner.setBornHost(msgExt.getBornHost());\n+        msgInner.setStoreHost(msgExt.getStoreHost());\n+        msgInner.setWaitStoreMsgOK(false);\n+        return msgInner;\n+    }\n+\n     public void resolveHalfMsg(final MessageExt msgExt) {\n         if (executorService != null) {\n             executorService.execute(new Runnable() {\ndiff --git a/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java b/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java\nindex 63b188e64..94b17c009 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java\n@@ -227,7 +227,13 @@ public class TransactionalMessageServiceImpl implements TransactionalMessageServ\n                             if (!putBackHalfMsgQueue(msgExt, i)) {\n                                 continue;\n                             }\n-                            listener.resolveHalfMsg(msgExt);\n+                            // Check if slave is acting as master, if so, escape half message to master\n+                            // instead of checking transaction status\n+                            if (isSlaveActingMaster()) {\n+                                listener.escapeHalfMessage(msgExt);\n+                            } else {\n+                                listener.resolveHalfMsg(msgExt);\n+                            }\n                         } else {\n                             pullResult = fillOpRemoveMap(removeMap, opQueue, pullResult.getNextBeginOffset(), halfOffset, doneOpOffset);\n                             log.debug(\"The miss offset:{} in messageQueue:{} need to get more opMsg, result is:{}\", i,\n@@ -494,4 +500,15 @@ public class TransactionalMessageServiceImpl implements TransactionalMessageServ\n \n     }\n \n+    /**\n+     * Check if the current broker is a slave acting as master.\n+     * This happens when enableSlaveActingMaster is true and there's no local master available.\n+     *\n+     * @return true if slave is acting as master, false otherwise\n+     */\n+    private boolean isSlaveActingMaster() {\n+        return transactionalMessageBridge.getBrokerController().getBrokerConfig().isEnableSlaveActingMaster()\n+            && transactionalMessageBridge.getBrokerController().peekMasterBroker() == null;\n+    }\n+\n }\n"}
{"instance_id": "apache__rocketmq-7420", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicBlackListFilter.java b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicBlackListFilter.java\nindex 50adbb713..f8bf165bc 100644\n--- a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicBlackListFilter.java\n+++ b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicBlackListFilter.java\n@@ -39,7 +39,7 @@ public class TieredStoreTopicBlackListFilter implements TieredStoreTopicFilter {\n     }\n \n     @Override\n-    public void addTopicToWhiteList(String topicName) {\n+    public void addTopicToBlackList(String topicName) {\n         this.topicBlackSet.add(topicName);\n     }\n }\ndiff --git a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicFilter.java b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicFilter.java\nindex 3f26b8b02..f983ed6e9 100644\n--- a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicFilter.java\n+++ b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicFilter.java\n@@ -21,5 +21,5 @@ public interface TieredStoreTopicFilter {\n \n     boolean filterTopic(String topicName);\n \n-    void addTopicToWhiteList(String topicName);\n+    void addTopicToBlackList(String topicName);\n }\n"}
{"instance_id": "apache__rocketmq-5841", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/consumer/ReceiveMessageActivity.java b/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/consumer/ReceiveMessageActivity.java\nindex 31b841132..1c6b1c658 100644\n--- a/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/consumer/ReceiveMessageActivity.java\n+++ b/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/consumer/ReceiveMessageActivity.java\n@@ -85,7 +85,7 @@ public class ReceiveMessageActivity extends AbstractMessingActivity {\n                 if (timeRemaining >= config.getGrpcClientConsumerMinLongPollingTimeoutMillis()) {\n                     pollingTime = timeRemaining;\n                 } else {\n-                    writer.writeAndComplete(ctx, Code.ILLEGAL_POLLING_TIME, \"The deadline time remaining is not enough\" +\n+                    writer.writeAndComplete(ctx, Code.BAD_REQUEST, \"The deadline time remaining is not enough\" +\n                         \" for polling, please check network condition\");\n                     return;\n                 }\n"}
{"instance_id": "apache__rocketmq-7426", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/proxy/src/main/java/org/apache/rocketmq/proxy/service/sysmessage/HeartbeatSyncer.java b/proxy/src/main/java/org/apache/rocketmq/proxy/service/sysmessage/HeartbeatSyncer.java\nindex f70c06b8f..5d13b5256 100644\n--- a/proxy/src/main/java/org/apache/rocketmq/proxy/service/sysmessage/HeartbeatSyncer.java\n+++ b/proxy/src/main/java/org/apache/rocketmq/proxy/service/sysmessage/HeartbeatSyncer.java\n@@ -80,7 +80,7 @@ public class HeartbeatSyncer extends AbstractSystemMessageSyncer {\n                     }\n                     if (args[0] instanceof ClientChannelInfo) {\n                         ClientChannelInfo clientChannelInfo = (ClientChannelInfo) args[0];\n-                        remoteChannelMap.remove(clientChannelInfo.getChannel().id().asLongText());\n+                        remoteChannelMap.remove(s + \"@\" + clientChannelInfo.getChannel().id().asLongText());\n                     }\n                 }\n             }\n"}
{"instance_id": "apache__dubbo-8414", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/StringUtils.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/StringUtils.java\nindex 1fee2e693a..0327ed4a11 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/StringUtils.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/StringUtils.java\n@@ -1134,21 +1134,56 @@ public final class StringUtils {\n         if (StringUtils.isBlank(rawParameters)) {\n             return Collections.emptyMap();\n         }\n-        Matcher matcher = PARAMETERS_PATTERN.matcher(rawParameters);\n-        if (!matcher.matches()) {\n+\n+        // Check basic format: must start with '[' and end with ']'\n+        String trimmed = rawParameters.trim();\n+        if (!trimmed.startsWith(\"[\") || !trimmed.endsWith(\"]\")) {\n             return Collections.emptyMap();\n         }\n \n-        String pairs = matcher.group(1);\n-        String[] pairArr = pairs.split(\"\\\\s*,\\\\s*\");\n+        // Remove the outer brackets\n+        String content = trimmed.substring(1, trimmed.length() - 1).trim();\n+        if (content.isEmpty()) {\n+            return Collections.emptyMap();\n+        }\n \n         Map<String, String> parameters = new HashMap<>();\n-        for (String pair : pairArr) {\n-            Matcher pairMatcher = PAIR_PARAMETERS_PATTERN.matcher(pair);\n-            if (pairMatcher.matches()) {\n-                parameters.put(pairMatcher.group(1), pairMatcher.group(2));\n+        int pairCount = 0;\n+        int validPairCount = 0;\n+\n+        // Parse each {key:value} pair by tracking brace depth\n+        int braceDepth = 0;\n+        int pairStart = -1;\n+\n+        for (int i = 0; i < content.length(); i++) {\n+            char ch = content.charAt(i);\n+\n+            if (ch == '{') {\n+                if (braceDepth == 0) {\n+                    pairStart = i;\n+                }\n+                braceDepth++;\n+            } else if (ch == '}') {\n+                braceDepth--;\n+                if (braceDepth == 0 && pairStart >= 0) {\n+                    // Found a complete {key:value} pair\n+                    pairCount++;\n+                    String pair = content.substring(pairStart, i + 1).trim();\n+                    Matcher pairMatcher = PAIR_PARAMETERS_PATTERN.matcher(pair);\n+                    if (pairMatcher.matches()) {\n+                        parameters.put(pairMatcher.group(1).trim(), pairMatcher.group(2).trim());\n+                        validPairCount++;\n+                    }\n+                    pairStart = -1;\n+                }\n             }\n         }\n+\n+        // If any pair is invalid, return empty map (maintain backward compatibility)\n+        if (pairCount != validPairCount) {\n+            return Collections.emptyMap();\n+        }\n+\n         return parameters;\n     }\n \n"}
{"instance_id": "apache__rocketmq-7346", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/file/TieredFlatFile.java b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/file/TieredFlatFile.java\nindex 426c4e09d..40cc5bb39 100644\n--- a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/file/TieredFlatFile.java\n+++ b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/file/TieredFlatFile.java\n@@ -365,7 +365,8 @@ public class TieredFlatFile {\n             if (!segmentList.isEmpty()) {\n                 return boundaryType == BoundaryType.UPPER ? segmentList.get(0) : segmentList.get(segmentList.size() - 1);\n             }\n-            return fileSegmentList.isEmpty() ? null : fileSegmentList.get(fileSegmentList.size() - 1);\n+            return fileSegmentList.isEmpty() ? null :\n+            (boundaryType == BoundaryType.LOWER ? fileSegmentList.get(0) : fileSegmentList.get(fileSegmentList.size() - 1));\n         } finally {\n             fileSegmentLock.readLock().unlock();\n         }\n"}
{"instance_id": "apache__rocketmq-5633", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/controller/src/main/java/org/apache/rocketmq/controller/impl/DLedgerController.java b/controller/src/main/java/org/apache/rocketmq/controller/impl/DLedgerController.java\nindex 71e8e465c..fab4f6005 100644\n--- a/controller/src/main/java/org/apache/rocketmq/controller/impl/DLedgerController.java\n+++ b/controller/src/main/java/org/apache/rocketmq/controller/impl/DLedgerController.java\n@@ -166,7 +166,7 @@ public class DLedgerController implements Controller {\n     @Override\n     public CompletableFuture<RemotingCommand> registerBroker(RegisterBrokerToControllerRequestHeader request) {\n         return this.scheduler.appendEvent(\"registerBroker\",\n-            () -> this.replicasInfoManager.registerBroker(request), true);\n+            () -> this.replicasInfoManager.registerBroker(request, this.brokerAlivePredicate), true);\n     }\n \n     @Override\ndiff --git a/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java b/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\nindex 02ea9a6b6..1ece0b07b 100644\n--- a/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\n+++ b/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\n@@ -216,7 +216,8 @@ public class ReplicasInfoManager {\n     }\n \n     public ControllerResult<RegisterBrokerToControllerResponseHeader> registerBroker(\n-        final RegisterBrokerToControllerRequestHeader request) {\n+        final RegisterBrokerToControllerRequestHeader request,\n+        final BiPredicate<String, String> brokerAlivePredicate) {\n         final String brokerName = request.getBrokerName();\n         final String brokerAddress = request.getBrokerAddress();\n         final ControllerResult<RegisterBrokerToControllerResponseHeader> result = new ControllerResult<>(new RegisterBrokerToControllerResponseHeader());\n@@ -240,9 +241,9 @@ public class ReplicasInfoManager {\n             response.setMasterEpoch(syncStateInfo.getMasterEpoch());\n             response.setSyncStateSetEpoch(syncStateInfo.getSyncStateSetEpoch());\n \n-            if (syncStateInfo.isMasterExist()) {\n+            final String masterAddress = syncStateInfo.getMasterAddress();\n+            if (syncStateInfo.isMasterExist() && brokerAlivePredicate.test(syncStateInfo.getClusterName(), masterAddress)) {\n                 // If the master is alive, just return master info.\n-                final String masterAddress = syncStateInfo.getMasterAddress();\n                 response.setMasterAddress(masterAddress);\n                 return result;\n             } else {\n"}
{"instance_id": "apache__rocketmq-7532", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java\nindex 7ed4d53ab..dd8d495b4 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java\n@@ -601,7 +601,7 @@ public class PopMessageProcessor implements NettyRequestProcessor {\n                             try {\n                                 String ckInfo = ExtraInfoUtil.buildExtraInfo(finalOffset, popTime, requestHeader.getInvisibleTime(),\n                                     reviveQid, messageExt.getTopic(), brokerName, messageExt.getQueueId(), messageExt.getQueueOffset());\n-                                messageExt.getProperties().putIfAbsent(MessageConst.PROPERTY_POP_CK, ckInfo);\n+                                messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK, ckInfo);\n \n                                 // Set retry message topic to origin topic and clear message store size to recode\n                                 messageExt.setTopic(requestHeader.getTopic());\ndiff --git a/client/src/main/java/org/apache/rocketmq/client/impl/MQClientAPIImpl.java b/client/src/main/java/org/apache/rocketmq/client/impl/MQClientAPIImpl.java\nindex 6074081c1..82bea04c1 100644\n--- a/client/src/main/java/org/apache/rocketmq/client/impl/MQClientAPIImpl.java\n+++ b/client/src/main/java/org/apache/rocketmq/client/impl/MQClientAPIImpl.java\n@@ -1131,50 +1131,48 @@ public class MQClientAPIImpl implements NameServerUpdateCallback {\n                     }\n                     messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK, map.get(key) + MessageConst.KEY_SEPARATOR + messageExt.getQueueOffset());\n                 } else {\n-                    if (messageExt.getProperty(MessageConst.PROPERTY_POP_CK) == null) {\n-                        final String queueIdKey;\n-                        final String queueOffsetKey;\n-                        final int index;\n-                        final Long msgQueueOffset;\n-                        if (MixAll.isLmq(topic) && messageExt.getReconsumeTimes() == 0 && StringUtils.isNotEmpty(\n-                            messageExt.getProperty(MessageConst.PROPERTY_INNER_MULTI_DISPATCH))) {\n-                            // process LMQ, LMQ topic has only 1 queue, which queue id is 0\n-                            queueIdKey = ExtraInfoUtil.getStartOffsetInfoMapKey(topic, MixAll.LMQ_QUEUE_ID);\n-                            queueOffsetKey = ExtraInfoUtil.getQueueOffsetMapKey(topic, MixAll.LMQ_QUEUE_ID, Long.parseLong(\n-                                messageExt.getProperty(MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET)));\n-                            index = sortMap.get(queueIdKey).indexOf(\n-                                Long.parseLong(messageExt.getProperty(MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET)));\n-                            msgQueueOffset = msgOffsetInfo.get(queueIdKey).get(index);\n-                            if (msgQueueOffset != Long.parseLong(\n-                                messageExt.getProperty(MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET))) {\n-                                log.warn(\"Queue offset[%d] of msg is strange, not equal to the stored in msg, %s\",\n-                                    msgQueueOffset, messageExt);\n-                            }\n-                            messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK,\n-                                ExtraInfoUtil.buildExtraInfo(startOffsetInfo.get(queueIdKey), responseHeader.getPopTime(), responseHeader.getInvisibleTime(),\n-                                    responseHeader.getReviveQid(), topic, brokerName, 0, msgQueueOffset)\n-                            );\n-                        } else {\n-                            queueIdKey = ExtraInfoUtil.getStartOffsetInfoMapKey(messageExt.getTopic(), messageExt.getQueueId());\n-                            queueOffsetKey = ExtraInfoUtil.getQueueOffsetMapKey(messageExt.getTopic(), messageExt.getQueueId(), messageExt.getQueueOffset());\n-                            index = sortMap.get(queueIdKey).indexOf(messageExt.getQueueOffset());\n-                            msgQueueOffset = msgOffsetInfo.get(queueIdKey).get(index);\n-                            if (msgQueueOffset != messageExt.getQueueOffset()) {\n-                                log.warn(\"Queue offset[%d] of msg is strange, not equal to the stored in msg, %s\", msgQueueOffset, messageExt);\n-                            }\n-                            messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK,\n-                                ExtraInfoUtil.buildExtraInfo(startOffsetInfo.get(queueIdKey), responseHeader.getPopTime(), responseHeader.getInvisibleTime(),\n-                                    responseHeader.getReviveQid(), messageExt.getTopic(), brokerName, messageExt.getQueueId(), msgQueueOffset)\n-                            );\n+                    final String queueIdKey;\n+                    final String queueOffsetKey;\n+                    final int index;\n+                    final Long msgQueueOffset;\n+                    if (MixAll.isLmq(topic) && messageExt.getReconsumeTimes() == 0 && StringUtils.isNotEmpty(\n+                        messageExt.getProperty(MessageConst.PROPERTY_INNER_MULTI_DISPATCH))) {\n+                        // process LMQ, LMQ topic has only 1 queue, which queue id is 0\n+                        queueIdKey = ExtraInfoUtil.getStartOffsetInfoMapKey(topic, MixAll.LMQ_QUEUE_ID);\n+                        queueOffsetKey = ExtraInfoUtil.getQueueOffsetMapKey(topic, MixAll.LMQ_QUEUE_ID, Long.parseLong(\n+                            messageExt.getProperty(MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET)));\n+                        index = sortMap.get(queueIdKey).indexOf(\n+                            Long.parseLong(messageExt.getProperty(MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET)));\n+                        msgQueueOffset = msgOffsetInfo.get(queueIdKey).get(index);\n+                        if (msgQueueOffset != Long.parseLong(\n+                            messageExt.getProperty(MessageConst.PROPERTY_INNER_MULTI_QUEUE_OFFSET))) {\n+                            log.warn(\"Queue offset[%d] of msg is strange, not equal to the stored in msg, %s\",\n+                                msgQueueOffset, messageExt);\n                         }\n-                        if (((PopMessageRequestHeader) requestHeader).isOrder() && orderCountInfo != null) {\n-                            Integer count = orderCountInfo.get(queueOffsetKey);\n-                            if (count == null) {\n-                                count = orderCountInfo.get(queueIdKey);\n-                            }\n-                            if (count != null && count > 0) {\n-                                messageExt.setReconsumeTimes(count);\n-                            }\n+                        messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK,\n+                            ExtraInfoUtil.buildExtraInfo(startOffsetInfo.get(queueIdKey), responseHeader.getPopTime(), responseHeader.getInvisibleTime(),\n+                                responseHeader.getReviveQid(), topic, brokerName, 0, msgQueueOffset)\n+                        );\n+                    } else {\n+                        queueIdKey = ExtraInfoUtil.getStartOffsetInfoMapKey(messageExt.getTopic(), messageExt.getQueueId());\n+                        queueOffsetKey = ExtraInfoUtil.getQueueOffsetMapKey(messageExt.getTopic(), messageExt.getQueueId(), messageExt.getQueueOffset());\n+                        index = sortMap.get(queueIdKey).indexOf(messageExt.getQueueOffset());\n+                        msgQueueOffset = msgOffsetInfo.get(queueIdKey).get(index);\n+                        if (msgQueueOffset != messageExt.getQueueOffset()) {\n+                            log.warn(\"Queue offset[%d] of msg is strange, not equal to the stored in msg, %s\", msgQueueOffset, messageExt);\n+                        }\n+                        messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK,\n+                            ExtraInfoUtil.buildExtraInfo(startOffsetInfo.get(queueIdKey), responseHeader.getPopTime(), responseHeader.getInvisibleTime(),\n+                                responseHeader.getReviveQid(), messageExt.getTopic(), brokerName, messageExt.getQueueId(), msgQueueOffset)\n+                        );\n+                    }\n+                    if (((PopMessageRequestHeader) requestHeader).isOrder() && orderCountInfo != null) {\n+                        Integer count = orderCountInfo.get(queueOffsetKey);\n+                        if (count == null) {\n+                            count = orderCountInfo.get(queueIdKey);\n+                        }\n+                        if (count != null && count > 0) {\n+                            messageExt.setReconsumeTimes(count);\n                         }\n                     }\n                 }\ndiff --git a/proxy/src/main/java/org/apache/rocketmq/proxy/service/message/LocalMessageService.java b/proxy/src/main/java/org/apache/rocketmq/proxy/service/message/LocalMessageService.java\nindex aaa688fee..efbafd42c 100644\n--- a/proxy/src/main/java/org/apache/rocketmq/proxy/service/message/LocalMessageService.java\n+++ b/proxy/src/main/java/org/apache/rocketmq/proxy/service/message/LocalMessageService.java\n@@ -273,23 +273,21 @@ public class LocalMessageService implements MessageService {\n                         }\n                         messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK, map.get(key) + MessageConst.KEY_SEPARATOR + messageExt.getQueueOffset());\n                     } else {\n-                        if (messageExt.getProperty(MessageConst.PROPERTY_POP_CK) == null) {\n-                            String key = ExtraInfoUtil.getStartOffsetInfoMapKey(messageExt.getTopic(), messageExt.getQueueId());\n-                            int index = sortMap.get(key).indexOf(messageExt.getQueueOffset());\n-                            Long msgQueueOffset = msgOffsetInfo.get(key).get(index);\n-                            if (msgQueueOffset != messageExt.getQueueOffset()) {\n-                                log.warn(\"Queue offset [{}] of msg is strange, not equal to the stored in msg, {}\", msgQueueOffset, messageExt);\n-                            }\n+                        String key = ExtraInfoUtil.getStartOffsetInfoMapKey(messageExt.getTopic(), messageExt.getQueueId());\n+                        int index = sortMap.get(key).indexOf(messageExt.getQueueOffset());\n+                        Long msgQueueOffset = msgOffsetInfo.get(key).get(index);\n+                        if (msgQueueOffset != messageExt.getQueueOffset()) {\n+                            log.warn(\"Queue offset [{}] of msg is strange, not equal to the stored in msg, {}\", msgQueueOffset, messageExt);\n+                        }\n \n-                            messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK,\n-                                ExtraInfoUtil.buildExtraInfo(startOffsetInfo.get(key), responseHeader.getPopTime(), responseHeader.getInvisibleTime(),\n-                                    responseHeader.getReviveQid(), messageExt.getTopic(), messageQueue.getBrokerName(), messageExt.getQueueId(), msgQueueOffset)\n-                            );\n-                            if (requestHeader.isOrder() && orderCountInfo != null) {\n-                                Integer count = orderCountInfo.get(key);\n-                                if (count != null && count > 0) {\n-                                    messageExt.setReconsumeTimes(count);\n-                                }\n+                        messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK,\n+                            ExtraInfoUtil.buildExtraInfo(startOffsetInfo.get(key), responseHeader.getPopTime(), responseHeader.getInvisibleTime(),\n+                                responseHeader.getReviveQid(), messageExt.getTopic(), messageQueue.getBrokerName(), messageExt.getQueueId(), msgQueueOffset)\n+                        );\n+                        if (requestHeader.isOrder() && orderCountInfo != null) {\n+                            Integer count = orderCountInfo.get(key);\n+                            if (count != null && count > 0) {\n+                                messageExt.setReconsumeTimes(count);\n                             }\n                         }\n                     }\n"}
{"instance_id": "apache__rocketmq-7745", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/client/src/main/java/org/apache/rocketmq/client/consumer/store/LocalFileOffsetStore.java b/client/src/main/java/org/apache/rocketmq/client/consumer/store/LocalFileOffsetStore.java\nindex f949b75a8..88aff99ee 100644\n--- a/client/src/main/java/org/apache/rocketmq/client/consumer/store/LocalFileOffsetStore.java\n+++ b/client/src/main/java/org/apache/rocketmq/client/consumer/store/LocalFileOffsetStore.java\n@@ -154,6 +154,30 @@ public class LocalFileOffsetStore implements OffsetStore {\n \n     @Override\n     public void persist(MessageQueue mq) {\n+        if (mq == null) {\n+            return;\n+        }\n+        AtomicLong offset = this.offsetTable.get(mq);\n+        if (offset != null) {\n+            OffsetSerializeWrapper offsetSerializeWrapper;\n+            try {\n+                offsetSerializeWrapper = this.readLocalOffset();\n+            } catch (MQClientException e) {\n+                offsetSerializeWrapper = new OffsetSerializeWrapper();\n+            }\n+            if (offsetSerializeWrapper == null) {\n+                offsetSerializeWrapper = new OffsetSerializeWrapper();\n+            }\n+            offsetSerializeWrapper.getOffsetTable().put(mq, offset);\n+            String jsonString = offsetSerializeWrapper.toJson(true);\n+            if (jsonString != null) {\n+                try {\n+                    MixAll.string2File(jsonString, this.storePath);\n+                } catch (IOException e) {\n+                    log.error(\"persist consumer offset Exception, \" + this.storePath, e);\n+                }\n+            }\n+        }\n     }\n \n     @Override\n"}
{"instance_id": "apache__rocketmq-7712", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/common/src/main/java/org/apache/rocketmq/common/UtilAll.java b/common/src/main/java/org/apache/rocketmq/common/UtilAll.java\nindex 19efa9aa9..f86157280 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/UtilAll.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/UtilAll.java\n@@ -31,6 +31,7 @@ import java.nio.file.Files;\n import java.text.NumberFormat;\n import java.text.ParseException;\n import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n import java.util.Arrays;\n import java.util.Calendar;\n import java.util.Date;\n@@ -681,6 +682,10 @@ public class UtilAll {\n             return null;\n         }\n \n+        if (str.isEmpty()) {\n+            return new ArrayList<>();\n+        }\n+\n         String[] addrArray = str.split(splitter);\n         return Arrays.asList(addrArray);\n     }\n"}
{"instance_id": "apache__rocketmq-7655", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/common/src/main/java/org/apache/rocketmq/common/KeyBuilder.java b/common/src/main/java/org/apache/rocketmq/common/KeyBuilder.java\nindex f2a8c4089..2c671b268 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/KeyBuilder.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/KeyBuilder.java\n@@ -19,7 +19,7 @@ package org.apache.rocketmq.common;\n public class KeyBuilder {\n     public static final int POP_ORDER_REVIVE_QUEUE = 999;\n     private static final String POP_RETRY_SEPARATOR_V1 = \"_\";\n-    private static final String POP_RETRY_SEPARATOR_V2 = \":\";\n+    private static final String POP_RETRY_SEPARATOR_V2 = \"+\";\n \n     public static String buildPopRetryTopic(String topic, String cid) {\n         return MixAll.RETRY_GROUP_TOPIC_PREFIX + cid + POP_RETRY_SEPARATOR_V2 + topic;\n@@ -42,7 +42,7 @@ public class KeyBuilder {\n \n     public static String parseNormalTopic(String retryTopic) {\n         if (isPopRetryTopicV2(retryTopic)) {\n-            String[] result = retryTopic.split(POP_RETRY_SEPARATOR_V2);\n+            String[] result = retryTopic.split(\"\\\\\" + POP_RETRY_SEPARATOR_V2);\n             if (result.length == 2) {\n                 return result[1];\n             }\n@@ -52,7 +52,7 @@ public class KeyBuilder {\n \n     public static String parseGroup(String retryTopic) {\n         if (isPopRetryTopicV2(retryTopic)) {\n-            String[] result = retryTopic.split(POP_RETRY_SEPARATOR_V2);\n+            String[] result = retryTopic.split(\"\\\\\" + POP_RETRY_SEPARATOR_V2);\n             if (result.length == 2) {\n                 return result[0].substring(MixAll.RETRY_GROUP_TOPIC_PREFIX.length());\n             }\n"}
{"instance_id": "apache__rocketmq-7563", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\nindex dc5f312e5..900465934 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\n@@ -3291,9 +3291,17 @@ public class DefaultMessageStore implements MessageStore {\n         // correct the \"from\" argument to min offset in queue if it is too small\n         long minOffset = consumeQueue.getMinOffsetInQueue();\n         if (from < minOffset) {\n-            long diff = to - from;\n             from = minOffset;\n-            to = from + diff;\n+        }\n+\n+        // correct the \"to\" argument to max offset in queue if it is too large\n+        long maxOffset = consumeQueue.getMaxOffsetInQueue();\n+        if (to > maxOffset) {\n+            to = maxOffset;\n+        }\n+\n+        if (from >= to) {\n+            return 0;\n         }\n \n         long msgCount = consumeQueue.estimateMessageCount(from, to, filter);\n"}
{"instance_id": "apache__rocketmq-7964", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/ConsumerManageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/ConsumerManageProcessor.java\nindex e16a1e909..33ce1dfbb 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/ConsumerManageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/ConsumerManageProcessor.java\n@@ -22,6 +22,7 @@ import org.apache.rocketmq.broker.BrokerController;\n import org.apache.rocketmq.broker.client.ConsumerGroupInfo;\n import org.apache.rocketmq.broker.offset.ConsumerOffsetManager;\n import org.apache.rocketmq.common.constant.LoggerName;\n+import org.apache.rocketmq.common.help.FAQUrl;\n import org.apache.rocketmq.logging.org.slf4j.Logger;\n import org.apache.rocketmq.logging.org.slf4j.LoggerFactory;\n import org.apache.rocketmq.remoting.common.RemotingHelper;\n@@ -170,6 +171,12 @@ public class ConsumerManageProcessor implements NettyRequestProcessor {\n             return response;\n         }\n \n+        if (null == this.brokerController.getSubscriptionGroupManager().findSubscriptionGroupConfig(group)) {\n+            response.setCode(ResponseCode.SUBSCRIPTION_GROUP_NOT_EXIST);\n+            response.setRemark(String.format(\"subscription group [%s] does not exist, %s\", group, FAQUrl.suggestTodo(FAQUrl.SUBSCRIPTION_GROUP_NOT_EXIST)));\n+            return response;\n+        }\n+\n         if (queueId == null) {\n             response.setCode(ResponseCode.SYSTEM_ERROR);\n             response.setRemark(\"QueueId is null, topic is \" + topic);\n"}
{"instance_id": "apolloconfig__apollo-1894", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/service/AppNamespaceService.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/service/AppNamespaceService.java\nindex e29ed819..691879b3 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/service/AppNamespaceService.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/service/AppNamespaceService.java\n@@ -135,14 +135,20 @@ public class AppNamespaceService {\n \n     appNamespace.setDataChangeLastModifiedBy(operator);\n \n-    // globally uniqueness check\n+    // globally uniqueness check for public app namespace\n     if (appNamespace.isPublic()) {\n       checkAppNamespaceGlobalUniqueness(appNamespace);\n-    }\n-\n-    if (!appNamespace.isPublic() &&\n-        appNamespaceRepository.findByAppIdAndName(appNamespace.getAppId(), appNamespace.getName()) != null) {\n-      throw new BadRequestException(\"Private AppNamespace \" + appNamespace.getName() + \" already exists!\");\n+    } else {\n+      // check private app namespace\n+      if (appNamespaceRepository.findByAppIdAndName(appNamespace.getAppId(), appNamespace.getName()) != null) {\n+        throw new BadRequestException(\"Private AppNamespace \" + appNamespace.getName() + \" already exists!\");\n+      }\n+      // check if there is a public app namespace with the same name\n+      // since public app namespace can be linked to any app, so need to check\n+      AppNamespace publicAppNamespace = findPublicAppNamespace(appNamespace.getName());\n+      if (publicAppNamespace != null) {\n+        throw new BadRequestException(\"Public AppNamespace \" + appNamespace.getName() + \" already exists in appId: \" + publicAppNamespace.getAppId() + \"!\");\n+      }\n     }\n \n     AppNamespace createdAppNamespace = appNamespaceRepository.save(appNamespace);\n"}
{"instance_id": "apache__rocketmq-7823", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/controller/src/main/java/org/apache/rocketmq/controller/impl/JRaftController.java b/controller/src/main/java/org/apache/rocketmq/controller/impl/JRaftController.java\nindex e40a63494..65da373a9 100644\n--- a/controller/src/main/java/org/apache/rocketmq/controller/impl/JRaftController.java\n+++ b/controller/src/main/java/org/apache/rocketmq/controller/impl/JRaftController.java\n@@ -108,7 +108,9 @@ public class JRaftController implements Controller {\n         initPeerIdMap();\n \n         NettyServerConfig nettyServerConfig = new NettyServerConfig();\n-        nettyServerConfig.setListenPort(Integer.parseInt(this.peerIdToAddr.get(serverId).split(\":\")[1]));\n+        String serverAddr = this.peerIdToAddr.get(serverId);\n+        int lastColonIndex = serverAddr.lastIndexOf(\":\");\n+        nettyServerConfig.setListenPort(Integer.parseInt(serverAddr.substring(lastColonIndex + 1)));\n         remotingServer = new NettyRemotingServer(nettyServerConfig, channelEventListener);\n     }\n \ndiff --git a/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/common/GrpcClientSettingsManager.java b/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/common/GrpcClientSettingsManager.java\nindex e741bd389..bde87c53c 100644\n--- a/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/common/GrpcClientSettingsManager.java\n+++ b/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/common/GrpcClientSettingsManager.java\n@@ -115,9 +115,9 @@ public class GrpcClientSettingsManager extends ServiceThread implements StartAnd\n         final Metric.Builder metricBuilder = Metric.newBuilder();\n         switch (metricCollectorMode) {\n             case ON:\n-                final String[] split = metricCollectorAddress.split(\":\");\n-                final String host = split[0];\n-                final int port = Integer.parseInt(split[1]);\n+                final int lastColonIndex = metricCollectorAddress.lastIndexOf(\":\");\n+                final String host = metricCollectorAddress.substring(0, lastColonIndex);\n+                final int port = Integer.parseInt(metricCollectorAddress.substring(lastColonIndex + 1));\n                 Address address = Address.newBuilder().setHost(host).setPort(port).build();\n                 final Endpoints endpoints = Endpoints.newBuilder().setScheme(AddressScheme.IPv4)\n                     .addAddresses(address).build();\ndiff --git a/proxy/src/main/java/org/apache/rocketmq/proxy/service/channel/SimpleChannel.java b/proxy/src/main/java/org/apache/rocketmq/proxy/service/channel/SimpleChannel.java\nindex 65c1fd406..38a1373e3 100644\n--- a/proxy/src/main/java/org/apache/rocketmq/proxy/service/channel/SimpleChannel.java\n+++ b/proxy/src/main/java/org/apache/rocketmq/proxy/service/channel/SimpleChannel.java\n@@ -88,9 +88,9 @@ public class SimpleChannel extends AbstractChannel {\n             return null;\n         }\n \n-        String[] segments = address.split(\":\");\n-        if (2 == segments.length) {\n-            return new InetSocketAddress(segments[0], Integer.parseInt(segments[1]));\n+        int split = address.lastIndexOf(\":\");\n+        if (split > 0) {\n+            return new InetSocketAddress(address.substring(0, split), Integer.parseInt(address.substring(split + 1)));\n         }\n \n         return null;\ndiff --git a/remoting/src/main/java/org/apache/rocketmq/remoting/common/RemotingHelper.java b/remoting/src/main/java/org/apache/rocketmq/remoting/common/RemotingHelper.java\nindex 363b22eac..34559b6b3 100644\n--- a/remoting/src/main/java/org/apache/rocketmq/remoting/common/RemotingHelper.java\n+++ b/remoting/src/main/java/org/apache/rocketmq/remoting/common/RemotingHelper.java\n@@ -248,12 +248,12 @@ public class RemotingHelper {\n             return \"\";\n         }\n \n-        String[] addressSplits = address.split(\":\");\n-        if (addressSplits.length < 1) {\n-            return \"\";\n+        int lastIndex = address.lastIndexOf(\":\");\n+        if (lastIndex < 0) {\n+            return address;\n         }\n \n-        return addressSplits[0];\n+        return address.substring(0, lastIndex);\n     }\n \n     public static String parseSocketAddressAddr(SocketAddress socketAddress) {\ndiff --git a/remoting/src/main/java/org/apache/rocketmq/remoting/netty/NettyRemotingClient.java b/remoting/src/main/java/org/apache/rocketmq/remoting/netty/NettyRemotingClient.java\nindex 9f1519130..a46ddbb50 100644\n--- a/remoting/src/main/java/org/apache/rocketmq/remoting/netty/NettyRemotingClient.java\n+++ b/remoting/src/main/java/org/apache/rocketmq/remoting/netty/NettyRemotingClient.java\n@@ -353,7 +353,8 @@ public class NettyRemotingClient extends NettyRemotingAbstract implements Remoti\n \n     // Do not use RemotingUtil, it will directly resolve the domain\n     private String[] getHostAndPort(String address) {\n-        return address.split(\":\");\n+        int split = address.lastIndexOf(\":\");\n+        return split < 0 ? new String[] {address} : new String[] {address.substring(0, split), address.substring(split + 1)};\n     }\n \n     @Override\n"}
{"instance_id": "apolloconfig__apollo-4207", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/component/config/PortalConfig.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/component/config/PortalConfig.java\nindex 8ae2a4ac..73865fde 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/component/config/PortalConfig.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/component/config/PortalConfig.java\n@@ -273,4 +273,20 @@ public class PortalConfig extends RefreshableConfig {\n   public boolean supportSearchByItem() {\n     return getBooleanProperty(\"searchByItem.switch\", true);\n   }\n+\n+  /**\n+   * Get the list of password fragments that are not allowed in user passwords.\n+   * This list is used to check if a password contains commonly used patterns.\n+   * The list can be configured via the \"userPasswordNotAllowList\" property.\n+   * If not configured, returns null to indicate that the default list should be used.\n+   *\n+   * @return the list of password fragments that are not allowed, or null if not configured\n+   */\n+  public List<String> userPasswordNotAllowList() {\n+    String[] configurations = getArrayProperty(\"userPasswordNotAllowList\", null);\n+    if (configurations == null || configurations.length == 0) {\n+      return null;\n+    }\n+    return Lists.newArrayList(configurations);\n+  }\n }\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/AuthUserPasswordChecker.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/AuthUserPasswordChecker.java\nindex a5199706..5093a6ce 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/AuthUserPasswordChecker.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/AuthUserPasswordChecker.java\n@@ -16,6 +16,7 @@\n  */\n package com.ctrip.framework.apollo.portal.util.checker;\n \n+import com.ctrip.framework.apollo.portal.component.config.PortalConfig;\n import com.google.common.base.Strings;\n import java.util.Arrays;\n import java.util.List;\n@@ -28,7 +29,11 @@ public class AuthUserPasswordChecker implements UserPasswordChecker {\n   private static final Pattern PWD_PATTERN = Pattern\n       .compile(\"^(?=.*[0-9].*)(?=.*[a-zA-Z].*).{8,20}$\");\n \n-  private static final List<String> LIST_OF_CODE_FRAGMENT = Arrays.asList(\n+  /**\n+   * Default list of password fragments that are not allowed.\n+   * This list is used when no custom list is configured via PortalConfig.\n+   */\n+  static final List<String> DEFAULT_USER_PASSWORD_NOT_ALLOW_LIST = Arrays.asList(\n       \"111\", \"222\", \"333\", \"444\", \"555\", \"666\", \"777\", \"888\", \"999\", \"000\",\n       \"001122\", \"112233\", \"223344\", \"334455\", \"445566\", \"556677\", \"667788\", \"778899\", \"889900\",\n       \"009988\", \"998877\", \"887766\", \"776655\", \"665544\", \"554433\", \"443322\", \"332211\", \"221100\",\n@@ -37,6 +42,12 @@ public class AuthUserPasswordChecker implements UserPasswordChecker {\n       \"1q2w\", \"2w3e\", \"3e4r\", \"5t6y\", \"abcd\", \"qwer\", \"asdf\", \"zxcv\"\n   );\n \n+  private final PortalConfig portalConfig;\n+\n+  public AuthUserPasswordChecker(final PortalConfig portalConfig) {\n+    this.portalConfig = portalConfig;\n+  }\n+\n   @Override\n   public CheckResult checkWeakPassword(String password) {\n     if (!PWD_PATTERN.matcher(password).matches()) {\n@@ -51,6 +62,21 @@ public class AuthUserPasswordChecker implements UserPasswordChecker {\n     return new CheckResult(Boolean.TRUE, null);\n   }\n \n+  /**\n+   * Get the list of password fragments that are not allowed.\n+   * If a custom list is configured via PortalConfig, it will be used.\n+   * Otherwise, the default list will be used.\n+   *\n+   * @return the list of password fragments that are not allowed\n+   */\n+  private List<String> getNotAllowList() {\n+    List<String> customList = portalConfig.userPasswordNotAllowList();\n+    if (customList != null && !customList.isEmpty()) {\n+      return customList;\n+    }\n+    return DEFAULT_USER_PASSWORD_NOT_ALLOW_LIST;\n+  }\n+\n   /**\n    * @return The password contains code fragment or is blank.\n    */\n@@ -58,7 +84,8 @@ public class AuthUserPasswordChecker implements UserPasswordChecker {\n     if (Strings.isNullOrEmpty(password)) {\n       return true;\n     }\n-    for (String s : LIST_OF_CODE_FRAGMENT) {\n+    List<String> notAllowList = getNotAllowList();\n+    for (String s : notAllowList) {\n       if (password.toLowerCase().contains(s)) {\n         return true;\n       }\n"}
{"instance_id": "google__gson-1703", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/Streams.java b/gson/src/main/java/com/google/gson/internal/Streams.java\nindex 0bb73aa1..42058531 100644\n--- a/gson/src/main/java/com/google/gson/internal/Streams.java\n+++ b/gson/src/main/java/com/google/gson/internal/Streams.java\n@@ -114,6 +114,9 @@ public final class Streams {\n       @Override public CharSequence subSequence(int start, int end) {\n         return new String(chars, start, end - start);\n       }\n+      @Override public String toString() {\n+        return new String(chars);\n+      }\n     }\n   }\n \n"}
{"instance_id": "coder__code-server-3277", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/vscode/src/vs/workbench/browser/parts/titlebar/menubarControl.ts b/lib/vscode/src/vs/workbench/browser/parts/titlebar/menubarControl.ts\nindex 397211f0..2c82433d 100644\n--- a/lib/vscode/src/vs/workbench/browser/parts/titlebar/menubarControl.ts\n+++ b/lib/vscode/src/vs/workbench/browser/parts/titlebar/menubarControl.ts\n@@ -721,27 +721,32 @@ export class CustomMenubarControl extends MenubarControl {\n \t\t\twebNavigationActions.pop();\n \t\t}\n \n-\t\twebNavigationActions.push(new Action('logout', localize('logout', \"Log out\"), undefined, true,\n-\t\tasync (event?: MouseEvent) => {\n-\t\t\tconst COOKIE_KEY = Cookie.Key;\n-\t\t\tconst loginCookie = getCookieValue(COOKIE_KEY);\n-\n-\t\t\tthis.logService.info('Logging out of code-server');\n-\n-\t\t\tif(loginCookie) {\n-\t\t\t\tthis.logService.info(`Removing cookie under ${COOKIE_KEY}`);\n-\n-\t\t\t\tif (document && document.cookie) {\n-\t\t\t\t\t// We delete the cookie by setting the expiration to a date/time in the past\n-\t\t\t\t\tdocument.cookie = COOKIE_KEY +'=; Path=/; Expires=Thu, 01 Jan 1970 00:00:01 GMT;';\n-\t\t\t\t\twindow.location.href = '/login';\n+\t\t// Only show the logout button if using password authentication\n+\t\tconst options = document.getElementById('coder-options');\n+\t\tconst authed = options ? JSON.parse(options.getAttribute('data-settings') || '{}').authed : false;\n+\t\tif (authed) {\n+\t\t\twebNavigationActions.push(new Action('logout', localize('logout', \"Log out\"), undefined, true,\n+\t\t\tasync (event?: MouseEvent) => {\n+\t\t\t\tconst COOKIE_KEY = Cookie.Key;\n+\t\t\t\tconst loginCookie = getCookieValue(COOKIE_KEY);\n+\n+\t\t\t\tthis.logService.info('Logging out of code-server');\n+\n+\t\t\t\tif(loginCookie) {\n+\t\t\t\t\tthis.logService.info(`Removing cookie under ${COOKIE_KEY}`);\n+\n+\t\t\t\t\tif (document && document.cookie) {\n+\t\t\t\t\t\t// We delete the cookie by setting the expiration to a date/time in the past\n+\t\t\t\t\t\tdocument.cookie = COOKIE_KEY +'=; Path=/; Expires=Thu, 01 Jan 1970 00:00:01 GMT;';\n+\t\t\t\t\t\twindow.location.href = '/login';\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tthis.logService.warn('Could not delete cookie because document and/or document.cookie is undefined');\n+\t\t\t\t\t}\n \t\t\t\t} else {\n-\t\t\t\t\tthis.logService.warn('Could not delete cookie because document and/or document.cookie is undefined');\n+\t\t\t\t\tthis.logService.warn('Could not log out because we could not find cookie');\n \t\t\t\t}\n-\t\t\t} else {\n-\t\t\t\tthis.logService.warn('Could not log out because we could not find cookie');\n-\t\t\t}\n-\t\t}));\n+\t\t\t}));\n+\t\t}\n \n \t\treturn webNavigationActions;\n \t}\ndiff --git a/src/common/util.ts b/src/common/util.ts\nindex 87ca6f59..a33a7d31 100644\n--- a/src/common/util.ts\n+++ b/src/common/util.ts\n@@ -1,6 +1,7 @@\n import { logger, field } from \"@coder/logger\"\n \n export interface Options {\n+  authed?: boolean\n   base: string\n   csStaticBase: string\n   logLevel: number\ndiff --git a/src/node/routes/vscode.ts b/src/node/routes/vscode.ts\nindex aee4cacd..97150950 100644\n--- a/src/node/routes/vscode.ts\n+++ b/src/node/routes/vscode.ts\n@@ -45,6 +45,7 @@ router.get(\"/\", async (req, res) => {\n       // better as a build step? Or maintain two HTML files again?\n       commit !== \"development\" ? content.replace(/<!-- PROD_ONLY/g, \"\").replace(/END_PROD_ONLY -->/g, \"\") : content,\n       {\n+        authed: req.args.auth !== \"none\",\n         disableTelemetry: !!req.args[\"disable-telemetry\"],\n         disableUpdateCheck: !!req.args[\"disable-update-check\"],\n       },\n"}
{"instance_id": "coder__code-server-6278", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/patches/store-socket.diff b/patches/store-socket.diff\nindex cdcac74f..a18f42f3 100644\n--- a/patches/store-socket.diff\n+++ b/patches/store-socket.diff\n@@ -52,7 +52,9 @@ Index: code-server/lib/vscode/src/vs/workbench/api/node/extHostExtensionService.\n +\t\t\t\tsocketPath\n +\t\t\t};\n +\t\t\tconst message = JSON.stringify({entry});\n-+\t\t\tconst codeServerSocketPath = path.join(os.tmpdir(), 'code-server-ipc.sock');\n++\t\t\t// Include user ID in socket path to allow multiple users to run code-server\n++\t\t\tconst userId = typeof process.getuid !== 'undefined' ? process.getuid() : os.userInfo().username;\n++\t\t\tconst codeServerSocketPath = path.join(os.tmpdir(), `code-server-ipc-${userId}.sock`);\n +\t\t\tawait new Promise<void>((resolve, reject) => {\n +\t\t\t\tconst opts: _http.RequestOptions = {\n +\t\t\t\t\tpath: '/add-session',\n@@ -114,7 +116,9 @@ Index: code-server/lib/vscode/src/vs/workbench/api/node/extensionHostProcess.ts\n +\t\t\treturn;\n +\t\t}\n +\t\tconst message = JSON.stringify({socketPath});\n-+\t\tconst codeServerSocketPath = path.join(os.tmpdir(), 'code-server-ipc.sock');\n++\t\t// Include user ID in socket path to allow multiple users to run code-server\n++\t\tconst userId = typeof process.getuid !== 'undefined' ? process.getuid() : os.userInfo().username;\n++\t\tconst codeServerSocketPath = path.join(os.tmpdir(), `code-server-ipc-${userId}.sock`);\n +\t\tconst opts: _http.RequestOptions = {\n +\t\t\tpath: '/delete-session',\n +\t\t\tsocketPath: codeServerSocketPath,\ndiff --git a/src/node/vscodeSocket.ts b/src/node/vscodeSocket.ts\nindex 1bdb895f..cf29f4dc 100644\n--- a/src/node/vscodeSocket.ts\n+++ b/src/node/vscodeSocket.ts\n@@ -8,7 +8,15 @@ import { listen } from \"./app\"\n import { canConnect } from \"./util\"\n \n // Socket path of the daemonized code-server instance.\n-export const DEFAULT_SOCKET_PATH = path.join(os.tmpdir(), \"code-server-ipc.sock\")\n+// We include the user ID to ensure that different users on the same machine\n+// can run their own instances of code-server without conflicts.\n+function getSocketPath(): string {\n+  // Use process.getuid() on Unix, fallback to username on Windows\n+  const userId = typeof process.getuid !== \"undefined\" ? process.getuid() : os.userInfo().username\n+  return path.join(os.tmpdir(), `code-server-ipc-${userId}.sock`)\n+}\n+\n+export const DEFAULT_SOCKET_PATH = getSocketPath()\n \n export interface EditorSessionEntry {\n   workspace: {\n"}
{"instance_id": "google__gson-1989", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex 1511bbb1..29359840 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -765,6 +765,8 @@ public final class Gson {\n     if (prettyPrinting) {\n       jsonWriter.setIndent(\"  \");\n     }\n+    jsonWriter.setLenient(lenient);\n+    jsonWriter.setHtmlSafe(htmlSafe);\n     jsonWriter.setSerializeNulls(serializeNulls);\n     return jsonWriter;\n   }\n"}
{"instance_id": "coder__code-server-4923", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 759cfe02..5b4541e6 100644\n--- a/package.json\n+++ b/package.json\n@@ -71,7 +71,6 @@\n     \"ansi-regex\": \"^5.0.1\",\n     \"normalize-package-data\": \"^3.0.0\",\n     \"doctoc/underscore\": \"^1.13.1\",\n-    \"doctoc/**/trim\": \"^1.0.0\",\n     \"postcss\": \"^8.2.1\",\n     \"browserslist\": \"^4.16.5\",\n     \"safe-buffer\": \"^5.1.1\",\n@@ -106,9 +105,7 @@\n     \"xdg-basedir\": \"^4.0.0\",\n     \"yarn\": \"^1.22.4\"\n   },\n-  \"bin\": {\n-    \"code-server\": \"out/node/entry.js\"\n-  },\n+  \"bin\": \"out/node/entry.js\",\n   \"keywords\": [\n     \"vscode\",\n     \"development\",\ndiff --git a/src/node/app.ts b/src/node/app.ts\nindex 13871355..0e4c2f7c 100644\n--- a/src/node/app.ts\n+++ b/src/node/app.ts\n@@ -11,7 +11,7 @@ import { disposer } from \"./http\"\n import { isNodeJSErrnoException } from \"./util\"\n import { handleUpgrade } from \"./wsRouter\"\n \n-type ListenOptions = Pick<DefaultedArgs, \"socket\" | \"port\" | \"host\">\n+type ListenOptions = Pick<DefaultedArgs, \"socket\" | \"socket-mode\" | \"port\" | \"host\">\n \n export interface App extends Disposable {\n   /** Handles regular HTTP requests. */\n@@ -22,15 +22,24 @@ export interface App extends Disposable {\n   server: http.Server\n }\n \n-const listen = (server: http.Server, { host, port, socket }: ListenOptions) => {\n+const listen = (server: http.Server, { host, port, socket, \"socket-mode\": socketMode }: ListenOptions) => {\n   return new Promise<void>(async (resolve, reject) => {\n     server.on(\"error\", reject)\n \n-    const onListen = () => {\n+    const onListen = async () => {\n       // Promise resolved earlier so this is an unrelated error.\n       server.off(\"error\", reject)\n       server.on(\"error\", (err) => util.logError(logger, \"http server error\", err))\n \n+      // Set socket file permissions if socket-mode is specified.\n+      if (socket && socketMode) {\n+        try {\n+          await fs.chmod(socket, parseInt(socketMode, 8))\n+        } catch (error: any) {\n+          logger.error(error.message ? error.message : error)\n+        }\n+      }\n+\n       resolve()\n     }\n \ndiff --git a/src/node/cli.ts b/src/node/cli.ts\nindex 9928db1c..2a36aaac 100644\n--- a/src/node/cli.ts\n+++ b/src/node/cli.ts\n@@ -56,6 +56,7 @@ export interface UserProvidedArgs {\n   open?: boolean\n   \"bind-addr\"?: string\n   socket?: string\n+  \"socket-mode\"?: string\n   version?: boolean\n   \"proxy-domain\"?: string[]\n   \"reuse-window\"?: boolean\n@@ -175,6 +176,7 @@ const options: Options<Required<UserProvidedArgs>> = {\n   port: { type: \"number\", description: \"\" },\n \n   socket: { type: \"string\", path: true, description: \"Path to a socket (bind-addr will be ignored).\" },\n+  \"socket-mode\": { type: \"string\", description: \"File mode of the socket.\" },\n   version: { type: \"boolean\", short: \"v\", description: \"Display version information.\" },\n   _: { type: \"string[]\" },\n \n"}
{"instance_id": "google__gson-1904", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex ce4517a3..b4e4c2c8 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -110,6 +110,7 @@ public final class Gson {\n   static final boolean DEFAULT_SERIALIZE_NULLS = false;\n   static final boolean DEFAULT_COMPLEX_MAP_KEYS = false;\n   static final boolean DEFAULT_SPECIALIZE_FLOAT_VALUES = false;\n+  static final boolean DEFAULT_USE_JDK_UNSAFE = true;\n \n   private static final TypeToken<?> NULL_KEY_SURROGATE = TypeToken.get(Object.class);\n   private static final String JSON_NON_EXECUTABLE_PREFIX = \")]}'\\n\";\n@@ -149,6 +150,7 @@ public final class Gson {\n   final List<TypeAdapterFactory> builderHierarchyFactories;\n   final ToNumberStrategy objectToNumberStrategy;\n   final ToNumberStrategy numberToNumberStrategy;\n+  final boolean useJdkUnsafe;\n \n   /**\n    * Constructs a Gson object with default configuration. The default configuration has the\n@@ -189,7 +191,7 @@ public final class Gson {\n         Collections.<Type, InstanceCreator<?>>emptyMap(), DEFAULT_SERIALIZE_NULLS,\n         DEFAULT_COMPLEX_MAP_KEYS, DEFAULT_JSON_NON_EXECUTABLE, DEFAULT_ESCAPE_HTML,\n         DEFAULT_PRETTY_PRINT, DEFAULT_LENIENT, DEFAULT_SPECIALIZE_FLOAT_VALUES,\n-        LongSerializationPolicy.DEFAULT, null, DateFormat.DEFAULT, DateFormat.DEFAULT,\n+        DEFAULT_USE_JDK_UNSAFE, LongSerializationPolicy.DEFAULT, null, DateFormat.DEFAULT, DateFormat.DEFAULT,\n         Collections.<TypeAdapterFactory>emptyList(), Collections.<TypeAdapterFactory>emptyList(),\n         Collections.<TypeAdapterFactory>emptyList(), ToNumberPolicy.DOUBLE, ToNumberPolicy.LAZILY_PARSED_NUMBER);\n   }\n@@ -198,7 +200,7 @@ public final class Gson {\n       Map<Type, InstanceCreator<?>> instanceCreators, boolean serializeNulls,\n       boolean complexMapKeySerialization, boolean generateNonExecutableGson, boolean htmlSafe,\n       boolean prettyPrinting, boolean lenient, boolean serializeSpecialFloatingPointValues,\n-      LongSerializationPolicy longSerializationPolicy, String datePattern, int dateStyle,\n+      boolean useJdkUnsafe, LongSerializationPolicy longSerializationPolicy, String datePattern, int dateStyle,\n       int timeStyle, List<TypeAdapterFactory> builderFactories,\n       List<TypeAdapterFactory> builderHierarchyFactories,\n       List<TypeAdapterFactory> factoriesToBeAdded,\n@@ -206,7 +208,8 @@ public final class Gson {\n     this.excluder = excluder;\n     this.fieldNamingStrategy = fieldNamingStrategy;\n     this.instanceCreators = instanceCreators;\n-    this.constructorConstructor = new ConstructorConstructor(instanceCreators);\n+    this.constructorConstructor = new ConstructorConstructor(instanceCreators, useJdkUnsafe);\n+    this.useJdkUnsafe = useJdkUnsafe;\n     this.serializeNulls = serializeNulls;\n     this.complexMapKeySerialization = complexMapKeySerialization;\n     this.generateNonExecutableJson = generateNonExecutableGson;\ndiff --git a/gson/src/main/java/com/google/gson/GsonBuilder.java b/gson/src/main/java/com/google/gson/GsonBuilder.java\nindex fa2bb926..902201cf 100644\n--- a/gson/src/main/java/com/google/gson/GsonBuilder.java\n+++ b/gson/src/main/java/com/google/gson/GsonBuilder.java\n@@ -94,6 +94,7 @@ public final class GsonBuilder {\n   private boolean prettyPrinting = DEFAULT_PRETTY_PRINT;\n   private boolean generateNonExecutableJson = DEFAULT_JSON_NON_EXECUTABLE;\n   private boolean lenient = DEFAULT_LENIENT;\n+  private boolean useJdkUnsafe = Gson.DEFAULT_USE_JDK_UNSAFE;\n   private ToNumberStrategy objectToNumberStrategy = ToNumberPolicy.DOUBLE;\n   private ToNumberStrategy numberToNumberStrategy = ToNumberPolicy.LAZILY_PARSED_NUMBER;\n \n@@ -129,6 +130,7 @@ public final class GsonBuilder {\n     this.timeStyle = gson.timeStyle;\n     this.factories.addAll(gson.builderFactories);\n     this.hierarchyFactories.addAll(gson.builderHierarchyFactories);\n+    this.useJdkUnsafe = gson.useJdkUnsafe;\n     this.objectToNumberStrategy = gson.objectToNumberStrategy;\n     this.numberToNumberStrategy = gson.numberToNumberStrategy;\n   }\n@@ -429,6 +431,24 @@ public final class GsonBuilder {\n     return this;\n   }\n \n+  /**\n+   * By default, Gson uses {@link sun.misc.Unsafe} to create instances of classes that do not\n+   * have a no-args constructor. However, {@code Unsafe} might not be available for all Java\n+   * runtimes. For example, it is not available in Android, and it is not available when\n+   * running in a security-restricted environment. In these cases, this method can be used\n+   * to disable the usage of {@code Unsafe}.\n+   *\n+   * <p>When Unsafe is disabled, Gson will throw a {@link com.google.gson.JsonIOException}\n+   * when it tries to deserialize a class that does not have a no-args constructor.\n+   *\n+   * @return a reference to this {@code GsonBuilder} object to fulfill the \"Builder\" pattern\n+   * @since 2.9.0\n+   */\n+  public GsonBuilder disableJdkUnsafe() {\n+    this.useJdkUnsafe = false;\n+    return this;\n+  }\n+\n   /**\n    * By default, Gson escapes HTML characters such as &lt; &gt; etc. Use this option to configure\n    * Gson to pass-through HTML characters as is.\n@@ -626,7 +646,7 @@ public final class GsonBuilder {\n     return new Gson(excluder, fieldNamingPolicy, instanceCreators,\n         serializeNulls, complexMapKeySerialization,\n         generateNonExecutableJson, escapeHtmlChars, prettyPrinting, lenient,\n-        serializeSpecialFloatingPointValues, longSerializationPolicy,\n+        serializeSpecialFloatingPointValues, useJdkUnsafe, longSerializationPolicy,\n         datePattern, dateStyle, timeStyle,\n         this.factories, this.hierarchyFactories, factories, objectToNumberStrategy, numberToNumberStrategy);\n   }\ndiff --git a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\nindex 9ef0d39a..1fe41394 100644\n--- a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n+++ b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n@@ -48,9 +48,11 @@ import com.google.gson.reflect.TypeToken;\n  */\n public final class ConstructorConstructor {\n   private final Map<Type, InstanceCreator<?>> instanceCreators;\n+  private final boolean useJdkUnsafe;\n \n-  public ConstructorConstructor(Map<Type, InstanceCreator<?>> instanceCreators) {\n+  public ConstructorConstructor(Map<Type, InstanceCreator<?>> instanceCreators, boolean useJdkUnsafe) {\n     this.instanceCreators = instanceCreators;\n+    this.useJdkUnsafe = useJdkUnsafe;\n   }\n \n   public <T> ObjectConstructor<T> get(TypeToken<T> typeToken) {\n@@ -233,21 +235,32 @@ public final class ConstructorConstructor {\n     return null;\n   }\n \n-  private <T> ObjectConstructor<T> newUnsafeAllocator(\n-      final Type type, final Class<? super T> rawType) {\n-    return new ObjectConstructor<T>() {\n-      private final UnsafeAllocator unsafeAllocator = UnsafeAllocator.create();\n-      @SuppressWarnings(\"unchecked\")\n-      @Override public T construct() {\n-        try {\n-          Object newInstance = unsafeAllocator.newInstance(rawType);\n-          return (T) newInstance;\n-        } catch (Exception e) {\n-          throw new RuntimeException((\"Unable to invoke no-args constructor for \" + type + \". \"\n-              + \"Registering an InstanceCreator with Gson for this type may fix this problem.\"), e);\n+  private <T> ObjectConstructor<T> newUnsafeAllocator(final Type type, final Class<? super T> rawType) {\n+    if (useJdkUnsafe) {\n+      return new ObjectConstructor<T>() {\n+        private final UnsafeAllocator unsafeAllocator = UnsafeAllocator.create();\n+        @SuppressWarnings(\"unchecked\")\n+        @Override public T construct() {\n+          try {\n+            Object newInstance = unsafeAllocator.newInstance(rawType);\n+            return (T) newInstance;\n+          } catch (Exception e) {\n+            throw new RuntimeException((\"Unable to invoke no-args constructor for \" + type + \". \"\n+                + \"Registering an InstanceCreator with Gson for this type may fix this problem.\"), e);\n+          }\n         }\n-      }\n-    };\n+      };\n+    } else {\n+      final String exceptionMessage = \"Unable to create instance of \" + rawType + \"; \"\n+          + \"usage of JDK Unsafe is disabled. Registering an InstanceCreator or a TypeAdapter \"\n+          + \"for this type, adding a no-args constructor, or enabling usage of JDK Unsafe \"\n+          + \"may fix this problem.\";\n+      return new ObjectConstructor<T>() {\n+        @Override public T construct() {\n+          throw new JsonIOException(exceptionMessage);\n+        }\n+      };\n+    }\n   }\n \n   @Override public String toString() {\n"}
{"instance_id": "apolloconfig__apollo-4464", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/controller/UserInfoController.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/controller/UserInfoController.java\nindex d5af6443..64bf3c78 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/controller/UserInfoController.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/controller/UserInfoController.java\n@@ -16,6 +16,7 @@\n  */\n package com.ctrip.framework.apollo.portal.controller;\n \n+import com.ctrip.framework.apollo.common.dto.PageDTO;\n import com.ctrip.framework.apollo.common.exception.BadRequestException;\n import com.ctrip.framework.apollo.core.utils.StringUtils;\n import com.ctrip.framework.apollo.portal.entity.bo.UserInfo;\n@@ -34,6 +35,7 @@ import org.springframework.security.access.prepost.PreAuthorize;\n import org.springframework.web.bind.annotation.GetMapping;\n import org.springframework.web.bind.annotation.PathVariable;\n import org.springframework.web.bind.annotation.PostMapping;\n+import org.springframework.web.bind.annotation.PutMapping;\n import org.springframework.web.bind.annotation.RequestBody;\n import org.springframework.web.bind.annotation.RequestParam;\n import org.springframework.web.bind.annotation.RestController;\n@@ -98,4 +100,24 @@ public class UserInfoController {\n     return userService.findByUserId(userId);\n   }\n \n+  @PreAuthorize(value = \"@permissionValidator.isSuperAdmin()\")\n+  @GetMapping(\"/users/page\")\n+  public PageDTO<UserInfo> getUsersByPage(\n+      @RequestParam(value = \"keyword\", required = false, defaultValue = \"\") String keyword,\n+      @RequestParam(value = \"page\", defaultValue = \"0\") int page,\n+      @RequestParam(value = \"size\", defaultValue = \"10\") int size) {\n+    return userService.findUsers(keyword, page, size);\n+  }\n+\n+  @PreAuthorize(value = \"@permissionValidator.isSuperAdmin()\")\n+  @PutMapping(\"/users/{username}/enabled\")\n+  public void updateUserEnabled(@PathVariable String username,\n+      @RequestParam boolean enabled) {\n+    if (userService instanceof SpringSecurityUserService) {\n+      ((SpringSecurityUserService) userService).updateUserEnabled(username, enabled);\n+    } else {\n+      throw new UnsupportedOperationException(\"Update user enabled status is unsupported\");\n+    }\n+  }\n+\n }\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/entity/bo/UserInfo.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/entity/bo/UserInfo.java\nindex 6c338400..0f225a40 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/entity/bo/UserInfo.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/entity/bo/UserInfo.java\n@@ -21,6 +21,7 @@ public class UserInfo {\n   private String userId;\n   private String name;\n   private String email;\n+  private int enabled;\n \n   public UserInfo() {\n \n@@ -54,6 +55,14 @@ public class UserInfo {\n     this.email = email;\n   }\n \n+  public int getEnabled() {\n+    return enabled;\n+  }\n+\n+  public void setEnabled(int enabled) {\n+    this.enabled = enabled;\n+  }\n+\n   @Override\n   public boolean equals(Object o) {\n     if (o instanceof UserInfo) {\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/entity/po/UserPO.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/entity/po/UserPO.java\nindex 076d13f4..689524fd 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/entity/po/UserPO.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/entity/po/UserPO.java\n@@ -100,6 +100,7 @@ public class UserPO {\n     userInfo.setUserId(this.getUsername());\n     userInfo.setName(this.getUserDisplayName());\n     userInfo.setEmail(this.getEmail());\n+    userInfo.setEnabled(this.getEnabled());\n     return userInfo;\n   }\n }\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/repository/UserRepository.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/repository/UserRepository.java\nindex 7eee74df..77fc8fe7 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/repository/UserRepository.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/repository/UserRepository.java\n@@ -18,6 +18,8 @@ package com.ctrip.framework.apollo.portal.repository;\n \n import com.ctrip.framework.apollo.portal.entity.po.UserPO;\n \n+import org.springframework.data.domain.Page;\n+import org.springframework.data.domain.Pageable;\n import org.springframework.data.repository.PagingAndSortingRepository;\n \n import java.util.List;\n@@ -36,4 +38,8 @@ public interface UserRepository extends PagingAndSortingRepository<UserPO, Long>\n   UserPO findByUsername(String username);\n \n   List<UserPO> findByUsernameIn(List<String> userNames);\n+\n+  Page<UserPO> findAll(Pageable pageable);\n+\n+  Page<UserPO> findByUsernameLikeOrUserDisplayNameLike(String username, String userDisplayName, Pageable pageable);\n }\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/UserService.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/UserService.java\nindex 3eefca17..f113acb3 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/UserService.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/UserService.java\n@@ -16,6 +16,7 @@\n  */\n package com.ctrip.framework.apollo.portal.spi;\n \n+import com.ctrip.framework.apollo.common.dto.PageDTO;\n import com.ctrip.framework.apollo.portal.entity.bo.UserInfo;\n \n import java.util.List;\n@@ -30,4 +31,14 @@ public interface UserService {\n \n   List<UserInfo> findByUserIds(List<String> userIds);\n \n+  /**\n+   * Find all users with pagination\n+   * @param page page number (0-based)\n+   * @param size page size\n+   * @return page of users\n+   */\n+  default PageDTO<UserInfo> findUsers(String keyword, int page, int size) {\n+    throw new UnsupportedOperationException(\"Find users with pagination is not supported\");\n+  }\n+\n }\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/defaultimpl/DefaultUserService.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/defaultimpl/DefaultUserService.java\nindex 19f8f5b2..dd910a3b 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/defaultimpl/DefaultUserService.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/defaultimpl/DefaultUserService.java\n@@ -56,6 +56,7 @@ public class DefaultUserService implements UserService {\n     defaultUser.setUserId(\"apollo\");\n     defaultUser.setName(\"apollo\");\n     defaultUser.setEmail(\"apollo@acme.com\");\n+    defaultUser.setEnabled(1);\n \n     return defaultUser;\n   }\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/springsecurity/SpringSecurityUserService.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/springsecurity/SpringSecurityUserService.java\nindex 7bda22f6..99f957e4 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/springsecurity/SpringSecurityUserService.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/spi/springsecurity/SpringSecurityUserService.java\n@@ -16,6 +16,7 @@\n  */\n package com.ctrip.framework.apollo.portal.spi.springsecurity;\n \n+import com.ctrip.framework.apollo.common.dto.PageDTO;\n import com.ctrip.framework.apollo.core.utils.StringUtils;\n import com.ctrip.framework.apollo.portal.entity.bo.UserInfo;\n import com.ctrip.framework.apollo.portal.entity.po.Authority;\n@@ -26,6 +27,8 @@ import com.ctrip.framework.apollo.portal.spi.UserService;\n \n import java.util.HashMap;\n import java.util.Map;\n+import org.springframework.data.domain.Page;\n+import org.springframework.data.domain.PageRequest;\n import org.springframework.security.crypto.password.PasswordEncoder;\n import org.springframework.transaction.annotation.Transactional;\n import org.springframework.util.CollectionUtils;\n@@ -127,4 +130,31 @@ public class SpringSecurityUserService implements UserService {\n \n     return users.stream().map(UserPO::toUserInfo).collect(Collectors.toList());\n   }\n+\n+  @Override\n+  public PageDTO<UserInfo> findUsers(String keyword, int page, int size) {\n+    PageRequest pageRequest = PageRequest.of(page, size);\n+    Page<UserPO> usersPage;\n+    if (StringUtils.isEmpty(keyword)) {\n+      usersPage = userRepository.findAll(pageRequest);\n+    } else {\n+      usersPage = userRepository.findByUsernameLikeOrUserDisplayNameLike(\n+          \"%\" + keyword + \"%\", \"%\" + keyword + \"%\", pageRequest);\n+    }\n+\n+    List<UserInfo> userInfos = usersPage.getContent().stream()\n+        .map(UserPO::toUserInfo)\n+        .collect(Collectors.toList());\n+\n+    return new PageDTO<>(userInfos, pageRequest, usersPage.getTotalElements());\n+  }\n+\n+  @Transactional\n+  public void updateUserEnabled(String username, boolean enabled) {\n+    UserPO user = userRepository.findByUsername(username);\n+    if (user != null) {\n+      user.setEnabled(enabled ? 1 : 0);\n+      userRepository.save(user);\n+    }\n+  }\n }\ndiff --git a/apollo-portal/src/main/resources/static/i18n/en.json b/apollo-portal/src/main/resources/static/i18n/en.json\nindex 743f42f3..bef1f6c2 100644\n--- a/apollo-portal/src/main/resources/static/i18n/en.json\n+++ b/apollo-portal/src/main/resources/static/i18n/en.json\n@@ -566,9 +566,25 @@\n   \"UserMange.UserDisplayName\": \"User Display Name\",\n   \"UserMange.UserNameTips\": \"If the user name entered does not exist, will create a new one. If it already exists, then it will be updated.\",\n   \"UserMange.Pwd\": \"Password\",\n+  \"UserMange.PwdTips\": \"Enter a new password to update\",\n   \"UserMange.Email\": \"Email\",\n   \"UserMange.Created\": \"Create user successfully\",\n   \"UserMange.CreateFailed\": \"Failed to create user\",\n+  \"UserMange.Status\": \"Status\",\n+  \"UserMange.Operation\": \"Operation\",\n+  \"UserMange.Enabled\": \"Enabled\",\n+  \"UserMange.Disabled\": \"Disabled\",\n+  \"UserMange.Enable\": \"Enable\",\n+  \"UserMange.Disable\": \"Disable\",\n+  \"UserMange.Edit\": \"Edit\",\n+  \"UserMange.AddUser\": \"Add User\",\n+  \"UserMange.EditUser\": \"Edit User\",\n+  \"UserMange.SearchPlaceholder\": \"Search by username or display name\",\n+  \"UserMange.NoUsers\": \"No users found\",\n+  \"UserMange.TotalUsers\": \"Total Users\",\n+  \"UserMange.LoadUsersFailed\": \"Failed to load users\",\n+  \"UserMange.UpdateStatusSuccess\": \"User status updated successfully\",\n+  \"UserMange.UpdateStatusFailed\": \"Failed to update user status\",\n   \"Open.Manage.Title\": \"Open Platform\",\n   \"Open.Manage.CreateThirdApp\": \"Create third-party applications\",\n   \"Open.Manage.CreateThirdAppTips\": \"(Note: Third-party applications can manage configuration through Apollo Open Platform)\",\ndiff --git a/apollo-portal/src/main/resources/static/i18n/zh-CN.json b/apollo-portal/src/main/resources/static/i18n/zh-CN.json\nindex a8e14c3a..97bc2b36 100644\n--- a/apollo-portal/src/main/resources/static/i18n/zh-CN.json\n+++ b/apollo-portal/src/main/resources/static/i18n/zh-CN.json\n@@ -566,9 +566,25 @@\n   \"UserMange.UserDisplayName\": \"\u7528\u6237\u540d\u79f0\",\n   \"UserMange.UserNameTips\": \"\u8f93\u5165\u7684\u7528\u6237\u540d\u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5219\u65b0\u5efa\u3002\u82e5\u5df2\u5b58\u5728\uff0c\u5219\u66f4\u65b0\u3002\",\n   \"UserMange.Pwd\": \"\u5bc6\u7801\",\n+  \"UserMange.PwdTips\": \"\u8f93\u5165\u65b0\u5bc6\u7801\u4ee5\u66f4\u65b0\",\n   \"UserMange.Email\": \"\u90ae\u7bb1\",\n   \"UserMange.Created\": \"\u521b\u5efa\u7528\u6237\u6210\u529f\",\n   \"UserMange.CreateFailed\": \"\u521b\u5efa\u7528\u6237\u5931\u8d25\",\n+  \"UserMange.Status\": \"\u72b6\u6001\",\n+  \"UserMange.Operation\": \"\u64cd\u4f5c\",\n+  \"UserMange.Enabled\": \"\u5df2\u542f\u7528\",\n+  \"UserMange.Disabled\": \"\u5df2\u7981\u7528\",\n+  \"UserMange.Enable\": \"\u542f\u7528\",\n+  \"UserMange.Disable\": \"\u7981\u7528\",\n+  \"UserMange.Edit\": \"\u7f16\u8f91\",\n+  \"UserMange.AddUser\": \"\u6dfb\u52a0\u7528\u6237\",\n+  \"UserMange.EditUser\": \"\u7f16\u8f91\u7528\u6237\",\n+  \"UserMange.SearchPlaceholder\": \"\u6309\u7528\u6237\u540d\u6216\u663e\u793a\u540d\u79f0\u641c\u7d22\",\n+  \"UserMange.NoUsers\": \"\u672a\u627e\u5230\u7528\u6237\",\n+  \"UserMange.TotalUsers\": \"\u7528\u6237\u603b\u6570\",\n+  \"UserMange.LoadUsersFailed\": \"\u52a0\u8f7d\u7528\u6237\u5217\u8868\u5931\u8d25\",\n+  \"UserMange.UpdateStatusSuccess\": \"\u7528\u6237\u72b6\u6001\u66f4\u65b0\u6210\u529f\",\n+  \"UserMange.UpdateStatusFailed\": \"\u7528\u6237\u72b6\u6001\u66f4\u65b0\u5931\u8d25\",\n   \"Open.Manage.Title\": \"\u5f00\u653e\u5e73\u53f0\",\n   \"Open.Manage.CreateThirdApp\": \"\u521b\u5efa\u7b2c\u4e09\u65b9\u5e94\u7528\",\n   \"Open.Manage.CreateThirdAppTips\": \"\uff08\u8bf4\u660e: \u7b2c\u4e09\u65b9\u5e94\u7528\u53ef\u4ee5\u901a\u8fc7 Apollo \u5f00\u653e\u5e73\u53f0\u6765\u5bf9\u914d\u7f6e\u8fdb\u884c\u7ba1\u7406\uff09\",\ndiff --git a/apollo-portal/src/main/resources/static/scripts/controller/UserController.js b/apollo-portal/src/main/resources/static/scripts/controller/UserController.js\nindex 82e0ef4a..af795b87 100644\n--- a/apollo-portal/src/main/resources/static/scripts/controller/UserController.js\n+++ b/apollo-portal/src/main/resources/static/scripts/controller/UserController.js\n@@ -21,6 +21,16 @@ user_module.controller('UserController',\n function UserController($scope, $window, $translate, toastr, AppUtil, UserService, PermissionService) {\n \n     $scope.user = {};\n+    $scope.users = [];\n+    $scope.usersPage = {\n+        page: 0,\n+        size: 10,\n+        keyword: '',\n+        totalElements: 0,\n+        totalPages: 0\n+    };\n+    $scope.showUserForm = false;\n+    $scope.isEdit = false;\n \n     initPermission();\n \n@@ -28,15 +38,85 @@ function UserController($scope, $window, $translate, toastr, AppUtil, UserServic\n         PermissionService.has_root_permission()\n         .then(function (result) {\n             $scope.isRootUser = result.hasPermission;\n+            if ($scope.isRootUser) {\n+                loadUsers();\n+            }\n         })\n     }\n \n+    function loadUsers() {\n+        UserService.findUsersByPage($scope.usersPage.keyword, $scope.usersPage.page, $scope.usersPage.size)\n+        .then(function (result) {\n+            $scope.users = result.content;\n+            $scope.usersPage.totalElements = result.total;\n+            $scope.usersPage.totalPages = Math.ceil(result.total / $scope.usersPage.size);\n+        }, function (result) {\n+            AppUtil.showErrorMsg(result, $translate.instant('UserMange.LoadUsersFailed'));\n+        });\n+    }\n+\n+    $scope.searchUsers = function () {\n+        $scope.usersPage.page = 0;\n+        loadUsers();\n+    };\n+\n+    $scope.goToPage = function (page) {\n+        if (page >= 0 && page < $scope.usersPage.totalPages) {\n+            $scope.usersPage.page = page;\n+            loadUsers();\n+        }\n+    };\n+\n+    $scope.showAddUserForm = function () {\n+        $scope.user = {};\n+        $scope.showUserForm = true;\n+        $scope.isEdit = false;\n+    };\n+\n+    $scope.showEditUserForm = function (userToEdit) {\n+        $scope.user = {\n+            username: userToEdit.userId,\n+            userDisplayName: userToEdit.name,\n+            email: userToEdit.email,\n+            enabled: userToEdit.enabled\n+        };\n+        $scope.showUserForm = true;\n+        $scope.isEdit = true;\n+    };\n+\n+    $scope.cancelUserForm = function () {\n+        $scope.showUserForm = false;\n+        $scope.user = {};\n+    };\n+\n     $scope.createOrUpdateUser = function () {\n         UserService.createOrUpdateUser($scope.user).then(function (result) {\n             toastr.success($translate.instant('UserMange.Created'));\n+            $scope.showUserForm = false;\n+            $scope.user = {};\n+            loadUsers();\n         }, function (result) {\n             AppUtil.showErrorMsg(result, $translate.instant('UserMange.CreateFailed'));\n         })\n+    };\n \n-    }\n+    $scope.toggleUserEnabled = function (user) {\n+        var newEnabled = user.enabled === 1 ? false : true;\n+        UserService.updateUserEnabled(user.userId, newEnabled).then(function (result) {\n+            toastr.success($translate.instant('UserMange.UpdateStatusSuccess'));\n+            loadUsers();\n+        }, function (result) {\n+            AppUtil.showErrorMsg(result, $translate.instant('UserMange.UpdateStatusFailed'));\n+        });\n+    };\n+\n+    $scope.getPageNumbers = function () {\n+        var pages = [];\n+        var startPage = Math.max(0, $scope.usersPage.page - 2);\n+        var endPage = Math.min($scope.usersPage.totalPages - 1, $scope.usersPage.page + 2);\n+        for (var i = startPage; i <= endPage; i++) {\n+            pages.push(i);\n+        }\n+        return pages;\n+    };\n }\ndiff --git a/apollo-portal/src/main/resources/static/scripts/services/UserService.js b/apollo-portal/src/main/resources/static/scripts/services/UserService.js\nindex 681e5066..764549ee 100644\n--- a/apollo-portal/src/main/resources/static/scripts/services/UserService.js\n+++ b/apollo-portal/src/main/resources/static/scripts/services/UserService.js\n@@ -27,6 +27,14 @@ appService.service('UserService', ['$resource', '$q', 'AppUtil', function ($reso\n         create_or_update_user: {\n             method: 'POST',\n             url: AppUtil.prefixPath() + '/users'\n+        },\n+        find_users_by_page: {\n+            method: 'GET',\n+            url: AppUtil.prefixPath() + '/users/page'\n+        },\n+        update_user_enabled: {\n+            method: 'PUT',\n+            url: AppUtil.prefixPath() + '/users/:username/enabled'\n         }\n     });\n     return {\n@@ -67,6 +75,35 @@ appService.service('UserService', ['$resource', '$q', 'AppUtil', function ($reso\n                                          d.reject(result);\n                                      });\n             return d.promise;   \n+        },\n+        findUsersByPage: function (keyword, page, size) {\n+            var d = $q.defer();\n+            user_resource.find_users_by_page({\n+                                         keyword: keyword,\n+                                         page: page,\n+                                         size: size\n+                                     },\n+                                     function (result) {\n+                                         d.resolve(result);\n+                                     },\n+                                     function (result) {\n+                                         d.reject(result);\n+                                     });\n+            return d.promise;\n+        },\n+        updateUserEnabled: function (username, enabled) {\n+            var d = $q.defer();\n+            user_resource.update_user_enabled({\n+                                         username: username,\n+                                         enabled: enabled\n+                                     },\n+                                     function (result) {\n+                                         d.resolve(result);\n+                                     },\n+                                     function (result) {\n+                                         d.reject(result);\n+                                     });\n+            return d.promise;\n         }\n     }\n }]);\ndiff --git a/apollo-portal/src/main/resources/static/user-manage.html b/apollo-portal/src/main/resources/static/user-manage.html\nindex 15227a06..833e493c 100644\n--- a/apollo-portal/src/main/resources/static/user-manage.html\n+++ b/apollo-portal/src/main/resources/static/user-manage.html\n@@ -34,60 +34,164 @@\n \n     <apollonav></apollonav>\n     <div class=\"container-fluid apollo-container\" ng-controller=\"UserController\">\n-        <div class=\"col-md-8 col-md-offset-2 panel\">\n+        <div class=\"col-md-10 col-md-offset-1 panel\">\n             <section class=\"panel-body\" ng-show=\"isRootUser\">\n-                <div class=\"row\">\n-                    <header class=\"panel-heading\">\n-                        {{'UserMange.Title' | translate }}\n-                        <small>\n-                            {{'UserMange.TitleTips' | translate }}\n-                        </small>\n-                    </header>\n-                    <form class=\"form-horizontal panel-body\" name=\"appForm\"\n-                          valdr-type=\"App\" ng-submit=\"createOrUpdateUser()\">\n-                        <div class=\"form-group\" valdr-form-group>\n+                <header class=\"panel-heading\">\n+                    {{'UserMange.Title' | translate }}\n+                    <small>\n+                        {{'UserMange.TitleTips' | translate }}\n+                    </small>\n+                </header>\n+\n+                <!-- User List Section -->\n+                <div class=\"panel-body\" ng-hide=\"showUserForm\">\n+                    <!-- Search and Add Button -->\n+                    <div class=\"row\" style=\"margin-bottom: 15px;\">\n+                        <div class=\"col-sm-6\">\n+                            <div class=\"input-group\">\n+                                <input type=\"text\" class=\"form-control\" \n+                                       placeholder=\"{{'UserMange.SearchPlaceholder' | translate }}\"\n+                                       ng-model=\"usersPage.keyword\"\n+                                       ng-keyup=\"$event.keyCode === 13 && searchUsers()\">\n+                                <span class=\"input-group-btn\">\n+                                    <button class=\"btn btn-default\" type=\"button\" ng-click=\"searchUsers()\">\n+                                        <span class=\"glyphicon glyphicon-search\"></span>\n+                                    </button>\n+                                </span>\n+                            </div>\n+                        </div>\n+                        <div class=\"col-sm-6 text-right\">\n+                            <button class=\"btn btn-primary\" ng-click=\"showAddUserForm()\">\n+                                <span class=\"glyphicon glyphicon-plus\"></span>\n+                                {{'UserMange.AddUser' | translate }}\n+                            </button>\n+                        </div>\n+                    </div>\n+\n+                    <!-- User Table -->\n+                    <div class=\"table-responsive\">\n+                        <table class=\"table table-striped table-hover\">\n+                            <thead>\n+                                <tr>\n+                                    <th>{{'UserMange.UserName' | translate }}</th>\n+                                    <th>{{'UserMange.UserDisplayName' | translate }}</th>\n+                                    <th>{{'UserMange.Email' | translate }}</th>\n+                                    <th>{{'UserMange.Status' | translate }}</th>\n+                                    <th>{{'UserMange.Operation' | translate }}</th>\n+                                </tr>\n+                            </thead>\n+                            <tbody>\n+                                <tr ng-repeat=\"u in users\">\n+                                    <td>{{u.userId}}</td>\n+                                    <td>{{u.name}}</td>\n+                                    <td>{{u.email}}</td>\n+                                    <td>\n+                                        <span class=\"label\" ng-class=\"{'label-success': u.enabled === 1, 'label-default': u.enabled !== 1}\">\n+                                            {{u.enabled === 1 ? ('UserMange.Enabled' | translate) : ('UserMange.Disabled' | translate)}}\n+                                        </span>\n+                                    </td>\n+                                    <td>\n+                                        <button class=\"btn btn-xs btn-info\" ng-click=\"showEditUserForm(u)\">\n+                                            <span class=\"glyphicon glyphicon-edit\"></span>\n+                                            {{'UserMange.Edit' | translate }}\n+                                        </button>\n+                                        <button class=\"btn btn-xs\" \n+                                                ng-class=\"{'btn-warning': u.enabled === 1, 'btn-success': u.enabled !== 1}\"\n+                                                ng-click=\"toggleUserEnabled(u)\">\n+                                            <span class=\"glyphicon\" ng-class=\"{'glyphicon-ban-circle': u.enabled === 1, 'glyphicon-ok-circle': u.enabled !== 1}\"></span>\n+                                            {{u.enabled === 1 ? ('UserMange.Disable' | translate) : ('UserMange.Enable' | translate)}}\n+                                        </button>\n+                                    </td>\n+                                </tr>\n+                                <tr ng-if=\"users.length === 0\">\n+                                    <td colspan=\"5\" class=\"text-center\">{{'UserMange.NoUsers' | translate }}</td>\n+                                </tr>\n+                            </tbody>\n+                        </table>\n+                    </div>\n+\n+                    <!-- Pagination -->\n+                    <div class=\"text-center\" ng-if=\"usersPage.totalPages > 1\">\n+                        <ul class=\"pagination\">\n+                            <li ng-class=\"{disabled: usersPage.page === 0}\">\n+                                <a href=\"#\" ng-click=\"goToPage(0); $event.preventDefault();\">&laquo;</a>\n+                            </li>\n+                            <li ng-class=\"{disabled: usersPage.page === 0}\">\n+                                <a href=\"#\" ng-click=\"goToPage(usersPage.page - 1); $event.preventDefault();\">&lsaquo;</a>\n+                            </li>\n+                            <li ng-repeat=\"p in getPageNumbers()\" ng-class=\"{active: p === usersPage.page}\">\n+                                <a href=\"#\" ng-click=\"goToPage(p); $event.preventDefault();\">{{p + 1}}</a>\n+                            </li>\n+                            <li ng-class=\"{disabled: usersPage.page >= usersPage.totalPages - 1}\">\n+                                <a href=\"#\" ng-click=\"goToPage(usersPage.page + 1); $event.preventDefault();\">&rsaquo;</a>\n+                            </li>\n+                            <li ng-class=\"{disabled: usersPage.page >= usersPage.totalPages - 1}\">\n+                                <a href=\"#\" ng-click=\"goToPage(usersPage.totalPages - 1); $event.preventDefault();\">&raquo;</a>\n+                            </li>\n+                        </ul>\n+                        <p class=\"text-muted\">\n+                            {{'UserMange.TotalUsers' | translate }}: {{usersPage.totalElements}}\n+                        </p>\n+                    </div>\n+                </div>\n+\n+                <!-- Add/Edit User Form -->\n+                <div class=\"panel-body\" ng-show=\"showUserForm\">\n+                    <h4>{{isEdit ? ('UserMange.EditUser' | translate) : ('UserMange.AddUser' | translate)}}</h4>\n+                    <form class=\"form-horizontal\" name=\"userForm\" ng-submit=\"createOrUpdateUser()\">\n+                        <div class=\"form-group\">\n                             <label class=\"col-sm-2 control-label\">\n                                 <apollorequiredfield></apollorequiredfield>\n                                 {{'UserMange.UserName' | translate }}\n                             </label>\n                             <div class=\"col-sm-5\">\n-                                <input type=\"text\" class=\"form-control\" name=\"username\" ng-model=\"user.username\">\n-                                <small>{{'UserMange.UserNameTips' | translate }}</small>\n+                                <input type=\"text\" class=\"form-control\" name=\"username\" \n+                                       ng-model=\"user.username\" \n+                                       ng-disabled=\"isEdit\"\n+                                       required>\n+                                <small ng-hide=\"isEdit\">{{'UserMange.UserNameTips' | translate }}</small>\n                             </div>\n                         </div>\n-                        <div class=\"form-group\" valdr-form-group>\n+                        <div class=\"form-group\">\n                             <label class=\"col-sm-2 control-label\">\n                                 <apollorequiredfield></apollorequiredfield>\n                                 {{'UserMange.UserDisplayName' | translate }}\n                             </label>\n                             <div class=\"col-sm-5\">\n-                                <input type=\"text\" class=\"form-control\" name=\"userDisplayName\" ng-model=\"user.userDisplayName\">\n+                                <input type=\"text\" class=\"form-control\" name=\"userDisplayName\" \n+                                       ng-model=\"user.userDisplayName\" required>\n                             </div>\n                         </div>\n-                        <div class=\"form-group\" valdr-form-group>\n+                        <div class=\"form-group\">\n                             <label class=\"col-sm-2 control-label\">\n                                 <apollorequiredfield></apollorequiredfield>\n                                 {{'UserMange.Pwd' | translate }}\n                             </label>\n                             <div class=\"col-sm-5\">\n-                                <input type=\"text\" class=\"form-control\" name=\"password\" ng-model=\"user.password\">\n+                                <input type=\"password\" class=\"form-control\" name=\"password\" \n+                                       ng-model=\"user.password\" required>\n+                                <small ng-show=\"isEdit\">{{'UserMange.PwdTips' | translate }}</small>\n                             </div>\n                         </div>\n-                        <div class=\"form-group\" valdr-form-group>\n+                        <div class=\"form-group\">\n                             <label class=\"col-sm-2 control-label\">\n                                 <apollorequiredfield></apollorequiredfield>\n                                 {{'UserMange.Email' | translate }}\n                             </label>\n                             <div class=\"col-sm-5\">\n-                                <input type=\"text\" class=\"form-control\" name=\"password\" ng-model=\"user.email\">\n+                                <input type=\"email\" class=\"form-control\" name=\"email\" \n+                                       ng-model=\"user.email\" required>\n                             </div>\n                         </div>\n \n                         <div class=\"form-group\">\n                             <div class=\"col-sm-offset-2 col-sm-9\">\n-\n                                 <button type=\"submit\" class=\"btn btn-primary\"\n-                                    ng-disabled=\"appForm.$invalid || submitBtnDisabled\">{{'Common.Submit' | translate }}\n+                                    ng-disabled=\"userForm.$invalid || submitBtnDisabled\">\n+                                    {{'Common.Submit' | translate }}\n+                                </button>\n+                                <button type=\"button\" class=\"btn btn-default\" ng-click=\"cancelUserForm()\">\n+                                    {{'Common.Cancel' | translate }}\n                                 </button>\n                             </div>\n                         </div>\n"}
{"instance_id": "apolloconfig__apollo-4568", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/apollo-common/src/main/java/com/ctrip/framework/apollo/common/utils/InputValidator.java b/apollo-common/src/main/java/com/ctrip/framework/apollo/common/utils/InputValidator.java\nindex b5d2e72c..30d5c83f 100644\n--- a/apollo-common/src/main/java/com/ctrip/framework/apollo/common/utils/InputValidator.java\n+++ b/apollo-common/src/main/java/com/ctrip/framework/apollo/common/utils/InputValidator.java\n@@ -24,10 +24,10 @@ import java.util.regex.Pattern;\n  * @author Jason Song(song_s@ctrip.com)\n  */\n public class InputValidator {\n-  public static final String INVALID_CLUSTER_NAMESPACE_MESSAGE = \"Only digits, alphabets and symbol - _ . are allowed\";\n+  public static final String INVALID_CLUSTER_NAMESPACE_MESSAGE = \"Only digits, alphabets and symbol - _ . are allowed and the name cannot start or end with .\";\n   public static final String INVALID_NAMESPACE_NAMESPACE_MESSAGE = \"not allowed to end with .json, .yml, .yaml, .xml, .properties\";\n-  public static final String CLUSTER_NAMESPACE_VALIDATOR = \"[0-9a-zA-Z_.-]+\";\n-  private static final String APP_NAMESPACE_VALIDATOR = \"[a-zA-Z0-9._-]+(?<!\\\\.(json|yml|yaml|xml|properties))$\";\n+  public static final String CLUSTER_NAMESPACE_VALIDATOR = \"[0-9a-zA-Z_-]+([.][0-9a-zA-Z_-]+)*\";\n+  private static final String APP_NAMESPACE_VALIDATOR = \"[0-9a-zA-Z_-]+([.][0-9a-zA-Z_-]+)*(?<!\\\\.(json|yml|yaml|xml|properties))$\";\n   private static final Pattern CLUSTER_NAMESPACE_PATTERN = Pattern.compile(CLUSTER_NAMESPACE_VALIDATOR);\n   private static final Pattern APP_NAMESPACE_PATTERN = Pattern.compile(APP_NAMESPACE_VALIDATOR);\n \n"}
{"instance_id": "google__gson-2134", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java b/gson/src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java\nindex 99ec679a..fe9114b7 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java\n@@ -150,7 +150,7 @@ public class ISO8601Utils\n             \n             if (!hasT && (date.length() <= offset)) {\n                 Calendar calendar = new GregorianCalendar(year, month - 1, day);\n-\n+                calendar.setLenient(false);\n                 pos.setIndex(offset);\n                 return calendar.getTime();\n             }\n"}
{"instance_id": "google__gson-2071", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\nindex aa1e3ff6..cb138725 100644\n--- a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n+++ b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n@@ -23,6 +23,7 @@ import java.lang.reflect.Type;\n import java.util.ArrayDeque;\n import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.EnumMap;\n import java.util.EnumSet;\n import java.util.LinkedHashMap;\n import java.util.LinkedHashSet;\n@@ -217,6 +218,22 @@ public final class ConstructorConstructor {\n             return (T) new TreeMap<Object, Object>();\n           }\n         };\n+      } else if (EnumMap.class.isAssignableFrom(rawType)) {\n+        return new ObjectConstructor<T>() {\n+          @SuppressWarnings(\"rawtypes\")\n+          @Override public T construct() {\n+            if (type instanceof ParameterizedType) {\n+              Type keyType = ((ParameterizedType) type).getActualTypeArguments()[0];\n+              if (keyType instanceof Class) {\n+                return (T) new EnumMap((Class) keyType);\n+              } else {\n+                throw new JsonIOException(\"Invalid EnumMap type: \" + type.toString());\n+              }\n+            } else {\n+              throw new JsonIOException(\"Invalid EnumMap type: \" + type.toString());\n+            }\n+          }\n+        };\n       } else if (type instanceof ParameterizedType && !(String.class.isAssignableFrom(\n           TypeToken.get(((ParameterizedType) type).getActualTypeArguments()[0]).getRawType()))) {\n         return new ObjectConstructor<T>() {\n"}
{"instance_id": "google__gson-2060", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex e45ac2f4..379ff92d 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -38,6 +38,7 @@ import java.util.concurrent.atomic.AtomicLongArray;\n import com.google.gson.internal.ConstructorConstructor;\n import com.google.gson.internal.Excluder;\n import com.google.gson.internal.GsonBuildConfig;\n+import com.google.gson.internal.LazilyParsedNumber;\n import com.google.gson.internal.Primitives;\n import com.google.gson.internal.Streams;\n import com.google.gson.internal.bind.ArrayTypeAdapter;\n@@ -267,6 +268,7 @@ public final class Gson {\n     factories.add(TypeAdapters.STRING_BUFFER_FACTORY);\n     factories.add(TypeAdapters.newFactory(BigDecimal.class, TypeAdapters.BIG_DECIMAL));\n     factories.add(TypeAdapters.newFactory(BigInteger.class, TypeAdapters.BIG_INTEGER));\n+    factories.add(TypeAdapters.newFactory(LazilyParsedNumber.class, TypeAdapters.LAZILY_PARSED_NUMBER));\n     factories.add(TypeAdapters.URL_FACTORY);\n     factories.add(TypeAdapters.URI_FACTORY);\n     factories.add(TypeAdapters.UUID_FACTORY);\ndiff --git a/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java b/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\nindex 81870bc9..83593e5d 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\n@@ -436,6 +436,21 @@ public final class TypeAdapters {\n     }\n   };\n \n+  public static final TypeAdapter<LazilyParsedNumber> LAZILY_PARSED_NUMBER = new TypeAdapter<LazilyParsedNumber>() {\n+    // Normally BigDecimal.class is used for this\n+    @Override public LazilyParsedNumber read(JsonReader in) throws IOException {\n+      if (in.peek() == JsonToken.NULL) {\n+        in.nextNull();\n+        return null;\n+      }\n+      return new LazilyParsedNumber(in.nextString());\n+    }\n+\n+    @Override public void write(JsonWriter out, LazilyParsedNumber value) throws IOException {\n+      out.value(value);\n+    }\n+  };\n+\n   public static final TypeAdapterFactory STRING_FACTORY = newFactory(String.class, STRING);\n \n   public static final TypeAdapter<StringBuilder> STRING_BUILDER = new TypeAdapter<StringBuilder>() {\n"}
{"instance_id": "google__gson-2410", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex ba7bf4b4..c6f8508e 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -102,7 +102,7 @@ import java.util.concurrent.atomic.AtomicLongArray;\n  * List&lt;MyType&gt; target2 = gson.fromJson(json, listType);\n  * </pre>\n  *\n- * <p>See the <a href=\"https://github.com/google/gson/blob/master/UserGuide.md\">Gson User Guide</a>\n+ * <p>See the <a href=\"https://github.com/google/gson/blob/main/UserGuide.md\">Gson User Guide</a>\n  * for a more complete set of examples.</p>\n  *\n  * <h2 id=\"default-lenient\">Lenient JSON handling</h2>\ndiff --git a/gson/src/main/java/com/google/gson/internal/TroubleshootingGuide.java b/gson/src/main/java/com/google/gson/internal/TroubleshootingGuide.java\nindex 69c1b06d..d0fbc1a4 100644\n--- a/gson/src/main/java/com/google/gson/internal/TroubleshootingGuide.java\n+++ b/gson/src/main/java/com/google/gson/internal/TroubleshootingGuide.java\n@@ -7,6 +7,6 @@ public class TroubleshootingGuide {\n    * Creates a URL referring to the specified troubleshooting section.\n    */\n   public static String createUrl(String id) {\n-    return \"https://github.com/google/gson/blob/master/Troubleshooting.md#\" + id;\n+    return \"https://github.com/google/gson/blob/main/Troubleshooting.md#\" + id;\n   }\n }\n"}
{"instance_id": "google__gson-2167", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/JsonObject.java b/gson/src/main/java/com/google/gson/JsonObject.java\nindex 285a8429..2eb3ad65 100644\n--- a/gson/src/main/java/com/google/gson/JsonObject.java\n+++ b/gson/src/main/java/com/google/gson/JsonObject.java\n@@ -18,7 +18,10 @@ package com.google.gson;\n \n import com.google.gson.internal.LinkedTreeMap;\n \n+import java.util.AbstractSet;\n+import java.util.Iterator;\n import java.util.Map;\n+import java.util.Objects;\n import java.util.Set;\n \n /**\n@@ -119,7 +122,82 @@ public final class JsonObject extends JsonElement {\n    * @return a set of members of this object.\n    */\n   public Set<Map.Entry<String, JsonElement>> entrySet() {\n-    return members.entrySet();\n+    return new JsonObjectEntrySet(members.entrySet());\n+  }\n+\n+  /**\n+   * Wrapper for the entry set that validates values on {@link Entry#setValue(JsonElement)}.\n+   */\n+  private static final class JsonObjectEntrySet extends AbstractSet<Map.Entry<String, JsonElement>> {\n+    private final Set<Map.Entry<String, JsonElement>> delegate;\n+\n+    JsonObjectEntrySet(Set<Map.Entry<String, JsonElement>> delegate) {\n+      this.delegate = delegate;\n+    }\n+\n+    @Override\n+    public Iterator<Map.Entry<String, JsonElement>> iterator() {\n+      return new Iterator<Map.Entry<String, JsonElement>>() {\n+        private final Iterator<Map.Entry<String, JsonElement>> delegateIterator = delegate.iterator();\n+\n+        @Override\n+        public boolean hasNext() {\n+          return delegateIterator.hasNext();\n+        }\n+\n+        @Override\n+        public Map.Entry<String, JsonElement> next() {\n+          return new JsonObjectEntry(delegateIterator.next());\n+        }\n+\n+        @Override\n+        public void remove() {\n+          delegateIterator.remove();\n+        }\n+      };\n+    }\n+\n+    @Override\n+    public int size() {\n+      return delegate.size();\n+    }\n+  }\n+\n+  /**\n+   * Wrapper for an entry that validates the value on {@link #setValue(JsonElement)}.\n+   */\n+  private static final class JsonObjectEntry implements Map.Entry<String, JsonElement> {\n+    private final Map.Entry<String, JsonElement> delegate;\n+\n+    JsonObjectEntry(Map.Entry<String, JsonElement> delegate) {\n+      this.delegate = delegate;\n+    }\n+\n+    @Override\n+    public String getKey() {\n+      return delegate.getKey();\n+    }\n+\n+    @Override\n+    public JsonElement getValue() {\n+      return delegate.getValue();\n+    }\n+\n+    @Override\n+    public JsonElement setValue(JsonElement value) {\n+      Objects.requireNonNull(value, \"value\");\n+      return delegate.setValue(value);\n+    }\n+\n+    @Override\n+    public boolean equals(Object o) {\n+      return delegate.equals(o);\n+    }\n+\n+    @Override\n+    public int hashCode() {\n+      return delegate.hashCode();\n+    }\n   }\n \n   /**\n"}
{"instance_id": "google__gson-2158", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex 666e5f8b..7b3413d6 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -398,7 +398,7 @@ public final class Gson {\n         }\n         double doubleValue = value.doubleValue();\n         checkValidFloatingPoint(doubleValue);\n-        out.value(value);\n+        out.value(doubleValue);\n       }\n     };\n   }\n@@ -422,7 +422,7 @@ public final class Gson {\n         }\n         float floatValue = value.floatValue();\n         checkValidFloatingPoint(floatValue);\n-        out.value(value);\n+        out.value(floatValue);\n       }\n     };\n   }\ndiff --git a/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java b/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\nindex 9ba13637..cbfd13f2 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\n@@ -194,7 +194,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+      } else {\n+        out.value(value.byteValue());\n+      }\n     }\n   };\n \n@@ -223,7 +227,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+      } else {\n+        out.value(value.shortValue());\n+      }\n     }\n   };\n \n@@ -245,7 +253,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+      } else {\n+        out.value(value.intValue());\n+      }\n     }\n   };\n   public static final TypeAdapterFactory INTEGER_FACTORY\n@@ -323,7 +335,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+      } else {\n+        out.value(value.longValue());\n+      }\n     }\n   };\n \n@@ -338,7 +354,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+      } else {\n+        out.value(value.floatValue());\n+      }\n     }\n   };\n \n@@ -353,7 +373,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+      } else {\n+        out.value(value.doubleValue());\n+      }\n     }\n   };\n \n"}
{"instance_id": "google__gson-2337", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/stream/JsonReader.java b/gson/src/main/java/com/google/gson/stream/JsonReader.java\nindex 559ab2db..ddda0b52 100644\n--- a/gson/src/main/java/com/google/gson/stream/JsonReader.java\n+++ b/gson/src/main/java/com/google/gson/stream/JsonReader.java\n@@ -992,7 +992,7 @@ public class JsonReader implements Closeable {\n    * not include it in the returned string.\n    *\n    * @param quote either ' or \".\n-   * @throws NumberFormatException if any unicode escape sequences are\n+   * @throws MalformedJsonException if any unicode escape sequences are\n    *     malformed.\n    */\n   private String nextQuotedValue(char quote) throws IOException {\n@@ -1587,7 +1587,7 @@ public class JsonReader implements Closeable {\n    * been read. This supports both unicode escapes \"u000A\" and two-character\n    * escapes \"\\n\".\n    *\n-   * @throws NumberFormatException if any unicode escape sequences are\n+   * @throws MalformedJsonException if any unicode escape sequences are\n    *     malformed.\n    */\n   @SuppressWarnings(\"fallthrough\")\n@@ -1614,7 +1614,7 @@ public class JsonReader implements Closeable {\n         } else if (c >= 'A' && c <= 'F') {\n           result += (c - 'A' + 10);\n         } else {\n-          throw new NumberFormatException(\"\\\\u\" + new String(buffer, pos, 4));\n+          throw syntaxError(\"Malformed Unicode escape \\\\u\" + new String(buffer, pos, 4));\n         }\n       }\n       pos += 4;\n"}
{"instance_id": "google__gson-2420", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/Troubleshooting.md b/Troubleshooting.md\nindex 57e781cb..729f7198 100644\n--- a/Troubleshooting.md\n+++ b/Troubleshooting.md\n@@ -1,329 +1,335 @@\n-# Troubleshooting Guide\r\n-\r\n-This guide describes how to troubleshoot common issues when using Gson.\r\n-\r\n-<!-- The '<a id=\"...\"></a>' anchors below are used to create stable links; don't remove or rename them -->\r\n-<!-- Use only lowercase IDs, GitHub seems to not support uppercase IDs, see also https://github.com/orgs/community/discussions/50962 -->\r\n-\r\n-## <a id=\"class-cast-exception\"></a> `ClassCastException` when using deserialized object\r\n-\r\n-**Symptom:** `ClassCastException` is thrown when accessing an object deserialized by Gson\r\n-\r\n-**Reason:** Your code is most likely not type-safe\r\n-\r\n-**Solution:** Make sure your code adheres to the following:\r\n-\r\n-- Avoid raw types: Instead of calling `fromJson(..., List.class)`, create for example a `TypeToken<List<MyClass>>`.\r\n-  See the [user guide](UserGuide.md#collections-examples) for more information.\r\n-- When using `TypeToken` prefer the `Gson.fromJson` overloads with `TypeToken` parameter such as [`fromJson(Reader, TypeToken)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#fromJson(java.io.Reader,com.google.gson.reflect.TypeToken)).\r\n-  The overloads with `Type` parameter do not provide any type-safety guarantees.\r\n-- When using `TypeToken` make sure you don't capture a type variable. For example avoid something like `new TypeToken<List<T>>()` (where `T` is a type variable). Due to Java type erasure the actual type of `T` is not available at runtime. Refactor your code to pass around `TypeToken` instances or use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementClass)`.\r\n-\r\n-## <a id=\"reflection-inaccessible\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to unnamed module'\r\n-\r\n-**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to unnamed module' is thrown\r\n-\r\n-**Reason:** You use Gson by accident to access internal fields of third-party classes\r\n-\r\n-**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data. If this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\r\n-\r\n-**Explanation:**\r\n-\r\n-When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are seeing this error because you (by accident) rely on the reflection-based adapter for third-party classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point. For the JDK it is also not possible anymore to access internal fields using reflection starting with JDK 17, see [JEP 403](https://openjdk.org/jeps/403).\r\n-\r\n-If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\r\n-\r\n-## <a id=\"reflection-inaccessible-to-module-gson\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to module com.google.gson'\r\n-\r\n-**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to module com.google.gson' is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- If the reported package is your own package then you have not configured the module declaration of your project to allow Gson to use reflection on your classes.\r\n-- If the reported package is from a third party library or the JDK see [this troubleshooting point](#inaccessibleobjectexception-module--does-not-opens--to-unnamed-module).\r\n-\r\n-**Solution:** Make sure the `module-info.java` file of your project allows Gson to use reflection on your classes, for example:\r\n-\r\n-```java\r\n-module mymodule {\r\n-    requires com.google.gson;\r\n-\r\n-    opens mypackage to com.google.gson;\r\n-}\r\n-```\r\n-\r\n-Or in case this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\r\n-\r\n-## <a id=\"android-app-random-names\"></a> Android app not working in Release mode; random property names\r\n-\r\n-**Symptom:** Your Android app is working fine in Debug mode but fails in Release mode and the JSON properties have seemingly random names such as `a`, `b`, ...\r\n-\r\n-**Reason:** You probably have not configured ProGuard / R8 correctly\r\n-\r\n-**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-## <a id=\"android-app-broken-after-app-update\"></a> Android app unable to parse JSON after app update\r\n-\r\n-**Symptom:** You released a new version of your Android app and it fails to parse JSON data created by the previous version of your app\r\n-\r\n-**Reason:** You probably have not configured ProGuard / R8 correctly; probably the fields names are being obfuscated and their naming changed between the versions of your app\r\n-\r\n-**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-If you want to preserve backward compatibility for you app you can use [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) on the fields to specify the obfuscated name as alternate, for example: `@SerializedName(value = \"myprop\", alternate = \"a\")`\r\n-\r\n-Normally ProGuard and R8 produce a mapping file, this makes it easier to find out the obfuscated field names instead of having to find them out through trial and error or other means. See the [Android Studio user guide](https://developer.android.com/studio/build/shrink-code.html#retracing) for more information.\r\n-\r\n-## <a id=\"default-field-values-missing\"></a> Default field values not present after deserialization\r\n-\r\n-**Symptom:** You have assign default values to fields but after deserialization the fields have their standard value (such as `null` or `0`)\r\n-\r\n-**Reason:** Gson cannot invoke the constructor of your class and falls back to JDK `Unsafe` (or similar means)\r\n-\r\n-**Solution:** Make sure that the class:\r\n-\r\n-- is `static` (explicitly or implicitly when it is a top-level class)\r\n-- has a no-args constructor\r\n-\r\n-Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\r\n-\r\n-## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\r\n-\r\n-**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\r\n-\r\n-**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\r\n-\r\n-**Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\r\n-\r\n-Notes:\r\n-\r\n-- \"double brace-initialization\" also creates anonymous classes\r\n-- Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\r\n-\r\n-## <a id=\"map-key-wrong-json\"></a> Map keys having unexpected format in JSON\r\n-\r\n-**Symptom:** JSON output for `Map` keys is unexpected / cannot be deserialized again\r\n-\r\n-**Reason:** The `Map` key type is 'complex' and you have not configured the `GsonBuilder` properly\r\n-\r\n-**Solution:** Use [`GsonBuilder.enableComplexMapKeySerialization()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#enableComplexMapKeySerialization()). See also the [user guide](UserGuide.md#maps-examples) for more information.\r\n-\r\n-## <a id=\"malformed-json\"></a> Parsing JSON fails with `MalformedJsonException`\r\n-\r\n-**Symptom:** JSON parsing fails with `MalformedJsonException`\r\n-\r\n-**Reason:** The JSON data is actually malformed\r\n-\r\n-**Solution:** During debugging, log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Sometimes APIs might return HTML error pages (instead of JSON data) when reaching rate limits or when other errors occur. Also read the location information of the `MalformedJsonException` exception message, it indicates where exactly in the document the malformed data was detected, including the [JSONPath](https://goessner.net/articles/JsonPath/).\r\n-\r\n-For example, let's assume you want to deserialize the following JSON data:\r\n-\r\n-```json\r\n-{\r\n-  \"languages\": [\r\n-    \"English\",\r\n-    \"French\",\r\n-  ]\r\n-}\r\n-```\r\n-\r\n-This will fail with an exception similar to this one: `MalformedJsonException: Use JsonReader.setLenient(true) to accept malformed JSON at line 5 column 4 path $.languages[2]`  \r\n-The problem here is the trailing comma (`,`) after `\"French\"`, trailing commas are not allowed by the JSON specification. The location information \"line 5 column 4\" points to the `]` in the JSON data (with some slight inaccuracies) because Gson expected another value after `,` instead of the closing `]`. The JSONPath `$.languages[2]` in the exception message also points there: `$.` refers to the root object, `languages` refers to its member of that name and `[2]` refers to the (missing) third value in the JSON array value of that member (numbering starts at 0, so it is `[2]` instead of `[3]`).  \r\n-The proper solution here is to fix the malformed JSON data.\r\n-\r\n-To spot syntax errors in the JSON data easily you can open it in an editor with support for JSON, for example Visual Studio Code. It will highlight within the JSON data the error location and show why the JSON data is considered invalid.\r\n-\r\n-## <a id=\"number-parsed-as-double\"></a> Integral JSON number is parsed as `double`\r\n-\r\n-**Symptom:** JSON data contains an integral number such as `45` but Gson returns it as `double`\r\n-\r\n-**Reason:** When parsing a JSON number as `Object`, Gson will by default create always return a `double`\r\n-\r\n-**Solution:** Use [`GsonBuilder.setObjectToNumberStrategy`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setObjectToNumberStrategy(com.google.gson.ToNumberStrategy)) to specify what type of number should be returned\r\n-\r\n-## <a id=\"default-lenient\"></a> Malformed JSON not rejected\r\n-\r\n-**Symptom:** Gson parses malformed JSON without throwing any exceptions\r\n-\r\n-**Reason:** Due to legacy reasons Gson performs parsing by default in lenient mode\r\n-\r\n-**Solution:** See [`Gson` class documentation](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#default-lenient) section \"Lenient JSON handling\"\r\n-\r\n-Note: Even in non-lenient mode Gson deviates slightly from the JSON specification, see [`JsonReader.setLenient`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonReader.html#setLenient(boolean)) for more details.\r\n-\r\n-## <a id=\"unexpected-json-structure\"></a> `IllegalStateException`: \"Expected ... but was ...\"\r\n-\r\n-**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was ...\" is thrown\r\n-\r\n-**Reason:** The JSON data does not have the correct format\r\n-\r\n-**Solution:** Make sure that your classes correctly model the JSON data. Also during debugging log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Read the location information of the exception message, it indicates where exactly in the document the error occurred, including the [JSONPath](https://goessner.net/articles/JsonPath/).\r\n-\r\n-For example, let's assume you have the following Java class:\r\n-\r\n-```java\r\n-class WebPage {\r\n-    String languages;\r\n-}\r\n-```\r\n-\r\n-And you want to deserialize the following JSON data:\r\n-\r\n-```json\r\n-{\r\n-  \"languages\": [\"English\", \"French\"]\r\n-}\r\n-```\r\n-\r\n-This will fail with an exception similar to this one: `IllegalStateException: Expected a string but was BEGIN_ARRAY at line 2 column 17 path $.languages`  \r\n-This means Gson expected a JSON string value but found the beginning of a JSON array (`[`). The location information \"line 2 column 17\" points to the `[` in the JSON data (with some slight inaccuracies), so does the JSONPath `$.languages` in the exception message. It refers to the `languages` member of the root object (`$.`).  \r\n-The solution here is to change in the `WebPage` class the field `String languages` to `List<String> languages`.\r\n-\r\n-## <a id=\"adapter-not-null-safe\"></a> `IllegalStateException`: \"Expected ... but was NULL\"\r\n-\r\n-**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was NULL\" is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- A built-in adapter does not support JSON null values\r\n-- You have written a custom `TypeAdapter` which does not properly handle JSON null values\r\n-\r\n-**Solution:** If this occurs for a custom adapter you wrote, add code similar to the following at the beginning of its `read` method:\r\n-\r\n-```java\r\n-@Override\r\n-public MyClass read(JsonReader in) throws IOException {\r\n-    if (in.peek() == JsonToken.NULL) {\r\n-        in.nextNull();\r\n-        return null;\r\n-    }\r\n-\r\n-    ...\r\n-}\r\n-```\r\n-\r\n-Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html#nullSafe()) on the adapter instance you created.\r\n-\r\n-## <a id=\"serialize-nulls\"></a> Properties missing in JSON\r\n-\r\n-**Symptom:** Properties are missing in the JSON output\r\n-\r\n-**Reason:** Gson by default omits JSON null from the output (or: ProGuard / R8 is not configured correctly and removed unused fields)\r\n-\r\n-**Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\r\n-\r\n-Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\r\n-\r\n-## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\r\n-\r\n-**Symptom:** The JSON output differs when running on newer Android versions\r\n-\r\n-**Reason:** You use Gson by accident to access internal fields of Android classes\r\n-\r\n-**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data\r\n-\r\n-**Explanation:**\r\n-\r\n-When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are experiencing this issue because you (by accident) rely on the reflection-based adapter for Android classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point.\r\n-\r\n-If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\r\n-\r\n-## <a id=\"json-static-fields\"></a> JSON output contains values of `static` fields\r\n-\r\n-**Symptom:** The JSON output contains values of `static` fields\r\n-\r\n-**Reason:** You used `GsonBuilder.excludeFieldsWithModifiers` to overwrite the default excluded modifiers\r\n-\r\n-**Solution:** When calling `GsonBuilder.excludeFieldsWithModifiers` you overwrite the default excluded modifiers. Therefore, you have to explicitly exclude `static` fields if desired. This can be done by adding `Modifier.STATIC` as additional argument.\r\n-\r\n-## <a id=\"no-such-method-error\"></a> `NoSuchMethodError` when calling Gson methods\r\n-\r\n-**Symptom:** A `java.lang.NoSuchMethodError` is thrown when trying to call certain Gson methods\r\n-\r\n-**Reason:**\r\n-\r\n-- You have multiple versions of Gson on your classpath\r\n-- Or, the Gson version you compiled against is different from the one on your classpath\r\n-- Or, you are using a code shrinking tool such as ProGuard or R8 which removed methods from Gson\r\n-\r\n-**Solution:** First disable any code shrinking tools such as ProGuard or R8 and check if the issue persists. If not, you have to tweak the configuration of that tool to not modify Gson classes. Otherwise verify that the Gson JAR on your classpath is the same you are compiling against, and that there is only one Gson JAR on your classpath. See [this Stack Overflow question](https://stackoverflow.com/q/227486) to find out where a class is loaded from. For example, for debugging you could include the following code:\r\n-\r\n-```java\r\n-System.out.println(Gson.class.getProtectionDomain().getCodeSource().getLocation());\r\n-```\r\n-\r\n-If that fails with a `NullPointerException` you have to try one of the other ways to find out where a class is loaded from.\r\n-\r\n-## <a id=\"duplicate-fields\"></a> `IllegalArgumentException`: 'Class ... declares multiple JSON fields named '...''\r\n-\r\n-**Symptom:** An exception with the message 'Class ... declares multiple JSON fields named '...'' is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- The name you have specified with a [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation for a field collides with the name of another field\r\n-- The [`FieldNamingStrategy`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/FieldNamingStrategy.html) you have specified produces conflicting field names\r\n-- A field of your class has the same name as the field of a superclass\r\n-\r\n-Gson prevents multiple fields with the same name because during deserialization it would be ambiguous for which field the JSON data should be deserialized. For serialization it would cause the same field to appear multiple times in JSON. While the JSON specification permits this, it is likely that the application parsing the JSON data will not handle it correctly.\r\n-\r\n-**Solution:** First identify the fields with conflicting names based on the exception message. Then decide if you want to rename one of them using the [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation, or if you want to [exclude](UserGuide.md#excluding-fields-from-serialization-and-deserialization) one of them. When excluding one of the fields you have to include it for both serialization and deserialization (even if your application only performs one of these actions) because the duplicate field check cannot differentiate between these actions.\r\n-\r\n-## <a id=\"java-lang-class-unsupported\"></a> `UnsupportedOperationException` when serializing or deserializing `java.lang.Class`\r\n-\r\n-**Symptom:** An `UnsupportedOperationException` is thrown when trying to serialize or deserialize `java.lang.Class`\r\n-\r\n-**Reason:** Gson intentionally does not permit serializing and deserializing `java.lang.Class` for security reasons. Otherwise a malicious user could make your application load an arbitrary class from the classpath and, depending on what your application does with the `Class`, in the worst case perform a remote code execution attack.\r\n-\r\n-**Solution:** First check if you really need to serialize or deserialize a `Class`. Often it is possible to use string aliases and then map them to the known `Class`; you could write a custom [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) to do this. If the `Class` values are not known in advance, try to introduce a common base class or interface for all these classes and then verify that the deserialized class is a subclass. For example assuming the base class is called `MyBaseClass`, your custom `TypeAdapter` should load the class like this:\r\n-\r\n-```java\r\n-Class.forName(jsonString, false, getClass().getClassLoader()).asSubclass(MyBaseClass.class)\r\n-```\r\n-\r\n-This will not initialize arbitrary classes, and it will throw a `ClassCastException` if the loaded class is not the same as or a subclass of `MyBaseClass`.\r\n-\r\n-## <a id=\"type-token-raw\"></a> `IllegalStateException`: 'TypeToken must be created with a type argument' <br> `RuntimeException`: 'Missing type parameter'\r\n-\r\n-**Symptom:** An `IllegalStateException` with the message 'TypeToken must be created with a type argument' is thrown.  \r\n-For older Gson versions a `RuntimeException` with message 'Missing type parameter' is thrown.\r\n-\r\n-**Reason:**\r\n-\r\n-- You created a `TypeToken` without type argument, for example `new TypeToken() {}` (note the missing `<...>`). You always have to provide the type argument, for example like this: `new TypeToken<List<String>>() {}`. Normally the compiler will also emit a 'raw types' warning when you forget the `<...>`.\r\n-- You are using a code shrinking tool such as ProGuard or R8 (Android app builds normally have this enabled by default) but have not configured it correctly for usage with Gson.\r\n-\r\n-**Solution:** When you are using a code shrinking tool such as ProGuard or R8 you have to adjust your configuration to include the following rules:\r\n-\r\n-```\r\n-# Keep generic signatures; needed for correct type resolution\r\n--keepattributes Signature\r\n-\r\n-# Keep class TypeToken (respectively its generic signature)\r\n--keep class com.google.gson.reflect.TypeToken { *; }\r\n-\r\n-# Keep any (anonymous) classes extending TypeToken\r\n--keep class * extends com.google.gson.reflect.TypeToken\r\n-```\r\n-\r\n-See also the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-Note: For newer Gson versions these rules might be applied automatically; make sure you are using the latest Gson version and the latest version of the code shrinking tool.\r\n-\r\n-## <a id=\"r8-abstract-class\"></a> `JsonIOException`: 'Abstract classes can't be instantiated!' (R8)\r\n-\r\n-**Symptom:** A `JsonIOException` with the message 'Abstract classes can't be instantiated!' is thrown; the class mentioned in the exception message is not actually `abstract` in your source code, and you are using the code shrinking tool R8 (Android app builds normally have this configured by default).\r\n-\r\n-**Reason:** The code shrinking tool R8 performs optimizations where it removes the no-args constructor from a class and makes the class `abstract`. Due to this Gson cannot create an instance of the class.\r\n-\r\n-**Solution:** Make sure the class has a no-args constructor, then adjust your R8 configuration file to keep the constructor of the class. For example:\r\n-\r\n-```\r\n-# Keep the no-args constructor of the deserialized class\r\n--keepclassmembers class com.example.MyClass {\r\n-  <init>();\r\n-}\r\n-```\r\n-\r\n-For Android you can add this rule to the `proguard-rules.pro` file, see also the [Android documentation](https://developer.android.com/build/shrink-code#keep-code). In case the class name in the exception message is obfuscated, see the Android documentation about [retracing](https://developer.android.com/build/shrink-code#retracing).\r\n-\r\n-Note: If the class which you are trying to deserialize is actually abstract, then this exception is probably unrelated to R8 and you will have to implement a custom [`InstanceCreator`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/InstanceCreator.html) or [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) which creates an instance of a non-abstract subclass of the class.\r\n+# Troubleshooting Guide\n+\n+This guide describes how to troubleshoot common issues when using Gson.\n+\n+<!-- The '<a id=\"...\"></a>' anchors below are used to create stable links; don't remove or rename them -->\n+<!-- Use only lowercase IDs, GitHub seems to not support uppercase IDs, see also https://github.com/orgs/community/discussions/50962 -->\n+\n+## <a id=\"class-cast-exception\"></a> `ClassCastException` when using deserialized object\n+\n+**Symptom:** `ClassCastException` is thrown when accessing an object deserialized by Gson\n+\n+**Reason:** Your code is most likely not type-safe\n+\n+**Solution:** Make sure your code adheres to the following:\n+\n+- Avoid raw types: Instead of calling `fromJson(..., List.class)`, create for example a `TypeToken<List<MyClass>>`.\n+  See the [user guide](UserGuide.md#collections-examples) for more information.\n+- When using `TypeToken` prefer the `Gson.fromJson` overloads with `TypeToken` parameter such as [`fromJson(Reader, TypeToken)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#fromJson(java.io.Reader,com.google.gson.reflect.TypeToken)).\n+  The overloads with `Type` parameter do not provide any type-safety guarantees.\n+- When using `TypeToken` make sure you don't capture a type variable. For example avoid something like `new TypeToken<List<T>>()` (where `T` is a type variable). Due to Java type erasure the actual type of `T` is not available at runtime. Refactor your code to pass around `TypeToken` instances or use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementClass)`.\n+\n+## <a id=\"reflection-inaccessible\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to unnamed module'\n+\n+**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to unnamed module' is thrown\n+\n+**Reason:** You use Gson by accident to access internal fields of third-party classes\n+\n+**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data. If this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\n+\n+**Explanation:**\n+\n+When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are seeing this error because you (by accident) rely on the reflection-based adapter for third-party classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point. For the JDK it is also not possible anymore to access internal fields using reflection starting with JDK 17, see [JEP 403](https://openjdk.org/jeps/403).\n+\n+If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\n+\n+## <a id=\"reflection-inaccessible-to-module-gson\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to module com.google.gson'\n+\n+**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to module com.google.gson' is thrown\n+\n+**Reason:**\n+\n+- If the reported package is your own package then you have not configured the module declaration of your project to allow Gson to use reflection on your classes.\n+- If the reported package is from a third party library or the JDK see [this troubleshooting point](#inaccessibleobjectexception-module--does-not-opens--to-unnamed-module).\n+\n+**Solution:** Make sure the `module-info.java` file of your project allows Gson to use reflection on your classes, for example:\n+\n+```java\n+module mymodule {\n+    requires com.google.gson;\n+\n+    opens mypackage to com.google.gson;\n+}\n+```\n+\n+Or in case this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\n+\n+## <a id=\"android-app-random-names\"></a> Android app not working in Release mode; random property names\n+\n+**Symptom:** Your Android app is working fine in Debug mode but fails in Release mode and the JSON properties have seemingly random names such as `a`, `b`, ...\n+\n+**Reason:** You probably have not configured ProGuard / R8 correctly\n+\n+**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+## <a id=\"android-app-broken-after-app-update\"></a> Android app unable to parse JSON after app update\n+\n+**Symptom:** You released a new version of your Android app and it fails to parse JSON data created by the previous version of your app\n+\n+**Reason:** You probably have not configured ProGuard / R8 correctly; probably the fields names are being obfuscated and their naming changed between the versions of your app\n+\n+**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+If you want to preserve backward compatibility for you app you can use [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) on the fields to specify the obfuscated name as alternate, for example: `@SerializedName(value = \"myprop\", alternate = \"a\")`\n+\n+Normally ProGuard and R8 produce a mapping file, this makes it easier to find out the obfuscated field names instead of having to find them out through trial and error or other means. See the [Android Studio user guide](https://developer.android.com/studio/build/shrink-code.html#retracing) for more information.\n+\n+## <a id=\"default-field-values-missing\"></a> Default field values not present after deserialization\n+\n+**Symptom:** You have assign default values to fields but after deserialization the fields have their standard value (such as `null` or `0`)\n+\n+**Reason:** Gson cannot invoke the constructor of your class and falls back to JDK `Unsafe` (or similar means)\n+\n+**Solution:** Make sure that the class:\n+\n+- is `static` (explicitly or implicitly when it is a top-level class)\n+- has a no-args constructor\n+\n+Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\n+\n+## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\n+\n+**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\n+\n+**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\n+\n+**Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\n+\n+Notes:\n+\n+- \"double brace-initialization\" also creates anonymous classes\n+- Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\n+\n+## <a id=\"map-key-wrong-json\"></a> Map keys having unexpected format in JSON\n+\n+**Symptom:** JSON output for `Map` keys is unexpected / cannot be deserialized again\n+\n+**Reason:** The `Map` key type is 'complex' and you have not configured the `GsonBuilder` properly\n+\n+**Solution:** Use [`GsonBuilder.enableComplexMapKeySerialization()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#enableComplexMapKeySerialization()). See also the [user guide](UserGuide.md#maps-examples) for more information.\n+\n+## <a id=\"malformed-json\"></a> Parsing JSON fails with `MalformedJsonException`\n+\n+**Symptom:** JSON parsing fails with `MalformedJsonException`\n+\n+**Reason:** The JSON data is actually malformed\n+\n+**Solution:** During debugging, log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Sometimes APIs might return HTML error pages (instead of JSON data) when reaching rate limits or when other errors occur. Also read the location information of the `MalformedJsonException` exception message, it indicates where exactly in the document the malformed data was detected, including the [JSONPath](https://goessner.net/articles/JsonPath/).\n+\n+For example, let's assume you want to deserialize the following JSON data:\n+\n+```json\n+{\n+  \"languages\": [\n+    \"English\",\n+    \"French\",\n+  ]\n+}\n+```\n+\n+This will fail with an exception similar to this one: `MalformedJsonException: Use JsonReader.setLenient(true) to accept malformed JSON at line 5 column 4 path $.languages[2]`  \n+The problem here is the trailing comma (`,`) after `\"French\"`, trailing commas are not allowed by the JSON specification. The location information \"line 5 column 4\" points to the `]` in the JSON data (with some slight inaccuracies) because Gson expected another value after `,` instead of the closing `]`. The JSONPath `$.languages[2]` in the exception message also points there: `$.` refers to the root object, `languages` refers to its member of that name and `[2]` refers to the (missing) third value in the JSON array value of that member (numbering starts at 0, so it is `[2]` instead of `[3]`).  \n+The proper solution here is to fix the malformed JSON data.\n+\n+To spot syntax errors in the JSON data easily you can open it in an editor with support for JSON, for example Visual Studio Code. It will highlight within the JSON data the error location and show why the JSON data is considered invalid.\n+\n+## <a id=\"number-parsed-as-double\"></a> Integral JSON number is parsed as `double`\n+\n+**Symptom:** JSON data contains an integral number such as `45` but Gson returns it as `double`\n+\n+**Reason:** When parsing a JSON number as `Object`, Gson will by default create always return a `double`\n+\n+**Solution:** Use [`GsonBuilder.setObjectToNumberStrategy`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setObjectToNumberStrategy(com.google.gson.ToNumberStrategy)) to specify what type of number should be returned\n+\n+## <a id=\"default-lenient\"></a> Malformed JSON not rejected\n+\n+**Symptom:** Gson parses malformed JSON without throwing any exceptions\n+\n+**Reason:** Due to legacy reasons Gson performs parsing by default in lenient mode\n+\n+**Solution:** See [`Gson` class documentation](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#default-lenient) section \"Lenient JSON handling\"\n+\n+Note: Even in non-lenient mode Gson deviates slightly from the JSON specification, see [`JsonReader.setLenient`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonReader.html#setLenient(boolean)) for more details.\n+\n+## <a id=\"unexpected-json-structure\"></a> `IllegalStateException`: \"Expected ... but was ...\"\n+\n+**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was ...\" is thrown\n+\n+**Reason:** The JSON data does not have the correct format\n+\n+**Solution:** Make sure that your classes correctly model the JSON data. Also during debugging log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Read the location information of the exception message, it indicates where exactly in the document the error occurred, including the [JSONPath](https://goessner.net/articles/JsonPath/).\n+\n+For example, let's assume you have the following Java class:\n+\n+```java\n+class WebPage {\n+    String languages;\n+}\n+```\n+\n+And you want to deserialize the following JSON data:\n+\n+```json\n+{\n+  \"languages\": [\"English\", \"French\"]\n+}\n+```\n+\n+This will fail with an exception similar to this one: `IllegalStateException: Expected a string but was BEGIN_ARRAY at line 2 column 17 path $.languages`  \n+This means Gson expected a JSON string value but found the beginning of a JSON array (`[`). The location information \"line 2 column 17\" points to the `[` in the JSON data (with some slight inaccuracies), so does the JSONPath `$.languages` in the exception message. It refers to the `languages` member of the root object (`$.`).  \n+The solution here is to change in the `WebPage` class the field `String languages` to `List<String> languages`.\n+\n+## <a id=\"adapter-not-null-safe\"></a> `IllegalStateException`: \"Expected ... but was NULL\"\n+\n+**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was NULL\" is thrown\n+\n+**Reason:**\n+\n+- A built-in adapter does not support JSON null values\n+- You have written a custom `TypeAdapter` which does not properly handle JSON null values\n+\n+**Solution:** If this occurs for a custom adapter you wrote, add code similar to the following at the beginning of its `read` method:\n+\n+```java\n+@Override\n+public MyClass read(JsonReader in) throws IOException {\n+    if (in.peek() == JsonToken.NULL) {\n+        in.nextNull();\n+        return null;\n+    }\n+\n+    ...\n+}\n+```\n+\n+Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html#nullSafe()) on the adapter instance you created.\n+\n+## <a id=\"serialize-nulls\"></a> Properties missing in JSON\n+\n+**Symptom:** Properties are missing in the JSON output\n+\n+**Reason:** Gson by default omits JSON null from the output (or: ProGuard / R8 is not configured correctly and removed unused fields)\n+\n+**Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\n+\n+Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\n+\n+## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\n+\n+**Symptom:** The JSON output differs when running on newer Android versions\n+\n+**Reason:** You use Gson by accident to access internal fields of Android classes\n+\n+**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data\n+\n+**Explanation:**\n+\n+When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are experiencing this issue because you (by accident) rely on the reflection-based adapter for Android classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point.\n+\n+If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\n+\n+## <a id=\"json-static-fields\"></a> JSON output contains values of `static` fields\n+\n+**Symptom:** The JSON output contains values of `static` fields\n+\n+**Reason:** You used `GsonBuilder.excludeFieldsWithModifiers` to overwrite the default excluded modifiers\n+\n+**Solution:** When calling `GsonBuilder.excludeFieldsWithModifiers` you overwrite the default excluded modifiers. Therefore, you have to explicitly exclude `static` fields if desired. This can be done by adding `Modifier.STATIC` as additional argument.\n+\n+## <a id=\"no-such-method-error\"></a> `NoSuchMethodError` when calling Gson methods\n+\n+**Symptom:** A `java.lang.NoSuchMethodError` is thrown when trying to call certain Gson methods\n+\n+**Reason:**\n+\n+- You have multiple versions of Gson on your classpath\n+- Or, the Gson version you compiled against is different from the one on your classpath\n+- Or, you are using a code shrinking tool such as ProGuard or R8 which removed methods from Gson\n+\n+**Solution:** First disable any code shrinking tools such as ProGuard or R8 and check if the issue persists. If not, you have to tweak the configuration of that tool to not modify Gson classes. Otherwise verify that the Gson JAR on your classpath is the same you are compiling against, and that there is only one Gson JAR on your classpath. See [this Stack Overflow question](https://stackoverflow.com/q/227486) to find out where a class is loaded from. For example, for debugging you could include the following code:\n+\n+```java\n+System.out.println(Gson.class.getProtectionDomain().getCodeSource().getLocation());\n+```\n+\n+If that fails with a `NullPointerException` you have to try one of the other ways to find out where a class is loaded from.\n+\n+## <a id=\"duplicate-fields\"></a> `IllegalArgumentException`: 'Class ... declares multiple JSON fields named '...''\n+\n+**Symptom:** An exception with the message 'Class ... declares multiple JSON fields named '...'' is thrown\n+\n+**Reason:**\n+\n+- The name you have specified with a [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation for a field collides with the name of another field\n+- The [`FieldNamingStrategy`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/FieldNamingStrategy.html) you have specified produces conflicting field names\n+- A field of your class has the same name as the field of a superclass\n+\n+Gson prevents multiple fields with the same name because during deserialization it would be ambiguous for which field the JSON data should be deserialized. For serialization it would cause the same field to appear multiple times in JSON. While the JSON specification permits this, it is likely that the application parsing the JSON data will not handle it correctly.\n+\n+**Solution:** First identify the fields with conflicting names based on the exception message. Then decide if you want to rename one of them using the [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation, or if you want to [exclude](UserGuide.md#excluding-fields-from-serialization-and-deserialization) one of them. When excluding one of the fields you have to include it for both serialization and deserialization (even if your application only performs one of these actions) because the duplicate field check cannot differentiate between these actions.\n+\n+## <a id=\"java-lang-class-unsupported\"></a> `UnsupportedOperationException` when serializing or deserializing `java.lang.Class`\n+\n+**Symptom:** An `UnsupportedOperationException` is thrown when trying to serialize or deserialize `java.lang.Class`\n+\n+**Reason:** Gson intentionally does not permit serializing and deserializing `java.lang.Class` for security reasons. Otherwise a malicious user could make your application load an arbitrary class from the classpath and, depending on what your application does with the `Class`, in the worst case perform a remote code execution attack.\n+\n+**Solution:** First check if you really need to serialize or deserialize a `Class`. Often it is possible to use string aliases and then map them to the known `Class`; you could write a custom [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) to do this. If the `Class` values are not known in advance, try to introduce a common base class or interface for all these classes and then verify that the deserialized class is a subclass. For example assuming the base class is called `MyBaseClass`, your custom `TypeAdapter` should load the class like this:\n+\n+```java\n+Class.forName(jsonString, false, getClass().getClassLoader()).asSubclass(MyBaseClass.class)\n+```\n+\n+This will not initialize arbitrary classes, and it will throw a `ClassCastException` if the loaded class is not the same as or a subclass of `MyBaseClass`.\n+\n+## <a id=\"type-token-raw\"></a> `IllegalStateException`: 'TypeToken must be created with a type argument' <br> `RuntimeException`: 'Missing type parameter'\n+\n+**Symptom:** An `IllegalStateException` with the message 'TypeToken must be created with a type argument' is thrown.  \n+For older Gson versions a `RuntimeException` with message 'Missing type parameter' is thrown.\n+\n+**Reason:**\n+\n+- You created a `TypeToken` without type argument, for example `new TypeToken() {}` (note the missing `<...>`). You always have to provide the type argument, for example like this: `new TypeToken<List<String>>() {}`. Normally the compiler will also emit a 'raw types' warning when you forget the `<...>`.\n+- You are using a code shrinking tool such as ProGuard or R8 (Android app builds normally have this enabled by default) but have not configured it correctly for usage with Gson.\n+\n+**Solution:** When you are using a code shrinking tool such as ProGuard or R8 you have to adjust your configuration to include the following rules:\n+\n+```\n+# Keep generic signatures; needed for correct type resolution\n+-keepattributes Signature\n+\n+# Keep class TypeToken (respectively its generic signature)\n+-keep class com.google.gson.reflect.TypeToken { *; }\n+\n+# Keep any (anonymous) classes extending TypeToken\n+-keep class * extends com.google.gson.reflect.TypeToken\n+```\n+\n+See also the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+Note: For newer Gson versions these rules might be applied automatically; make sure you are using the latest Gson version and the latest version of the code shrinking tool.\n+\n+## <a id=\"r8-abstract-class\"></a> `JsonIOException`: 'Abstract classes can't be instantiated!' (R8)\n+\n+**Symptom:** A `JsonIOException` with the message 'Abstract classes can't be instantiated!' is thrown; the class mentioned in the exception message is not actually `abstract` in your source code, and you are using the code shrinking tool R8 (Android app builds normally have this configured by default).\n+\n+**Reason:** The code shrinking tool R8 performs optimizations where it removes the no-args constructor from a class and makes the class `abstract`. Due to this Gson cannot create an instance of the class.\n+\n+**Solution:** Make sure the class has a no-args constructor, then adjust your R8 configuration file to keep the constructor of the class. For example:\n+\n+```\n+# Keep the no-args constructor of the deserialized class\n+-keep class com.example.MyClass {\n+  <init>();\n+}\n+```\n+\n+You can also use `<init>(...);` to keep all constructors of that class.\n+\n+For Android you can add this rule to the `proguard-rules.pro` file, see also the [Android documentation](https://developer.android.com/build/shrink-code#keep-code). In case the class name in the exception message is obfuscated, see the Android documentation about [retracing](https://developer.android.com/build/shrink-code#retracing).\n+\n+Alternatively, if you are using R8 you can add the [`@Keep` annotation](https://developer.android.com/studio/write/annotations#keep) to the class or constructor you want to keep. That annotation only works with R8, not with ProGuard.\n+\n+For Kotlin classes, make sure the class has a no-args constructor. Kotlin classes which declare constructor parameters, such as `class MyClass(val s: String)`, don't have a no-args constructor by default. You can either add a secondary no-args constructor, or annotate the primary constructor with `@Keep`.\n+\n+Note: If the class which you are trying to deserialize is actually abstract in your source code, then this exception is unrelated to R8 and you will have to implement a custom [`InstanceCreator`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/InstanceCreator.html) or [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) which creates an instance of a non-abstract subclass of the class.\ndiff --git a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\nindex 7d2dc9b6..c5c41154 100644\n--- a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n+++ b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n@@ -75,15 +75,11 @@ public final class ConstructorConstructor {\n     }\n     if (Modifier.isAbstract(modifiers)) {\n       // R8 performs aggressive optimizations where it removes the default constructor of a class\n-      // and makes the class `abstract`; check for that here explicitly\n-      if (c.getDeclaredConstructors().length == 0) {\n-        return \"Abstract classes can't be instantiated! Adjust the R8 configuration or register\"\n-            + \" an InstanceCreator or a TypeAdapter for this type. Class name: \" + c.getName()\n-            + \"\\nSee \" + TroubleshootingGuide.createUrl(\"r8-abstract-class\");\n-      }\n-\n+      // and makes the class `abstract`. Suggest it might be an R8 issue and provide a\n+      // troubleshooting link, because the class might not have been abstract originally.\n       return \"Abstract classes can't be instantiated! Register an InstanceCreator\"\n-          + \" or a TypeAdapter for this type. Class name: \" + c.getName();\n+          + \" or a TypeAdapter for this type. Class name: \" + c.getName()\n+          + \"\\nSee \" + TroubleshootingGuide.createUrl(\"r8-abstract-class\");\n     }\n     return null;\n   }\ndiff --git a/gson/src/main/resources/META-INF/proguard/gson.pro b/gson/src/main/resources/META-INF/proguard/gson.pro\nindex c9f235e9..26499fa6 100644\n--- a/gson/src/main/resources/META-INF/proguard/gson.pro\n+++ b/gson/src/main/resources/META-INF/proguard/gson.pro\n@@ -42,6 +42,30 @@\n   @com.google.gson.annotations.Until <fields>;\n }\n \n+# Keep no-args constructor of classes which can be deserialized by Gson\n+# This is needed because R8 in \"full mode\" might otherwise make the class abstract\n+# and remove its no-args constructor\n+-keepclassmembers class * {\n+  @com.google.gson.annotations.SerializedName <fields>;\n+  <init>();\n+}\n+-keepclassmembers class * {\n+  @com.google.gson.annotations.Expose <fields>;\n+  <init>();\n+}\n+-keepclassmembers class * {\n+  @com.google.gson.annotations.JsonAdapter <fields>;\n+  <init>();\n+}\n+-keepclassmembers class * {\n+  @com.google.gson.annotations.Since <fields>;\n+  <init>();\n+}\n+-keepclassmembers class * {\n+  @com.google.gson.annotations.Until <fields>;\n+  <init>();\n+}\n+\n # Keep no-args constructor of classes which can be used with @JsonAdapter\n # By default their no-args constructor is invoked to create an adapter instance\n -keep class * extends com.google.gson.TypeAdapter {\n"}
{"instance_id": "google__gson-2376", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/Troubleshooting.md b/Troubleshooting.md\nindex 6bf2b857..43eaf833 100644\n--- a/Troubleshooting.md\n+++ b/Troubleshooting.md\n@@ -1,338 +1,366 @@\n-# Troubleshooting Guide\r\n-\r\n-This guide describes how to troubleshoot common issues when using Gson.\r\n-\r\n-<!-- The '<a id=\"...\"></a>' anchors below are used to create stable links; don't remove or rename them -->\r\n-<!-- Use only lowercase IDs, GitHub seems to not support uppercase IDs, see also https://github.com/orgs/community/discussions/50962 -->\r\n-\r\n-## <a id=\"class-cast-exception\"></a> `ClassCastException` when using deserialized object\r\n-\r\n-**Symptom:** `ClassCastException` is thrown when accessing an object deserialized by Gson\r\n-\r\n-**Reason:** Your code is most likely not type-safe\r\n-\r\n-**Solution:** Make sure your code adheres to the following:\r\n-\r\n-- Avoid raw types: Instead of calling `fromJson(..., List.class)`, create for example a `TypeToken<List<MyClass>>`.\r\n-  See the [user guide](UserGuide.md#collections-examples) for more information.\r\n-- When using `TypeToken` prefer the `Gson.fromJson` overloads with `TypeToken` parameter such as [`fromJson(Reader, TypeToken)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#fromJson(java.io.Reader,com.google.gson.reflect.TypeToken)).\r\n-  The overloads with `Type` parameter do not provide any type-safety guarantees.\r\n-- When using `TypeToken` make sure you don't capture a type variable. For example avoid something like `new TypeToken<List<T>>()` (where `T` is a type variable). Due to Java type erasure the actual type of `T` is not available at runtime. Refactor your code to pass around `TypeToken` instances or use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementClass)`.\r\n-\r\n-## <a id=\"reflection-inaccessible\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to unnamed module'\r\n-\r\n-**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to unnamed module' is thrown\r\n-\r\n-**Reason:** You use Gson by accident to access internal fields of third-party classes\r\n-\r\n-**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data. If this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\r\n-\r\n-**Explanation:**\r\n-\r\n-When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are seeing this error because you (by accident) rely on the reflection-based adapter for third-party classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point. For the JDK it is also not possible anymore to access internal fields using reflection starting with JDK 17, see [JEP 403](https://openjdk.org/jeps/403).\r\n-\r\n-If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\r\n-\r\n-## <a id=\"reflection-inaccessible-to-module-gson\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to module com.google.gson'\r\n-\r\n-**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to module com.google.gson' is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- If the reported package is your own package then you have not configured the module declaration of your project to allow Gson to use reflection on your classes.\r\n-- If the reported package is from a third party library or the JDK see [this troubleshooting point](#inaccessibleobjectexception-module--does-not-opens--to-unnamed-module).\r\n-\r\n-**Solution:** Make sure the `module-info.java` file of your project allows Gson to use reflection on your classes, for example:\r\n-\r\n-```java\r\n-module mymodule {\r\n-    requires com.google.gson;\r\n-\r\n-    opens mypackage to com.google.gson;\r\n-}\r\n-```\r\n-\r\n-Or in case this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\r\n-\r\n-## <a id=\"android-app-random-names\"></a> Android app not working in Release mode; random property names\r\n-\r\n-**Symptom:** Your Android app is working fine in Debug mode but fails in Release mode and the JSON properties have seemingly random names such as `a`, `b`, ...\r\n-\r\n-**Reason:** You probably have not configured ProGuard / R8 correctly\r\n-\r\n-**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-## <a id=\"android-app-broken-after-app-update\"></a> Android app unable to parse JSON after app update\r\n-\r\n-**Symptom:** You released a new version of your Android app and it fails to parse JSON data created by the previous version of your app\r\n-\r\n-**Reason:** You probably have not configured ProGuard / R8 correctly; probably the fields names are being obfuscated and their naming changed between the versions of your app\r\n-\r\n-**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-If you want to preserve backward compatibility for you app you can use [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) on the fields to specify the obfuscated name as alternate, for example: `@SerializedName(value = \"myprop\", alternate = \"a\")`\r\n-\r\n-Normally ProGuard and R8 produce a mapping file, this makes it easier to find out the obfuscated field names instead of having to find them out through trial and error or other means. See the [Android Studio user guide](https://developer.android.com/studio/build/shrink-code.html#retracing) for more information.\r\n-\r\n-## <a id=\"default-field-values-missing\"></a> Default field values not present after deserialization\r\n-\r\n-**Symptom:** You have assign default values to fields but after deserialization the fields have their standard value (such as `null` or `0`)\r\n-\r\n-**Reason:** Gson cannot invoke the constructor of your class and falls back to JDK `Unsafe` (or similar means)\r\n-\r\n-**Solution:** Make sure that the class:\r\n-\r\n-- is `static` (explicitly or implicitly when it is a top-level class)\r\n-- has a no-args constructor\r\n-\r\n-Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\r\n-\r\n-## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\r\n-\r\n-**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\r\n-\r\n-**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\r\n-\r\n-**Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\r\n-\r\n-Notes:\r\n-\r\n-- \"double brace-initialization\" also creates anonymous classes\r\n-- Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\r\n-\r\n-## <a id=\"map-key-wrong-json\"></a> Map keys having unexpected format in JSON\r\n-\r\n-**Symptom:** JSON output for `Map` keys is unexpected / cannot be deserialized again\r\n-\r\n-**Reason:** The `Map` key type is 'complex' and you have not configured the `GsonBuilder` properly\r\n-\r\n-**Solution:** Use [`GsonBuilder.enableComplexMapKeySerialization()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#enableComplexMapKeySerialization()). See also the [user guide](UserGuide.md#maps-examples) for more information.\r\n-\r\n-## <a id=\"malformed-json\"></a> Parsing JSON fails with `MalformedJsonException`\r\n-\r\n-**Symptom:** JSON parsing fails with `MalformedJsonException`\r\n-\r\n-**Reason:** The JSON data is actually malformed\r\n-\r\n-**Solution:** During debugging, log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Sometimes APIs might return HTML error pages (instead of JSON data) when reaching rate limits or when other errors occur. Also read the location information of the `MalformedJsonException` exception message, it indicates where exactly in the document the malformed data was detected, including the [JSONPath](https://goessner.net/articles/JsonPath/).\r\n-\r\n-For example, let's assume you want to deserialize the following JSON data:\r\n-\r\n-```json\r\n-{\r\n-  \"languages\": [\r\n-    \"English\",\r\n-    \"French\",\r\n-  ]\r\n-}\r\n-```\r\n-\r\n-This will fail with an exception similar to this one: `MalformedJsonException: Use JsonReader.setStrictness(Strictness.LENIENT) to accept malformed JSON at line 5 column 4 path $.languages[2]`  \r\n-The problem here is the trailing comma (`,`) after `\"French\"`, trailing commas are not allowed by the JSON specification. The location information \"line 5 column 4\" points to the `]` in the JSON data (with some slight inaccuracies) because Gson expected another value after `,` instead of the closing `]`. The JSONPath `$.languages[2]` in the exception message also points there: `$.` refers to the root object, `languages` refers to its member of that name and `[2]` refers to the (missing) third value in the JSON array value of that member (numbering starts at 0, so it is `[2]` instead of `[3]`).  \r\n-The proper solution here is to fix the malformed JSON data.\r\n-\r\n-To spot syntax errors in the JSON data easily you can open it in an editor with support for JSON, for example Visual Studio Code. It will highlight within the JSON data the error location and show why the JSON data is considered invalid.\r\n-\r\n-## <a id=\"number-parsed-as-double\"></a> Integral JSON number is parsed as `double`\r\n-\r\n-**Symptom:** JSON data contains an integral number such as `45` but Gson returns it as `double`\r\n-\r\n-**Reason:** When parsing a JSON number as `Object`, Gson will by default create always return a `double`\r\n-\r\n-**Solution:** Use [`GsonBuilder.setObjectToNumberStrategy`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setObjectToNumberStrategy(com.google.gson.ToNumberStrategy)) to specify what type of number should be returned\r\n-\r\n-## <a id=\"default-lenient\"></a> Malformed JSON not rejected\r\n-\r\n-**Symptom:** Gson parses malformed JSON without throwing any exceptions\r\n-\r\n-**Reason:** Due to legacy reasons Gson performs parsing by default in lenient mode\r\n-\r\n-**Solution:** If you are using Gson 2.11.0 or newer, call [`GsonBuilder.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setStrictness(com.google.gson.Strictness)),\r\n-[`JsonReader.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonReader.html#setStrictness(com.google.gson.Strictness))\r\n-and [`JsonWriter.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonWriter.html#setStrictness(com.google.gson.Strictness))\r\n-with `Strictness.STRICT` to overwrite the default lenient behavior of `Gson` and make these classes strictly adhere to the JSON specification.\r\n-Otherwise if you are using an older Gson version, see the [`Gson` class documentation](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#default-lenient)\r\n-section \"JSON Strictness handling\" for alternative solutions.\r\n-\r\n-## <a id=\"unexpected-json-structure\"></a> `IllegalStateException`: \"Expected ... but was ...\"\r\n-\r\n-**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was ...\" is thrown\r\n-\r\n-**Reason:** The JSON data does not have the correct format\r\n-\r\n-**Solution:** Make sure that your classes correctly model the JSON data. Also during debugging log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Read the location information of the exception message, it indicates where exactly in the document the error occurred, including the [JSONPath](https://goessner.net/articles/JsonPath/).\r\n-\r\n-For example, let's assume you have the following Java class:\r\n-\r\n-```java\r\n-class WebPage {\r\n-    String languages;\r\n-}\r\n-```\r\n-\r\n-And you want to deserialize the following JSON data:\r\n-\r\n-```json\r\n-{\r\n-  \"languages\": [\"English\", \"French\"]\r\n-}\r\n-```\r\n-\r\n-This will fail with an exception similar to this one: `IllegalStateException: Expected a string but was BEGIN_ARRAY at line 2 column 17 path $.languages`  \r\n-This means Gson expected a JSON string value but found the beginning of a JSON array (`[`). The location information \"line 2 column 17\" points to the `[` in the JSON data (with some slight inaccuracies), so does the JSONPath `$.languages` in the exception message. It refers to the `languages` member of the root object (`$.`).  \r\n-The solution here is to change in the `WebPage` class the field `String languages` to `List<String> languages`.\r\n-\r\n-## <a id=\"adapter-not-null-safe\"></a> `IllegalStateException`: \"Expected ... but was NULL\"\r\n-\r\n-**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was NULL\" is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- A built-in adapter does not support JSON null values\r\n-- You have written a custom `TypeAdapter` which does not properly handle JSON null values\r\n-\r\n-**Solution:** If this occurs for a custom adapter you wrote, add code similar to the following at the beginning of its `read` method:\r\n-\r\n-```java\r\n-@Override\r\n-public MyClass read(JsonReader in) throws IOException {\r\n-    if (in.peek() == JsonToken.NULL) {\r\n-        in.nextNull();\r\n-        return null;\r\n-    }\r\n-\r\n-    ...\r\n-}\r\n-```\r\n-\r\n-Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html#nullSafe()) on the adapter instance you created.\r\n-\r\n-## <a id=\"serialize-nulls\"></a> Properties missing in JSON\r\n-\r\n-**Symptom:** Properties are missing in the JSON output\r\n-\r\n-**Reason:** Gson by default omits JSON null from the output (or: ProGuard / R8 is not configured correctly and removed unused fields)\r\n-\r\n-**Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\r\n-\r\n-Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\r\n-\r\n-## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\r\n-\r\n-**Symptom:** The JSON output differs when running on newer Android versions\r\n-\r\n-**Reason:** You use Gson by accident to access internal fields of Android classes\r\n-\r\n-**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data\r\n-\r\n-**Explanation:**\r\n-\r\n-When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are experiencing this issue because you (by accident) rely on the reflection-based adapter for Android classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point.\r\n-\r\n-If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\r\n-\r\n-## <a id=\"json-static-fields\"></a> JSON output contains values of `static` fields\r\n-\r\n-**Symptom:** The JSON output contains values of `static` fields\r\n-\r\n-**Reason:** You used `GsonBuilder.excludeFieldsWithModifiers` to overwrite the default excluded modifiers\r\n-\r\n-**Solution:** When calling `GsonBuilder.excludeFieldsWithModifiers` you overwrite the default excluded modifiers. Therefore, you have to explicitly exclude `static` fields if desired. This can be done by adding `Modifier.STATIC` as additional argument.\r\n-\r\n-## <a id=\"no-such-method-error\"></a> `NoSuchMethodError` when calling Gson methods\r\n-\r\n-**Symptom:** A `java.lang.NoSuchMethodError` is thrown when trying to call certain Gson methods\r\n-\r\n-**Reason:**\r\n-\r\n-- You have multiple versions of Gson on your classpath\r\n-- Or, the Gson version you compiled against is different from the one on your classpath\r\n-- Or, you are using a code shrinking tool such as ProGuard or R8 which removed methods from Gson\r\n-\r\n-**Solution:** First disable any code shrinking tools such as ProGuard or R8 and check if the issue persists. If not, you have to tweak the configuration of that tool to not modify Gson classes. Otherwise verify that the Gson JAR on your classpath is the same you are compiling against, and that there is only one Gson JAR on your classpath. See [this Stack Overflow question](https://stackoverflow.com/q/227486) to find out where a class is loaded from. For example, for debugging you could include the following code:\r\n-\r\n-```java\r\n-System.out.println(Gson.class.getProtectionDomain().getCodeSource().getLocation());\r\n-```\r\n-\r\n-If that fails with a `NullPointerException` you have to try one of the other ways to find out where a class is loaded from.\r\n-\r\n-## <a id=\"duplicate-fields\"></a> `IllegalArgumentException`: 'Class ... declares multiple JSON fields named '...''\r\n-\r\n-**Symptom:** An exception with the message 'Class ... declares multiple JSON fields named '...'' is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- The name you have specified with a [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation for a field collides with the name of another field\r\n-- The [`FieldNamingStrategy`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/FieldNamingStrategy.html) you have specified produces conflicting field names\r\n-- A field of your class has the same name as the field of a superclass\r\n-\r\n-Gson prevents multiple fields with the same name because during deserialization it would be ambiguous for which field the JSON data should be deserialized. For serialization it would cause the same field to appear multiple times in JSON. While the JSON specification permits this, it is likely that the application parsing the JSON data will not handle it correctly.\r\n-\r\n-**Solution:** First identify the fields with conflicting names based on the exception message. Then decide if you want to rename one of them using the [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation, or if you want to [exclude](UserGuide.md#excluding-fields-from-serialization-and-deserialization) one of them. When excluding one of the fields you have to include it for both serialization and deserialization (even if your application only performs one of these actions) because the duplicate field check cannot differentiate between these actions.\r\n-\r\n-## <a id=\"java-lang-class-unsupported\"></a> `UnsupportedOperationException` when serializing or deserializing `java.lang.Class`\r\n-\r\n-**Symptom:** An `UnsupportedOperationException` is thrown when trying to serialize or deserialize `java.lang.Class`\r\n-\r\n-**Reason:** Gson intentionally does not permit serializing and deserializing `java.lang.Class` for security reasons. Otherwise a malicious user could make your application load an arbitrary class from the classpath and, depending on what your application does with the `Class`, in the worst case perform a remote code execution attack.\r\n-\r\n-**Solution:** First check if you really need to serialize or deserialize a `Class`. Often it is possible to use string aliases and then map them to the known `Class`; you could write a custom [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) to do this. If the `Class` values are not known in advance, try to introduce a common base class or interface for all these classes and then verify that the deserialized class is a subclass. For example assuming the base class is called `MyBaseClass`, your custom `TypeAdapter` should load the class like this:\r\n-\r\n-```java\r\n-Class.forName(jsonString, false, getClass().getClassLoader()).asSubclass(MyBaseClass.class)\r\n-```\r\n-\r\n-This will not initialize arbitrary classes, and it will throw a `ClassCastException` if the loaded class is not the same as or a subclass of `MyBaseClass`.\r\n-\r\n-## <a id=\"type-token-raw\"></a> `IllegalStateException`: 'TypeToken must be created with a type argument' <br> `RuntimeException`: 'Missing type parameter'\r\n-\r\n-**Symptom:** An `IllegalStateException` with the message 'TypeToken must be created with a type argument' is thrown.  \r\n-For older Gson versions a `RuntimeException` with message 'Missing type parameter' is thrown.\r\n-\r\n-**Reason:**\r\n-\r\n-- You created a `TypeToken` without type argument, for example `new TypeToken() {}` (note the missing `<...>`). You always have to provide the type argument, for example like this: `new TypeToken<List<String>>() {}`. Normally the compiler will also emit a 'raw types' warning when you forget the `<...>`.\r\n-- You are using a code shrinking tool such as ProGuard or R8 (Android app builds normally have this enabled by default) but have not configured it correctly for usage with Gson.\r\n-\r\n-**Solution:** When you are using a code shrinking tool such as ProGuard or R8 you have to adjust your configuration to include the following rules:\r\n-\r\n-```\r\n-# Keep generic signatures; needed for correct type resolution\r\n--keepattributes Signature\r\n-\r\n-# Keep class TypeToken (respectively its generic signature)\r\n--keep class com.google.gson.reflect.TypeToken { *; }\r\n-\r\n-# Keep any (anonymous) classes extending TypeToken\r\n--keep class * extends com.google.gson.reflect.TypeToken\r\n-```\r\n-\r\n-See also the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-Note: For newer Gson versions these rules might be applied automatically; make sure you are using the latest Gson version and the latest version of the code shrinking tool.\r\n-\r\n-## <a id=\"r8-abstract-class\"></a> `JsonIOException`: 'Abstract classes can't be instantiated!' (R8)\r\n-\r\n-**Symptom:** A `JsonIOException` with the message 'Abstract classes can't be instantiated!' is thrown; the class mentioned in the exception message is not actually `abstract` in your source code, and you are using the code shrinking tool R8 (Android app builds normally have this configured by default).\r\n-\r\n-Note: If the class which you are trying to deserialize is actually abstract, then this exception is probably unrelated to R8 and you will have to implement a custom [`InstanceCreator`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/InstanceCreator.html) or [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) which creates an instance of a non-abstract subclass of the class.\r\n-\r\n-**Reason:** The code shrinking tool R8 performs optimizations where it removes the no-args constructor from a class and makes the class `abstract`. Due to this Gson cannot create an instance of the class.\r\n-\r\n-**Solution:** Make sure the class has a no-args constructor, then adjust your R8 configuration file to keep the constructor of the class. For example:\r\n-\r\n-```\r\n-# Keep the no-args constructor of the deserialized class\r\n--keepclassmembers class com.example.MyClass {\r\n-  <init>();\r\n-}\r\n-```\r\n-\r\n-You can also use `<init>(...);` to keep all constructors of that class, but then you might actually rely on `sun.misc.Unsafe` on both JDK and Android to create classes without no-args constructor, see [`GsonBuilder.disableJdkUnsafe()`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) for more information.\r\n-\r\n-For Android you can add this rule to the `proguard-rules.pro` file, see also the [Android documentation](https://developer.android.com/build/shrink-code#keep-code). In case the class name in the exception message is obfuscated, see the Android documentation about [retracing](https://developer.android.com/build/shrink-code#retracing).\r\n-\r\n-For Android you can alternatively use the [`@Keep` annotation](https://developer.android.com/studio/write/annotations#keep) on the class or constructor you want to keep. That might be easier than having to maintain a custom R8 configuration.\r\n-\r\n-Note that the latest Gson versions (> 2.10.1) specify a default R8 configuration. If your class is a top-level class or is `static`, has a no-args constructor and its fields are annotated with Gson's [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html), you might not have to perform any additional R8 configuration.\r\n+# Troubleshooting Guide\n+\n+This guide describes how to troubleshoot common issues when using Gson.\n+\n+<!-- The '<a id=\"...\"></a>' anchors below are used to create stable links; don't remove or rename them -->\n+<!-- Use only lowercase IDs, GitHub seems to not support uppercase IDs, see also https://github.com/orgs/community/discussions/50962 -->\n+\n+## <a id=\"class-cast-exception\"></a> `ClassCastException` when using deserialized object\n+\n+**Symptom:** `ClassCastException` is thrown when accessing an object deserialized by Gson\n+\n+**Reason:** Your code is most likely not type-safe\n+\n+**Solution:** Make sure your code adheres to the following:\n+\n+- Avoid raw types: Instead of calling `fromJson(..., List.class)`, create for example a `TypeToken<List<MyClass>>`.\n+  See the [user guide](UserGuide.md#collections-examples) for more information.\n+- When using `TypeToken` prefer the `Gson.fromJson` overloads with `TypeToken` parameter such as [`fromJson(Reader, TypeToken)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#fromJson(java.io.Reader,com.google.gson.reflect.TypeToken)).\n+  The overloads with `Type` parameter do not provide any type-safety guarantees.\n+- When using `TypeToken` make sure you don't capture a type variable. For example avoid something like `new TypeToken<List<T>>()` (where `T` is a type variable). Due to Java type erasure the actual type of `T` is not available at runtime. Refactor your code to pass around `TypeToken` instances or use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementClass)`.\n+\n+## <a id=\"reflection-inaccessible\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to unnamed module'\n+\n+**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to unnamed module' is thrown\n+\n+**Reason:** You use Gson by accident to access internal fields of third-party classes\n+\n+**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data. If this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\n+\n+**Explanation:**\n+\n+When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are seeing this error because you (by accident) rely on the reflection-based adapter for third-party classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point. For the JDK it is also not possible anymore to access internal fields using reflection starting with JDK 17, see [JEP 403](https://openjdk.org/jeps/403).\n+\n+If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\n+\n+## <a id=\"reflection-inaccessible-to-module-gson\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to module com.google.gson'\n+\n+**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to module com.google.gson' is thrown\n+\n+**Reason:**\n+\n+- If the reported package is your own package then you have not configured the module declaration of your project to allow Gson to use reflection on your classes.\n+- If the reported package is from a third party library or the JDK see [this troubleshooting point](#inaccessibleobjectexception-module--does-not-opens--to-unnamed-module).\n+\n+**Solution:** Make sure the `module-info.java` file of your project allows Gson to use reflection on your classes, for example:\n+\n+```java\n+module mymodule {\n+    requires com.google.gson;\n+\n+    opens mypackage to com.google.gson;\n+}\n+```\n+\n+Or in case this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\n+\n+## <a id=\"android-app-random-names\"></a> Android app not working in Release mode; random property names\n+\n+**Symptom:** Your Android app is working fine in Debug mode but fails in Release mode and the JSON properties have seemingly random names such as `a`, `b`, ...\n+\n+**Reason:** You probably have not configured ProGuard / R8 correctly\n+\n+**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+## <a id=\"android-app-broken-after-app-update\"></a> Android app unable to parse JSON after app update\n+\n+**Symptom:** You released a new version of your Android app and it fails to parse JSON data created by the previous version of your app\n+\n+**Reason:** You probably have not configured ProGuard / R8 correctly; probably the fields names are being obfuscated and their naming changed between the versions of your app\n+\n+**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+If you want to preserve backward compatibility for you app you can use [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) on the fields to specify the obfuscated name as alternate, for example: `@SerializedName(value = \"myprop\", alternate = \"a\")`\n+\n+Normally ProGuard and R8 produce a mapping file, this makes it easier to find out the obfuscated field names instead of having to find them out through trial and error or other means. See the [Android Studio user guide](https://developer.android.com/studio/build/shrink-code.html#retracing) for more information.\n+\n+## <a id=\"default-field-values-missing\"></a> Default field values not present after deserialization\n+\n+**Symptom:** You have assign default values to fields but after deserialization the fields have their standard value (such as `null` or `0`)\n+\n+**Reason:** Gson cannot invoke the constructor of your class and falls back to JDK `Unsafe` (or similar means)\n+\n+**Solution:** Make sure that the class:\n+\n+- is `static` (explicitly or implicitly when it is a top-level class)\n+- has a no-args constructor\n+\n+Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\n+\n+## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\n+\n+**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\n+\n+**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\n+\n+**Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\n+\n+Notes:\n+\n+- \"double brace-initialization\" also creates anonymous classes\n+- Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\n+\n+## <a id=\"map-key-wrong-json\"></a> Map keys having unexpected format in JSON\n+\n+**Symptom:** JSON output for `Map` keys is unexpected / cannot be deserialized again\n+\n+**Reason:** The `Map` key type is 'complex' and you have not configured the `GsonBuilder` properly\n+\n+**Solution:** Use [`GsonBuilder.enableComplexMapKeySerialization()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#enableComplexMapKeySerialization()). See also the [user guide](UserGuide.md#maps-examples) for more information.\n+\n+## <a id=\"malformed-json\"></a> Parsing JSON fails with `MalformedJsonException`\n+\n+**Symptom:** JSON parsing fails with `MalformedJsonException`\n+\n+**Reason:** The JSON data is actually malformed\n+\n+**Solution:** During debugging, log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Sometimes APIs might return HTML error pages (instead of JSON data) when reaching rate limits or when other errors occur. Also read the location information of the `MalformedJsonException` exception message, it indicates where exactly in the document the malformed data was detected, including the [JSONPath](https://goessner.net/articles/JsonPath/).\n+\n+For example, let's assume you want to deserialize the following JSON data:\n+\n+```json\n+{\n+  \"languages\": [\n+    \"English\",\n+    \"French\",\n+  ]\n+}\n+```\n+\n+This will fail with an exception similar to this one: `MalformedJsonException: Use JsonReader.setStrictness(Strictness.LENIENT) to accept malformed JSON at line 5 column 4 path $.languages[2]`  \n+The problem here is the trailing comma (`,`) after `\"French\"`, trailing commas are not allowed by the JSON specification. The location information \"line 5 column 4\" points to the `]` in the JSON data (with some slight inaccuracies) because Gson expected another value after `,` instead of the closing `]`. The JSONPath `$.languages[2]` in the exception message also points there: `$.` refers to the root object, `languages` refers to its member of that name and `[2]` refers to the (missing) third value in the JSON array value of that member (numbering starts at 0, so it is `[2]` instead of `[3]`).  \n+The proper solution here is to fix the malformed JSON data.\n+\n+To spot syntax errors in the JSON data easily you can open it in an editor with support for JSON, for example Visual Studio Code. It will highlight within the JSON data the error location and show why the JSON data is considered invalid.\n+\n+## <a id=\"number-parsed-as-double\"></a> Integral JSON number is parsed as `double`\n+\n+**Symptom:** JSON data contains an integral number such as `45` but Gson returns it as `double`\n+\n+**Reason:** When parsing a JSON number as `Object`, Gson will by default create always return a `double`\n+\n+**Solution:** Use [`GsonBuilder.setObjectToNumberStrategy`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setObjectToNumberStrategy(com.google.gson.ToNumberStrategy)) to specify what type of number should be returned\n+\n+## <a id=\"default-lenient\"></a> Malformed JSON not rejected\n+\n+**Symptom:** Gson parses malformed JSON without throwing any exceptions\n+\n+**Reason:** Due to legacy reasons Gson performs parsing by default in lenient mode\n+\n+**Solution:** If you are using Gson 2.11.0 or newer, call [`GsonBuilder.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setStrictness(com.google.gson.Strictness)),\n+[`JsonReader.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonReader.html#setStrictness(com.google.gson.Strictness))\n+and [`JsonWriter.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonWriter.html#setStrictness(com.google.gson.Strictness))\n+with `Strictness.STRICT` to overwrite the default lenient behavior of `Gson` and make these classes strictly adhere to the JSON specification.\n+Otherwise if you are using an older Gson version, see the [`Gson` class documentation](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#default-lenient)\n+section \"JSON Strictness handling\" for alternative solutions.\n+\n+## <a id=\"unexpected-json-structure\"></a> `IllegalStateException`: \"Expected ... but was ...\"\n+\n+**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was ...\" is thrown\n+\n+**Reason:** The JSON data does not have the correct format\n+\n+**Solution:** Make sure that your classes correctly model the JSON data. Also during debugging log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Read the location information of the exception message, it indicates where exactly in the document the error occurred, including the [JSONPath](https://goessner.net/articles/JsonPath/).\n+\n+For example, let's assume you have the following Java class:\n+\n+```java\n+class WebPage {\n+    String languages;\n+}\n+```\n+\n+And you want to deserialize the following JSON data:\n+\n+```json\n+{\n+  \"languages\": [\"English\", \"French\"]\n+}\n+```\n+\n+This will fail with an exception similar to this one: `IllegalStateException: Expected a string but was BEGIN_ARRAY at line 2 column 17 path $.languages`  \n+This means Gson expected a JSON string value but found the beginning of a JSON array (`[`). The location information \"line 2 column 17\" points to the `[` in the JSON data (with some slight inaccuracies), so does the JSONPath `$.languages` in the exception message. It refers to the `languages` member of the root object (`$.`).  \n+The solution here is to change in the `WebPage` class the field `String languages` to `List<String> languages`.\n+\n+## <a id=\"adapter-not-null-safe\"></a> `IllegalStateException`: \"Expected ... but was NULL\"\n+\n+**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was NULL\" is thrown\n+\n+**Reason:**\n+\n+- A built-in adapter does not support JSON null values\n+- You have written a custom `TypeAdapter` which does not properly handle JSON null values\n+\n+**Solution:** If this occurs for a custom adapter you wrote, add code similar to the following at the beginning of its `read` method:\n+\n+```java\n+@Override\n+public MyClass read(JsonReader in) throws IOException {\n+    if (in.peek() == JsonToken.NULL) {\n+        in.nextNull();\n+        return null;\n+    }\n+\n+    ...\n+}\n+```\n+\n+Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html#nullSafe()) on the adapter instance you created.\n+\n+## <a id=\"serialize-nulls\"></a> Properties missing in JSON\n+\n+**Symptom:** Properties are missing in the JSON output\n+\n+**Reason:** Gson by default omits JSON null from the output (or: ProGuard / R8 is not configured correctly and removed unused fields)\n+\n+**Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\n+\n+Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\n+\n+## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\n+\n+**Symptom:** The JSON output differs when running on newer Android versions\n+\n+**Reason:** You use Gson by accident to access internal fields of Android classes\n+\n+**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data\n+\n+**Explanation:**\n+\n+When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are experiencing this issue because you (by accident) rely on the reflection-based adapter for Android classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point.\n+\n+If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\n+\n+## <a id=\"json-static-fields\"></a> JSON output contains values of `static` fields\n+\n+**Symptom:** The JSON output contains values of `static` fields\n+\n+**Reason:** You used `GsonBuilder.excludeFieldsWithModifiers` to overwrite the default excluded modifiers\n+\n+**Solution:** When calling `GsonBuilder.excludeFieldsWithModifiers` you overwrite the default excluded modifiers. Therefore, you have to explicitly exclude `static` fields if desired. This can be done by adding `Modifier.STATIC` as additional argument.\n+\n+## <a id=\"no-such-method-error\"></a> `NoSuchMethodError` when calling Gson methods\n+\n+**Symptom:** A `java.lang.NoSuchMethodError` is thrown when trying to call certain Gson methods\n+\n+**Reason:**\n+\n+- You have multiple versions of Gson on your classpath\n+- Or, the Gson version you compiled against is different from the one on your classpath\n+- Or, you are using a code shrinking tool such as ProGuard or R8 which removed methods from Gson\n+\n+**Solution:** First disable any code shrinking tools such as ProGuard or R8 and check if the issue persists. If not, you have to tweak the configuration of that tool to not modify Gson classes. Otherwise verify that the Gson JAR on your classpath is the same you are compiling against, and that there is only one Gson JAR on your classpath. See [this Stack Overflow question](https://stackoverflow.com/q/227486) to find out where a class is loaded from. For example, for debugging you could include the following code:\n+\n+```java\n+System.out.println(Gson.class.getProtectionDomain().getCodeSource().getLocation());\n+```\n+\n+If that fails with a `NullPointerException` you have to try one of the other ways to find out where a class is loaded from.\n+\n+## <a id=\"duplicate-fields\"></a> `IllegalArgumentException`: 'Class ... declares multiple JSON fields named '...''\n+\n+**Symptom:** An exception with the message 'Class ... declares multiple JSON fields named '...'' is thrown\n+\n+**Reason:**\n+\n+- The name you have specified with a [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation for a field collides with the name of another field\n+- The [`FieldNamingStrategy`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/FieldNamingStrategy.html) you have specified produces conflicting field names\n+- A field of your class has the same name as the field of a superclass\n+\n+Gson prevents multiple fields with the same name because during deserialization it would be ambiguous for which field the JSON data should be deserialized. For serialization it would cause the same field to appear multiple times in JSON. While the JSON specification permits this, it is likely that the application parsing the JSON data will not handle it correctly.\n+\n+**Solution:** First identify the fields with conflicting names based on the exception message. Then decide if you want to rename one of them using the [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation, or if you want to [exclude](UserGuide.md#excluding-fields-from-serialization-and-deserialization) one of them. When excluding one of the fields you have to include it for both serialization and deserialization (even if your application only performs one of these actions) because the duplicate field check cannot differentiate between these actions.\n+\n+## <a id=\"java-lang-class-unsupported\"></a> `UnsupportedOperationException` when serializing or deserializing `java.lang.Class`\n+\n+**Symptom:** An `UnsupportedOperationException` is thrown when trying to serialize or deserialize `java.lang.Class`\n+\n+**Reason:** Gson intentionally does not permit serializing and deserializing `java.lang.Class` for security reasons. Otherwise a malicious user could make your application load an arbitrary class from the classpath and, depending on what your application does with the `Class`, in the worst case perform a remote code execution attack.\n+\n+**Solution:** First check if you really need to serialize or deserialize a `Class`. Often it is possible to use string aliases and then map them to the known `Class`; you could write a custom [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) to do this. If the `Class` values are not known in advance, try to introduce a common base class or interface for all these classes and then verify that the deserialized class is a subclass. For example assuming the base class is called `MyBaseClass`, your custom `TypeAdapter` should load the class like this:\n+\n+```java\n+Class.forName(jsonString, false, getClass().getClassLoader()).asSubclass(MyBaseClass.class)\n+```\n+\n+This will not initialize arbitrary classes, and it will throw a `ClassCastException` if the loaded class is not the same as or a subclass of `MyBaseClass`.\n+\n+## <a id=\"type-token-raw\"></a> `IllegalStateException`: 'TypeToken must be created with a type argument' <br> `RuntimeException`: 'Missing type parameter'\n+\n+**Symptom:** An `IllegalStateException` with the message 'TypeToken must be created with a type argument' is thrown.  \n+For older Gson versions a `RuntimeException` with message 'Missing type parameter' is thrown.\n+\n+**Reason:**\n+\n+- You created a `TypeToken` without type argument, for example `new TypeToken() {}` (note the missing `<...>`). You always have to provide the type argument, for example like this: `new TypeToken<List<String>>() {}`. Normally the compiler will also emit a 'raw types' warning when you forget the `<...>`.\n+- You are using a code shrinking tool such as ProGuard or R8 (Android app builds normally have this enabled by default) but have not configured it correctly for usage with Gson.\n+\n+**Solution:** When you are using a code shrinking tool such as ProGuard or R8 you have to adjust your configuration to include the following rules:\n+\n+```\n+# Keep generic signatures; needed for correct type resolution\n+-keepattributes Signature\n+\n+# Keep class TypeToken (respectively its generic signature)\n+-keep class com.google.gson.reflect.TypeToken { *; }\n+\n+# Keep any (anonymous) classes extending TypeToken\n+-keep class * extends com.google.gson.reflect.TypeToken\n+```\n+\n+See also the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+Note: For newer Gson versions these rules might be applied automatically; make sure you are using the latest Gson version and the latest version of the code shrinking tool.\n+\n+## <a id=\"typetoken-type-variable\"></a> `IllegalStateException`: 'TypeToken type argument must not contain a type variable'\n+\n+**Symptom:** An `IllegalStateException` with a message like 'TypeToken type argument must not contain a type variable; captured type variable T from ...' is thrown.\n+\n+**Reason:** You created a `TypeToken` using a type variable as type argument, for example:\n+\n+```java\n+public <T> TypeToken<T> getTypeToken() {\n+    return new TypeToken<T>() {};  // Throws IllegalStateException\n+}\n+```\n+\n+Due to Java's type erasure, the runtime type of a type variable is not available to Gson. The type variable `T` is erased at runtime, so Gson cannot determine what actual type it represents. This would lead to confusing behavior or a `ClassCastException` later, so Gson now throws an exception early to alert you of this issue.\n+\n+**Solution:** If the type arguments are only available at runtime, use [`TypeToken.getParameterized`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)) to create the `TypeToken` dynamically. For example:\n+\n+```java\n+public <T> TypeToken<?> getTypeToken(Class<T> elementClass) {\n+    return TypeToken.getParameterized(List.class, elementClass);\n+}\n+```\n+\n+Alternatively, if you know the concrete type at compile time, use that directly:\n+\n+```java\n+TypeToken<List<String>> typeToken = new TypeToken<List<String>>() {};\n+```\n+\n+## <a id=\"r8-abstract-class\"></a> `JsonIOException`: 'Abstract classes can't be instantiated!' (R8)\n+\n+**Symptom:** A `JsonIOException` with the message 'Abstract classes can't be instantiated!' is thrown; the class mentioned in the exception message is not actually `abstract` in your source code, and you are using the code shrinking tool R8 (Android app builds normally have this configured by default).\n+\n+Note: If the class which you are trying to deserialize is actually abstract, then this exception is probably unrelated to R8 and you will have to implement a custom [`InstanceCreator`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/InstanceCreator.html) or [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) which creates an instance of a non-abstract subclass of the class.\n+\n+**Reason:** The code shrinking tool R8 performs optimizations where it removes the no-args constructor from a class and makes the class `abstract`. Due to this Gson cannot create an instance of the class.\n+\n+**Solution:** Make sure the class has a no-args constructor, then adjust your R8 configuration file to keep the constructor of the class. For example:\n+\n+```\n+# Keep the no-args constructor of the deserialized class\n+-keepclassmembers class com.example.MyClass {\n+  <init>();\n+}\n+```\n+\n+You can also use `<init>(...);` to keep all constructors of that class, but then you might actually rely on `sun.misc.Unsafe` on both JDK and Android to create classes without no-args constructor, see [`GsonBuilder.disableJdkUnsafe()`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) for more information.\n+\n+For Android you can add this rule to the `proguard-rules.pro` file, see also the [Android documentation](https://developer.android.com/build/shrink-code#keep-code). In case the class name in the exception message is obfuscated, see the Android documentation about [retracing](https://developer.android.com/build/shrink-code#retracing).\n+\n+For Android you can alternatively use the [`@Keep` annotation](https://developer.android.com/studio/write/annotations#keep) on the class or constructor you want to keep. That might be easier than having to maintain a custom R8 configuration.\n+\n+Note that the latest Gson versions (> 2.10.1) specify a default R8 configuration. If your class is a top-level class or is `static`, has a no-args constructor and its fields are annotated with Gson's [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html), you might not have to perform any additional R8 configuration.\ndiff --git a/gson/src/main/java/com/google/gson/reflect/TypeToken.java b/gson/src/main/java/com/google/gson/reflect/TypeToken.java\nindex 3921a70b..2b08b411 100644\n--- a/gson/src/main/java/com/google/gson/reflect/TypeToken.java\n+++ b/gson/src/main/java/com/google/gson/reflect/TypeToken.java\n@@ -93,7 +93,13 @@ public class TypeToken<T> {\n     if (superclass instanceof ParameterizedType) {\n       ParameterizedType parameterized = (ParameterizedType) superclass;\n       if (parameterized.getRawType() == TypeToken.class) {\n-        return $Gson$Types.canonicalize(parameterized.getActualTypeArguments()[0]);\n+        Type typeArgument = $Gson$Types.canonicalize(parameterized.getActualTypeArguments()[0]);\n+        if (typeArgument instanceof TypeVariable) {\n+          throw new IllegalStateException(\"TypeToken type argument must not contain a type variable; captured type variable \"\n+              + typeArgument + \" from \" + this.getClass()\n+              + \"\\nSee \" + TroubleshootingGuide.createUrl(\"typetoken-type-variable\"));\n+        }\n+        return typeArgument;\n       }\n     }\n     // Check for raw TypeToken as superclass\n"}
{"instance_id": "google__gson-2435", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex 0219c1a1..a8745fea 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -648,13 +648,11 @@ public final class Gson {\n    * @since 2.2\n    */\n   public <T> TypeAdapter<T> getDelegateAdapter(TypeAdapterFactory skipPast, TypeToken<T> type) {\n-    // Hack. If the skipPast factory isn't registered, assume the factory is being requested via\n-    // our @JsonAdapter annotation.\n-    if (!factories.contains(skipPast)) {\n-      skipPast = jsonAdapterFactory;\n-    }\n+    // If the skipPast factory is not registered, it is being used via @JsonAdapter annotation\n+    // on a class or field. In this case, we should not skip any factory, but start from the\n+    // beginning of the list to find the appropriate delegate adapter.\n+    boolean skipPastFound = !factories.contains(skipPast);\n \n-    boolean skipPastFound = false;\n     for (TypeAdapterFactory factory : factories) {\n       if (!skipPastFound) {\n         if (factory == skipPast) {\n"}
{"instance_id": "google__gson-2345", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/FormattingStyle.java b/gson/src/main/java/com/google/gson/FormattingStyle.java\nindex ed9f86dd..04a255f1 100644\n--- a/gson/src/main/java/com/google/gson/FormattingStyle.java\n+++ b/gson/src/main/java/com/google/gson/FormattingStyle.java\n@@ -34,27 +34,37 @@ import java.util.Objects;\n public class FormattingStyle {\n   private final String newline;\n   private final String indent;\n+  private final boolean spaceAfterSeparators;\n \n   /**\n    * The default pretty printing formatting style using {@code \"\\n\"} as\n-   * newline and two spaces as indent.\n+   * newline, two spaces as indent, and spaces after {@code ':'} and {@code ','}.\n    */\n   public static final FormattingStyle DEFAULT =\n-      new FormattingStyle(\"\\n\", \"  \");\n+      new FormattingStyle(\"\\n\", \"  \", true);\n \n-  private FormattingStyle(String newline, String indent) {\n+  /**\n+   * A compact formatting style that outputs JSON on a single line with spaces\n+   * after {@code ':'} and {@code ','}. For example:\n+   * <pre>{\"a\": [1, 2, 3], \"b\": true}</pre>\n+   */\n+  public static final FormattingStyle COMPACT =\n+      new FormattingStyle(\"\", \"\", true);\n+\n+  private FormattingStyle(String newline, String indent, boolean spaceAfterSeparators) {\n     Objects.requireNonNull(newline, \"newline == null\");\n     Objects.requireNonNull(indent, \"indent == null\");\n-    if (!newline.matches(\"[\\r\\n]*\")) {\n+    if (!newline.matches(\"[\\\\r\\\\n]*\")) {\n       throw new IllegalArgumentException(\n           \"Only combinations of \\\\n and \\\\r are allowed in newline.\");\n     }\n-    if (!indent.matches(\"[ \\t]*\")) {\n+    if (!indent.matches(\"[ \\\\t]*\")) {\n       throw new IllegalArgumentException(\n           \"Only combinations of spaces and tabs are allowed in indent.\");\n     }\n     this.newline = newline;\n     this.indent = indent;\n+    this.spaceAfterSeparators = spaceAfterSeparators;\n   }\n \n   /**\n@@ -70,7 +80,7 @@ public class FormattingStyle {\n    * @return a newly created {@link FormattingStyle}\n    */\n   public FormattingStyle withNewline(String newline) {\n-    return new FormattingStyle(newline, this.indent);\n+    return new FormattingStyle(newline, this.indent, this.spaceAfterSeparators);\n   }\n \n   /**\n@@ -82,7 +92,22 @@ public class FormattingStyle {\n    * @return a newly created {@link FormattingStyle}\n    */\n   public FormattingStyle withIndent(String indent) {\n-    return new FormattingStyle(this.newline, indent);\n+    return new FormattingStyle(this.newline, indent, this.spaceAfterSeparators);\n+  }\n+\n+  /**\n+   * Creates a {@link FormattingStyle} which either uses a space after\n+   * the separators {@code ','} and {@code ':'} in the JSON output, or not.\n+   *\n+   * <p>This setting has no effect on the {@linkplain #withNewline(String) configured newline}.\n+   * If a non-empty newline is configured, it will always be added after\n+   * {@code ','} and no space is added after the {@code ','} in that case.</p>\n+   *\n+   * @param spaceAfterSeparators whether to output a space after {@code ','} and {@code ':'}.\n+   * @return a newly created {@link FormattingStyle}\n+   */\n+  public FormattingStyle withSpaceAfterSeparators(boolean spaceAfterSeparators) {\n+    return new FormattingStyle(this.newline, this.indent, spaceAfterSeparators);\n   }\n \n   /**\n@@ -102,4 +127,13 @@ public class FormattingStyle {\n   public String getIndent() {\n     return this.indent;\n   }\n+\n+  /**\n+   * Returns whether a space will be used after {@code ','} and {@code ':'}.\n+   *\n+   * @return whether a space will be used after {@code ','} and {@code ':'}.\n+   */\n+  public boolean usesSpaceAfterSeparators() {\n+    return this.spaceAfterSeparators;\n+  }\n }\ndiff --git a/gson/src/main/java/com/google/gson/stream/JsonWriter.java b/gson/src/main/java/com/google/gson/stream/JsonWriter.java\nindex 4a2424e6..e4729a14 100644\n--- a/gson/src/main/java/com/google/gson/stream/JsonWriter.java\n+++ b/gson/src/main/java/com/google/gson/stream/JsonWriter.java\n@@ -192,6 +192,11 @@ public class JsonWriter implements Closeable, Flushable {\n    */\n   private String separator = \":\";\n \n+  /**\n+   * The comma separator; either \",\" or \", \".\n+   */\n+  private String comma = \",\";\n+\n   private boolean lenient;\n \n   private boolean htmlSafe;\n@@ -242,8 +247,14 @@ public class JsonWriter implements Closeable, Flushable {\n     this.formattingStyle = formattingStyle;\n     if (formattingStyle == null) {\n       this.separator = \":\";\n-    } else {\n+      this.comma = \",\";\n+    } else if (formattingStyle.usesSpaceAfterSeparators()) {\n       this.separator = \": \";\n+      // Only add space after comma if newline is empty (single-line output)\n+      this.comma = formattingStyle.getNewline().isEmpty() ? \", \" : \",\";\n+    } else {\n+      this.separator = \":\";\n+      this.comma = \",\";\n     }\n   }\n \n@@ -710,7 +721,7 @@ public class JsonWriter implements Closeable, Flushable {\n   private void beforeName() throws IOException {\n     int context = peek();\n     if (context == NONEMPTY_OBJECT) { // first in object\n-      out.write(',');\n+      out.write(comma);\n     } else if (context != EMPTY_OBJECT) { // not in an object!\n       throw new IllegalStateException(\"Nesting problem.\");\n     }\n@@ -742,7 +753,7 @@ public class JsonWriter implements Closeable, Flushable {\n       break;\n \n     case NONEMPTY_ARRAY: // another in array\n-      out.append(',');\n+      out.append(comma);\n       newline();\n       break;\n \n"}
{"instance_id": "google__guava-3971", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/android/guava/src/com/google/common/util/concurrent/Uninterruptibles.java b/android/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\nindex c7a8e32da..29fd7724d 100644\n--- a/android/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\n+++ b/android/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\n@@ -24,6 +24,7 @@ import java.util.concurrent.BlockingQueue;\n import java.util.concurrent.CancellationException;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Future;\n import java.util.concurrent.Semaphore;\n import java.util.concurrent.TimeUnit;\n@@ -396,6 +397,61 @@ public final class Uninterruptibles {\n     }\n   }\n \n+  /**\n+   * Invokes {@code executor.}{@link ExecutorService#awaitTermination(long, TimeUnit)\n+   * awaitTermination(long, TimeUnit)} uninterruptibly with no timeout.\n+   *\n+   * @since NEXT\n+   */\n+  @GwtIncompatible // concurrency\n+  public static void awaitTerminationUninterruptibly(ExecutorService executor) {\n+    boolean interrupted = false;\n+    try {\n+      while (true) {\n+        try {\n+          executor.awaitTermination(Long.MAX_VALUE, NANOSECONDS);\n+          return;\n+        } catch (InterruptedException e) {\n+          interrupted = true;\n+        }\n+      }\n+    } finally {\n+      if (interrupted) {\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Invokes {@code executor.}{@link ExecutorService#awaitTermination(long, TimeUnit)\n+   * awaitTermination(timeout, unit)} uninterruptibly.\n+   *\n+   * @since NEXT\n+   */\n+  @GwtIncompatible // concurrency\n+  @SuppressWarnings(\"GoodTime\") // should accept a java.time.Duration\n+  public static boolean awaitTerminationUninterruptibly(\n+      ExecutorService executor, long timeout, TimeUnit unit) {\n+    boolean interrupted = false;\n+    try {\n+      long remainingNanos = unit.toNanos(timeout);\n+      long end = System.nanoTime() + remainingNanos;\n+\n+      while (true) {\n+        try {\n+          return executor.awaitTermination(remainingNanos, NANOSECONDS);\n+        } catch (InterruptedException e) {\n+          interrupted = true;\n+          remainingNanos = end - System.nanoTime();\n+        }\n+      }\n+    } finally {\n+      if (interrupted) {\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+  }\n+\n   // TODO(user): Add support for waitUninterruptibly.\n \n   private Uninterruptibles() {}\ndiff --git a/guava/src/com/google/common/util/concurrent/Uninterruptibles.java b/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\nindex 784efa82d..ec262542f 100644\n--- a/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\n+++ b/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\n@@ -27,6 +27,7 @@ import java.util.concurrent.BlockingQueue;\n import java.util.concurrent.CancellationException;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Future;\n import java.util.concurrent.Semaphore;\n import java.util.concurrent.TimeUnit;\n@@ -513,6 +514,74 @@ public final class Uninterruptibles {\n     }\n   }\n \n+  /**\n+   * Invokes {@code executor.}{@link ExecutorService#awaitTermination(long, TimeUnit)\n+   * awaitTermination(long, TimeUnit)} uninterruptibly with no timeout.\n+   *\n+   * @since NEXT\n+   */\n+  @GwtIncompatible // concurrency\n+  public static void awaitTerminationUninterruptibly(ExecutorService executor) {\n+    boolean interrupted = false;\n+    try {\n+      while (true) {\n+        try {\n+          executor.awaitTermination(Long.MAX_VALUE, NANOSECONDS);\n+          return;\n+        } catch (InterruptedException e) {\n+          interrupted = true;\n+        }\n+      }\n+    } finally {\n+      if (interrupted) {\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Invokes {@code executor.}{@link ExecutorService#awaitTermination(long, TimeUnit)\n+   * awaitTermination(timeout, unit)} uninterruptibly.\n+   *\n+   * @since NEXT\n+   */\n+  @GwtIncompatible // concurrency\n+  @Beta\n+  public static boolean awaitTerminationUninterruptibly(\n+      ExecutorService executor, Duration timeout) {\n+    return awaitTerminationUninterruptibly(executor, toNanosSaturated(timeout), TimeUnit.NANOSECONDS);\n+  }\n+\n+  /**\n+   * Invokes {@code executor.}{@link ExecutorService#awaitTermination(long, TimeUnit)\n+   * awaitTermination(timeout, unit)} uninterruptibly.\n+   *\n+   * @since NEXT\n+   */\n+  @GwtIncompatible // concurrency\n+  @SuppressWarnings(\"GoodTime\") // should accept a java.time.Duration\n+  public static boolean awaitTerminationUninterruptibly(\n+      ExecutorService executor, long timeout, TimeUnit unit) {\n+    boolean interrupted = false;\n+    try {\n+      long remainingNanos = unit.toNanos(timeout);\n+      long end = System.nanoTime() + remainingNanos;\n+\n+      while (true) {\n+        try {\n+          return executor.awaitTermination(remainingNanos, NANOSECONDS);\n+        } catch (InterruptedException e) {\n+          interrupted = true;\n+          remainingNanos = end - System.nanoTime();\n+        }\n+      }\n+    } finally {\n+      if (interrupted) {\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+  }\n+\n   // TODO(user): Add support for waitUninterruptibly.\n \n   private Uninterruptibles() {}\n"}
{"instance_id": "google__gson-2549", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/bind/DefaultDateTypeAdapter.java b/gson/src/main/java/com/google/gson/internal/bind/DefaultDateTypeAdapter.java\nindex 4a371348..e77fcc09 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/DefaultDateTypeAdapter.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/DefaultDateTypeAdapter.java\n@@ -187,10 +187,15 @@ public final class DefaultDateTypeAdapter<T extends Date> extends TypeAdapter<T>\n     // Needs to be synchronized since JDK DateFormat classes are not thread-safe\n     synchronized (dateFormats) {\n       for (DateFormat dateFormat : dateFormats) {\n+        // Need to save and restore the time zone because parsing can modify it, see\n+        // https://github.com/google/gson/issues/2472\n+        TimeZone originalTimeZone = dateFormat.getTimeZone();\n         try {\n           return dateFormat.parse(s);\n         } catch (ParseException ignored) {\n           // OK: try the next format\n+        } finally {\n+          dateFormat.setTimeZone(originalTimeZone);\n         }\n       }\n     }\n"}
{"instance_id": "google__gson-2475", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/stream/JsonWriter.java b/gson/src/main/java/com/google/gson/stream/JsonWriter.java\nindex 07848b06..fc1c2c89 100644\n--- a/gson/src/main/java/com/google/gson/stream/JsonWriter.java\n+++ b/gson/src/main/java/com/google/gson/stream/JsonWriter.java\n@@ -498,6 +498,10 @@ public class JsonWriter implements Closeable, Flushable {\n     if (stackSize == 0) {\n       throw new IllegalStateException(\"JsonWriter is closed.\");\n     }\n+    int context = peek();\n+    if (context != EMPTY_OBJECT && context != NONEMPTY_OBJECT) {\n+      throw new IllegalStateException(\"Nesting problem.\");\n+    }\n     deferredName = name;\n     return this;\n   }\n"}
{"instance_id": "google__gson-2479", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/gson/src/main/java/com/google/gson/GsonBuilder.java b/gson/src/main/java/com/google/gson/GsonBuilder.java\nindex 68eb7d71..bbe60a8e 100644\n--- a/gson/src/main/java/com/google/gson/GsonBuilder.java\n+++ b/gson/src/main/java/com/google/gson/GsonBuilder.java\n@@ -660,10 +660,17 @@ public final class GsonBuilder {\n    * {@code null} without calling the deserializer. If it is desired to handle {@code null} values,\n    * a {@link TypeAdapter} should be used instead.\n    *\n+   * <p>Registering an adapter for {@link Object} or {@link JsonElement} and subclasses of it is\n+   * not supported because these types have built-in adapters which cannot be overwritten. To\n+   * override the adapter for a specific field, use {@link com.google.gson.annotations.JsonAdapter\n+   * @JsonAdapter} on the field instead.\n+   *\n    * @param type the type definition for the type adapter being registered\n    * @param typeAdapter This object must implement at least one of the {@link TypeAdapter},\n    * {@link InstanceCreator}, {@link JsonSerializer}, and a {@link JsonDeserializer} interfaces.\n    * @return a reference to this {@code GsonBuilder} object to fulfill the \"Builder\" pattern\n+   * @throws IllegalArgumentException if {@code type} is {@link Object} or {@link JsonElement}, or\n+   *     a subclass of {@link JsonElement}\n    */\n   @CanIgnoreReturnValue\n   public GsonBuilder registerTypeAdapter(Type type, Object typeAdapter) {\n@@ -672,6 +679,16 @@ public final class GsonBuilder {\n         || typeAdapter instanceof JsonDeserializer<?>\n         || typeAdapter instanceof InstanceCreator<?>\n         || typeAdapter instanceof TypeAdapter<?>);\n+\n+    if (type == Object.class) {\n+      throw new IllegalArgumentException(\"Cannot override built-in adapter for \" + type);\n+    }\n+\n+    Class<?> rawType = TypeToken.get(type).getRawType();\n+    if (JsonElement.class.isAssignableFrom(rawType)) {\n+      throw new IllegalArgumentException(\"Cannot override built-in adapter for \" + type);\n+    }\n+\n     if (typeAdapter instanceof InstanceCreator<?>) {\n       instanceCreators.put(type, (InstanceCreator<?>) typeAdapter);\n     }\n@@ -713,11 +730,17 @@ public final class GsonBuilder {\n    * type hierarchy, it is overridden. If a type adapter is registered for a specific type in\n    * the type hierarchy, it will be invoked instead of the one registered for the type hierarchy.\n    *\n+   * <p>Registering an adapter for {@link JsonElement} and subclasses of it is not supported because\n+   * Gson has a built-in adapter for this type hierarchy which cannot be overwritten. To override\n+   * the adapter for a specific field, use {@link com.google.gson.annotations.JsonAdapter @JsonAdapter}\n+   * on the field instead.\n+   *\n    * @param baseType the class definition for the type adapter being registered for the base class\n    *        or interface\n    * @param typeAdapter This object must implement at least one of {@link TypeAdapter},\n    *        {@link JsonSerializer} or {@link JsonDeserializer} interfaces.\n    * @return a reference to this {@code GsonBuilder} object to fulfill the \"Builder\" pattern\n+   * @throws IllegalArgumentException if {@code baseType} is {@link JsonElement} or a subclass of it\n    * @since 1.7\n    */\n   @CanIgnoreReturnValue\n@@ -726,6 +749,11 @@ public final class GsonBuilder {\n     $Gson$Preconditions.checkArgument(typeAdapter instanceof JsonSerializer<?>\n         || typeAdapter instanceof JsonDeserializer<?>\n         || typeAdapter instanceof TypeAdapter<?>);\n+\n+    if (JsonElement.class.isAssignableFrom(baseType)) {\n+      throw new IllegalArgumentException(\"Cannot override built-in adapter for \" + baseType);\n+    }\n+\n     if (typeAdapter instanceof JsonDeserializer || typeAdapter instanceof JsonSerializer) {\n       hierarchyFactories.add(TreeTypeAdapter.newTypeHierarchyFactory(baseType, typeAdapter));\n     }\n"}
{"instance_id": "google__gson-2498", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/Troubleshooting.md b/Troubleshooting.md\nindex d79457c4..bbff50e6 100644\n--- a/Troubleshooting.md\n+++ b/Troubleshooting.md\n@@ -87,16 +87,17 @@ Normally ProGuard and R8 produce a mapping file, this makes it easier to find ou\n \n Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\n \n-## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\n+## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes during deserialization\n \n-**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\n+**Symptom:** Objects of an anonymous or local class are always deserialized as Java `null`\n \n-**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\n+**Reason:** The class you are deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\n \n **Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\n \n Notes:\n \n+- Gson supports serialization of anonymous and local classes, but not deserialization because they cannot be instantiated\n - \"double brace-initialization\" also creates anonymous classes\n - Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\n \n@@ -215,7 +216,7 @@ Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.\n \n **Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\n \n-Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\n+Note: Gson does not support deserialization of anonymous and local classes and will deserialize them as Java null, see the [related troubleshooting point](#anonymous-local-null).\n \n ## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\n \ndiff --git a/gson/src/main/java/com/google/gson/internal/Excluder.java b/gson/src/main/java/com/google/gson/internal/Excluder.java\nindex b3d2288a..4c5bcb53 100644\n--- a/gson/src/main/java/com/google/gson/internal/Excluder.java\n+++ b/gson/src/main/java/com/google/gson/internal/Excluder.java\n@@ -37,7 +37,7 @@ import java.util.List;\n /**\n  * This class selects which fields and types to omit. It is configurable, supporting version\n  * attributes {@link Since} and {@link Until}, modifiers, synthetic fields, anonymous and local\n- * classes, inner classes, and fields with the {@link Expose} annotation.\n+ * classes (for deserialization), inner classes, and fields with the {@link Expose} annotation.\n  *\n  * <p>This class is a type adapter factory; types that are excluded will be adapted to null. It may\n  * delegate to another type adapter if only one direction is excluded.\n@@ -109,10 +109,11 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n   @Override\n   public <T> TypeAdapter<T> create(final Gson gson, final TypeToken<T> type) {\n     Class<?> rawType = type.getRawType();\n-    boolean excludeClass = excludeClassChecks(rawType);\n \n-    final boolean skipSerialize = excludeClass || excludeClassInStrategy(rawType, true);\n-    final boolean skipDeserialize = excludeClass || excludeClassInStrategy(rawType, false);\n+    final boolean skipSerialize =\n+        excludeClassChecks(rawType, true) || excludeClassInStrategy(rawType, true);\n+    final boolean skipDeserialize =\n+        excludeClassChecks(rawType, false) || excludeClassInStrategy(rawType, false);\n \n     if (!skipSerialize && !skipDeserialize) {\n       return null;\n@@ -172,7 +173,9 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n       return true;\n     }\n \n-    if (isAnonymousOrNonStaticLocal(field.getType())) {\n+    // Anonymous and local classes are excluded from deserialization because they cannot be\n+    // instantiated, but they are allowed for serialization\n+    if (!serialize && isAnonymousOrNonStaticLocal(field.getType())) {\n       return true;\n     }\n \n@@ -189,7 +192,7 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n     return false;\n   }\n \n-  private boolean excludeClassChecks(Class<?> clazz) {\n+  private boolean excludeClassChecks(Class<?> clazz, boolean serialize) {\n     if (version != Excluder.IGNORE_VERSIONS\n         && !isValidVersion(clazz.getAnnotation(Since.class), clazz.getAnnotation(Until.class))) {\n       return true;\n@@ -199,11 +202,13 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n       return true;\n     }\n \n-    return isAnonymousOrNonStaticLocal(clazz);\n+    // Anonymous and local classes are excluded from deserialization because they cannot be\n+    // instantiated, but they are allowed for serialization\n+    return !serialize && isAnonymousOrNonStaticLocal(clazz);\n   }\n \n   public boolean excludeClass(Class<?> clazz, boolean serialize) {\n-    return excludeClassChecks(clazz) || excludeClassInStrategy(clazz, serialize);\n+    return excludeClassChecks(clazz, serialize) || excludeClassInStrategy(clazz, serialize);\n   }\n \n   private boolean excludeClassInStrategy(Class<?> clazz, boolean serialize) {\n"}
{"instance_id": "huggingface__transformers-12981", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/trainer.py b/src/transformers/trainer.py\nindex a2c56f8a8b..a29de64294 100755\n--- a/src/transformers/trainer.py\n+++ b/src/transformers/trainer.py\n@@ -1030,6 +1030,9 @@ class Trainer:\n         # This might change the seed so needs to run first.\n         self._hp_search_setup(trial)\n \n+        # handle passing `resume_from_checkpoint=False`\n+        resume_from_checkpoint = None if not resume_from_checkpoint else resume_from_checkpoint\n+\n         # Model re-init\n         model_reloaded = False\n         if self.model_init is not None:\n"}
{"instance_id": "google__gson-2701", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/proto/src/main/java/com/google/gson/protobuf/ProtoTypeAdapter.java b/proto/src/main/java/com/google/gson/protobuf/ProtoTypeAdapter.java\nindex 7b872f18..8cade726 100644\n--- a/proto/src/main/java/com/google/gson/protobuf/ProtoTypeAdapter.java\n+++ b/proto/src/main/java/com/google/gson/protobuf/ProtoTypeAdapter.java\n@@ -89,6 +89,7 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n     private EnumSerialization enumSerialization;\n     private CaseFormat protoFormat;\n     private CaseFormat jsonFormat;\n+    private boolean shouldUseJsonNameFieldOption;\n \n     private Builder(\n         EnumSerialization enumSerialization,\n@@ -96,6 +97,7 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n         CaseFormat toFieldNameFormat) {\n       this.serializedNameExtensions = new HashSet<>();\n       this.serializedEnumValueExtensions = new HashSet<>();\n+      this.shouldUseJsonNameFieldOption = false;\n       setEnumSerialization(enumSerialization);\n       setFieldNameSerializationFormat(fromFieldNameFormat, toFieldNameFormat);\n     }\n@@ -174,13 +176,33 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n       return this;\n     }\n \n+    /**\n+     * Sets whether the adapter should use the {@code json_name} field option from the proto field\n+     * descriptor for serialization and deserialization. When enabled, the {@code json_name} value\n+     * will be used as the JSON field name without any case format conversion.\n+     *\n+     * <p>Note that custom serialized name extensions added via {@link\n+     * #addSerializedNameExtension(Extension)} take precedence over the {@code json_name} option.\n+     *\n+     * <p>By default, this option is disabled ({@code false}).\n+     *\n+     * @param shouldUseJsonNameFieldOption whether to use the {@code json_name} field option\n+     * @return a reference to this {@code Builder} object to fulfill the \"Builder\" pattern\n+     */\n+    @CanIgnoreReturnValue\n+    public Builder setShouldUseJsonNameFieldOption(boolean shouldUseJsonNameFieldOption) {\n+      this.shouldUseJsonNameFieldOption = shouldUseJsonNameFieldOption;\n+      return this;\n+    }\n+\n     public ProtoTypeAdapter build() {\n       return new ProtoTypeAdapter(\n           enumSerialization,\n           protoFormat,\n           jsonFormat,\n           serializedNameExtensions,\n-          serializedEnumValueExtensions);\n+          serializedEnumValueExtensions,\n+          shouldUseJsonNameFieldOption);\n     }\n   }\n \n@@ -203,18 +225,21 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n   private final CaseFormat jsonFormat;\n   private final Set<Extension<FieldOptions, String>> serializedNameExtensions;\n   private final Set<Extension<EnumValueOptions, String>> serializedEnumValueExtensions;\n+  private final boolean shouldUseJsonNameFieldOption;\n \n   private ProtoTypeAdapter(\n       EnumSerialization enumSerialization,\n       CaseFormat protoFormat,\n       CaseFormat jsonFormat,\n       Set<Extension<FieldOptions, String>> serializedNameExtensions,\n-      Set<Extension<EnumValueOptions, String>> serializedEnumValueExtensions) {\n+      Set<Extension<EnumValueOptions, String>> serializedEnumValueExtensions,\n+      boolean shouldUseJsonNameFieldOption) {\n     this.enumSerialization = enumSerialization;\n     this.protoFormat = protoFormat;\n     this.jsonFormat = jsonFormat;\n     this.serializedNameExtensions = serializedNameExtensions;\n     this.serializedEnumValueExtensions = serializedEnumValueExtensions;\n+    this.shouldUseJsonNameFieldOption = shouldUseJsonNameFieldOption;\n   }\n \n   @Override\n@@ -224,7 +249,7 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n \n     for (Map.Entry<FieldDescriptor, Object> fieldPair : fields.entrySet()) {\n       final FieldDescriptor desc = fieldPair.getKey();\n-      String name = getCustSerializedName(desc.getOptions(), desc.getName());\n+      String name = getCustSerializedName(desc);\n \n       if (desc.getType() == ENUM_TYPE) {\n         // Enum collections are also returned as ENUM_TYPE\n@@ -272,8 +297,7 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n           (Descriptor) getCachedMethod(protoClass, \"getDescriptor\").invoke(null);\n       // Call setters on all of the available fields\n       for (FieldDescriptor fieldDescriptor : protoDescriptor.getFields()) {\n-        String jsonFieldName =\n-            getCustSerializedName(fieldDescriptor.getOptions(), fieldDescriptor.getName());\n+        String jsonFieldName = getCustSerializedName(fieldDescriptor);\n \n         JsonElement jsonElement = jsonObject.get(jsonFieldName);\n         if (jsonElement != null && !jsonElement.isJsonNull()) {\n@@ -317,16 +341,29 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n   }\n \n   /**\n-   * Retrieves the custom field name from the given options, and if not found, returns the specified\n-   * default name.\n+   * Retrieves the custom field name from the given field descriptor. The name is determined in the\n+   * following order of priority:\n+   *\n+   * <ol>\n+   *   <li>Custom serialized name extensions added via {@link\n+   *       Builder#addSerializedNameExtension(Extension)}\n+   *   <li>The {@code json_name} field option (if {@link\n+   *       Builder#setShouldUseJsonNameFieldOption(boolean)} is enabled)\n+   *   <li>The default field name with case format conversion applied\n+   * </ol>\n    */\n-  private String getCustSerializedName(FieldOptions options, String defaultName) {\n+  private String getCustSerializedName(FieldDescriptor fieldDescriptor) {\n+    FieldOptions options = fieldDescriptor.getOptions();\n     for (Extension<FieldOptions, String> extension : serializedNameExtensions) {\n       if (options.hasExtension(extension)) {\n         return options.getExtension(extension);\n       }\n     }\n-    return protoFormat.to(jsonFormat, defaultName);\n+    if (shouldUseJsonNameFieldOption) {\n+      // Use the json_name from the field descriptor (no case format conversion)\n+      return fieldDescriptor.getJsonName();\n+    }\n+    return protoFormat.to(jsonFormat, fieldDescriptor.getName());\n   }\n \n   /**\n"}
{"instance_id": "huggingface__transformers-13865", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex 7197800151..d1fcde6e2a 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -16,7 +16,7 @@ import dataclasses\n import json\n import re\n import sys\n-from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser, ArgumentTypeError\n+from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser, ArgumentTypeError, SUPPRESS\n from enum import Enum\n from pathlib import Path\n from typing import Any, Iterable, List, NewType, Optional, Tuple, Union\n@@ -110,7 +110,7 @@ class HfArgumentParser(ArgumentParser):\n                     kwargs[\"required\"] = True\n             elif field.type is bool or field.type == Optional[bool]:\n                 if field.default is True:\n-                    parser.add_argument(f\"--no_{field.name}\", action=\"store_false\", dest=field.name, **kwargs)\n+                    parser.add_argument(f\"--no_{field.name}\", action=\"store_false\", dest=field.name, default=SUPPRESS, **kwargs)\n \n                 # Hack because type=bool in argparse does not behave as we want.\n                 kwargs[\"type\"] = string_to_bool\n"}
{"instance_id": "huggingface__transformers-13491", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/gpt_neo/modeling_gpt_neo.py b/src/transformers/models/gpt_neo/modeling_gpt_neo.py\nindex 05e5b1ce28..1995bd4d55 100755\n--- a/src/transformers/models/gpt_neo/modeling_gpt_neo.py\n+++ b/src/transformers/models/gpt_neo/modeling_gpt_neo.py\n@@ -423,8 +423,8 @@ class GPTNeoLocalSelfAttention(nn.Module, GPTNeoAttentionMixin):\n \n         # create buckets\n         if layer_past is not None:\n-            # we just need 1 block with block_length 1 when caching is enabled\n-            query = self._split_seq_length_dim_to(query, 1, 1)\n+            # we need 1 block with block_length seq_length when caching is enabled\n+            query = self._split_seq_length_dim_to(query, 1, seq_length)\n         else:\n             query = self._split_seq_length_dim_to(query, num_blocks, block_length)\n \n@@ -442,7 +442,7 @@ class GPTNeoLocalSelfAttention(nn.Module, GPTNeoAttentionMixin):\n \n         if layer_past is not None:\n             # only take the mask for the last block\n-            attention_mask = attention_mask[:, -1:, :, -1:, :]\n+            attention_mask = attention_mask[:, -1:, :, -seq_length:, :]\n \n         # attn\n         attn_output, attn_weights = self._attn(\n"}
{"instance_id": "huggingface__transformers-13919", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py b/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py\nindex fbe7596d63..39c298b9e2 100644\n--- a/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py\n+++ b/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py\n@@ -213,7 +213,7 @@ class FlaxGPTNeoSelfAttention(nn.Module):\n         attention_bias = lax.select(\n             attention_mask > 0,\n             jnp.full(attention_mask.shape, 0.0).astype(self.dtype),\n-            jnp.full(attention_mask.shape, -1e9).astype(self.dtype),\n+            jnp.full(attention_mask.shape, -1e4).astype(self.dtype),\n         )\n \n         # usual dot product attention\ndiff --git a/src/transformers/models/gpt_neo/modeling_gpt_neo.py b/src/transformers/models/gpt_neo/modeling_gpt_neo.py\nindex 3fafd75ac2..652c8a8eb4 100755\n--- a/src/transformers/models/gpt_neo/modeling_gpt_neo.py\n+++ b/src/transformers/models/gpt_neo/modeling_gpt_neo.py\n@@ -150,7 +150,7 @@ class GPTNeoSelfAttention(nn.Module):\n             bias = torch.bitwise_xor(bias, torch.tril(bias, -config.window_size))\n \n         self.register_buffer(\"bias\", bias)\n-        self.register_buffer(\"masked_bias\", torch.tensor(-1e9))\n+        self.register_buffer(\"masked_bias\", torch.tensor(-1e4))\n \n         self.attn_dropout = nn.Dropout(config.attention_dropout)\n         self.resid_dropout = nn.Dropout(config.resid_dropout)\ndiff --git a/src/transformers/models/gptj/modeling_gptj.py b/src/transformers/models/gptj/modeling_gptj.py\nindex a23da08347..bb1f3ae4d7 100755\n--- a/src/transformers/models/gptj/modeling_gptj.py\n+++ b/src/transformers/models/gptj/modeling_gptj.py\n@@ -75,7 +75,7 @@ class GPTJAttention(nn.Module):\n                 1, 1, max_positions, max_positions\n             ),\n         )\n-        self.register_buffer(\"masked_bias\", torch.tensor(-1e9))\n+        self.register_buffer(\"masked_bias\", torch.tensor(-1e4))\n \n         self.attn_dropout = nn.Dropout(config.attn_pdrop)\n         self.resid_dropout = nn.Dropout(config.resid_pdrop)\n"}
{"instance_id": "google__guava-5696", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/android/guava/src/com/google/common/collect/TopKSelector.java b/android/guava/src/com/google/common/collect/TopKSelector.java\nindex 108679a18..f8cca0dea 100644\n--- a/android/guava/src/com/google/common/collect/TopKSelector.java\n+++ b/android/guava/src/com/google/common/collect/TopKSelector.java\n@@ -185,7 +185,7 @@ final class TopKSelector<\n       iterations++;\n       if (iterations >= maxIterations) {\n         // We've already taken O(k log k), let's make sure we don't take longer than O(k log k).\n-        Arrays.sort(buffer, left, right, comparator);\n+        Arrays.sort(buffer, left, right + 1, comparator);\n         break;\n       }\n     }\ndiff --git a/guava/src/com/google/common/collect/TopKSelector.java b/guava/src/com/google/common/collect/TopKSelector.java\nindex 69b32f40c..8411fcdea 100644\n--- a/guava/src/com/google/common/collect/TopKSelector.java\n+++ b/guava/src/com/google/common/collect/TopKSelector.java\n@@ -186,7 +186,7 @@ final class TopKSelector<\n       iterations++;\n       if (iterations >= maxIterations) {\n         // We've already taken O(k log k), let's make sure we don't take longer than O(k log k).\n-        Arrays.sort(buffer, left, right, comparator);\n+        Arrays.sort(buffer, left, right + 1, comparator);\n         break;\n       }\n     }\n"}
{"instance_id": "huggingface__transformers-15158", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/bert/tokenization_bert_fast.py b/src/transformers/models/bert/tokenization_bert_fast.py\nindex 4fd53be98d..50094d5de7 100644\n--- a/src/transformers/models/bert/tokenization_bert_fast.py\n+++ b/src/transformers/models/bert/tokenization_bert_fast.py\n@@ -192,10 +192,12 @@ class BertTokenizerFast(PreTrainedTokenizerFast):\n         if (\n             pre_tok_state.get(\"lowercase\", do_lower_case) != do_lower_case\n             or pre_tok_state.get(\"strip_accents\", strip_accents) != strip_accents\n+            or pre_tok_state.get(\"handle_chinese_chars\", tokenize_chinese_chars) != tokenize_chinese_chars\n         ):\n             pre_tok_class = getattr(normalizers, pre_tok_state.pop(\"type\"))\n             pre_tok_state[\"lowercase\"] = do_lower_case\n             pre_tok_state[\"strip_accents\"] = strip_accents\n+            pre_tok_state[\"handle_chinese_chars\"] = tokenize_chinese_chars\n             self.backend_tokenizer.normalizer = pre_tok_class(**pre_tok_state)\n \n         self.do_lower_case = do_lower_case\ndiff --git a/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py b/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py\nindex 0292f1a580..9627817abf 100644\n--- a/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py\n+++ b/src/transformers/models/layoutlmv2/tokenization_layoutlmv2_fast.py\n@@ -153,10 +153,12 @@ class LayoutLMv2TokenizerFast(PreTrainedTokenizerFast):\n         if (\n             pre_tok_state.get(\"lowercase\", do_lower_case) != do_lower_case\n             or pre_tok_state.get(\"strip_accents\", strip_accents) != strip_accents\n+            or pre_tok_state.get(\"handle_chinese_chars\", tokenize_chinese_chars) != tokenize_chinese_chars\n         ):\n             pre_tok_class = getattr(normalizers, pre_tok_state.pop(\"type\"))\n             pre_tok_state[\"lowercase\"] = do_lower_case\n             pre_tok_state[\"strip_accents\"] = strip_accents\n+            pre_tok_state[\"handle_chinese_chars\"] = tokenize_chinese_chars\n             self.backend_tokenizer.normalizer = pre_tok_class(**pre_tok_state)\n \n         self.do_lower_case = do_lower_case\ndiff --git a/src/transformers/models/mpnet/tokenization_mpnet_fast.py b/src/transformers/models/mpnet/tokenization_mpnet_fast.py\nindex c913f85682..15d094e289 100644\n--- a/src/transformers/models/mpnet/tokenization_mpnet_fast.py\n+++ b/src/transformers/models/mpnet/tokenization_mpnet_fast.py\n@@ -146,10 +146,12 @@ class MPNetTokenizerFast(PreTrainedTokenizerFast):\n         if (\n             pre_tok_state.get(\"lowercase\", do_lower_case) != do_lower_case\n             or pre_tok_state.get(\"strip_accents\", strip_accents) != strip_accents\n+            or pre_tok_state.get(\"handle_chinese_chars\", tokenize_chinese_chars) != tokenize_chinese_chars\n         ):\n             pre_tok_class = getattr(normalizers, pre_tok_state.pop(\"type\"))\n             pre_tok_state[\"lowercase\"] = do_lower_case\n             pre_tok_state[\"strip_accents\"] = strip_accents\n+            pre_tok_state[\"handle_chinese_chars\"] = tokenize_chinese_chars\n             self.backend_tokenizer.normalizer = pre_tok_class(**pre_tok_state)\n \n         self.do_lower_case = do_lower_case\ndiff --git a/src/transformers/models/roformer/tokenization_roformer_fast.py b/src/transformers/models/roformer/tokenization_roformer_fast.py\nindex 26c37d4580..5b783b0a1a 100644\n--- a/src/transformers/models/roformer/tokenization_roformer_fast.py\n+++ b/src/transformers/models/roformer/tokenization_roformer_fast.py\n@@ -118,10 +118,12 @@ class RoFormerTokenizerFast(PreTrainedTokenizerFast):\n         if (\n             pre_tok_state.get(\"lowercase\", do_lower_case) != do_lower_case\n             or pre_tok_state.get(\"strip_accents\", strip_accents) != strip_accents\n+            or pre_tok_state.get(\"handle_chinese_chars\", tokenize_chinese_chars) != tokenize_chinese_chars\n         ):\n             pre_tok_class = getattr(normalizers, pre_tok_state.pop(\"type\"))\n             pre_tok_state[\"lowercase\"] = do_lower_case\n             pre_tok_state[\"strip_accents\"] = strip_accents\n+            pre_tok_state[\"handle_chinese_chars\"] = tokenize_chinese_chars\n             self.backend_tokenizer.normalizer = pre_tok_class(**pre_tok_state)\n \n         self.do_lower_case = do_lower_case\ndiff --git a/src/transformers/models/splinter/tokenization_splinter_fast.py b/src/transformers/models/splinter/tokenization_splinter_fast.py\nindex 103ead72ae..97760f8c24 100644\n--- a/src/transformers/models/splinter/tokenization_splinter_fast.py\n+++ b/src/transformers/models/splinter/tokenization_splinter_fast.py\n@@ -134,10 +134,12 @@ class SplinterTokenizerFast(PreTrainedTokenizerFast):\n         if (\n             pre_tok_state.get(\"lowercase\", do_lower_case) != do_lower_case\n             or pre_tok_state.get(\"strip_accents\", strip_accents) != strip_accents\n+            or pre_tok_state.get(\"handle_chinese_chars\", tokenize_chinese_chars) != tokenize_chinese_chars\n         ):\n             pre_tok_class = getattr(normalizers, pre_tok_state.pop(\"type\"))\n             pre_tok_state[\"lowercase\"] = do_lower_case\n             pre_tok_state[\"strip_accents\"] = strip_accents\n+            pre_tok_state[\"handle_chinese_chars\"] = tokenize_chinese_chars\n             self.backend_tokenizer.normalizer = pre_tok_class(**pre_tok_state)\n \n         self.do_lower_case = do_lower_case\n"}
{"instance_id": "huggingface__transformers-15473", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/trainer.py b/src/transformers/trainer.py\nindex 6a68f7d6f4..dfee34e4c0 100755\n--- a/src/transformers/trainer.py\n+++ b/src/transformers/trainer.py\n@@ -243,6 +243,12 @@ class Trainer:\n         compute_metrics (`Callable[[EvalPrediction], Dict]`, *optional*):\n             The function that will be used to compute metrics at evaluation. Must take a [`EvalPrediction`] and return\n             a dictionary string to metric values.\n+        preprocess_logits_for_metrics (`Callable[[torch.Tensor, torch.Tensor], torch.Tensor]`, *optional*):\n+            A function that preprocess the logits right before caching them at each evaluation step. Must take two\n+            tensors, the logits and the labels, and return the logits once processed as desired. The modifications\n+            made by this function will be reflected in the predictions received by `compute_metrics`.\n+\n+            Note that the labels (second parameter) will be `None` if the dataset does not have them.\n         callbacks (List of [`TrainerCallback`], *optional*):\n             A list of callbacks to customize the training loop. Will add those to the list of default callbacks\n             detailed in [here](callback).\n@@ -282,6 +288,7 @@ class Trainer:\n         tokenizer: Optional[PreTrainedTokenizerBase] = None,\n         model_init: Callable[[], PreTrainedModel] = None,\n         compute_metrics: Optional[Callable[[EvalPrediction], Dict]] = None,\n+        preprocess_logits_for_metrics: Callable[[torch.Tensor, torch.Tensor], torch.Tensor] = None,\n         callbacks: Optional[List[TrainerCallback]] = None,\n         optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None),\n     ):\n@@ -385,6 +392,7 @@ class Trainer:\n         self.model = model\n \n         self.compute_metrics = compute_metrics\n+        self.preprocess_logits_for_metrics = preprocess_logits_for_metrics\n         self.optimizer, self.lr_scheduler = optimizers\n         if model_init is not None and (self.optimizer is not None or self.lr_scheduler is not None):\n             raise RuntimeError(\n@@ -2415,6 +2423,8 @@ class Trainer:\n             if logits is not None:\n                 logits = self._pad_across_processes(logits)\n                 logits = self._nested_gather(logits)\n+                if self.preprocess_logits_for_metrics is not None:\n+                    logits = self.preprocess_logits_for_metrics(logits, labels)\n                 preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)\n             if labels is not None:\n                 labels = self._pad_across_processes(labels)\n@@ -2915,6 +2925,8 @@ class Trainer:\n                 losses = loss.repeat(batch_size)\n                 losses_host = losses if losses_host is None else torch.cat((losses_host, losses), dim=0)\n             if logits is not None:\n+                if self.preprocess_logits_for_metrics is not None:\n+                    logits = self.preprocess_logits_for_metrics(logits, labels)\n                 preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)\n             if labels is not None:\n                 labels_host = labels if labels_host is None else nested_concat(labels_host, labels, padding_index=-100)\n"}
{"instance_id": "huggingface__transformers-13989", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/auto/auto_factory.py b/src/transformers/models/auto/auto_factory.py\nindex 516aec52be..7b64abd548 100644\n--- a/src/transformers/models/auto/auto_factory.py\n+++ b/src/transformers/models/auto/auto_factory.py\n@@ -422,6 +422,25 @@ class _BaseAutoModelClass:\n             f\"Model type should be one of {', '.join(c.__name__ for c in cls._model_mapping.keys())}.\"\n         )\n \n+    @classmethod\n+    def register(cls, config_class, model_class):\n+        \"\"\"\n+        Register a new model for this class.\n+\n+        Args:\n+            config_class (:class:`~transformers.PretrainedConfig`):\n+                The configuration corresponding to the model to register.\n+            model_class (:class:`~transformers.PreTrainedModel`):\n+                The model to register.\n+        \"\"\"\n+        if hasattr(model_class, \"config_class\") and model_class.config_class != config_class:\n+            raise ValueError(\n+                \"The model class you are passing has a `config_class` attribute that is not consistent with the \"\n+                f\"config class you passed (model has {model_class.config_class} and you passed {config_class}. Fix \"\n+                \"one of those so they match!\"\n+            )\n+        cls._model_mapping.register(config_class, model_class)\n+\n \n def insert_head_doc(docstring, head_doc=\"\"):\n     if len(head_doc) > 0:\n@@ -507,9 +526,12 @@ class _LazyAutoMapping(OrderedDict):\n         self._config_mapping = config_mapping\n         self._reverse_config_mapping = {v: k for k, v in config_mapping.items()}\n         self._model_mapping = model_mapping\n+        self._extra_content = {}\n         self._modules = {}\n \n     def __getitem__(self, key):\n+        if key in self._extra_content:\n+            return self._extra_content[key]\n         model_type = self._reverse_config_mapping[key.__name__]\n         if model_type not in self._model_mapping:\n             raise KeyError(key)\n@@ -523,11 +545,12 @@ class _LazyAutoMapping(OrderedDict):\n         return getattribute_from_module(self._modules[module_name], attr)\n \n     def keys(self):\n-        return [\n+        mapping_keys = [\n             self._load_attr_from_module(key, name)\n             for key, name in self._config_mapping.items()\n             if key in self._model_mapping.keys()\n         ]\n+        return mapping_keys + list(self._extra_content.keys())\n \n     def get(self, key, default):\n         try:\n@@ -539,14 +562,15 @@ class _LazyAutoMapping(OrderedDict):\n         return bool(self.keys())\n \n     def values(self):\n-        return [\n+        mapping_values = [\n             self._load_attr_from_module(key, name)\n             for key, name in self._model_mapping.items()\n             if key in self._config_mapping.keys()\n         ]\n+        return mapping_values + list(self._extra_content.values())\n \n     def items(self):\n-        return [\n+        mapping_items = [\n             (\n                 self._load_attr_from_module(key, self._config_mapping[key]),\n                 self._load_attr_from_module(key, self._model_mapping[key]),\n@@ -554,12 +578,26 @@ class _LazyAutoMapping(OrderedDict):\n             for key in self._model_mapping.keys()\n             if key in self._config_mapping.keys()\n         ]\n+        return mapping_items + list(self._extra_content.items())\n \n     def __iter__(self):\n-        return iter(self._model_mapping.keys())\n+        return iter(list(self._model_mapping.keys()) + list(self._extra_content.keys()))\n \n     def __contains__(self, item):\n+        if item in self._extra_content:\n+            return True\n         if not hasattr(item, \"__name__\") or item.__name__ not in self._reverse_config_mapping:\n             return False\n         model_type = self._reverse_config_mapping[item.__name__]\n         return model_type in self._model_mapping\n+\n+    def register(self, key, value):\n+        \"\"\"\n+        Register a new model in this mapping.\n+        \"\"\"\n+        if hasattr(key, \"__name__\") and key.__name__ in self._reverse_config_mapping:\n+            model_type = self._reverse_config_mapping[key.__name__]\n+            if model_type in self._model_mapping.keys():\n+                raise ValueError(f\"'{key}' is already used by a Transformers model.\")\n+\n+        self._extra_content[key] = value\ndiff --git a/src/transformers/models/auto/configuration_auto.py b/src/transformers/models/auto/configuration_auto.py\nindex 78a33659a0..f4dd86b832 100644\n--- a/src/transformers/models/auto/configuration_auto.py\n+++ b/src/transformers/models/auto/configuration_auto.py\n@@ -275,9 +275,12 @@ class _LazyConfigMapping(OrderedDict):\n \n     def __init__(self, mapping):\n         self._mapping = mapping\n+        self._extra_content = {}\n         self._modules = {}\n \n     def __getitem__(self, key):\n+        if key in self._extra_content:\n+            return self._extra_content[key]\n         if key not in self._mapping:\n             raise KeyError(key)\n         value = self._mapping[key]\n@@ -287,19 +290,27 @@ class _LazyConfigMapping(OrderedDict):\n         return getattr(self._modules[module_name], value)\n \n     def keys(self):\n-        return self._mapping.keys()\n+        return list(self._mapping.keys()) + list(self._extra_content.keys())\n \n     def values(self):\n-        return [self[k] for k in self._mapping.keys()]\n+        return [self[k] for k in self._mapping.keys()] + list(self._extra_content.values())\n \n     def items(self):\n-        return [(k, self[k]) for k in self._mapping.keys()]\n+        return [(k, self[k]) for k in self._mapping.keys()] + list(self._extra_content.items())\n \n     def __iter__(self):\n-        return iter(self._mapping.keys())\n+        return iter(list(self._mapping.keys()) + list(self._extra_content.keys()))\n \n     def __contains__(self, item):\n-        return item in self._mapping\n+        return item in self._mapping or item in self._extra_content\n+\n+    def register(self, key, value):\n+        \"\"\"\n+        Register a new configuration in this mapping.\n+        \"\"\"\n+        if key in self._mapping.keys():\n+            raise ValueError(f\"'{key}' is already used by a Transformers config, pick another name.\")\n+        self._extra_content[key] = value\n \n \n CONFIG_MAPPING = _LazyConfigMapping(CONFIG_MAPPING_NAMES)\n@@ -543,3 +554,20 @@ class AutoConfig:\n             f\"Should have a `model_type` key in its {CONFIG_NAME}, or contain one of the following strings \"\n             f\"in its name: {', '.join(CONFIG_MAPPING.keys())}\"\n         )\n+\n+    @staticmethod\n+    def register(model_type, config):\n+        \"\"\"\n+        Register a new configuration for this class.\n+\n+        Args:\n+            model_type (:obj:`str`): The model type like \"bert\" or \"gpt\".\n+            config (:class:`~transformers.PretrainedConfig`): The config to register.\n+        \"\"\"\n+        if issubclass(config, PretrainedConfig) and config.model_type != model_type:\n+            raise ValueError(\n+                \"The config you are passing has a `model_type` attribute that is not consistent with the model type \"\n+                f\"you passed (config has {config.model_type} and you passed {model_type}. Fix one of those so they \"\n+                \"match!\"\n+            )\n+        CONFIG_MAPPING.register(model_type, config)\ndiff --git a/src/transformers/models/auto/feature_extraction_auto.py b/src/transformers/models/auto/feature_extraction_auto.py\nindex 7fcd0dd556..f64b5c714f 100644\n--- a/src/transformers/models/auto/feature_extraction_auto.py\n+++ b/src/transformers/models/auto/feature_extraction_auto.py\n@@ -176,3 +176,16 @@ class AutoFeatureExtractor:\n             f\"its {FEATURE_EXTRACTOR_NAME}, or one of the following `model_type` keys in its {CONFIG_NAME}: \"\n             f\"{', '.join(c for c in FEATURE_EXTRACTOR_MAPPING_NAMES.keys())}\"\n         )\n+\n+    @staticmethod\n+    def register(config_class, feature_extractor_class):\n+        \"\"\"\n+        Register a new feature extractor for this class.\n+\n+        Args:\n+            config_class (:class:`~transformers.PretrainedConfig`):\n+                The configuration corresponding to the model to register.\n+            feature_extractor_class (:class:`~transformers.FeatureExtractionMixin`):\n+                The feature extractor to register.\n+        \"\"\"\n+        FEATURE_EXTRACTOR_MAPPING.register(config_class, feature_extractor_class)\ndiff --git a/src/transformers/models/auto/tokenization_auto.py b/src/transformers/models/auto/tokenization_auto.py\nindex a30d981874..55dc12691e 100644\n--- a/src/transformers/models/auto/tokenization_auto.py\n+++ b/src/transformers/models/auto/tokenization_auto.py\n@@ -28,6 +28,7 @@ from ...file_utils import (\n     is_sentencepiece_available,\n     is_tokenizers_available,\n )\n+from ...tokenization_utils import PreTrainedTokenizer\n from ...tokenization_utils_base import TOKENIZER_CONFIG_FILE\n from ...tokenization_utils_fast import PreTrainedTokenizerFast\n from ...utils import logging\n@@ -509,3 +510,26 @@ class AutoTokenizer:\n             f\"Unrecognized configuration class {config.__class__} to build an AutoTokenizer.\\n\"\n             f\"Model type should be one of {', '.join(c.__name__ for c in TOKENIZER_MAPPING.keys())}.\"\n         )\n+\n+    @staticmethod\n+    def register(config_class, slow_tokenizer_class=None, fast_tokenizer_class=None):\n+        \"\"\"\n+        Register a new tokenizer in this mapping.\n+\n+\n+        Args:\n+            config_class (:class:`~transformers.PretrainedConfig`):\n+                The configuration corresponding to the model to register.\n+            slow_tokenizer_class (:class:`~transformers.PretrainedTokenizer`, `optional`):\n+                The slow tokenizer to register.\n+            fast_tokenizer_class (:class:`~transformers.PretrainedTokenizerFast`, `optional`):\n+                The fast tokenizer to register.\n+        \"\"\"\n+        if slow_tokenizer_class is None and fast_tokenizer_class is None:\n+            raise ValueError(\"You need to pass either a `slow_tokenizer_class` or a `fast_tokenizer_class\")\n+        if slow_tokenizer_class is not None and issubclass(slow_tokenizer_class, PreTrainedTokenizerFast):\n+            raise ValueError(\"You passed a fast tokenizer in the `slow_tokenizer_class`.\")\n+        if fast_tokenizer_class is not None and issubclass(fast_tokenizer_class, PreTrainedTokenizer):\n+            raise ValueError(\"You passed a slow tokenizer in the `fast_tokenizer_class`.\")\n+\n+        TOKENIZER_MAPPING.register(config_class, (slow_tokenizer_class, fast_tokenizer_class))\n"}
{"instance_id": "huggingface__transformers-15795", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex 59ceeb5143..a96e6e5935 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -20,7 +20,7 @@ from argparse import ArgumentDefaultsHelpFormatter, ArgumentParser, ArgumentType\n from copy import copy\n from enum import Enum\n from pathlib import Path\n-from typing import Any, Iterable, List, NewType, Optional, Tuple, Union\n+from typing import Any, Dict, Iterable, List, NewType, Optional, Tuple, Union, get_type_hints\n \n \n DataClass = NewType(\"DataClass\", Any)\n@@ -75,6 +75,13 @@ class HfArgumentParser(ArgumentParser):\n             parser = self.add_argument_group(dtype._argument_group_name)\n         else:\n             parser = self\n+        try:\n+            type_hints: Dict[str, type] = get_type_hints(dtype)\n+        except NameError:\n+            raise RuntimeError(\n+                f\"Type resolution failed for {dtype}. Try declaring the class in global scope or \"\n+                \"removing line of `from __future__ import annotations` which opts in PEP://563 changes\"\n+            )\n         for field in dataclasses.fields(dtype):\n             if not field.init:\n                 continue\n@@ -82,44 +89,40 @@ class HfArgumentParser(ArgumentParser):\n             kwargs = field.metadata.copy()\n             # field.metadata is not used at all by Data Classes,\n             # it is provided as a third-party extension mechanism.\n-            if isinstance(field.type, str):\n-                raise ImportError(\n-                    \"This implementation is not compatible with Postponed Evaluation of Annotations (PEP 563), \"\n-                    \"which can be opted in from Python 3.7 with `from __future__ import annotations`. \"\n-                    \"We will add compatibility when Python 3.9 is released.\"\n-                )\n-            typestring = str(field.type)\n+            origin_type = type_hints[field.name]\n+            typestring = str(origin_type)\n             for prim_type in (int, float, str):\n                 for collection in (List,):\n                     if (\n                         typestring == f\"typing.Union[{collection[prim_type]}, NoneType]\"\n                         or typestring == f\"typing.Optional[{collection[prim_type]}]\"\n                     ):\n-                        field.type = collection[prim_type]\n+                        origin_type = collection[prim_type]\n+                        typestring = str(origin_type)\n                 if (\n                     typestring == f\"typing.Union[{prim_type.__name__}, NoneType]\"\n                     or typestring == f\"typing.Optional[{prim_type.__name__}]\"\n                 ):\n-                    field.type = prim_type\n+                    origin_type = prim_type\n \n             # A variable to store kwargs for a boolean field, if needed\n             # so that we can init a `no_*` complement argument (see below)\n             bool_kwargs = {}\n-            if isinstance(field.type, type) and issubclass(field.type, Enum):\n-                kwargs[\"choices\"] = [x.value for x in field.type]\n+            if isinstance(origin_type, type) and issubclass(origin_type, Enum):\n+                kwargs[\"choices\"] = [x.value for x in origin_type]\n                 kwargs[\"type\"] = type(kwargs[\"choices\"][0])\n                 if field.default is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default\n                 else:\n                     kwargs[\"required\"] = True\n-            elif field.type is bool or field.type == Optional[bool]:\n+            elif origin_type is bool or origin_type == Optional[bool]:\n                 # Copy the currect kwargs to use to instantiate a `no_*` complement argument below.\n                 # We do not init it here because the `no_*` alternative must be instantiated after the real argument\n                 bool_kwargs = copy(kwargs)\n \n                 # Hack because type=bool in argparse does not behave as we want.\n                 kwargs[\"type\"] = string_to_bool\n-                if field.type is bool or (field.default is not None and field.default is not dataclasses.MISSING):\n+                if origin_type is bool or (field.default is not None and field.default is not dataclasses.MISSING):\n                     # Default value is False if we have no default when of type bool.\n                     default = False if field.default is dataclasses.MISSING else field.default\n                     # This is the value that will get picked if we don't include --field_name in any way\n@@ -129,19 +132,19 @@ class HfArgumentParser(ArgumentParser):\n                     # This is the value that will get picked if we do --field_name (without value)\n                     kwargs[\"const\"] = True\n             elif (\n-                hasattr(field.type, \"__origin__\")\n-                and re.search(r\"^(typing\\.List|list)\\[(.*)\\]$\", str(field.type)) is not None\n+                hasattr(origin_type, \"__origin__\")\n+                and re.search(r\"^(typing\\.List|list)\\[(.*)\\]$\", typestring) is not None\n             ):\n                 kwargs[\"nargs\"] = \"+\"\n-                kwargs[\"type\"] = field.type.__args__[0]\n-                if not all(x == kwargs[\"type\"] for x in field.type.__args__):\n+                kwargs[\"type\"] = origin_type.__args__[0]\n+                if not all(x == kwargs[\"type\"] for x in origin_type.__args__):\n                     raise ValueError(f\"{field.name} cannot be a List of mixed types\")\n                 if field.default_factory is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default_factory()\n                 elif field.default is dataclasses.MISSING:\n                     kwargs[\"required\"] = True\n             else:\n-                kwargs[\"type\"] = field.type\n+                kwargs[\"type\"] = origin_type\n                 if field.default is not dataclasses.MISSING:\n                     kwargs[\"default\"] = field.default\n                 elif field.default_factory is not dataclasses.MISSING:\n@@ -154,7 +157,7 @@ class HfArgumentParser(ArgumentParser):\n             # Order is important for arguments with the same destination!\n             # We use a copy of earlier kwargs because the original kwargs have changed a lot before reaching down\n             # here and we do not need those changes/additional keys.\n-            if field.default is True and (field.type is bool or field.type == Optional[bool]):\n+            if field.default is True and (origin_type is bool or origin_type == Optional[bool]):\n                 bool_kwargs[\"default\"] = False\n                 parser.add_argument(f\"--no_{field.name}\", action=\"store_false\", dest=field.name, **bool_kwargs)\n \n"}
{"instance_id": "huggingface__transformers-19657", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/pipelines/base.py b/src/transformers/pipelines/base.py\nindex b5e7c9cb58..4205ef2eb2 100644\n--- a/src/transformers/pipelines/base.py\n+++ b/src/transformers/pipelines/base.py\n@@ -836,13 +836,13 @@ class Pipeline(_ScikitCompat):\n         \"\"\"\n         Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n         \"\"\"\n-        return self(X=X)\n+        return self(X)\n \n     def predict(self, X):\n         \"\"\"\n         Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n         \"\"\"\n-        return self(X=X)\n+        return self(X)\n \n     @contextmanager\n     def device_placement(self):\n"}
{"instance_id": "huggingface__transformers-16198", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/clip/modeling_clip.py b/src/transformers/models/clip/modeling_clip.py\nindex cf13926ebd..48e63d00af 100755\n--- a/src/transformers/models/clip/modeling_clip.py\n+++ b/src/transformers/models/clip/modeling_clip.py\n@@ -680,6 +680,10 @@ class CLIPTextModel(CLIPPreTrainedModel):\n \n     def __init__(self, config: CLIPTextConfig):\n         super().__init__(config)\n+\n+        if isinstance(config, CLIPConfig):\n+            config = config.text_config\n+\n         self.text_model = CLIPTextTransformer(config)\n         # Initialize weights and apply final processing\n         self.post_init()\n@@ -792,6 +796,10 @@ class CLIPVisionModel(CLIPPreTrainedModel):\n \n     def __init__(self, config: CLIPVisionConfig):\n         super().__init__(config)\n+\n+        if isinstance(config, CLIPConfig):\n+            config = config.vision_config\n+\n         self.vision_model = CLIPVisionTransformer(config)\n         # Initialize weights and apply final processing\n         self.post_init()\ndiff --git a/src/transformers/models/clip/modeling_flax_clip.py b/src/transformers/models/clip/modeling_flax_clip.py\nindex 237d29fe71..c7f0046bf8 100644\n--- a/src/transformers/models/clip/modeling_flax_clip.py\n+++ b/src/transformers/models/clip/modeling_flax_clip.py\n@@ -587,6 +587,8 @@ class FlaxCLIPTextPreTrainedModel(FlaxPreTrainedModel):\n     def __init__(\n         self, config: CLIPTextConfig, input_shape=(1, 1), seed: int = 0, dtype: jnp.dtype = jnp.float32, **kwargs\n     ):\n+        if isinstance(config, CLIPConfig):\n+            config = config.text_config\n         module = self.module_class(config=config, dtype=dtype, **kwargs)\n         super().__init__(config, module, input_shape=input_shape, seed=seed, dtype=dtype)\n \n@@ -656,6 +658,8 @@ class FlaxCLIPVisionPreTrainedModel(FlaxPreTrainedModel):\n         dtype: jnp.dtype = jnp.float32,\n         **kwargs\n     ):\n+        if isinstance(config, CLIPConfig):\n+            config = config.vision_config\n         if input_shape is None:\n             input_shape = (1, config.image_size, config.image_size, 3)\n         module = self.module_class(config=config, dtype=dtype, **kwargs)\ndiff --git a/src/transformers/models/clip/modeling_tf_clip.py b/src/transformers/models/clip/modeling_tf_clip.py\nindex eac593fb54..34c44d2751 100644\n--- a/src/transformers/models/clip/modeling_tf_clip.py\n+++ b/src/transformers/models/clip/modeling_tf_clip.py\n@@ -1044,6 +1044,9 @@ class TFCLIPTextModel(TFCLIPPreTrainedModel):\n     def __init__(self, config: CLIPTextConfig, *inputs, **kwargs):\n         super().__init__(config, *inputs, **kwargs)\n \n+        if isinstance(config, CLIPConfig):\n+            config = config.text_config\n+\n         self.clip = TFCLIPTextMainLayer(config, name=\"clip\")\n \n     @unpack_inputs\n@@ -1109,6 +1112,9 @@ class TFCLIPVisionModel(TFCLIPPreTrainedModel):\n     def __init__(self, config: CLIPVisionConfig, *inputs, **kwargs):\n         super().__init__(config, *inputs, **kwargs)\n \n+        if isinstance(config, CLIPConfig):\n+            config = config.vision_config\n+\n         self.clip = TFCLIPVisionMainLayer(config, name=\"clip\")\n \n     @property\n"}
{"instance_id": "huggingface__transformers-15843", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/pipelines/automatic_speech_recognition.py b/src/transformers/pipelines/automatic_speech_recognition.py\nindex 3552a23ce3..296cf893ad 100644\n--- a/src/transformers/pipelines/automatic_speech_recognition.py\n+++ b/src/transformers/pipelines/automatic_speech_recognition.py\n@@ -323,12 +323,15 @@ class AutomaticSpeechRecognitionPipeline(ChunkPipeline):\n             attention_mask = model_inputs.pop(\"attention_mask\", None)\n             outputs = self.model(input_values=input_values, attention_mask=attention_mask)\n             tokens = outputs.logits.argmax(dim=-1)\n+            out = {\"tokens\": tokens}\n             if stride is not None:\n+                # Send stride to `postprocess`.\n+                # it needs to be handled there where\n+                # the pieces are to be concatenated.\n                 if isinstance(stride, tuple):\n-                    stride = [stride]\n-\n-                apply_stride(tokens, stride)\n-            out = {\"tokens\": tokens}\n+                    out[\"stride\"] = rescale_stride(tokens, [stride])[0]\n+                else:\n+                    out[\"stride\"] = rescale_stride(tokens, stride)\n         else:\n             logger.warning(\"This is an unknown class, treating it as CTC.\")\n             outputs = self.model(**model_inputs)\n@@ -366,7 +369,20 @@ class AutomaticSpeechRecognitionPipeline(ChunkPipeline):\n             text = self.decoder.decode_beams(logits, **decoder_kwargs)[0][0]\n         else:\n             skip_special_tokens = self.type != \"ctc\"\n-            tokens = np.concatenate([outputs[\"tokens\"].numpy() for outputs in model_outputs], axis=-1)\n+            final_items = []\n+            for outputs in model_outputs:\n+                items = outputs[\"tokens\"].numpy()\n+                stride = outputs.pop(\"stride\", None)\n+                if stride is not None:\n+                    total_n, left, right = stride\n+                    # Total_n might be < items.shape[1]\n+                    # because of padding, that's why\n+                    # we need to reconstruct this information\n+                    # This won't work with left padding (which doesn't exist right now)\n+                    right_n = total_n - right\n+                    items = items[:, left:right_n]\n+                final_items.append(items)\n+            tokens = np.concatenate(final_items, axis=-1)\n             tokens = tokens.squeeze(0)\n             text = self.tokenizer.decode(tokens, skip_special_tokens=skip_special_tokens)\n \n"}
{"instance_id": "huggingface__transformers-17082", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/deberta/tokenization_deberta.py b/src/transformers/models/deberta/tokenization_deberta.py\nindex 6bca0ed581..13bb8b4817 100644\n--- a/src/transformers/models/deberta/tokenization_deberta.py\n+++ b/src/transformers/models/deberta/tokenization_deberta.py\n@@ -210,7 +210,7 @@ class DebertaTokenizer(GPT2Tokenizer):\n \n         if token_ids_1 is None:\n             return len(cls + token_ids_0 + sep) * [0]\n-        return len(cls + token_ids_0 + sep + token_ids_1 + sep) * [0]\n+        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n \n     def prepare_for_tokenization(self, text, is_split_into_words=False, **kwargs):\n         add_prefix_space = kwargs.pop(\"add_prefix_space\", self.add_prefix_space)\ndiff --git a/src/transformers/models/deberta/tokenization_deberta_fast.py b/src/transformers/models/deberta/tokenization_deberta_fast.py\nindex 74c2e4aca2..62deff8b14 100644\n--- a/src/transformers/models/deberta/tokenization_deberta_fast.py\n+++ b/src/transformers/models/deberta/tokenization_deberta_fast.py\n@@ -183,7 +183,7 @@ class DebertaTokenizerFast(GPT2TokenizerFast):\n         sequence pair mask has the following format:\n \n         ```\n-        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n+        0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n         | first sequence    | second sequence |\n         ```\n \n@@ -203,4 +203,4 @@ class DebertaTokenizerFast(GPT2TokenizerFast):\n \n         if token_ids_1 is None:\n             return len(cls + token_ids_0 + sep) * [0]\n-        return len(cls + token_ids_0 + sep + token_ids_1 + sep) * [0]\n+        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n"}
{"instance_id": "huggingface__transformers-16661", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/setup.py b/setup.py\nindex 4d386ae008..59becf116f 100644\n--- a/setup.py\n+++ b/setup.py\n@@ -151,7 +151,7 @@ _deps = [\n     \"tf2onnx\",\n     \"timeout-decorator\",\n     \"timm\",\n-    \"tokenizers>=0.11.1,!=0.11.3,<0.13\",\n+    \"tokenizers>=0.11.1,!=0.11.3\",\n     \"torch>=1.0\",\n     \"torchaudio\",\n     \"pyctcdecode>=0.3.0\",\ndiff --git a/src/transformers/dependency_versions_table.py b/src/transformers/dependency_versions_table.py\nindex 334103c20a..2ba72f5b95 100644\n--- a/src/transformers/dependency_versions_table.py\n+++ b/src/transformers/dependency_versions_table.py\n@@ -61,7 +61,7 @@ deps = {\n     \"tf2onnx\": \"tf2onnx\",\n     \"timeout-decorator\": \"timeout-decorator\",\n     \"timm\": \"timm\",\n-    \"tokenizers\": \"tokenizers>=0.11.1,!=0.11.3,<0.13\",\n+    \"tokenizers\": \"tokenizers>=0.11.1,!=0.11.3\",\n     \"torch\": \"torch>=1.0\",\n     \"torchaudio\": \"torchaudio\",\n     \"pyctcdecode\": \"pyctcdecode>=0.3.0\",\ndiff --git a/src/transformers/tokenization_utils_base.py b/src/transformers/tokenization_utils_base.py\nindex c76197f544..899c5d3a02 100644\n--- a/src/transformers/tokenization_utils_base.py\n+++ b/src/transformers/tokenization_utils_base.py\n@@ -1150,35 +1150,35 @@ class SpecialTokensMixin:\n \n     @bos_token_id.setter\n     def bos_token_id(self, value):\n-        self._bos_token = self.convert_tokens_to_ids(value)\n+        self._bos_token = self.convert_ids_to_tokens(value) if value is not None else None\n \n     @eos_token_id.setter\n     def eos_token_id(self, value):\n-        self._eos_token = self.convert_tokens_to_ids(value)\n+        self._eos_token = self.convert_ids_to_tokens(value) if value is not None else None\n \n     @unk_token_id.setter\n     def unk_token_id(self, value):\n-        self._unk_token = self.convert_tokens_to_ids(value)\n+        self._unk_token = self.convert_ids_to_tokens(value) if value is not None else None\n \n     @sep_token_id.setter\n     def sep_token_id(self, value):\n-        self._sep_token = self.convert_tokens_to_ids(value)\n+        self._sep_token = self.convert_ids_to_tokens(value) if value is not None else None\n \n     @pad_token_id.setter\n     def pad_token_id(self, value):\n-        self._pad_token = self.convert_tokens_to_ids(value)\n+        self._pad_token = self.convert_ids_to_tokens(value) if value is not None else None\n \n     @cls_token_id.setter\n     def cls_token_id(self, value):\n-        self._cls_token = self.convert_tokens_to_ids(value)\n+        self._cls_token = self.convert_ids_to_tokens(value) if value is not None else None\n \n     @mask_token_id.setter\n     def mask_token_id(self, value):\n-        self._mask_token = self.convert_tokens_to_ids(value)\n+        self._mask_token = self.convert_ids_to_tokens(value) if value is not None else None\n \n     @additional_special_tokens_ids.setter\n     def additional_special_tokens_ids(self, values):\n-        self._additional_special_tokens = [self.convert_tokens_to_ids(value) for value in values]\n+        self._additional_special_tokens = [self.convert_ids_to_tokens(value) for value in values]\n \n     @property\n     def special_tokens_map(self) -> Dict[str, Union[str, List[str]]]:\n"}
{"instance_id": "huggingface__transformers-19590", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/bert/tokenization_bert_tf.py b/src/transformers/models/bert/tokenization_bert_tf.py\nindex 477ba37e0c..bcb91879c5 100644\n--- a/src/transformers/models/bert/tokenization_bert_tf.py\n+++ b/src/transformers/models/bert/tokenization_bert_tf.py\n@@ -3,6 +3,7 @@ from typing import List, Union\n \n import tensorflow as tf\n \n+from tensorflow_text import BertTokenizer as BertTokenizerLayer\n from tensorflow_text import FastBertTokenizer, ShrinkLongestTrimmer, case_fold_utf8, combine_segments, pad_model_inputs\n \n from .tokenization_bert import BertTokenizer\n@@ -47,6 +48,10 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n             Whether to return token_type_ids.\n         return_attention_mask (`bool`, *optional*, defaults to `True`):\n             Whether to return the attention_mask.\n+        use_fast_bert_tokenizer (`bool`, *optional*, defaults to `True`):\n+            If True, will use the FastBertTokenizer class from Tensorflow Text. If False, will use the BertTokenizer\n+            class instead. BertTokenizer supports tokenizing for TensorFlow Serving, but is slower than\n+            FastBertTokenizer. See https://github.com/tensorflow/text/issues/577 for more details.\n     \"\"\"\n \n     def __init__(\n@@ -62,11 +67,26 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n         pad_to_multiple_of: int = None,\n         return_token_type_ids: bool = True,\n         return_attention_mask: bool = True,\n+        use_fast_bert_tokenizer: bool = True,\n     ):\n         super().__init__()\n-        self.tf_tokenizer = FastBertTokenizer(\n-            vocab_list, token_out_type=tf.int64, lower_case_nfd_strip_accents=do_lower_case\n-        )\n+        if use_fast_bert_tokenizer:\n+            self.tf_tokenizer = FastBertTokenizer(\n+                vocab_list, token_out_type=tf.int64, lower_case_nfd_strip_accents=do_lower_case\n+            )\n+        else:\n+            lookup_table = tf.lookup.StaticVocabularyTable(\n+                tf.lookup.KeyValueTensorInitializer(\n+                    keys=vocab_list,\n+                    key_dtype=tf.string,\n+                    values=tf.range(tf.size(vocab_list, out_type=tf.int64), dtype=tf.int64),\n+                    value_dtype=tf.int64,\n+                ),\n+                num_oov_buckets=1,\n+            )\n+            self.tf_tokenizer = BertTokenizerLayer(\n+                lookup_table, token_out_type=tf.int64, lower_case=do_lower_case\n+            )\n         self.vocab_list = vocab_list\n         self.do_lower_case = do_lower_case\n         self.cls_token_id = cls_token_id or vocab_list.index(\"[CLS]\")\n@@ -79,6 +99,7 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n         self.pad_to_multiple_of = pad_to_multiple_of\n         self.return_token_type_ids = return_token_type_ids\n         self.return_attention_mask = return_attention_mask\n+        self.use_fast_bert_tokenizer = use_fast_bert_tokenizer\n \n     @classmethod\n     def from_tokenizer(cls, tokenizer: \"PreTrainedTokenizerBase\", **kwargs):  # noqa: F821\n@@ -219,4 +240,11 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n             \"cls_token_id\": self.cls_token_id,\n             \"sep_token_id\": self.sep_token_id,\n             \"pad_token_id\": self.pad_token_id,\n+            \"padding\": self.padding,\n+            \"truncation\": self.truncation,\n+            \"max_length\": self.max_length,\n+            \"pad_to_multiple_of\": self.pad_to_multiple_of,\n+            \"return_token_type_ids\": self.return_token_type_ids,\n+            \"return_attention_mask\": self.return_attention_mask,\n+            \"use_fast_bert_tokenizer\": self.use_fast_bert_tokenizer,\n         }\n"}
{"instance_id": "huggingface__transformers-18851", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/generation_beam_search.py b/src/transformers/generation_beam_search.py\nindex e0514edafb..7c50c0d7ac 100644\n--- a/src/transformers/generation_beam_search.py\n+++ b/src/transformers/generation_beam_search.py\n@@ -259,7 +259,7 @@ class BeamSearchScorer(BeamScorer):\n                         continue\n                     if beam_indices is not None:\n                         beam_index = beam_indices[batch_beam_idx]\n-                        beam_index = beam_index + (next_index,)\n+                        beam_index = beam_index + (batch_beam_idx,)\n                     else:\n                         beam_index = None\n \n"}
{"instance_id": "huggingface__transformers-21345", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/activations.py b/src/transformers/activations.py\nindex d9caf8763e..436d2b95fe 100644\n--- a/src/transformers/activations.py\n+++ b/src/transformers/activations.py\n@@ -25,6 +25,27 @@ from .utils import logging\n logger = logging.get_logger(__name__)\n \n \n+class PytorchGELUTanh(nn.Module):\n+    \"\"\"\n+    A fast C implementation of the tanh approximation of the GeLU activation function. See\n+    https://arxiv.org/abs/1606.08415.\n+\n+    This implementation is equivalent to NewGELU and FastGELU but much faster. However, it is not an exact numerical\n+    match due to rounding errors.\n+    \"\"\"\n+\n+    def __init__(self):\n+        super().__init__()\n+        if version.parse(torch.__version__) < version.parse(\"1.12.0\"):\n+            raise ImportError(\n+                f\"You are using torch=={torch.__version__}, but torch>=1.12.0 is required to use \"\n+                \"PytorchGELUTanh. Please upgrade torch.\"\n+            )\n+\n+    def forward(self, input: Tensor) -> Tensor:\n+        return nn.functional.gelu(input, approximate=\"tanh\")\n+\n+\n class NewGELUActivation(nn.Module):\n     \"\"\"\n     Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT). Also see\n@@ -155,6 +176,7 @@ ACT2CLS = {\n     \"gelu_fast\": FastGELUActivation,\n     \"gelu_new\": NewGELUActivation,\n     \"gelu_python\": (GELUActivation, {\"use_gelu_python\": True}),\n+    \"gelu_pytorch_tanh\": PytorchGELUTanh,\n     \"linear\": LinearActivation,\n     \"mish\": MishActivation,\n     \"quick_gelu\": QuickGELUActivation,\n"}
{"instance_id": "huggingface__transformers-21768", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/optimization.py b/src/transformers/optimization.py\nindex 659b92a59b..f74ada777d 100644\n--- a/src/transformers/optimization.py\n+++ b/src/transformers/optimization.py\n@@ -16,6 +16,7 @@\n \n import math\n import warnings\n+from functools import partial\n from typing import Callable, Iterable, Optional, Tuple, Union\n \n import torch\n@@ -31,6 +32,77 @@ from .utils.versions import require_version\n logger = logging.get_logger(__name__)\n \n \n+def _get_constant_lambda(current_step: int):\n+    return 1\n+\n+\n+def _get_constant_schedule_with_warmup_lr_lambda(current_step: int, *, num_warmup_steps: int):\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1.0, num_warmup_steps))\n+    return 1.0\n+\n+\n+def _get_linear_schedule_with_warmup_lr_lambda(current_step: int, *, num_warmup_steps: int, num_training_steps: int):\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    return max(\n+        0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n+    )\n+\n+\n+def _get_cosine_schedule_with_warmup_lr_lambda(\n+    current_step: int, *, num_warmup_steps: int, num_training_steps: int, num_cycles: float\n+):\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n+    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n+\n+\n+def _get_cosine_with_hard_restarts_schedule_with_warmup_lr_lambda(\n+    current_step: int, *, num_warmup_steps: int, num_training_steps: int, num_cycles: int\n+):\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n+    if progress >= 1.0:\n+        return 0.0\n+    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * ((float(num_cycles) * progress) % 1.0))))\n+\n+\n+def _get_polynomial_decay_schedule_with_warmup_lr_lambda(\n+    current_step: int,\n+    *,\n+    num_warmup_steps: int,\n+    num_training_steps: int,\n+    lr_end: float,\n+    power: float,\n+    lr_init: int,\n+):\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    elif current_step > num_training_steps:\n+        return lr_end / lr_init  # as LambdaLR multiplies by lr_init\n+    else:\n+        lr_range = lr_init - lr_end\n+        decay_steps = num_training_steps - num_warmup_steps\n+        pct_remaining = 1 - (current_step - num_warmup_steps) / decay_steps\n+        decay = lr_range * pct_remaining**power + lr_end\n+        return decay / lr_init  # as LambdaLR multiplies by lr_init\n+\n+\n+def _get_inverse_sqrt_schedule_lr_lambda(current_step: int, *, num_warmup_steps: int, timescale: int):\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    shift = timescale - num_warmup_steps\n+    decay = 1.0 / math.sqrt((current_step + shift) / timescale)\n+    return decay\n+\n+\n+def _get_adafactor_schedule_lr_lambda(_: int, *, initial_lr: float):\n+    return initial_lr\n+\n+\n def get_constant_schedule(optimizer: Optimizer, last_epoch: int = -1):\n     \"\"\"\n     Create a schedule with a constant learning rate, using the learning rate set in optimizer.\n@@ -44,7 +116,7 @@ def get_constant_schedule(optimizer: Optimizer, last_epoch: int = -1):\n     Return:\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n-    return LambdaLR(optimizer, lambda _: 1, last_epoch=last_epoch)\n+    return LambdaLR(optimizer, _get_constant_lambda, last_epoch=last_epoch)\n \n \n def get_constant_schedule_with_warmup(optimizer: Optimizer, num_warmup_steps: int, last_epoch: int = -1):\n@@ -64,11 +136,7 @@ def get_constant_schedule_with_warmup(optimizer: Optimizer, num_warmup_steps: in\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n \n-    def lr_lambda(current_step: int):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1.0, num_warmup_steps))\n-        return 1.0\n-\n+    lr_lambda = partial(_get_constant_schedule_with_warmup_lr_lambda, num_warmup_steps=num_warmup_steps)\n     return LambdaLR(optimizer, lr_lambda, last_epoch=last_epoch)\n \n \n@@ -91,13 +159,11 @@ def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_st\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n \n-    def lr_lambda(current_step: int):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        return max(\n-            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n-        )\n-\n+    lr_lambda = partial(\n+        _get_linear_schedule_with_warmup_lr_lambda,\n+        num_warmup_steps=num_warmup_steps,\n+        num_training_steps=num_training_steps,\n+    )\n     return LambdaLR(optimizer, lr_lambda, last_epoch)\n \n \n@@ -126,12 +192,12 @@ def get_cosine_schedule_with_warmup(\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n \n-    def lr_lambda(current_step):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n-        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n-\n+    lr_lambda = partial(\n+        _get_cosine_schedule_with_warmup_lr_lambda,\n+        num_warmup_steps=num_warmup_steps,\n+        num_training_steps=num_training_steps,\n+        num_cycles=num_cycles,\n+    )\n     return LambdaLR(optimizer, lr_lambda, last_epoch)\n \n \n@@ -159,14 +225,12 @@ def get_cosine_with_hard_restarts_schedule_with_warmup(\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n \n-    def lr_lambda(current_step):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n-        if progress >= 1.0:\n-            return 0.0\n-        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * ((float(num_cycles) * progress) % 1.0))))\n-\n+    lr_lambda = partial(\n+        _get_cosine_with_hard_restarts_schedule_with_warmup_lr_lambda,\n+        num_warmup_steps=num_warmup_steps,\n+        num_training_steps=num_training_steps,\n+        num_cycles=num_cycles,\n+    )\n     return LambdaLR(optimizer, lr_lambda, last_epoch)\n \n \n@@ -205,18 +269,14 @@ def get_polynomial_decay_schedule_with_warmup(\n     if not (lr_init > lr_end):\n         raise ValueError(f\"lr_end ({lr_end}) must be be smaller than initial lr ({lr_init})\")\n \n-    def lr_lambda(current_step: int):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        elif current_step > num_training_steps:\n-            return lr_end / lr_init  # as LambdaLR multiplies by lr_init\n-        else:\n-            lr_range = lr_init - lr_end\n-            decay_steps = num_training_steps - num_warmup_steps\n-            pct_remaining = 1 - (current_step - num_warmup_steps) / decay_steps\n-            decay = lr_range * pct_remaining**power + lr_end\n-            return decay / lr_init  # as LambdaLR multiplies by lr_init\n-\n+    lr_lambda = partial(\n+        _get_polynomial_decay_schedule_with_warmup_lr_lambda,\n+        num_warmup_steps=num_warmup_steps,\n+        num_training_steps=num_training_steps,\n+        lr_end=lr_end,\n+        power=power,\n+        lr_init=lr_init,\n+    )\n     return LambdaLR(optimizer, lr_lambda, last_epoch)\n \n \n@@ -246,13 +306,11 @@ def get_inverse_sqrt_schedule(\n     if timescale is None:\n         timescale = num_warmup_steps\n \n-    def lr_lambda(current_step: int):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        shift = timescale - num_warmup_steps\n-        decay = 1.0 / math.sqrt((current_step + shift) / timescale)\n-        return decay\n-\n+    lr_lambda = partial(\n+        _get_inverse_sqrt_schedule_lr_lambda,\n+        num_warmup_steps=num_warmup_steps,\n+        timescale=timescale,\n+    )\n     return LambdaLR(optimizer, lr_lambda, last_epoch=last_epoch)\n \n \n@@ -672,9 +730,7 @@ class AdafactorSchedule(LambdaLR):\n     \"\"\"\n \n     def __init__(self, optimizer, initial_lr=0.0):\n-        def lr_lambda(_):\n-            return initial_lr\n-\n+        lr_lambda = partial(_get_adafactor_schedule_lr_lambda, initial_lr=initial_lr)\n         for group in optimizer.param_groups:\n             group[\"initial_lr\"] = initial_lr\n         super().__init__(optimizer, lr_lambda)\n"}
{"instance_id": "huggingface__transformers-22158", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex 16016d9704..57cf2a6afd 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -158,10 +158,10 @@ def to_pil_image(\n \n     # PIL.Image can only store uint8 values, so we rescale the image to be between 0 and 255 if needed.\n     if do_rescale is None:\n-        if np.all(0 <= image) and np.all(image <= 1):\n-            do_rescale = True\n-        elif np.allclose(image, image.astype(int)):\n+        if np.allclose(image, image.astype(int)):\n             do_rescale = False\n+        elif np.all(0 <= image) and np.all(image <= 1):\n+            do_rescale = True\n         else:\n             raise ValueError(\n                 \"The image to be converted to a PIL image contains values outside the range [0, 1], \"\n"}
{"instance_id": "huggingface__transformers-23126", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex b1fa67f458..84d3a1abbb 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -32,6 +32,13 @@ except ImportError:\n     # For Python 3.7\n     from typing_extensions import Literal\n \n+try:\n+    # For Python 3.10+, the `|` operator for types returns a types.UnionType\n+    from types import UnionType\n+except ImportError:\n+    # For Python <3.10, UnionType doesn't exist\n+    UnionType = None\n+\n \n DataClass = NewType(\"DataClass\", Any)\n DataClassType = NewType(\"DataClassType\", Any)\n@@ -159,7 +166,7 @@ class HfArgumentParser(ArgumentParser):\n             aliases = [aliases]\n \n         origin_type = getattr(field.type, \"__origin__\", field.type)\n-        if origin_type is Union:\n+        if origin_type is Union or (UnionType is not None and isinstance(field.type, UnionType)):\n             if str not in field.type.__args__ and (\n                 len(field.type.__args__) != 2 or type(None) not in field.type.__args__\n             ):\n"}
{"instance_id": "huggingface__transformers-22920", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/sam/image_processing_sam.py b/src/transformers/models/sam/image_processing_sam.py\nindex 361567f704..b86e797c01 100644\n--- a/src/transformers/models/sam/image_processing_sam.py\n+++ b/src/transformers/models/sam/image_processing_sam.py\n@@ -403,7 +403,12 @@ class SamImageProcessor(BaseImageProcessor):\n         for i, original_size in enumerate(original_sizes):\n             interpolated_mask = F.interpolate(masks[i], target_image_size, mode=\"bilinear\", align_corners=False)\n             interpolated_mask = interpolated_mask[..., : reshaped_input_sizes[i][0], : reshaped_input_sizes[i][1]]\n-            interpolated_mask = F.interpolate(interpolated_mask, original_size, mode=\"bilinear\", align_corners=False)\n+            interpolated_mask = F.interpolate(\n+                interpolated_mask,\n+                tuple(original_size.tolist()) if torch.is_tensor(original_size) else original_size,\n+                mode=\"bilinear\",\n+                align_corners=False,\n+            )\n             if binarize:\n                 interpolated_mask = interpolated_mask > mask_threshold\n             output_masks.append(interpolated_mask)\n"}
{"instance_id": "huggingface__transformers-22458", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/image_utils.py b/src/transformers/image_utils.py\nindex 08ec05fa09..e6626c4392 100644\n--- a/src/transformers/image_utils.py\n+++ b/src/transformers/image_utils.py\n@@ -132,12 +132,27 @@ def make_list_of_images(images, expected_ndims: int = 3) -> List[ImageInput]:\n \n \n def to_numpy_array(img) -> np.ndarray:\n+    \"\"\"\n+    Converts `img` to a numpy array. If the image is already a numpy array, it is returned as is.\n+    If the image is a PIL image, it is converted to a numpy array. If the image is a torch, tensorflow\n+    or jax tensor, it is converted to a numpy array.\n+\n+    For float tensors/arrays with values in [0, 1], the values are rescaled to [0, 255] to be consistent\n+    with PIL image behavior.\n+    \"\"\"\n     if not is_valid_image(img):\n         raise ValueError(f\"Invalid image type: {type(img)}\")\n \n     if is_vision_available() and isinstance(img, PIL.Image.Image):\n         return np.array(img)\n-    return to_numpy(img)\n+\n+    img = to_numpy(img)\n+\n+    # Rescale float images with values in [0, 1] to [0, 255] to be consistent with PIL image behavior\n+    if img.dtype.kind == \"f\" and np.all(0 <= img) and np.all(img <= 1):\n+        img = (img * 255).astype(np.uint8)\n+\n+    return img\n \n \n def infer_channel_dimension_format(image: np.ndarray) -> ChannelDimension:\n"}
{"instance_id": "huggingface__transformers-20136", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/owlvit/__init__.py b/src/transformers/models/owlvit/__init__.py\nindex cc528d315e..335da44545 100644\n--- a/src/transformers/models/owlvit/__init__.py\n+++ b/src/transformers/models/owlvit/__init__.py\n@@ -61,6 +61,7 @@ else:\n         \"OwlViTTextModel\",\n         \"OwlViTVisionModel\",\n         \"OwlViTForObjectDetection\",\n+        \"OwlViTImageGuidedObjectDetectionOutput\",\n     ]\n \n if TYPE_CHECKING:\n@@ -90,6 +91,7 @@ if TYPE_CHECKING:\n         from .modeling_owlvit import (\n             OWLVIT_PRETRAINED_MODEL_ARCHIVE_LIST,\n             OwlViTForObjectDetection,\n+            OwlViTImageGuidedObjectDetectionOutput,\n             OwlViTModel,\n             OwlViTPreTrainedModel,\n             OwlViTTextModel,\ndiff --git a/src/transformers/models/owlvit/modeling_owlvit.py b/src/transformers/models/owlvit/modeling_owlvit.py\nindex 684f155efd..9bfe010bb1 100644\n--- a/src/transformers/models/owlvit/modeling_owlvit.py\n+++ b/src/transformers/models/owlvit/modeling_owlvit.py\n@@ -76,6 +76,84 @@ def owlvit_loss(similarity: torch.Tensor) -> torch.Tensor:\n     return (caption_loss + image_loss) / 2.0\n \n \n+# Copied from transformers.models.detr.modeling_detr._upcast\n+def _upcast(t: torch.Tensor) -> torch.Tensor:\n+    # Protects from numerical overflows in multiplications by upcasting to the equivalent higher type\n+    if t.is_floating_point():\n+        return t if t.dtype in (torch.float32, torch.float64) else t.float()\n+    else:\n+        return t if t.dtype in (torch.int32, torch.int64) else t.int()\n+\n+\n+# Copied from transformers.models.detr.modeling_detr.box_area\n+def box_area(boxes: torch.Tensor) -> torch.Tensor:\n+    \"\"\"\n+    Computes the area of a set of bounding boxes, which are specified by its (x1, y1, x2, y2) coordinates.\n+\n+    Args:\n+        boxes (`torch.FloatTensor` of shape `(number_of_boxes, 4)`):\n+            Boxes for which the area will be computed. They are expected to be in (x1, y1, x2, y2) format with `0 <= x1\n+            < x2` and `0 <= y1 < y2`.\n+\n+    Returns:\n+        `torch.FloatTensor`: a tensor containing the area for each box.\n+    \"\"\"\n+    boxes = _upcast(boxes)\n+    return (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n+\n+\n+# Copied from transformers.models.detr.modeling_detr.box_iou\n+def box_iou(boxes1: torch.Tensor, boxes2: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n+    area1 = box_area(boxes1)\n+    area2 = box_area(boxes2)\n+\n+    left_top = torch.max(boxes1[:, None, :2], boxes2[:, :2])  # [N,M,2]\n+    right_bottom = torch.min(boxes1[:, None, 2:], boxes2[:, 2:])  # [N,M,2]\n+\n+    width_height = (right_bottom - left_top).clamp(min=0)  # [N,M,2]\n+    inter = width_height[:, :, 0] * width_height[:, :, 1]  # [N,M]\n+\n+    union = area1[:, None] + area2 - inter\n+\n+    iou = inter / union\n+    return iou, union\n+\n+\n+# Copied from transformers.models.detr.modeling_detr.generalized_box_iou\n+def generalized_box_iou(boxes1: torch.Tensor, boxes2: torch.Tensor) -> torch.Tensor:\n+    \"\"\"\n+    Generalized IoU from https://giou.stanford.edu/. The boxes should be in [x0, y0, x1, y1] (corner) format.\n+\n+    Returns:\n+        `torch.FloatTensor`: a [N, M] pairwise matrix, where N = len(boxes1) and M = len(boxes2)\n+    \"\"\"\n+    # degenerate boxes gives inf / nan results\n+    # so do an early check\n+    if not (boxes1[:, 2:] >= boxes1[:, :2]).all():\n+        raise ValueError(f\"boxes1 must be in [x0, y0, x1, y1] (corner) format, but got {boxes1}\")\n+    if not (boxes2[:, 2:] >= boxes2[:, :2]).all():\n+        raise ValueError(f\"boxes2 must be in [x0, y0, x1, y1] (corner) format, but got {boxes2}\")\n+    iou, union = box_iou(boxes1, boxes2)\n+\n+    top_left = torch.min(boxes1[:, None, :2], boxes2[:, :2])\n+    bottom_right = torch.max(boxes1[:, None, 2:], boxes2[:, 2:])\n+\n+    width_height = (bottom_right - top_left).clamp(min=0)  # [N,M,2]\n+    area = width_height[:, :, 0] * width_height[:, :, 1]\n+\n+    return iou - (area - union) / area\n+\n+\n+def center_to_corners_format(x: torch.Tensor) -> torch.Tensor:\n+    \"\"\"\n+    Converts a PyTorch tensor of bounding boxes of center format (center_x, center_y, width, height) to corners format\n+    (left, top, right, bottom).\n+    \"\"\"\n+    x_center, y_center, width, height = x.unbind(-1)\n+    boxes = [(x_center - 0.5 * width), (y_center - 0.5 * height), (x_center + 0.5 * width), (y_center + 0.5 * height)]\n+    return torch.stack(boxes, dim=-1)\n+\n+\n @dataclass\n class OwlViTOutput(ModelOutput):\n     \"\"\"\n@@ -159,6 +237,43 @@ class OwlViTObjectDetectionOutput(ModelOutput):\n     vision_model_last_hidden_state: Optional[torch.FloatTensor] = None\n \n \n+@dataclass\n+class OwlViTImageGuidedObjectDetectionOutput(ModelOutput):\n+    \"\"\"\n+    Output type of [`OwlViTForObjectDetection.image_guided_detection`].\n+\n+    Args:\n+        logits (`torch.FloatTensor` of shape `(batch_size, num_patches, num_queries)`):\n+            Classification logits (including no-object) for all queries.\n+        target_pred_boxes (`torch.FloatTensor` of shape `(batch_size, num_patches, 4)`):\n+            Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height). These\n+            values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding\n+            possible padding). You can use [`~OwlViTFeatureExtractor.post_process`] to retrieve the unnormalized\n+            bounding boxes.\n+        query_pred_boxes (`torch.FloatTensor` of shape `(batch_size, num_patches, 4)`):\n+            Normalized boxes coordinates for all queries, represented as (center_x, center_y, width, height). These\n+            values are normalized in [0, 1], relative to the size of each individual image in the batch (disregarding\n+            possible padding). You can use [`~OwlViTFeatureExtractor.post_process`] to retrieve the unnormalized\n+            bounding boxes.\n+        image_embeds (`torch.FloatTensor` of shape `(batch_size, patch_size, patch_size, output_dim`):\n+            Pooled output of [`OwlViTVisionModel`]. OWL-ViT represents images as a set of image patches and computes\n+            image embeddings for each patch.\n+        query_image_embeds (`torch.FloatTensor` of shape `(batch_size, patch_size, patch_size, output_dim`):\n+            Pooled output of [`OwlViTVisionModel`]. OWL-ViT represents images as a set of image patches and computes\n+            image embeddings for each patch.\n+        class_embeds (`torch.FloatTensor` of shape `(batch_size, num_patches, hidden_size)`):\n+            Class embeddings of all image patches. OWL-ViT represents images as a set of image patches where the total\n+            number of patches is (image_size / patch_size)**2.\n+    \"\"\"\n+\n+    logits: torch.FloatTensor = None\n+    image_embeds: torch.FloatTensor = None\n+    query_image_embeds: torch.FloatTensor = None\n+    target_pred_boxes: torch.FloatTensor = None\n+    query_pred_boxes: torch.FloatTensor = None\n+    class_embeds: torch.FloatTensor = None\n+\n+\n class OwlViTVisionEmbeddings(nn.Module):\n     def __init__(self, config: OwlViTVisionConfig):\n         super().__init__()\n@@ -1233,8 +1348,8 @@ class OwlViTForObjectDetection(OwlViTPreTrainedModel):\n     def class_predictor(\n         self,\n         image_feats: torch.FloatTensor,\n-        query_embeds: torch.FloatTensor,\n-        query_mask: torch.Tensor,\n+        query_embeds: Optional[torch.FloatTensor] = None,\n+        query_mask: Optional[torch.Tensor] = None,\n     ) -> Tuple[torch.FloatTensor]:\n         \"\"\"\n         Args:\n@@ -1294,6 +1409,231 @@ class OwlViTForObjectDetection(OwlViTPreTrainedModel):\n \n         return (text_embeds, image_embeds, text_model_last_hidden_state, vision_model_last_hidden_state)\n \n+    def image_embedder(\n+        self,\n+        pixel_values: torch.FloatTensor,\n+        output_attentions: Optional[bool] = None,\n+        output_hidden_states: Optional[bool] = None,\n+    ) -> Tuple[torch.FloatTensor]:\n+        \"\"\"\n+        Returns the image embeddings by processing the pixel values through the vision model.\n+\n+        Args:\n+            pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n+                Pixel values.\n+            output_attentions (`bool`, *optional*):\n+                Whether or not to return the attentions tensors of all attention layers.\n+            output_hidden_states (`bool`, *optional*):\n+                Whether or not to return the hidden states of all layers.\n+\n+        Returns:\n+            image_embeds (`torch.FloatTensor` of shape `(batch_size, num_patches, num_patches, hidden_size)`):\n+                Image embeddings.\n+            feature_map (`torch.FloatTensor` of shape `(batch_size, num_patches, num_patches, hidden_size)`):\n+                Spatial re-arrangement of image embeddings for computing box predictions.\n+        \"\"\"\n+        # Encode image\n+        vision_outputs = self.owlvit.vision_model(\n+            pixel_values=pixel_values,\n+            output_attentions=output_attentions,\n+            output_hidden_states=output_hidden_states,\n+            return_dict=True,\n+        )\n+\n+        # Resize class token\n+        last_hidden_state = vision_outputs[0]\n+        image_embeds = self.owlvit.vision_model.post_layernorm(last_hidden_state)\n+        new_size = tuple(np.array(image_embeds.shape) - np.array((0, 1, 0)))\n+        class_token_out = torch.broadcast_to(image_embeds[:, :1, :], new_size)\n+\n+        # Merge image embedding with class tokens\n+        image_embeds = image_embeds[:, 1:, :] * class_token_out\n+        image_embeds = self.layer_norm(image_embeds)\n+\n+        # Resize to [batch_size, num_patches, num_patches, hidden_size]\n+        new_size = (\n+            image_embeds.shape[0],\n+            int(np.sqrt(image_embeds.shape[1])),\n+            int(np.sqrt(image_embeds.shape[1])),\n+            image_embeds.shape[-1],\n+        )\n+        feature_map = image_embeds.reshape(new_size)\n+\n+        return (feature_map, vision_outputs)\n+\n+    def embed_image_query(\n+        self,\n+        query_image_features: torch.FloatTensor,\n+        query_feature_map: torch.FloatTensor,\n+    ) -> torch.FloatTensor:\n+        \"\"\"\n+        Computes query embeddings from image features for image-guided detection.\n+\n+        Args:\n+            query_image_features (`torch.FloatTensor`):\n+                Image features extracted from the query image.\n+            query_feature_map (`torch.FloatTensor`):\n+                Feature map of the query image.\n+\n+        Returns:\n+            query_embeds (`torch.FloatTensor`):\n+                Query embeddings for image-guided detection.\n+        \"\"\"\n+        # Compute class embeddings directly from the class head's dense layer\n+        class_embeds = self.class_head.dense0(query_image_features)\n+        # Normalize class embeddings\n+        class_embeds = class_embeds / (torch.linalg.norm(class_embeds, dim=-1, keepdim=True) + 1e-6)\n+\n+        pred_boxes = self.box_predictor(query_image_features, query_feature_map)\n+        pred_boxes_as_corners = center_to_corners_format(pred_boxes)\n+\n+        # Loop over query images\n+        best_class_embeds = []\n+        best_box_indices = []\n+        pred_boxes_device = pred_boxes_as_corners.device\n+\n+        for i in range(query_image_features.shape[0]):\n+            each_query_box = torch.tensor([[0, 0, 1, 1]], device=pred_boxes_device)\n+            each_query_pred_boxes = pred_boxes_as_corners[i]\n+            ious, _ = box_iou(each_query_box, each_query_pred_boxes)\n+\n+            # If there are no overlapping boxes, fall back to generalized IoU\n+            if torch.all(ious[0] == 0.0):\n+                ious = generalized_box_iou(each_query_box, each_query_pred_boxes)\n+\n+            # Use an adaptive threshold to include all boxes within 80% of the best IoU\n+            iou_threshold = torch.max(ious) * 0.8\n+\n+            selected_inds = (ious[0] >= iou_threshold).nonzero()\n+            if selected_inds.numel():\n+                selected_embeddings = class_embeds[i][selected_inds.squeeze(1)]\n+                mean_embeds = torch.mean(class_embeds[i], axis=0)\n+                mean_sim = torch.einsum(\"d,id->i\", mean_embeds, selected_embeddings)\n+                best_box_ind = selected_inds[torch.argmin(mean_sim)]\n+                best_class_embeds.append(class_embeds[i][best_box_ind])\n+                best_box_indices.append(best_box_ind)\n+\n+        if best_class_embeds:\n+            query_embeds = torch.stack(best_class_embeds)\n+            box_indices = torch.stack(best_box_indices)\n+        else:\n+            query_embeds, box_indices = None, None\n+\n+        return query_embeds, box_indices, pred_boxes\n+\n+    def image_guided_detection(\n+        self,\n+        pixel_values: torch.FloatTensor,\n+        query_pixel_values: Optional[torch.FloatTensor] = None,\n+        output_attentions: Optional[bool] = None,\n+        output_hidden_states: Optional[bool] = None,\n+        return_dict: Optional[bool] = None,\n+    ) -> OwlViTImageGuidedObjectDetectionOutput:\n+        \"\"\"\n+        Performs image-guided object detection using query images.\n+\n+        Args:\n+            pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n+                Pixel values of the target images.\n+            query_pixel_values (`torch.FloatTensor` of shape `(batch_size, num_channels, height, width)`):\n+                Pixel values of the query images.\n+            output_attentions (`bool`, *optional*):\n+                Whether or not to return the attentions tensors of all attention layers.\n+            output_hidden_states (`bool`, *optional*):\n+                Whether or not to return the hidden states of all layers.\n+            return_dict (`bool`, *optional*):\n+                Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n+\n+        Returns:\n+            [`OwlViTImageGuidedObjectDetectionOutput`] or `tuple`: Returns an\n+            [`OwlViTImageGuidedObjectDetectionOutput`] if `return_dict=True`, otherwise returns a tuple.\n+\n+        Examples:\n+        ```python\n+        >>> import requests\n+        >>> from PIL import Image\n+        >>> import torch\n+        >>> from transformers import OwlViTProcessor, OwlViTForObjectDetection\n+\n+        >>> processor = OwlViTProcessor.from_pretrained(\"google/owlvit-base-patch32\")\n+        >>> model = OwlViTForObjectDetection.from_pretrained(\"google/owlvit-base-patch32\")\n+\n+        >>> url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n+        >>> image = Image.open(requests.get(url, stream=True).raw)\n+        >>> query_url = \"http://images.cocodataset.org/val2017/000000001675.jpg\"\n+        >>> query_image = Image.open(requests.get(query_url, stream=True).raw)\n+        >>> inputs = processor(images=image, query_images=query_image, return_tensors=\"pt\")\n+        >>> with torch.no_grad():\n+        ...     outputs = model.image_guided_detection(**inputs)\n+\n+        >>> # Target image sizes (height, width) to rescale box predictions [batch_size, 2]\n+        >>> target_sizes = torch.Tensor([image.size[::-1]])\n+        >>> # Convert outputs (bounding boxes and class logits) to COCO API\n+        >>> results = processor.post_process_image_guided_detection(\n+        ...     outputs=outputs, threshold=0.6, nms_threshold=0.3, target_sizes=target_sizes\n+        ... )\n+        >>> i = 0  # Retrieve predictions for the first image\n+        >>> boxes, scores = results[i][\"boxes\"], results[i][\"scores\"]\n+        >>> for box, score in zip(boxes, scores):\n+        ...     box = [round(i, 2) for i in box.tolist()]\n+        ...     print(f\"Detected object with confidence {round(score.item(), 3)} at location {box}\")\n+        ```\n+        \"\"\"\n+        output_attentions = output_attentions if output_attentions is not None else self.config.output_attentions\n+        output_hidden_states = (\n+            output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n+        )\n+        return_dict = return_dict if return_dict is not None else self.config.return_dict\n+\n+        # Compute feature maps for target and query images\n+        query_feature_map, _ = self.image_embedder(\n+            pixel_values=query_pixel_values,\n+            output_attentions=output_attentions,\n+            output_hidden_states=output_hidden_states,\n+        )\n+        feature_map, vision_outputs = self.image_embedder(\n+            pixel_values=pixel_values,\n+            output_attentions=output_attentions,\n+            output_hidden_states=output_hidden_states,\n+        )\n+\n+        batch_size, num_patches, num_patches, hidden_dim = feature_map.shape\n+        image_feats = torch.reshape(feature_map, (batch_size, num_patches * num_patches, hidden_dim))\n+\n+        batch_size, num_patches, num_patches, hidden_dim = query_feature_map.shape\n+        query_image_feats = torch.reshape(query_feature_map, (batch_size, num_patches * num_patches, hidden_dim))\n+\n+        # Get top class embedding and best box index for each query image in batch\n+        query_embeds, best_box_indices, query_pred_boxes = self.embed_image_query(query_image_feats, query_feature_map)\n+\n+        # Predict object classes [batch_size, num_patches, num_queries+1]\n+        (pred_logits, class_embeds) = self.class_predictor(image_feats, query_embeds)\n+\n+        # Predict object boxes\n+        target_pred_boxes = self.box_predictor(image_feats, feature_map)\n+\n+        if not return_dict:\n+            output = (\n+                feature_map,\n+                query_feature_map,\n+                target_pred_boxes,\n+                query_pred_boxes,\n+                pred_logits,\n+                class_embeds,\n+                vision_outputs.to_tuple(),\n+            )\n+            output = tuple(x for x in output if x is not None)\n+            return output\n+\n+        return OwlViTImageGuidedObjectDetectionOutput(\n+            image_embeds=feature_map,\n+            query_image_embeds=query_feature_map,\n+            target_pred_boxes=target_pred_boxes,\n+            query_pred_boxes=query_pred_boxes,\n+            logits=pred_logits,\n+            class_embeds=class_embeds,\n+        )\n+\n     @add_start_docstrings_to_model_forward(OWLVIT_OBJECT_DETECTION_INPUTS_DOCSTRING)\n     @replace_return_docstrings(output_type=OwlViTObjectDetectionOutput, config_class=OwlViTConfig)\n     def forward(\ndiff --git a/src/transformers/models/owlvit/processing_owlvit.py b/src/transformers/models/owlvit/processing_owlvit.py\nindex 707fa47690..79eab5771f 100644\n--- a/src/transformers/models/owlvit/processing_owlvit.py\n+++ b/src/transformers/models/owlvit/processing_owlvit.py\n@@ -43,7 +43,7 @@ class OwlViTProcessor(ProcessorMixin):\n     def __init__(self, feature_extractor, tokenizer):\n         super().__init__(feature_extractor, tokenizer)\n \n-    def __call__(self, text=None, images=None, padding=\"max_length\", return_tensors=\"np\", **kwargs):\n+    def __call__(self, text=None, images=None, query_images=None, padding=\"max_length\", return_tensors=\"np\", **kwargs):\n         \"\"\"\n         Main method to prepare for the model one or several text(s) and image(s). This method forwards the `text` and\n         `kwargs` arguments to CLIPTokenizerFast's [`~CLIPTokenizerFast.__call__`] if `text` is not `None` to encode:\n@@ -61,6 +61,10 @@ class OwlViTProcessor(ProcessorMixin):\n                 The image or batch of images to be prepared. Each image can be a PIL image, NumPy array or PyTorch\n                 tensor. In case of a NumPy array/PyTorch tensor, each image should be of shape (C, H, W), where C is a\n                 number of channels, H and W are image height and width.\n+            query_images (`PIL.Image.Image`, `np.ndarray`, `torch.Tensor`, `List[PIL.Image.Image]`, `List[np.ndarray]`, `List[torch.Tensor]`):\n+                The query image to be prepared, one query image is expected per target image to be queried. Each image\n+                can be a PIL image, NumPy array or PyTorch tensor. In case of a NumPy array/PyTorch tensor, each image\n+                should be of shape (C, H, W), where C is a number of channels, H and W are image height and width.\n             return_tensors (`str` or [`~utils.TensorType`], *optional*):\n                 If set, will return tensors of a particular framework. Acceptable values are:\n                 - `'tf'`: Return TensorFlow `tf.constant` objects.\n@@ -76,8 +80,10 @@ class OwlViTProcessor(ProcessorMixin):\n             - **pixel_values** -- Pixel values to be fed to a model. Returned when `images` is not `None`.\n         \"\"\"\n \n-        if text is None and images is None:\n-            raise ValueError(\"You have to specify at least one text or image. Both cannot be none.\")\n+        if text is None and images is None and query_images is None:\n+            raise ValueError(\n+                \"You have to specify at least one text or query image or image. All three cannot be none.\"\n+            )\n \n         if text is not None:\n             if isinstance(text, str) or (isinstance(text, List) and not isinstance(text[0], List)):\n@@ -131,13 +137,27 @@ class OwlViTProcessor(ProcessorMixin):\n         if images is not None:\n             image_features = self.feature_extractor(images, return_tensors=return_tensors, **kwargs)\n \n+        if query_images is not None:\n+            query_image_features = self.feature_extractor(query_images, return_tensors=return_tensors, **kwargs)\n+            # Query images always override text\n+            if text is not None:\n+                encoding[\"query_pixel_values\"] = query_image_features.pixel_values\n+            else:\n+                encoding = BatchEncoding()\n+                encoding[\"query_pixel_values\"] = query_image_features.pixel_values\n+\n         if text is not None and images is not None:\n             encoding[\"pixel_values\"] = image_features.pixel_values\n             return encoding\n         elif text is not None:\n             return encoding\n-        else:\n+        elif query_images is not None and images is not None:\n+            encoding[\"pixel_values\"] = image_features.pixel_values\n+            return encoding\n+        elif images is not None:\n             return BatchEncoding(data=dict(**image_features), tensor_type=return_tensors)\n+        else:\n+            return encoding\n \n     def post_process(self, *args, **kwargs):\n         \"\"\"\n@@ -146,6 +166,76 @@ class OwlViTProcessor(ProcessorMixin):\n         \"\"\"\n         return self.feature_extractor.post_process(*args, **kwargs)\n \n+    def post_process_image_guided_detection(self, outputs, threshold=0.6, nms_threshold=0.3, target_sizes=None):\n+        \"\"\"\n+        Converts the output of [`OwlViTForObjectDetection.image_guided_detection`] into the format expected by the COCO\n+        api.\n+\n+        Args:\n+            outputs ([`OwlViTImageGuidedObjectDetectionOutput`]):\n+                Raw outputs of the model.\n+            threshold (`float`, *optional*, defaults to 0.6):\n+                Minimum confidence threshold to use to filter out predicted boxes.\n+            nms_threshold (`float`, *optional*, defaults to 0.3):\n+                IoU threshold for non-maximum suppression of overlapping boxes.\n+            target_sizes (`torch.Tensor`, *optional*):\n+                Tensor of shape (batch_size, 2) where each entry is the (height, width) of the corresponding image in\n+                the batch. If set, predicted normalized bounding boxes are rescaled to the target sizes. If left to\n+                None, predictions will not be unnormalized.\n+\n+        Returns:\n+            `List[Dict]`: A list of dictionaries, each dictionary containing the scores and bounding boxes for an image\n+            in the batch as predicted by the model. All labels are set to None as\n+            `OwlViTForObjectDetection.image_guided_detection` perform one-shot object detection.\n+        \"\"\"\n+        logits, target_boxes = outputs.logits, outputs.target_pred_boxes\n+\n+        if len(logits) != len(target_sizes):\n+            raise ValueError(\"Make sure that you pass in as many target sizes as the batch dimension of the logits\")\n+        if target_sizes.shape[1] != 2:\n+            raise ValueError(\"Each element of target_sizes must contain the size (h, w) of each image of the batch\")\n+\n+        if is_torch_available():\n+            import torch\n+\n+            from ...models.owlvit.modeling_owlvit import box_iou, center_to_corners_format\n+\n+            probs = torch.max(logits, dim=-1)\n+            scores = torch.sigmoid(probs.values)\n+\n+            # Convert to [x0, y0, x1, y1] format\n+            target_boxes = center_to_corners_format(target_boxes)\n+\n+            # Apply non-maximum suppression (NMS)\n+            if nms_threshold < 1.0:\n+                for idx in range(target_boxes.shape[0]):\n+                    for i in torch.argsort(-scores[idx]):\n+                        if not scores[idx][i]:\n+                            continue\n+\n+                        ious = box_iou(target_boxes[idx][i, :].unsqueeze(0), target_boxes[idx])[0][0]\n+                        ious[i] = -1.0  # Mask self-IoU.\n+                        scores[idx][ious > nms_threshold] = 0.0\n+\n+            # Convert from relative [0, 1] to absolute [0, height] coordinates\n+            img_h, img_w = target_sizes.unbind(1)\n+            scale_fct = torch.stack([img_w, img_h, img_w, img_h], dim=1).to(target_boxes.device)\n+            target_boxes = target_boxes * scale_fct[:, None, :]\n+\n+            # Compute box display alphas based on prediction scores\n+            results = []\n+            for idx in range(target_boxes.shape[0]):\n+                # Filter out low-confidence predictions\n+                score_mask = scores[idx] > threshold\n+                filtered_scores = scores[idx][score_mask]\n+                filtered_boxes = target_boxes[idx][score_mask]\n+\n+                results.append({\"scores\": filtered_scores, \"labels\": None, \"boxes\": filtered_boxes})\n+\n+            return results\n+        else:\n+            raise NotImplementedError(\"post_process_image_guided_detection requires PyTorch.\")\n+\n     def batch_decode(self, *args, **kwargs):\n         \"\"\"\n         This method forwards all its arguments to CLIPTokenizerFast's [`~PreTrainedTokenizer.batch_decode`]. Please\n"}
{"instance_id": "huggingface__transformers-21969", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex 0ae19c43c7..3cb748f3d3 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -156,7 +156,7 @@ def to_pil_image(\n     image = np.squeeze(image, axis=-1) if image.shape[-1] == 1 else image\n \n     # PIL.Image can only store uint8 values, so we rescale the image to be between 0 and 255 if needed.\n-    do_rescale = isinstance(image.flat[0], (float, np.float32, np.float64)) if do_rescale is None else do_rescale\n+    do_rescale = isinstance(image.flat[0], np.floating) if do_rescale is None else do_rescale\n     if do_rescale:\n         image = rescale(image, 255)\n     image = image.astype(np.uint8)\n"}
{"instance_id": "huggingface__transformers-22649", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/opt/modeling_opt.py b/src/transformers/models/opt/modeling_opt.py\nindex f9eac7d915..103560db2a 100644\n--- a/src/transformers/models/opt/modeling_opt.py\n+++ b/src/transformers/models/opt/modeling_opt.py\n@@ -638,7 +638,11 @@ class OPTDecoder(OPTPreTrainedModel):\n \n         # embed positions\n         if attention_mask is None:\n-            attention_mask = torch.ones(inputs_embeds.shape[:2], dtype=torch.bool, device=inputs_embeds.device)\n+            attention_mask = torch.ones(\n+                (inputs_embeds.shape[0], inputs_embeds.shape[1] + past_key_values_length),\n+                dtype=torch.bool,\n+                device=inputs_embeds.device,\n+            )\n         pos_embeds = self.embed_positions(attention_mask, past_key_values_length)\n \n         attention_mask = self._prepare_decoder_attention_mask(\ndiff --git a/src/transformers/models/opt/modeling_tf_opt.py b/src/transformers/models/opt/modeling_tf_opt.py\nindex cd34130228..6c1ca3e003 100644\n--- a/src/transformers/models/opt/modeling_tf_opt.py\n+++ b/src/transformers/models/opt/modeling_tf_opt.py\n@@ -644,7 +644,10 @@ class TFOPTDecoder(tf.keras.layers.Layer):\n             inputs_embeds = self.embed_tokens(input_ids)\n \n         if attention_mask is None:\n-            attention_mask = tf.ones(inputs_embeds.shape[:2], dtype=tf.bool)\n+            attention_mask = tf.ones(\n+                (shape_list(inputs_embeds)[0], shape_list(inputs_embeds)[1] + past_key_values_length),\n+                dtype=tf.bool,\n+            )\n \n         pos_embeds = self.embed_positions(attention_mask, past_key_values_length)\n \n"}
{"instance_id": "huggingface__transformers-23796", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/whisper/tokenization_whisper.py b/src/transformers/models/whisper/tokenization_whisper.py\nindex 4c7c9c89fd..428254a26a 100644\n--- a/src/transformers/models/whisper/tokenization_whisper.py\n+++ b/src/transformers/models/whisper/tokenization_whisper.py\n@@ -721,7 +721,7 @@ class WhisperTokenizer(PreTrainedTokenizer):\n \n     def get_prompt_ids(self, text: str, return_tensors=\"np\"):\n         \"\"\"Converts prompt text to IDs that can be passed to [`~WhisperForConditionalGeneration.generate`].\"\"\"\n-        batch_encoding = self(\"<|startofprev|>\", text.strip(), add_prefix_space=True, add_special_tokens=False)\n+        batch_encoding = self(\"<|startofprev|>\", \" \" + text.strip(), add_special_tokens=False)\n \n         # Check for special tokens\n         prompt_text_ids = batch_encoding[\"input_ids\"][1:]\ndiff --git a/src/transformers/models/whisper/tokenization_whisper_fast.py b/src/transformers/models/whisper/tokenization_whisper_fast.py\nindex be4ad842a7..a31fe00056 100644\n--- a/src/transformers/models/whisper/tokenization_whisper_fast.py\n+++ b/src/transformers/models/whisper/tokenization_whisper_fast.py\n@@ -494,7 +494,7 @@ class WhisperTokenizerFast(PreTrainedTokenizerFast):\n     # Copied from transformers.models.whisper.tokenization_whisper.WhisperTokenizer.get_prompt_ids\n     def get_prompt_ids(self, text: str, return_tensors=\"np\"):\n         \"\"\"Converts prompt text to IDs that can be passed to [`~WhisperForConditionalGeneration.generate`].\"\"\"\n-        batch_encoding = self(\"<|startofprev|>\", text.strip(), add_prefix_space=True, add_special_tokens=False)\n+        batch_encoding = self(\"<|startofprev|>\", \" \" + text.strip(), add_special_tokens=False)\n \n         # Check for special tokens\n         prompt_text_ids = batch_encoding[\"input_ids\"][1:]\n"}
{"instance_id": "huggingface__transformers-24238", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/generation/configuration_utils.py b/src/transformers/generation/configuration_utils.py\nindex 9f3bedcdeb..d1a19d2954 100644\n--- a/src/transformers/generation/configuration_utils.py\n+++ b/src/transformers/generation/configuration_utils.py\n@@ -570,6 +570,7 @@ class GenerationConfig(PushToHubMixin):\n             kwargs[\"_commit_hash\"] = config_dict[\"_commit_hash\"]\n \n         # remove all the arguments that are in the config_dict\n+        config_dict = {key: value for key, value in config_dict.items() if key not in kwargs}\n \n         config = cls(**config_dict, **kwargs)\n         unused_kwargs = config.update(**kwargs)\n"}
{"instance_id": "huggingface__transformers-23223", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py b/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\nindex 9550b7c2a9..1b725118bb 100644\n--- a/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\n+++ b/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\n@@ -181,10 +181,16 @@ class Wav2Vec2FeatureExtractor(SequenceFeatureExtractor):\n                 \"Failing to do so can result in silent errors that might be hard to debug.\"\n             )\n \n-        is_batched = bool(\n-            isinstance(raw_speech, (list, tuple))\n-            and (isinstance(raw_speech[0], np.ndarray) or isinstance(raw_speech[0], (tuple, list)))\n-        )\n+        is_batched_numpy = isinstance(raw_speech, np.ndarray) and len(raw_speech.shape) > 1\n+        if not is_batched_numpy:\n+            is_batched = bool(\n+                isinstance(raw_speech, (list, tuple)) and (isinstance(raw_speech[0], (np.ndarray, tuple, list)))\n+            )\n+        else:\n+            is_batched = True\n+\n+        if is_batched_numpy:\n+            raw_speech = [raw_speech[i] for i in range(len(raw_speech))]\n \n         # always return batch\n         if not is_batched:\n"}
{"instance_id": "huggingface__transformers-23141", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/whisper/modeling_whisper.py b/src/transformers/models/whisper/modeling_whisper.py\nindex ed845febac..f65284c833 100644\n--- a/src/transformers/models/whisper/modeling_whisper.py\n+++ b/src/transformers/models/whisper/modeling_whisper.py\n@@ -1573,10 +1573,13 @@ class WhisperForConditionalGeneration(WhisperPreTrainedModel):\n                     language_token = generation_config.language\n                 elif generation_config.language in TO_LANGUAGE_CODE.keys():\n                     language_token = f\"<|{TO_LANGUAGE_CODE[generation_config.language]}|>\"\n+                elif generation_config.language in TO_LANGUAGE_CODE.values():\n+                    language_token = f\"<|{generation_config.language}|>\"\n                 else:\n+                    is_language_code = len(generation_config.language) == 2\n                     raise ValueError(\n-                        f\"Unsupported language: {self.language}. Language should be one of:\"\n-                        f\" {list(TO_LANGUAGE_CODE.keys()) if generation_config.language in TO_LANGUAGE_CODE.keys() else list(TO_LANGUAGE_CODE.values())}.\"\n+                        f\"Unsupported language: {generation_config.language}. Language should be one of:\"\n+                        f\" {list(TO_LANGUAGE_CODE.values()) if is_language_code else list(TO_LANGUAGE_CODE.keys())}.\"\n                     )\n                 forced_decoder_ids.append((1, generation_config.lang_to_id[language_token]))\n             else:\n"}
{"instance_id": "huggingface__transformers-25636", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/bart/modeling_flax_bart.py b/src/transformers/models/bart/modeling_flax_bart.py\nindex 9858eb2d1b..f9bafcbd77 100644\n--- a/src/transformers/models/bart/modeling_flax_bart.py\n+++ b/src/transformers/models/bart/modeling_flax_bart.py\n@@ -1482,7 +1482,7 @@ class FlaxBartForConditionalGeneration(FlaxBartPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \n@@ -1971,7 +1971,7 @@ class FlaxBartForCausalLM(FlaxBartDecoderPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/bert/modeling_flax_bert.py b/src/transformers/models/bert/modeling_flax_bert.py\nindex 99dfa2a0e2..5cff909795 100644\n--- a/src/transformers/models/bert/modeling_flax_bert.py\n+++ b/src/transformers/models/bert/modeling_flax_bert.py\n@@ -1688,7 +1688,7 @@ class FlaxBertForCausalLM(FlaxBertPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/big_bird/modeling_flax_big_bird.py b/src/transformers/models/big_bird/modeling_flax_big_bird.py\nindex afdac2645f..bf73e5a181 100644\n--- a/src/transformers/models/big_bird/modeling_flax_big_bird.py\n+++ b/src/transformers/models/big_bird/modeling_flax_big_bird.py\n@@ -2610,7 +2610,7 @@ class FlaxBigBirdForCausalLM(FlaxBigBirdPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/blenderbot/modeling_flax_blenderbot.py b/src/transformers/models/blenderbot/modeling_flax_blenderbot.py\nindex 1035272fd0..ad5263ad7a 100644\n--- a/src/transformers/models/blenderbot/modeling_flax_blenderbot.py\n+++ b/src/transformers/models/blenderbot/modeling_flax_blenderbot.py\n@@ -1458,7 +1458,7 @@ class FlaxBlenderbotForConditionalGeneration(FlaxBlenderbotPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py b/src/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py\nindex 2bf8b59e27..3d470929a4 100644\n--- a/src/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py\n+++ b/src/transformers/models/blenderbot_small/modeling_flax_blenderbot_small.py\n@@ -1456,7 +1456,7 @@ class FlaxBlenderbotSmallForConditionalGeneration(FlaxBlenderbotSmallPreTrainedM\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/bloom/modeling_flax_bloom.py b/src/transformers/models/bloom/modeling_flax_bloom.py\nindex 187230f35a..57c8aa275c 100644\n--- a/src/transformers/models/bloom/modeling_flax_bloom.py\n+++ b/src/transformers/models/bloom/modeling_flax_bloom.py\n@@ -719,7 +719,7 @@ class FlaxBloomForCausalLM(FlaxBloomPreTrainedModel):\n         # which is more efficient for compilation\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n \n         return {\n             \"past_key_values\": past_key_values,\ndiff --git a/src/transformers/models/electra/modeling_flax_electra.py b/src/transformers/models/electra/modeling_flax_electra.py\nindex 32e76b8b58..0efbb04aff 100644\n--- a/src/transformers/models/electra/modeling_flax_electra.py\n+++ b/src/transformers/models/electra/modeling_flax_electra.py\n@@ -1576,7 +1576,7 @@ class FlaxElectraForCausalLM(FlaxElectraPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py b/src/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py\nindex 3d9679f26a..e6dfbe0935 100644\n--- a/src/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py\n+++ b/src/transformers/models/encoder_decoder/modeling_flax_encoder_decoder.py\n@@ -737,7 +737,7 @@ class FlaxEncoderDecoderModel(FlaxPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             decoder_position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             decoder_position_ids = jnp.broadcast_to(\n                 jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length)\ndiff --git a/src/transformers/models/gpt2/modeling_flax_gpt2.py b/src/transformers/models/gpt2/modeling_flax_gpt2.py\nindex 8973e081a3..0a5742c49c 100644\n--- a/src/transformers/models/gpt2/modeling_flax_gpt2.py\n+++ b/src/transformers/models/gpt2/modeling_flax_gpt2.py\n@@ -753,7 +753,7 @@ class FlaxGPT2LMHeadModel(FlaxGPT2PreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py b/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py\nindex 5639ca50f1..81a09db916 100644\n--- a/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py\n+++ b/src/transformers/models/gpt_neo/modeling_flax_gpt_neo.py\n@@ -665,7 +665,7 @@ class FlaxGPTNeoForCausalLM(FlaxGPTNeoPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/gptj/modeling_flax_gptj.py b/src/transformers/models/gptj/modeling_flax_gptj.py\nindex 9f0d4d6e86..c941c25572 100644\n--- a/src/transformers/models/gptj/modeling_flax_gptj.py\n+++ b/src/transformers/models/gptj/modeling_flax_gptj.py\n@@ -694,7 +694,7 @@ class FlaxGPTJForCausalLM(FlaxGPTJPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/marian/modeling_flax_marian.py b/src/transformers/models/marian/modeling_flax_marian.py\nindex a713fdb05d..56edc9ff13 100644\n--- a/src/transformers/models/marian/modeling_flax_marian.py\n+++ b/src/transformers/models/marian/modeling_flax_marian.py\n@@ -1451,7 +1451,7 @@ class FlaxMarianMTModel(FlaxMarianPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/mbart/modeling_flax_mbart.py b/src/transformers/models/mbart/modeling_flax_mbart.py\nindex 907fd53aa1..eb6a4d847f 100644\n--- a/src/transformers/models/mbart/modeling_flax_mbart.py\n+++ b/src/transformers/models/mbart/modeling_flax_mbart.py\n@@ -1517,7 +1517,7 @@ class FlaxMBartForConditionalGeneration(FlaxMBartPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/opt/modeling_flax_opt.py b/src/transformers/models/opt/modeling_flax_opt.py\nindex 5d9839f120..8751f6984a 100644\n--- a/src/transformers/models/opt/modeling_flax_opt.py\n+++ b/src/transformers/models/opt/modeling_flax_opt.py\n@@ -775,7 +775,7 @@ class FlaxOPTForCausalLM(FlaxOPTPreTrainedModel):\n \n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/pegasus/modeling_flax_pegasus.py b/src/transformers/models/pegasus/modeling_flax_pegasus.py\nindex c5189746b1..cba49788c0 100644\n--- a/src/transformers/models/pegasus/modeling_flax_pegasus.py\n+++ b/src/transformers/models/pegasus/modeling_flax_pegasus.py\n@@ -1465,7 +1465,7 @@ class FlaxPegasusForConditionalGeneration(FlaxPegasusPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/roberta/modeling_flax_roberta.py b/src/transformers/models/roberta/modeling_flax_roberta.py\nindex 845fcea442..5656e88682 100644\n--- a/src/transformers/models/roberta/modeling_flax_roberta.py\n+++ b/src/transformers/models/roberta/modeling_flax_roberta.py\n@@ -1463,7 +1463,7 @@ class FlaxRobertaForCausalLM(FlaxRobertaPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py b/src/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py\nindex b7c347693d..bc4a6f2c7b 100644\n--- a/src/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py\n+++ b/src/transformers/models/roberta_prelayernorm/modeling_flax_roberta_prelayernorm.py\n@@ -1489,7 +1489,7 @@ class FlaxRobertaPreLayerNormForCausalLM(FlaxRobertaPreLayerNormPreTrainedModel)\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py b/src/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py\nindex b9975510ab..b6cbf18b2f 100644\n--- a/src/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py\n+++ b/src/transformers/models/speech_encoder_decoder/modeling_flax_speech_encoder_decoder.py\n@@ -760,7 +760,7 @@ class FlaxSpeechEncoderDecoderModel(FlaxPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             decoder_position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             decoder_position_ids = jnp.broadcast_to(\n                 jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length)\ndiff --git a/src/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py b/src/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py\nindex 3d914c9658..e2e24d89c4 100644\n--- a/src/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py\n+++ b/src/transformers/models/vision_encoder_decoder/modeling_flax_vision_encoder_decoder.py\n@@ -702,7 +702,7 @@ class FlaxVisionEncoderDecoderModel(FlaxPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             decoder_position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             decoder_position_ids = jnp.broadcast_to(\n                 jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length)\ndiff --git a/src/transformers/models/whisper/modeling_flax_whisper.py b/src/transformers/models/whisper/modeling_flax_whisper.py\nindex 0f158fb602..4d2291e710 100644\n--- a/src/transformers/models/whisper/modeling_flax_whisper.py\n+++ b/src/transformers/models/whisper/modeling_flax_whisper.py\n@@ -1463,7 +1463,7 @@ class FlaxWhisperForConditionalGeneration(FlaxWhisperPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             position_ids = decoder_attention_mask.cumsum(-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/xglm/modeling_flax_xglm.py b/src/transformers/models/xglm/modeling_flax_xglm.py\nindex d6b90a7f00..0d992a10f9 100644\n--- a/src/transformers/models/xglm/modeling_flax_xglm.py\n+++ b/src/transformers/models/xglm/modeling_flax_xglm.py\n@@ -777,7 +777,7 @@ class FlaxXGLMForCausalLM(FlaxXGLMPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/src/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py b/src/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py\nindex f6f39ee93b..f119a7642a 100644\n--- a/src/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py\n+++ b/src/transformers/models/xlm_roberta/modeling_flax_xlm_roberta.py\n@@ -1480,7 +1480,7 @@ class FlaxXLMRobertaForCausalLM(FlaxXLMRobertaPreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \ndiff --git a/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_flax_{{cookiecutter.lowercase_modelname}}.py b/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_flax_{{cookiecutter.lowercase_modelname}}.py\nindex 83263a6a47..6800af3e7e 100644\n--- a/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_flax_{{cookiecutter.lowercase_modelname}}.py\n+++ b/templates/adding_a_new_model/cookiecutter-template-{{cookiecutter.modelname}}/modeling_flax_{{cookiecutter.lowercase_modelname}}.py\n@@ -1480,7 +1480,7 @@ class Flax{{cookiecutter.camelcase_modelname}}ForCausalLM(Flax{{cookiecutter.cam\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \n@@ -2984,7 +2984,7 @@ class Flax{{cookiecutter.camelcase_modelname}}ForConditionalGeneration(Flax{{coo\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if decoder_attention_mask is not None:\n             position_ids = decoder_attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, decoder_attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \n"}
{"instance_id": "huggingface__transformers-25884", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/pipelines/base.py b/src/transformers/pipelines/base.py\nindex 153e8e9f6b..f1af0f865b 100644\n--- a/src/transformers/pipelines/base.py\n+++ b/src/transformers/pipelines/base.py\n@@ -872,6 +872,9 @@ class Pipeline(_ScikitCompat):\n         if self.feature_extractor is not None:\n             self.feature_extractor.save_pretrained(save_directory)\n \n+        if self.image_processor is not None:\n+            self.image_processor.save_pretrained(save_directory)\n+\n         if self.modelcard is not None:\n             self.modelcard.save_pretrained(save_directory)\n \ndiff --git a/src/transformers/utils/hub.py b/src/transformers/utils/hub.py\nindex b900311003..a476c5a7e7 100644\n--- a/src/transformers/utils/hub.py\n+++ b/src/transformers/utils/hub.py\n@@ -398,8 +398,7 @@ def cached_file(\n         if not os.path.isfile(resolved_file):\n             if _raise_exceptions_for_missing_entries:\n                 raise EnvironmentError(\n-                    f\"{path_or_repo_id} does not appear to have a file named {full_filename}. Checkout \"\n-                    f\"'https://huggingface.co/{path_or_repo_id}/{revision}' for available files.\"\n+                    f\"{path_or_repo_id} does not appear to have a file named {full_filename}.\"\n                 )\n             else:\n                 return None\n"}
{"instance_id": "huggingface__transformers-26164", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/whisper/modeling_whisper.py b/src/transformers/models/whisper/modeling_whisper.py\nindex 926101156d..f79950c25a 100644\n--- a/src/transformers/models/whisper/modeling_whisper.py\n+++ b/src/transformers/models/whisper/modeling_whisper.py\n@@ -1719,14 +1719,10 @@ class WhisperForConditionalGeneration(WhisperPreTrainedModel):\n             decoder_start_token_id, *text_prompt_ids = prompt_ids\n             # Slicing the text prompt ids in a manner consistent with the OpenAI implementation\n             # to accomodate context space for the prefix (see https://github.com/openai/whisper/blob/c09a7ae299c4c34c5839a76380ae407e7d785914/whisper/decoding.py#L599)\n-            text_prompt_ids = text_prompt_ids[-self.config.max_length // 2 - 1 :]\n+            text_prompt_ids = text_prompt_ids[-(self.config.max_length // 2 - 1) :]\n             # Set the decoder_start_token_id to <|startofprev|>\n             kwargs.update({\"decoder_start_token_id\": decoder_start_token_id})\n \n-            # If the user passes `max_new_tokens`, increase its number to account for the prompt\n-            if kwargs.get(\"max_new_tokens\", None) is not None:\n-                kwargs[\"max_new_tokens\"] += len(text_prompt_ids)\n-\n             # Reformat the forced_decoder_ids to incorporate the prompt\n             non_prompt_forced_decoder_ids = (\n                 kwargs.pop(\"forced_decoder_ids\", None) or generation_config.forced_decoder_ids\n@@ -1739,6 +1735,25 @@ class WhisperForConditionalGeneration(WhisperPreTrainedModel):\n             forced_decoder_ids = [(rank + 1, token) for rank, token in enumerate(forced_decoder_ids)]\n             generation_config.forced_decoder_ids = forced_decoder_ids\n \n+            # If the user passes `max_new_tokens`, increase its number to account for the prompt\n+            if kwargs.get(\"max_new_tokens\", None) is not None:\n+                user_max_new_tokens = kwargs[\"max_new_tokens\"]\n+                max_new_tokens = user_max_new_tokens + len(text_prompt_ids)\n+                # Ensure max_new_tokens does not exceed the model's max_length\n+                # The total length is: 1 (decoder_start_token_id) + len(forced_decoder_ids) + new_tokens\n+                # We need: 1 + len(forced_decoder_ids) + new_tokens <= max_length\n+                # So: max_new_tokens <= max_length - 1 - len(forced_decoder_ids)\n+                max_allowed_new_tokens = self.config.max_length - 1 - len(forced_decoder_ids)\n+                if max_new_tokens > max_allowed_new_tokens:\n+                    max_new_tokens = max_allowed_new_tokens\n+                    effective_user_max_new_tokens = max(0, max_new_tokens - len(text_prompt_ids))\n+                    logger.warning_once(\n+                        f\"The length of `prompt_ids` plus `max_new_tokens` exceeds the maximum allowed length. \"\n+                        f\"Reducing `max_new_tokens` from {user_max_new_tokens} to {effective_user_max_new_tokens} to fit within \"\n+                        f\"`max_length` ({self.config.max_length}).\"\n+                    )\n+                kwargs[\"max_new_tokens\"] = max_new_tokens\n+\n         if generation_config.return_timestamps:\n             logits_processor = [WhisperTimeStampLogitsProcessor(generation_config)]\n \n"}
{"instance_id": "huggingface__transformers-26752", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py b/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py\nindex 3548e48c59..099b6d31e9 100644\n--- a/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py\n+++ b/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py\n@@ -620,6 +620,9 @@ class EncoderDecoderModel(PreTrainedModel):\n             decoder_input_ids = shift_tokens_right(\n                 labels, self.config.pad_token_id, self.config.decoder_start_token_id\n             )\n+            if decoder_attention_mask is None:\n+                decoder_attention_mask = decoder_input_ids.new_ones(decoder_input_ids.shape, dtype=torch.long)\n+                decoder_attention_mask[decoder_input_ids == self.config.pad_token_id] = 0\n \n         # Decode\n         decoder_outputs = self.decoder(\ndiff --git a/src/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py b/src/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py\nindex 19fc47546b..f20c1a1f96 100644\n--- a/src/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py\n+++ b/src/transformers/models/encoder_decoder/modeling_tf_encoder_decoder.py\n@@ -575,6 +575,10 @@ class TFEncoderDecoderModel(TFPreTrainedModel, TFCausalLanguageModelingLoss):\n             decoder_input_ids = shift_tokens_right(\n                 labels, self.config.pad_token_id, self.config.decoder_start_token_id\n             )\n+            if decoder_attention_mask is None:\n+                decoder_attention_mask = tf.cast(\n+                    tf.math.not_equal(decoder_input_ids, self.config.pad_token_id), dtype=decoder_input_ids.dtype\n+                )\n \n         decoder_inputs = {\n             \"input_ids\": decoder_input_ids,\n"}
{"instance_id": "huggingface__transformers-26568", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/swin2sr/configuration_swin2sr.py b/src/transformers/models/swin2sr/configuration_swin2sr.py\nindex c65274e0ae..9962d72ff4 100644\n--- a/src/transformers/models/swin2sr/configuration_swin2sr.py\n+++ b/src/transformers/models/swin2sr/configuration_swin2sr.py\n@@ -44,6 +44,8 @@ class Swin2SRConfig(PretrainedConfig):\n             The size (resolution) of each patch.\n         num_channels (`int`, *optional*, defaults to 3):\n             The number of input channels.\n+        num_output_channels (`int`, *optional*):\n+            The number of output channels. If not set, it will be set to `num_channels`.\n         embed_dim (`int`, *optional*, defaults to 180):\n             Dimensionality of patch embedding.\n         depths (`list(int)`, *optional*, defaults to `[6, 6, 6, 6, 6, 6]`):\n@@ -108,6 +110,7 @@ class Swin2SRConfig(PretrainedConfig):\n         image_size=64,\n         patch_size=1,\n         num_channels=3,\n+        num_output_channels=None,\n         embed_dim=180,\n         depths=[6, 6, 6, 6, 6, 6],\n         num_heads=[6, 6, 6, 6, 6, 6],\n@@ -132,6 +135,7 @@ class Swin2SRConfig(PretrainedConfig):\n         self.image_size = image_size\n         self.patch_size = patch_size\n         self.num_channels = num_channels\n+        self.num_output_channels = num_output_channels if num_output_channels is not None else num_channels\n         self.embed_dim = embed_dim\n         self.depths = depths\n         self.num_layers = len(depths)\ndiff --git a/src/transformers/models/swin2sr/modeling_swin2sr.py b/src/transformers/models/swin2sr/modeling_swin2sr.py\nindex 72de9ac1cb..41bea7c036 100644\n--- a/src/transformers/models/swin2sr/modeling_swin2sr.py\n+++ b/src/transformers/models/swin2sr/modeling_swin2sr.py\n@@ -1026,7 +1026,7 @@ class PixelShuffleUpsampler(nn.Module):\n         self.conv_before_upsample = nn.Conv2d(config.embed_dim, num_features, 3, 1, 1)\n         self.activation = nn.LeakyReLU(inplace=True)\n         self.upsample = Upsample(config.upscale, num_features)\n-        self.final_convolution = nn.Conv2d(num_features, config.num_channels, 3, 1, 1)\n+        self.final_convolution = nn.Conv2d(num_features, config.num_output_channels, 3, 1, 1)\n \n     def forward(self, sequence_output):\n         x = self.conv_before_upsample(sequence_output)\n@@ -1048,7 +1048,7 @@ class NearestConvUpsampler(nn.Module):\n         self.conv_up1 = nn.Conv2d(num_features, num_features, 3, 1, 1)\n         self.conv_up2 = nn.Conv2d(num_features, num_features, 3, 1, 1)\n         self.conv_hr = nn.Conv2d(num_features, num_features, 3, 1, 1)\n-        self.final_convolution = nn.Conv2d(num_features, config.num_channels, 3, 1, 1)\n+        self.final_convolution = nn.Conv2d(num_features, config.num_output_channels, 3, 1, 1)\n         self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n \n     def forward(self, sequence_output):\n@@ -1072,10 +1072,10 @@ class PixelShuffleAuxUpsampler(nn.Module):\n         self.conv_bicubic = nn.Conv2d(config.num_channels, num_features, 3, 1, 1)\n         self.conv_before_upsample = nn.Conv2d(config.embed_dim, num_features, 3, 1, 1)\n         self.activation = nn.LeakyReLU(inplace=True)\n-        self.conv_aux = nn.Conv2d(num_features, config.num_channels, 3, 1, 1)\n-        self.conv_after_aux = nn.Sequential(nn.Conv2d(3, num_features, 3, 1, 1), nn.LeakyReLU(inplace=True))\n+        self.conv_aux = nn.Conv2d(num_features, config.num_output_channels, 3, 1, 1)\n+        self.conv_after_aux = nn.Sequential(nn.Conv2d(config.num_output_channels, num_features, 3, 1, 1), nn.LeakyReLU(inplace=True))\n         self.upsample = Upsample(config.upscale, num_features)\n-        self.final_convolution = nn.Conv2d(num_features, config.num_channels, 3, 1, 1)\n+        self.final_convolution = nn.Conv2d(num_features, config.num_output_channels, 3, 1, 1)\n \n     def forward(self, sequence_output, bicubic, height, width):\n         bicubic = self.conv_bicubic(bicubic)\n@@ -1114,13 +1114,13 @@ class Swin2SRForImageSuperResolution(Swin2SRPreTrainedModel):\n             self.upsample = PixelShuffleAuxUpsampler(config, num_features)\n         elif self.upsampler == \"pixelshuffledirect\":\n             # for lightweight SR (to save parameters)\n-            self.upsample = UpsampleOneStep(config.upscale, config.embed_dim, config.num_channels)\n+            self.upsample = UpsampleOneStep(config.upscale, config.embed_dim, config.num_output_channels)\n         elif self.upsampler == \"nearest+conv\":\n             # for real-world SR (less artifacts)\n             self.upsample = NearestConvUpsampler(config, num_features)\n         else:\n             # for image denoising and JPEG compression artifact reduction\n-            self.final_convolution = nn.Conv2d(config.embed_dim, config.num_channels, 3, 1, 1)\n+            self.final_convolution = nn.Conv2d(config.embed_dim, config.num_output_channels, 3, 1, 1)\n \n         # Initialize weights and apply final processing\n         self.post_init()\n@@ -1193,7 +1193,10 @@ class Swin2SRForImageSuperResolution(Swin2SRPreTrainedModel):\n             reconstruction, aux = self.upsample(sequence_output, bicubic, height, width)\n             aux = aux / self.swin2sr.img_range + self.swin2sr.mean\n         else:\n-            reconstruction = pixel_values + self.final_convolution(sequence_output)\n+            reconstruction = self.final_convolution(sequence_output)\n+            # Add residual only when input and output channels match\n+            if self.config.num_channels == self.config.num_output_channels:\n+                reconstruction = pixel_values + reconstruction\n \n         reconstruction = reconstruction / self.swin2sr.img_range + self.swin2sr.mean\n         reconstruction = reconstruction[:, :, : height * self.upscale, : width * self.upscale]\n"}
{"instance_id": "huggingface__transformers-26839", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/idefics/modeling_idefics.py b/src/transformers/models/idefics/modeling_idefics.py\nindex 28841903a1..3e4e198a70 100644\n--- a/src/transformers/models/idefics/modeling_idefics.py\n+++ b/src/transformers/models/idefics/modeling_idefics.py\n@@ -917,6 +917,18 @@ class IdeficsGatedCrossAttentionLayer(nn.Module):\n         hidden_states = nn.functional.dropout(hidden_states, p=self.config, training=self.training)\n         # when there are no images the model is used in pure language mode\n         gate = 0 if no_images else 1\n+        # zero out the cross attention output for tokens attending to no images\n+        # this is needed to prevent tokens that should not be able to attend to any image\n+        # (because they appear before any image in the sequence) from attending to all images\n+        # with equal (non-zero) weights\n+        if image_attention_mask is not None:\n+            # image_attention_mask shape: (batch, 1, tgt_len, src_len)\n+            # check if all values along src_len dimension are masked (i.e., equal to the min value)\n+            # if so, the cross attention output should be zeroed out for that position\n+            cross_attn_gate = (image_attention_mask.max(dim=-1).values > torch.finfo(hidden_states.dtype).min / 2)\n+            # cross_attn_gate shape: (batch, 1, tgt_len) -> (batch, tgt_len, 1)\n+            cross_attn_gate = cross_attn_gate.transpose(1, 2).to(hidden_states.dtype)\n+            hidden_states = hidden_states * cross_attn_gate\n         hidden_states = residual + gate * self.act_cross_attn(self.alpha_cross_attn) * hidden_states\n \n         # Fully Connected\n"}
{"instance_id": "huggingface__transformers-27463", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/sam/image_processing_sam.py b/src/transformers/models/sam/image_processing_sam.py\nindex a5c5c1e5fb..87453574fd 100644\n--- a/src/transformers/models/sam/image_processing_sam.py\n+++ b/src/transformers/models/sam/image_processing_sam.py\n@@ -73,6 +73,10 @@ class SamImageProcessor(BaseImageProcessor):\n             Size of the output image after resizing. Resizes the longest edge of the image to match\n             `size[\"longest_edge\"]` while maintaining the aspect ratio. Can be overridden by the `size` parameter in the\n             `preprocess` method.\n+        mask_size (`dict`, *optional*, defaults to `{\"longest_edge\": 256}`):\n+            Size of the output segmentation map after resizing. Resizes the longest edge of the image to match\n+            `size[\"longest_edge\"]` while maintaining the aspect ratio. Can be overridden by the `mask_size` parameter\n+            in the `preprocess` method.\n         resample (`PILImageResampling`, *optional*, defaults to `Resampling.BILINEAR`):\n             Resampling filter to use if resizing the image. Can be overridden by the `resample` parameter in the\n             `preprocess` method.\n@@ -99,6 +103,9 @@ class SamImageProcessor(BaseImageProcessor):\n         pad_size (`dict`, *optional*, defaults to `{\"height\": 1024, \"width\": 1024}`):\n             Size of the output image after padding. Can be overridden by the `pad_size` parameter in the `preprocess`\n             method.\n+        mask_pad_size (`dict`, *optional*, defaults to `{\"height\": 256, \"width\": 256}`):\n+            Size of the output segmentation map after padding. Can be overridden by the `mask_pad_size` parameter in\n+            the `preprocess` method.\n         do_convert_rgb (`bool`, *optional*, defaults to `True`):\n             Whether to convert the image to RGB.\n     \"\"\"\n@@ -109,6 +116,7 @@ class SamImageProcessor(BaseImageProcessor):\n         self,\n         do_resize: bool = True,\n         size: Dict[str, int] = None,\n+        mask_size: Dict[str, int] = None,\n         resample: PILImageResampling = PILImageResampling.BILINEAR,\n         do_rescale: bool = True,\n         rescale_factor: Union[int, float] = 1 / 255,\n@@ -117,6 +125,7 @@ class SamImageProcessor(BaseImageProcessor):\n         image_std: Optional[Union[float, List[float]]] = None,\n         do_pad: bool = True,\n         pad_size: int = None,\n+        mask_pad_size: Dict[str, int] = None,\n         do_convert_rgb: bool = True,\n         **kwargs,\n     ) -> None:\n@@ -127,8 +136,15 @@ class SamImageProcessor(BaseImageProcessor):\n         pad_size = pad_size if pad_size is not None else {\"height\": 1024, \"width\": 1024}\n         pad_size = get_size_dict(pad_size, default_to_square=True)\n \n+        mask_size = mask_size if mask_size is not None else {\"longest_edge\": 256}\n+        mask_size = get_size_dict(max_size=mask_size, default_to_square=False) if not isinstance(mask_size, dict) else mask_size\n+\n+        mask_pad_size = mask_pad_size if mask_pad_size is not None else {\"height\": 256, \"width\": 256}\n+        mask_pad_size = get_size_dict(mask_pad_size, default_to_square=True)\n+\n         self.do_resize = do_resize\n         self.size = size\n+        self.mask_size = mask_size\n         self.resample = resample\n         self.do_rescale = do_rescale\n         self.rescale_factor = rescale_factor\n@@ -137,6 +153,7 @@ class SamImageProcessor(BaseImageProcessor):\n         self.image_std = image_std if image_std is not None else IMAGENET_DEFAULT_STD\n         self.do_pad = do_pad\n         self.pad_size = pad_size\n+        self.mask_pad_size = mask_pad_size\n         self.do_convert_rgb = do_convert_rgb\n \n     def pad_image(\n@@ -236,11 +253,155 @@ class SamImageProcessor(BaseImageProcessor):\n             **kwargs,\n         )\n \n+    def _preprocess(\n+        self,\n+        image: ImageInput,\n+        do_resize: bool,\n+        do_rescale: bool,\n+        do_normalize: bool,\n+        size: Optional[Dict[str, int]] = None,\n+        resample: PILImageResampling = None,\n+        rescale_factor: Optional[float] = None,\n+        image_mean: Optional[Union[float, List[float]]] = None,\n+        image_std: Optional[Union[float, List[float]]] = None,\n+        do_pad: Optional[bool] = None,\n+        pad_size: Optional[Dict[str, int]] = None,\n+        input_data_format: Optional[Union[str, ChannelDimension]] = None,\n+    ):\n+        if do_resize:\n+            image = self.resize(image=image, size=size, resample=resample, input_data_format=input_data_format)\n+\n+        if do_rescale:\n+            image = self.rescale(image=image, scale=rescale_factor, input_data_format=input_data_format)\n+\n+        if do_normalize:\n+            image = self.normalize(image=image, mean=image_mean, std=image_std, input_data_format=input_data_format)\n+\n+        if do_pad:\n+            image = self.pad_image(image=image, pad_size=pad_size, input_data_format=input_data_format)\n+\n+        return image\n+\n+    def _preprocess_image(\n+        self,\n+        image: ImageInput,\n+        do_resize: bool = None,\n+        size: Dict[str, int] = None,\n+        resample: PILImageResampling = None,\n+        do_rescale: bool = None,\n+        rescale_factor: float = None,\n+        do_normalize: bool = None,\n+        image_mean: Optional[Union[float, List[float]]] = None,\n+        image_std: Optional[Union[float, List[float]]] = None,\n+        do_pad: Optional[bool] = None,\n+        pad_size: Optional[Dict[str, int]] = None,\n+        do_convert_rgb: bool = None,\n+        data_format: Optional[Union[str, ChannelDimension]] = None,\n+        input_data_format: Optional[Union[str, ChannelDimension]] = None,\n+    ) -> np.ndarray:\n+        \"\"\"Preprocesses a single image.\"\"\"\n+        # PIL RGBA images are converted to RGB\n+        if do_convert_rgb:\n+            image = convert_to_rgb(image)\n+\n+        # All transformations expect numpy arrays.\n+        image = to_numpy_array(image)\n+\n+        if is_scaled_image(image) and do_rescale:\n+            logger.warning_once(\n+                \"It looks like you are trying to rescale already rescaled images. If the input\"\n+                \" images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\"\n+            )\n+\n+        if input_data_format is None:\n+            input_data_format = infer_channel_dimension_format(image)\n+\n+        original_size = get_image_size(image, channel_dim=input_data_format)\n+\n+        image = self._preprocess(\n+            image=image,\n+            do_resize=do_resize,\n+            size=size,\n+            resample=resample,\n+            do_rescale=do_rescale,\n+            rescale_factor=rescale_factor,\n+            do_normalize=do_normalize,\n+            image_mean=image_mean,\n+            image_std=image_std,\n+            do_pad=do_pad,\n+            pad_size=pad_size,\n+            input_data_format=input_data_format,\n+        )\n+\n+        reshaped_input_size = get_image_size(image, channel_dim=input_data_format)\n+\n+        if data_format is not None:\n+            image = to_channel_dimension_format(image, data_format, input_channel_dim=input_data_format)\n+\n+        return image, original_size, reshaped_input_size\n+\n+    def _preprocess_mask(\n+        self,\n+        segmentation_map: ImageInput,\n+        do_resize: bool = None,\n+        mask_size: Dict[str, int] = None,\n+        do_pad: Optional[bool] = None,\n+        mask_pad_size: Optional[Dict[str, int]] = None,\n+        input_data_format: Optional[Union[str, ChannelDimension]] = None,\n+    ) -> np.ndarray:\n+        \"\"\"Preprocesses a single mask.\"\"\"\n+        segmentation_map = to_numpy_array(segmentation_map)\n+        # Add channel dimension if missing - needed for certain transformations\n+        if segmentation_map.ndim == 2:\n+            added_channel_dim = True\n+            segmentation_map = segmentation_map[None, ...]\n+            input_data_format = ChannelDimension.FIRST\n+        else:\n+            added_channel_dim = False\n+            if input_data_format is None:\n+                input_data_format = infer_channel_dimension_format(segmentation_map, num_channels=1)\n+\n+        segmentation_map = self._preprocess(\n+            image=segmentation_map,\n+            do_resize=do_resize,\n+            size=mask_size,\n+            resample=PILImageResampling.NEAREST,\n+            do_rescale=False,\n+            rescale_factor=None,\n+            do_normalize=False,\n+            image_mean=None,\n+            image_std=None,\n+            do_pad=do_pad,\n+            pad_size=mask_pad_size,\n+            input_data_format=input_data_format,\n+        )\n+        # Remove extra channel dimension if added for processing\n+        if added_channel_dim:\n+            segmentation_map = segmentation_map.squeeze(0)\n+        segmentation_map = segmentation_map.astype(np.int64)\n+        return segmentation_map\n+\n+    def __call__(\n+        self,\n+        images,\n+        segmentation_maps=None,\n+        **kwargs,\n+    ):\n+        \"\"\"\n+        Preprocesses a batch of images and optionally segmentation maps.\n+\n+        Overrides the `__call__` method of the `Preprocessor` class so that both images and segmentation maps can be\n+        passed in as positional arguments.\n+        \"\"\"\n+        return super().__call__(images, segmentation_maps=segmentation_maps, **kwargs)\n+\n     def preprocess(\n         self,\n         images: ImageInput,\n+        segmentation_maps: Optional[ImageInput] = None,\n         do_resize: Optional[bool] = None,\n         size: Optional[Dict[str, int]] = None,\n+        mask_size: Optional[Dict[str, int]] = None,\n         resample: Optional[\"PILImageResampling\"] = None,\n         do_rescale: Optional[bool] = None,\n         rescale_factor: Optional[Union[int, float]] = None,\n@@ -249,6 +410,7 @@ class SamImageProcessor(BaseImageProcessor):\n         image_std: Optional[Union[float, List[float]]] = None,\n         do_pad: Optional[bool] = None,\n         pad_size: Optional[Dict[str, int]] = None,\n+        mask_pad_size: Optional[Dict[str, int]] = None,\n         do_convert_rgb: bool = None,\n         return_tensors: Optional[Union[str, TensorType]] = None,\n         data_format: ChannelDimension = ChannelDimension.FIRST,\n@@ -262,11 +424,16 @@ class SamImageProcessor(BaseImageProcessor):\n             images (`ImageInput`):\n                 Image to preprocess. Expects a single or batch of images with pixel values ranging from 0 to 255. If\n                 passing in images with pixel values between 0 and 1, set `do_rescale=False`.\n+            segmentation_maps (`ImageInput`, *optional*):\n+                Segmentation map to preprocess.\n             do_resize (`bool`, *optional*, defaults to `self.do_resize`):\n                 Whether to resize the image.\n             size (`Dict[str, int]`, *optional*, defaults to `self.size`):\n                 Controls the size of the image after `resize`. The longest edge of the image is resized to\n                 `size[\"longest_edge\"]` whilst preserving the aspect ratio.\n+            mask_size (`Dict[str, int]`, *optional*, defaults to `self.mask_size`):\n+                Controls the size of the segmentation map after `resize`. The longest edge of the image is resized to\n+                `size[\"longest_edge\"]` whilst preserving the aspect ratio.\n             resample (`PILImageResampling`, *optional*, defaults to `self.resample`):\n                 `PILImageResampling` filter to use when resizing the image e.g. `PILImageResampling.BILINEAR`.\n             do_rescale (`bool`, *optional*, defaults to `self.do_rescale`):\n@@ -284,6 +451,9 @@ class SamImageProcessor(BaseImageProcessor):\n             pad_size (`Dict[str, int]`, *optional*, defaults to `self.pad_size`):\n                 Controls the size of the padding applied to the image. The image is padded to `pad_size[\"height\"]` and\n                 `pad_size[\"width\"]` if `do_pad` is set to `True`.\n+            mask_pad_size (`Dict[str, int]`, *optional*, defaults to `self.mask_pad_size`):\n+                Controls the size of the padding applied to the segmentation map. The segmentation map is padded to\n+                `mask_pad_size[\"height\"]` and `mask_pad_size[\"width\"]` if `do_pad` is set to `True`.\n             do_convert_rgb (`bool`, *optional*, defaults to `self.do_convert_rgb`):\n                 Whether to convert the image to RGB.\n             return_tensors (`str` or `TensorType`, *optional*):\n@@ -308,6 +478,8 @@ class SamImageProcessor(BaseImageProcessor):\n         do_resize = do_resize if do_resize is not None else self.do_resize\n         size = size if size is not None else self.size\n         size = get_size_dict(max_size=size, default_to_square=False) if not isinstance(size, dict) else size\n+        mask_size = mask_size if mask_size is not None else self.mask_size\n+        mask_size = get_size_dict(max_size=mask_size, default_to_square=False) if not isinstance(mask_size, dict) else mask_size\n         resample = resample if resample is not None else self.resample\n         do_rescale = do_rescale if do_rescale is not None else self.do_rescale\n         rescale_factor = rescale_factor if rescale_factor is not None else self.rescale_factor\n@@ -317,16 +489,27 @@ class SamImageProcessor(BaseImageProcessor):\n         do_pad = do_pad if do_pad is not None else self.do_pad\n         pad_size = pad_size if pad_size is not None else self.pad_size\n         pad_size = get_size_dict(pad_size, default_to_square=True)\n+        mask_pad_size = mask_pad_size if mask_pad_size is not None else self.mask_pad_size\n+        mask_pad_size = get_size_dict(mask_pad_size, default_to_square=True)\n         do_convert_rgb = do_convert_rgb if do_convert_rgb is not None else self.do_convert_rgb\n \n         images = make_list_of_images(images)\n \n+        if segmentation_maps is not None:\n+            segmentation_maps = make_list_of_images(segmentation_maps, expected_ndims=2)\n+\n         if not valid_images(images):\n             raise ValueError(\n                 \"Invalid image type. Must be of type PIL.Image.Image, numpy.ndarray, \"\n                 \"torch.Tensor, tf.Tensor or jax.ndarray.\"\n             )\n \n+        if segmentation_maps is not None and not valid_images(segmentation_maps):\n+            raise ValueError(\n+                \"Invalid segmentation map type. Must be of type PIL.Image.Image, numpy.ndarray, \"\n+                \"torch.Tensor, tf.Tensor or jax.ndarray.\"\n+            )\n+\n         if do_resize and (size is None or resample is None):\n             raise ValueError(\"Size and resample must be specified if do_resize is True.\")\n \n@@ -386,12 +569,28 @@ class SamImageProcessor(BaseImageProcessor):\n         images = [\n             to_channel_dimension_format(image, data_format, input_channel_dim=input_data_format) for image in images\n         ]\n+\n+        data = {\n+            \"pixel_values\": images,\n+            \"original_sizes\": original_sizes,\n+            \"reshaped_input_sizes\": reshaped_input_sizes,\n+        }\n+\n+        if segmentation_maps is not None:\n+            segmentation_maps = [\n+                self._preprocess_mask(\n+                    segmentation_map=segmentation_map,\n+                    do_resize=do_resize,\n+                    mask_size=mask_size,\n+                    do_pad=do_pad,\n+                    mask_pad_size=mask_pad_size,\n+                )\n+                for segmentation_map in segmentation_maps\n+            ]\n+            data[\"labels\"] = segmentation_maps\n+\n         encoded_outputs = BatchFeature(\n-            data={\n-                \"pixel_values\": images,\n-                \"original_sizes\": original_sizes,\n-                \"reshaped_input_sizes\": reshaped_input_sizes,\n-            },\n+            data=data,\n             tensor_type=return_tensors,\n         )\n         return encoded_outputs\n"}
{"instance_id": "huggingface__transformers-25765", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/whisper/modeling_whisper.py b/src/transformers/models/whisper/modeling_whisper.py\nindex 926101156d..663b5f3f0a 100644\n--- a/src/transformers/models/whisper/modeling_whisper.py\n+++ b/src/transformers/models/whisper/modeling_whisper.py\n@@ -1269,6 +1269,14 @@ class WhisperModel(WhisperPreTrainedModel):\n         # generate indices & apply SpecAugment along time axis\n         batch_size, hidden_size, sequence_length = input_features.size()\n \n+        if attention_mask is not None:\n+            # make sure padded tokens are not masked\n+            # check if attention_mask length is correct, if not, subsample it\n+            if attention_mask.shape[-1] != sequence_length:\n+                # subsample attention_mask to match sequence_length\n+                subsampling_factor = attention_mask.shape[-1] // sequence_length\n+                attention_mask = attention_mask[:, ::subsampling_factor]\n+\n         if self.config.mask_time_prob > 0 and self.training:\n             # generate indices & apply SpecAugment along time axis\n             mask_time_indices = _compute_mask_indices(\n"}
{"instance_id": "huggingface__transformers-28115", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/mixtral/modeling_mixtral.py b/src/transformers/models/mixtral/modeling_mixtral.py\nindex c07346c6de..a672723aee 100644\n--- a/src/transformers/models/mixtral/modeling_mixtral.py\n+++ b/src/transformers/models/mixtral/modeling_mixtral.py\n@@ -98,8 +98,9 @@ def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tenso\n         compute_device = gate_logits[0].device\n         gate_logits = torch.cat([gate.to(compute_device) for gate in gate_logits], dim=0)\n \n-    routing_weights, selected_experts = torch.topk(gate_logits, top_k, dim=-1)\n-    routing_weights = routing_weights.softmax(dim=-1)\n+    routing_weights = torch.nn.functional.softmax(gate_logits, dim=-1)\n+\n+    _, selected_experts = torch.topk(routing_weights, top_k, dim=-1)\n \n     # cast the expert indices to int64, otherwise one-hot encoding will fail\n     if selected_experts.dtype != torch.int64:\n@@ -117,8 +118,8 @@ def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tenso\n     expert_mask = expert_mask.to(torch.float32)\n     tokens_per_group_and_expert = torch.mean(expert_mask, axis=-2)\n \n-    router_prob_per_group_and_expert = torch.mean(routing_weights, axis=-1)\n-    return torch.mean(tokens_per_group_and_expert * router_prob_per_group_and_expert.unsqueeze(-1)) * (num_experts**2)\n+    router_prob_per_group_and_expert = torch.mean(routing_weights, axis=-2)\n+    return torch.mean(tokens_per_group_and_expert * router_prob_per_group_and_expert) * (num_experts**2)\n \n \n # Copied from transformers.models.llama.modeling_llama._get_unpad_data\n"}
{"instance_id": "huggingface__transformers-27663", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/conditional_detr/image_processing_conditional_detr.py b/src/transformers/models/conditional_detr/image_processing_conditional_detr.py\nindex 2fe33db810..b33c6f185c 100644\n--- a/src/transformers/models/conditional_detr/image_processing_conditional_detr.py\n+++ b/src/transformers/models/conditional_detr/image_processing_conditional_detr.py\n@@ -105,14 +105,24 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n             size = int(round(max_size * min_original_size / max_original_size))\n \n     if (height <= width and height == size) or (width <= height and width == size):\n-        return height, width\n-\n-    if width < height:\n+        oh, ow = height, width\n+    elif width < height:\n         ow = size\n         oh = int(size * height / width)\n     else:\n         oh = size\n         ow = int(size * width / height)\n+\n+    # Ensure the longest edge does not exceed max_size\n+    # This is needed because of rounding errors when computing size above\n+    if max_size is not None and max(oh, ow) > max_size:\n+        if oh > ow:\n+            oh = max_size\n+            ow = int(max_size * width / height)\n+        else:\n+            ow = max_size\n+            oh = int(max_size * height / width)\n+\n     return (oh, ow)\n \n \ndiff --git a/src/transformers/models/deformable_detr/image_processing_deformable_detr.py b/src/transformers/models/deformable_detr/image_processing_deformable_detr.py\nindex 8c40d20c81..d76f747767 100644\n--- a/src/transformers/models/deformable_detr/image_processing_deformable_detr.py\n+++ b/src/transformers/models/deformable_detr/image_processing_deformable_detr.py\n@@ -103,14 +103,24 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n             size = int(round(max_size * min_original_size / max_original_size))\n \n     if (height <= width and height == size) or (width <= height and width == size):\n-        return height, width\n-\n-    if width < height:\n+        oh, ow = height, width\n+    elif width < height:\n         ow = size\n         oh = int(size * height / width)\n     else:\n         oh = size\n         ow = int(size * width / height)\n+\n+    # Ensure the longest edge does not exceed max_size\n+    # This is needed because of rounding errors when computing size above\n+    if max_size is not None and max(oh, ow) > max_size:\n+        if oh > ow:\n+            oh = max_size\n+            ow = int(max_size * width / height)\n+        else:\n+            ow = max_size\n+            oh = int(max_size * height / width)\n+\n     return (oh, ow)\n \n \ndiff --git a/src/transformers/models/deta/image_processing_deta.py b/src/transformers/models/deta/image_processing_deta.py\nindex bdd7ab1118..7a615f3135 100644\n--- a/src/transformers/models/deta/image_processing_deta.py\n+++ b/src/transformers/models/deta/image_processing_deta.py\n@@ -97,14 +97,24 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n             size = int(round(max_size * min_original_size / max_original_size))\n \n     if (height <= width and height == size) or (width <= height and width == size):\n-        return height, width\n-\n-    if width < height:\n+        oh, ow = height, width\n+    elif width < height:\n         ow = size\n         oh = int(size * height / width)\n     else:\n         oh = size\n         ow = int(size * width / height)\n+\n+    # Ensure the longest edge does not exceed max_size\n+    # This is needed because of rounding errors when computing size above\n+    if max_size is not None and max(oh, ow) > max_size:\n+        if oh > ow:\n+            oh = max_size\n+            ow = int(max_size * width / height)\n+        else:\n+            ow = max_size\n+            oh = int(max_size * height / width)\n+\n     return (oh, ow)\n \n \ndiff --git a/src/transformers/models/detr/image_processing_detr.py b/src/transformers/models/detr/image_processing_detr.py\nindex 24c36c5d10..ce69721cfc 100644\n--- a/src/transformers/models/detr/image_processing_detr.py\n+++ b/src/transformers/models/detr/image_processing_detr.py\n@@ -102,14 +102,24 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n             size = int(round(max_size * min_original_size / max_original_size))\n \n     if (height <= width and height == size) or (width <= height and width == size):\n-        return height, width\n-\n-    if width < height:\n+        oh, ow = height, width\n+    elif width < height:\n         ow = size\n         oh = int(size * height / width)\n     else:\n         oh = size\n         ow = int(size * width / height)\n+\n+    # Ensure the longest edge does not exceed max_size\n+    # This is needed because of rounding errors when computing size above\n+    if max_size is not None and max(oh, ow) > max_size:\n+        if oh > ow:\n+            oh = max_size\n+            ow = int(max_size * width / height)\n+        else:\n+            ow = max_size\n+            oh = int(max_size * height / width)\n+\n     return (oh, ow)\n \n \ndiff --git a/src/transformers/models/yolos/image_processing_yolos.py b/src/transformers/models/yolos/image_processing_yolos.py\nindex 3b0c635c0e..c0afdb3797 100644\n--- a/src/transformers/models/yolos/image_processing_yolos.py\n+++ b/src/transformers/models/yolos/image_processing_yolos.py\n@@ -120,14 +120,24 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n             size = int(round(max_size * min_original_size / max_original_size))\n \n     if (height <= width and height == size) or (width <= height and width == size):\n-        return height, width\n-\n-    if width < height:\n+        oh, ow = height, width\n+    elif width < height:\n         ow = size\n         oh = int(size * height / width)\n     else:\n         oh = size\n         ow = int(size * width / height)\n+\n+    # Ensure the longest edge does not exceed max_size\n+    # This is needed because of rounding errors when computing size above\n+    if max_size is not None and max(oh, ow) > max_size:\n+        if oh > ow:\n+            oh = max_size\n+            ow = int(max_size * width / height)\n+        else:\n+            ow = max_size\n+            oh = int(max_size * height / width)\n+\n     return (oh, ow)\n \n \n"}
{"instance_id": "huggingface__transformers-28071", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/speecht5/modeling_speecht5.py b/src/transformers/models/speecht5/modeling_speecht5.py\nindex a5e228b6a8..2560581772 100644\n--- a/src/transformers/models/speecht5/modeling_speecht5.py\n+++ b/src/transformers/models/speecht5/modeling_speecht5.py\n@@ -2700,6 +2700,10 @@ class SpeechT5ForTextToSpeech(SpeechT5PreTrainedModel):\n         if labels is not None:\n             if decoder_input_values is None:\n                 decoder_input_values = shift_spectrograms_right(labels, self.config.reduction_factor)\n+                if decoder_attention_mask is not None:\n+                    decoder_attention_mask = decoder_attention_mask[\n+                        :, self.config.reduction_factor - 1 :: self.config.reduction_factor\n+                    ]\n             if self.config.use_guided_attention_loss:\n                 output_attentions = True\n \n@@ -3045,6 +3049,10 @@ class SpeechT5ForSpeechToSpeech(SpeechT5PreTrainedModel):\n         if labels is not None:\n             if decoder_input_values is None:\n                 decoder_input_values = shift_spectrograms_right(labels, self.config.reduction_factor)\n+                if decoder_attention_mask is not None:\n+                    decoder_attention_mask = decoder_attention_mask[\n+                        :, self.config.reduction_factor - 1 :: self.config.reduction_factor\n+                    ]\n \n         outputs = self.speecht5(\n             input_values=input_values,\n"}
{"instance_id": "huggingface__transformers-28398", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/oneformer/image_processing_oneformer.py b/src/transformers/models/oneformer/image_processing_oneformer.py\nindex c42001a962..efa286e12f 100644\n--- a/src/transformers/models/oneformer/image_processing_oneformer.py\n+++ b/src/transformers/models/oneformer/image_processing_oneformer.py\n@@ -15,6 +15,7 @@\n \"\"\"Image processor class for OneFormer.\"\"\"\n \n import json\n+import os\n import warnings\n from typing import Any, Dict, Iterable, List, Optional, Set, Tuple, Union\n \n@@ -332,7 +333,14 @@ def get_oneformer_resize_output_image_size(\n \n \n def prepare_metadata(repo_path, class_info_file):\n-    with open(hf_hub_download(repo_path, class_info_file, repo_type=\"dataset\"), \"r\") as f:\n+    if os.path.isdir(repo_path):\n+        # If repo_path is a local directory, read the class_info_file directly from it\n+        class_info_file_path = os.path.join(repo_path, class_info_file)\n+    else:\n+        # Otherwise, download from the HuggingFace Hub\n+        class_info_file_path = hf_hub_download(repo_path, class_info_file, repo_type=\"dataset\")\n+\n+    with open(class_info_file_path, \"r\") as f:\n         class_info = json.load(f)\n     metadata = {}\n     class_names = []\n@@ -386,11 +394,12 @@ class OneFormerImageProcessor(BaseImageProcessor):\n             Whether or not to decrement all label values of segmentation maps by 1. Usually used for datasets where 0\n             is used for background, and background itself is not included in all classes of a dataset (e.g. ADE20k).\n             The background label will be replaced by `ignore_index`.\n-        repo_path (`str`, defaults to `shi-labs/oneformer_demo`, *optional*, defaults to `\"shi-labs/oneformer_demo\"`):\n-            Dataset repository on huggingface hub containing the JSON file with class information for the dataset.\n+        repo_path (`str`, *optional*, defaults to `\"shi-labs/oneformer_demo\"`):\n+            Path to the dataset repository. Can be either a local directory path or a dataset repository on the\n+            Hugging Face Hub containing the JSON file with class information for the dataset.\n         class_info_file (`str`, *optional*):\n-            JSON file containing class information for the dataset. It is stored inside on the `repo_path` dataset\n-            repository.\n+            JSON file containing class information for the dataset. It is stored inside the `repo_path` dataset\n+            repository or local directory.\n         num_text (`int`, *optional*):\n             Number of text entries in the text input list.\n     \"\"\"\n"}
{"instance_id": "huggingface__transformers-28517", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/mixtral/modeling_mixtral.py b/src/transformers/models/mixtral/modeling_mixtral.py\nindex 99bd282086..69f340776a 100644\n--- a/src/transformers/models/mixtral/modeling_mixtral.py\n+++ b/src/transformers/models/mixtral/modeling_mixtral.py\n@@ -74,7 +74,9 @@ logger = logging.get_logger(__name__)\n _CONFIG_FOR_DOC = \"MixtralConfig\"\n \n \n-def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tensor = None, top_k=2) -> float:\n+def load_balancing_loss_func(\n+    gate_logits: torch.Tensor, num_experts: torch.Tensor = None, top_k=2, attention_mask: Optional[torch.Tensor] = None\n+) -> float:\n     r\"\"\"\n     Computes auxiliary load balancing loss as in Switch Transformer - implemented in Pytorch.\n \n@@ -88,6 +90,11 @@ def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tenso\n             shape [batch_size X sequence_length, num_experts].\n         num_experts (`int`, *optional*):\n             Number of experts\n+        top_k (`int`, *optional*):\n+            Number of top k experts to be considered for the loss computation.\n+        attention_mask (`torch.Tensor`, *optional*):\n+            The attention_mask used in forward function\n+            shape [batch_size X sequence_length] if not None.\n \n     Returns:\n         The auxiliary loss.\n@@ -105,11 +112,41 @@ def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tenso\n \n     expert_mask = torch.nn.functional.one_hot(selected_experts, num_experts)\n \n-    # Compute the percentage of tokens routed to each experts\n-    tokens_per_expert = torch.mean(expert_mask.float(), dim=0)\n+    if attention_mask is None:\n+        # Compute the percentage of tokens routed to each experts\n+        tokens_per_expert = torch.mean(expert_mask.float(), dim=0)\n+\n+        # Compute the average probability of routing to these experts\n+        router_prob_per_expert = torch.mean(routing_weights, dim=0)\n+    else:\n+        batch_size, sequence_length = attention_mask.shape\n+        num_hidden_layers = concatenated_gate_logits.shape[0] // (batch_size * sequence_length)\n+\n+        # Compute the mask that masks all padding tokens as 0 with the same shape of expert_mask\n+        expert_attention_mask = (\n+            attention_mask[None, :, :, None, None]\n+            .expand((num_hidden_layers, batch_size, sequence_length, top_k, num_experts))\n+            .reshape(-1, top_k, num_experts)\n+            .to(compute_device)\n+        )\n+\n+        # Compute the percentage of tokens routed to each experts\n+        tokens_per_expert = torch.sum(expert_mask.float() * expert_attention_mask, dim=0) / torch.sum(\n+            expert_attention_mask, dim=0\n+        )\n \n-    # Compute the average probability of routing to these experts\n-    router_prob_per_expert = torch.mean(routing_weights, dim=0)\n+        # Compute the mask that masks all padding tokens as 0 with the same shape of tokens_per_expert\n+        router_per_expert_attention_mask = (\n+            attention_mask[None, :, :, None]\n+            .expand((num_hidden_layers, batch_size, sequence_length, num_experts))\n+            .reshape(-1, num_experts)\n+            .to(compute_device)\n+        )\n+\n+        # Compute the average probability of routing to these experts\n+        router_prob_per_expert = torch.sum(routing_weights * router_per_expert_attention_mask, dim=0) / torch.sum(\n+            router_per_expert_attention_mask, dim=0\n+        )\n \n     overall_loss = torch.sum(tokens_per_expert * router_prob_per_expert.unsqueeze(0))\n     return overall_loss * num_experts\n@@ -1347,7 +1384,10 @@ class MixtralForCausalLM(MixtralPreTrainedModel):\n         aux_loss = None\n         if output_router_logits:\n             aux_loss = load_balancing_loss_func(\n-                outputs.router_logits if return_dict else outputs[-1], self.num_experts, self.num_experts_per_tok\n+                outputs.router_logits if return_dict else outputs[-1],\n+                self.num_experts,\n+                self.num_experts_per_tok,\n+                attention_mask,\n             )\n             if labels is not None:\n                 loss += self.router_aux_loss_coef * aux_loss\n"}
{"instance_id": "huggingface__transformers-28535", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/esm/tokenization_esm.py b/src/transformers/models/esm/tokenization_esm.py\nindex 065eaae1d5..75565da432 100644\n--- a/src/transformers/models/esm/tokenization_esm.py\n+++ b/src/transformers/models/esm/tokenization_esm.py\n@@ -14,10 +14,9 @@\n # limitations under the License.\n \"\"\"Tokenization classes for ESM.\"\"\"\n import os\n-from typing import List, Optional, Union\n+from typing import List, Optional\n \n from ...tokenization_utils import PreTrainedTokenizer\n-from ...tokenization_utils_base import AddedToken\n from ...utils import logging\n \n \n@@ -95,7 +94,9 @@ class EsmTokenizer(PreTrainedTokenizer):\n         return len(self._id_to_token)\n \n     def get_vocab(self):\n-        return {token: i for i, token in enumerate(self.all_tokens)}\n+        base_vocab = {token: i for i, token in enumerate(self.all_tokens)}\n+        base_vocab.update(self.added_tokens_encoder)\n+        return base_vocab\n \n     def token_to_id(self, token: str) -> int:\n         return self._token_to_id.get(token, self._token_to_id.get(self.unk_token))\n@@ -157,6 +158,3 @@ class EsmTokenizer(PreTrainedTokenizer):\n     @property\n     def vocab_size(self) -> int:\n         return self.get_vocab_size(with_added_tokens=False)\n-\n-    def _add_tokens(self, new_tokens: Union[List[str], List[AddedToken]], special_tokens: bool = False) -> int:\n-        return super()._add_tokens(new_tokens, special_tokens=True)\n"}
{"instance_id": "huggingface__transformers-27717", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/nllb/tokenization_nllb.py b/src/transformers/models/nllb/tokenization_nllb.py\nindex 7daf729c13..121745c554 100644\n--- a/src/transformers/models/nllb/tokenization_nllb.py\n+++ b/src/transformers/models/nllb/tokenization_nllb.py\n@@ -113,6 +113,11 @@ class NllbTokenizer(PreTrainedTokenizer):\n             The language to use as target language for translation.\n         sp_model_kwargs (`Dict[str, str]`):\n             Additional keyword arguments to pass to the model initialization.\n+        additional_special_tokens (tuple or list of `str` or `tokenizers.AddedToken`, *optional*):\n+            A tuple or a list of additional special tokens. Can be used to specify the list of languages that will\n+            be supported by the tokenizer. If a list of language codes (strings matching the pattern `xxx_Xxxx`) is\n+            provided, it will be used instead of the default `FAIRSEQ_LANGUAGE_CODES`. This enables extending or\n+            modifying the list of supported languages.\n     \"\"\"\n \n     vocab_files_names = VOCAB_FILES_NAMES\n@@ -167,8 +172,23 @@ class NllbTokenizer(PreTrainedTokenizer):\n         self.fairseq_offset = 1\n \n         self.sp_model_size = len(self.sp_model)\n+\n+        # Determine the language codes to use.\n+        # If additional_special_tokens contains language codes (strings matching the pattern xxx_Xxxx),\n+        # use those. Otherwise, use FAIRSEQ_LANGUAGE_CODES as the default.\n+        _additional_special_tokens = additional_special_tokens or []\n+        # Filter to get only string tokens (not AddedToken objects) that look like language codes\n+        _language_codes = [\n+            t for t in _additional_special_tokens\n+            if isinstance(t, str) and len(t) == 8 and t[3] == \"_\"\n+        ]\n+\n+        # If no language codes were found in additional_special_tokens, use the default\n+        if not _language_codes:\n+            _language_codes = list(FAIRSEQ_LANGUAGE_CODES)\n+\n         self.lang_code_to_id = {\n-            code: self.sp_model_size + i + self.fairseq_offset for i, code in enumerate(FAIRSEQ_LANGUAGE_CODES)\n+            code: self.sp_model_size + i + self.fairseq_offset for i, code in enumerate(_language_codes)\n         }\n         self.id_to_lang_code = {v: k for k, v in self.lang_code_to_id.items()}\n         self.fairseq_tokens_to_ids[\"<mask>\"] = len(self.sp_model) + len(self.lang_code_to_id) + self.fairseq_offset\n@@ -179,8 +199,8 @@ class NllbTokenizer(PreTrainedTokenizer):\n         self._src_lang = src_lang if src_lang is not None else \"eng_Latn\"\n         self.cur_lang_code_id = self.lang_code_to_id[self._src_lang]\n \n+        # Build the final additional_special_tokens list: language codes + any extra tokens\n         _additional_special_tokens = list(self.lang_code_to_id.keys())\n-\n         if additional_special_tokens is not None:\n             # Only add those special tokens if they are not already there.\n             _additional_special_tokens.extend(\ndiff --git a/src/transformers/models/nllb/tokenization_nllb_fast.py b/src/transformers/models/nllb/tokenization_nllb_fast.py\nindex 7240133e1d..8c816acc0b 100644\n--- a/src/transformers/models/nllb/tokenization_nllb_fast.py\n+++ b/src/transformers/models/nllb/tokenization_nllb_fast.py\n@@ -124,6 +124,11 @@ class NllbTokenizerFast(PreTrainedTokenizerFast):\n             The language to use as source language for translation.\n         tgt_lang (`str`, *optional*):\n             The language to use as target language for translation.\n+        additional_special_tokens (tuple or list of `str` or `tokenizers.AddedToken`, *optional*):\n+            A tuple or a list of additional special tokens. Can be used to specify the list of languages that will\n+            be supported by the tokenizer. If a list of language codes (strings matching the pattern `xxx_Xxxx`) is\n+            provided, it will be used instead of the default `FAIRSEQ_LANGUAGE_CODES`. This enables extending or\n+            modifying the list of supported languages.\n     \"\"\"\n \n     vocab_files_names = VOCAB_FILES_NAMES\n@@ -160,8 +165,22 @@ class NllbTokenizerFast(PreTrainedTokenizerFast):\n         )\n         self.legacy_behaviour = legacy_behaviour\n \n-        _additional_special_tokens = FAIRSEQ_LANGUAGE_CODES.copy()\n-\n+        # Determine the language codes to use.\n+        # If additional_special_tokens contains language codes (strings matching the pattern xxx_Xxxx),\n+        # use those. Otherwise, use FAIRSEQ_LANGUAGE_CODES as the default.\n+        _additional_special_tokens = additional_special_tokens or []\n+        # Filter to get only string tokens (not AddedToken objects) that look like language codes\n+        _language_codes = [\n+            t for t in _additional_special_tokens\n+            if isinstance(t, str) and len(t) == 8 and t[3] == \"_\"\n+        ]\n+\n+        # If no language codes were found in additional_special_tokens, use the default\n+        if not _language_codes:\n+            _language_codes = list(FAIRSEQ_LANGUAGE_CODES)\n+\n+        # Build the final additional_special_tokens list: language codes + any extra tokens\n+        _additional_special_tokens = list(_language_codes)\n         if additional_special_tokens is not None:\n             # Only add those special tokens if they are not already there.\n             _additional_special_tokens.extend(\n@@ -188,7 +207,7 @@ class NllbTokenizerFast(PreTrainedTokenizerFast):\n         self.vocab_file = vocab_file\n \n         self.lang_code_to_id = {\n-            lang_code: self.convert_tokens_to_ids(lang_code) for lang_code in FAIRSEQ_LANGUAGE_CODES\n+            lang_code: self.convert_tokens_to_ids(lang_code) for lang_code in _language_codes\n         }\n \n         self._src_lang = src_lang if src_lang is not None else \"eng_Latn\"\n"}
{"instance_id": "huggingface__transformers-28563", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/whisper/modeling_whisper.py b/src/transformers/models/whisper/modeling_whisper.py\nindex a3550c791c..8f7a43c43d 100644\n--- a/src/transformers/models/whisper/modeling_whisper.py\n+++ b/src/transformers/models/whisper/modeling_whisper.py\n@@ -60,6 +60,9 @@ logger = logging.get_logger(__name__)\n _CONFIG_FOR_DOC = \"WhisperConfig\"\n _CHECKPOINT_FOR_DOC = \"openai/whisper-tiny\"\n \n+# Copied from transformers.models.wav2vec2.modeling_wav2vec2._HIDDEN_STATES_START_POSITION\n+_HIDDEN_STATES_START_POSITION = 1\n+\n \n WHISPER_PRETRAINED_MODEL_ARCHIVE_LIST = [\n     \"openai/whisper-base\",\n@@ -2957,6 +2960,8 @@ class WhisperForAudioClassification(WhisperPreTrainedModel):\n         output_hidden_states = (\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n+        if self.config.use_weighted_layer_sum:\n+            output_hidden_states = True\n         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         if encoder_outputs is None:\n@@ -2969,7 +2974,8 @@ class WhisperForAudioClassification(WhisperPreTrainedModel):\n             )\n \n         if self.config.use_weighted_layer_sum:\n-            hidden_states = torch.stack(encoder_outputs, dim=1)\n+            hidden_states = encoder_outputs[_HIDDEN_STATES_START_POSITION]\n+            hidden_states = torch.stack(hidden_states, dim=1)\n             norm_weights = nn.functional.softmax(self.layer_weights, dim=-1)\n             hidden_states = (hidden_states * norm_weights.view(-1, 1, 1)).sum(dim=1)\n         else:\n"}
{"instance_id": "huggingface__transformers-29449", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/idefics/processing_idefics.py b/src/transformers/models/idefics/processing_idefics.py\nindex 590e2475ca..7cc9b64175 100644\n--- a/src/transformers/models/idefics/processing_idefics.py\n+++ b/src/transformers/models/idefics/processing_idefics.py\n@@ -325,16 +325,24 @@ class IdeficsProcessor(ProcessorMixin):\n             all_prompts.append(full_text)\n             all_images.append(image_objects)\n \n+        # we tokenize without padding to get the unpadded lengths, as we need them later\n+        # for generating the attention mask and image_attention_mask\n         text_encoding = self.tokenizer(\n             text=all_prompts,\n             add_special_tokens=False,\n-            padding=padding,\n+            padding=False,\n             truncation=truncation,\n             max_length=max_length,\n         )\n         all_texts = text_encoding[\"input_ids\"]\n \n-        max_seq_len = max(len(x) for x in all_texts)\n+        # max_seq_len is the maximum length of the sequences in the batch\n+        # if padding is \"max_length\", we pad to max_length\n+        # otherwise, we pad to the longest sequence in the batch\n+        if padding == \"max_length\" and max_length is not None:\n+            max_seq_len = max_length\n+        else:\n+            max_seq_len = max(len(x) for x in all_texts)\n \n         # max_num_images has to be at least 1 even when there are no images\n         max_num_images = max(len(x) for x in all_images)\n@@ -347,11 +355,14 @@ class IdeficsProcessor(ProcessorMixin):\n         for text, images in zip(all_texts, all_images):\n             padded_input_ids = [self.tokenizer.pad_token_id] * max_seq_len\n             unpadded_seq_len = len(text)\n-            start = max_seq_len - unpadded_seq_len\n-            padded_input_ids[start:] = text[:max_seq_len]\n-\n             attention_mask = torch.zeros((max_seq_len,), dtype=torch.long)\n-            attention_mask[start:] = 1\n+\n+            if self.tokenizer.padding_side == \"left\":\n+                padded_input_ids[max_seq_len - unpadded_seq_len :] = text[:max_seq_len]\n+                attention_mask[max_seq_len - unpadded_seq_len :] = 1\n+            else:\n+                padded_input_ids[:unpadded_seq_len] = text[:max_seq_len]\n+                attention_mask[:unpadded_seq_len] = 1\n \n             image_count = padded_input_ids.count(self.image_token_id)\n             local_max_num_images = min(image_count, max_num_images)\n"}
{"instance_id": "huggingface__transformers-29519", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/mistral/modeling_flax_mistral.py b/src/transformers/models/mistral/modeling_flax_mistral.py\nindex 3480fc7214..2ef91d9207 100644\n--- a/src/transformers/models/mistral/modeling_flax_mistral.py\n+++ b/src/transformers/models/mistral/modeling_flax_mistral.py\n@@ -239,7 +239,7 @@ class FlaxMistralAttention(nn.Module):\n         self.v_proj = nn.Dense(self.num_key_value_heads * self.head_dim, use_bias=False, dtype=self.dtype)\n         self.o_proj = nn.Dense(self.hidden_size, use_bias=False, dtype=self.dtype)\n         casual_mask = make_causal_mask(jnp.ones((1, config.max_position_embeddings), dtype=\"bool\"), dtype=\"bool\")\n-        self.causal_mask = jnp.triu(casual_mask, k=-config.sliding_window)\n+        self.causal_mask = jnp.triu(casual_mask, k=-config.sliding_window + 1)\n         self.rotary_emb = FlaxMistralRotaryEmbedding(config, dtype=self.dtype)\n \n     def _split_heads(self, hidden_states, num_heads):\n"}
{"instance_id": "huggingface__transformers-29311", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/big_bird/tokenization_big_bird.py b/src/transformers/models/big_bird/tokenization_big_bird.py\nindex e7c43a86a6..049a571247 100644\n--- a/src/transformers/models/big_bird/tokenization_big_bird.py\n+++ b/src/transformers/models/big_bird/tokenization_big_bird.py\n@@ -219,7 +219,7 @@ class BigBirdTokenizer(PreTrainedTokenizer):\n         sub_texts = []\n         current_sub_text = []\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n             if token in self.added_tokens_encoder:\n                 if current_sub_text:\ndiff --git a/src/transformers/models/wav2vec2/tokenization_wav2vec2.py b/src/transformers/models/wav2vec2/tokenization_wav2vec2.py\nindex 00bb00fba3..38cb90d1d1 100644\n--- a/src/transformers/models/wav2vec2/tokenization_wav2vec2.py\n+++ b/src/transformers/models/wav2vec2/tokenization_wav2vec2.py\n@@ -434,7 +434,7 @@ class Wav2Vec2CTCTokenizer(PreTrainedTokenizer):\n \n         result = []\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n             result.append(token)\n \n@@ -895,7 +895,7 @@ class Wav2Vec2Tokenizer(PreTrainedTokenizer):\n \n         result = []\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n             result.append(token)\n \ndiff --git a/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py b/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py\nindex c10b679409..34347567ce 100644\n--- a/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py\n+++ b/src/transformers/models/wav2vec2_phoneme/tokenization_wav2vec2_phoneme.py\n@@ -440,7 +440,7 @@ class Wav2Vec2PhonemeCTCTokenizer(PreTrainedTokenizer):\n \n         result = []\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n             result.append(token)\n \ndiff --git a/src/transformers/models/whisper/tokenization_whisper.py b/src/transformers/models/whisper/tokenization_whisper.py\nindex f853c60e26..54a088ed71 100644\n--- a/src/transformers/models/whisper/tokenization_whisper.py\n+++ b/src/transformers/models/whisper/tokenization_whisper.py\n@@ -745,7 +745,7 @@ class WhisperTokenizer(PreTrainedTokenizer):\n         sub_texts = []\n         current_sub_text = []\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n             if token in self.added_tokens_encoder:\n                 if current_sub_text:\ndiff --git a/src/transformers/models/xlnet/tokenization_xlnet.py b/src/transformers/models/xlnet/tokenization_xlnet.py\nindex 808a7ff5bf..6c8e3cb051 100644\n--- a/src/transformers/models/xlnet/tokenization_xlnet.py\n+++ b/src/transformers/models/xlnet/tokenization_xlnet.py\n@@ -268,7 +268,7 @@ class XLNetTokenizer(PreTrainedTokenizer):\n         sub_texts = []\n         current_sub_text = []\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n             if token in self.added_tokens_encoder:\n                 if current_sub_text:\ndiff --git a/src/transformers/tokenization_utils.py b/src/transformers/tokenization_utils.py\nindex 8f1b15c1c1..94a5a30364 100644\n--- a/src/transformers/tokenization_utils.py\n+++ b/src/transformers/tokenization_utils.py\n@@ -1009,7 +1009,7 @@ class PreTrainedTokenizer(PreTrainedTokenizerBase):\n         current_sub_text = []\n         # TODO @ArthurZ in version 5, special tokens should be handled in convert_tokens_to_string, while _convert_tokens_to_string\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n             if token in legacy_added_tokens:\n                 if current_sub_text:\n"}
{"instance_id": "huggingface__transformers-29675", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/generation/configuration_utils.py b/src/transformers/generation/configuration_utils.py\nindex 974e1452d0..51c355b2a1 100644\n--- a/src/transformers/generation/configuration_utils.py\n+++ b/src/transformers/generation/configuration_utils.py\n@@ -390,7 +390,31 @@ class GenerationConfig(PushToHubMixin):\n                     raise err\n \n         # Validate the values of the attributes\n-        self.validate(is_init=True)\n+        self._validate_init()\n+\n+    def _validate_init(self):\n+        \"\"\"\n+        Validates the values of the attributes of the [`GenerationConfig`] instance during initialization. Raises\n+        exceptions in the presence of parameterization that can be detected as incorrect from the configuration\n+        instance alone.\n+\n+        This method is called at the end of `__init__` to ensure that the instance is valid. It catches warnings\n+        and raises them as exceptions to ensure that users are aware of any issues with their configuration before\n+        training, rather than only at save time.\n+        \"\"\"\n+        try:\n+            with warnings.catch_warnings(record=True) as caught_warnings:\n+                self.validate(is_init=True)\n+            if len(caught_warnings) > 0:\n+                raise ValueError(str([w.message for w in caught_warnings]))\n+        except ValueError as exc:\n+            raise ValueError(\n+                \"The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. \"\n+                \"Fix these issues to save the configuration. Commonly, warnings are thrown when setting generation \"\n+                \"parameters that are not compatible with the active generation mode (e.g. `do_sample=False` and \"\n+                \"`temperature!=1.0`). Exceptions are thrown when the parameterization is invalid (e.g. \"\n+                \"`max_new_tokens<0`).\\n\\nThrown during validation:\\n\" + str(exc)\n+            ) from None\n \n     def __hash__(self):\n         return hash(self.to_json_string(ignore_metadata=True))\n"}
{"instance_id": "huggingface__transformers-29563", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/mamba/modeling_mamba.py b/src/transformers/models/mamba/modeling_mamba.py\nindex 4870c0281f..e5450a479e 100644\n--- a/src/transformers/models/mamba/modeling_mamba.py\n+++ b/src/transformers/models/mamba/modeling_mamba.py\n@@ -152,7 +152,7 @@ class MambaMixer(nn.Module):\n                     conv_states = nn.functional.pad(\n                         hidden_states, (self.conv_kernel_size - hidden_states.shape[-1], 0)\n                     )\n-                    cache_params.conv_states[self.layer_idx].copy_(conv_states)\n+                    cache_params.conv_states[self.layer_idx] = conv_states\n                 hidden_states = causal_conv1d_fn(\n                     hidden_states, conv_weights, self.conv1d.bias, activation=self.activation\n                 )\n@@ -195,7 +195,7 @@ class MambaMixer(nn.Module):\n                     return_last_state=True,\n                 )\n                 if ssm_state is not None and cache_params is not None:\n-                    cache_params.ssm_states[self.layer_idx].copy_(ssm_state)\n+                    cache_params.ssm_states[self.layer_idx] = ssm_state\n \n             # 4. Final linear projection\n             contextualized_states = self.out_proj(scan_outputs.transpose(1, 2))\n@@ -213,10 +213,10 @@ class MambaMixer(nn.Module):\n         if cache_params is not None:\n             ssm_state = cache_params.ssm_states[self.layer_idx]\n             if cache_params.seqlen_offset > 0:\n-                conv_state = cache_params.conv_states[self.layer_idx]                   # [batch, intermediate_size, conv_kernel_size]\n+                conv_state = cache_params.conv_states[self.layer_idx].clone()            # [batch, intermediate_size, conv_kernel_size]\n                 conv_state = torch.roll(conv_state, shifts=-1, dims=-1)\n                 conv_state[:, :, -1] = hidden_states[:, :, 0]\n-                cache_params.conv_states[self.layer_idx].copy_(conv_state)\n+                cache_params.conv_states[self.layer_idx] = conv_state\n                 hidden_states = torch.sum(conv_state * self.conv1d.weight[:, 0, :], dim=-1)\n                 if self.use_conv_bias:\n                     hidden_states += self.conv1d.bias\n@@ -226,7 +226,7 @@ class MambaMixer(nn.Module):\n                     hidden_states,\n                     (self.conv_kernel_size - hidden_states.shape[-1], 0)\n                 )\n-                cache_params.conv_states[self.layer_idx].copy_(conv_state)\n+                cache_params.conv_states[self.layer_idx] = conv_state\n                 hidden_states = self.act(self.conv1d(hidden_states)[..., :seq_len])     # [batch, intermediate_size, seq_len]\n         else:\n             ssm_state = torch.zeros(\n@@ -261,7 +261,7 @@ class MambaMixer(nn.Module):\n         scan_output = (scan_output * self.act(gate))\n \n         if cache_params is not None:\n-            cache_params.ssm_states[self.layer_idx].copy_(ssm_state)\n+            cache_params.ssm_states[self.layer_idx] = ssm_state\n \n         # 4. Final linear projection\n         contextualized_states = self.out_proj(scan_output.transpose(1, 2))             # [batch, seq_len, hidden_size]\n"}
{"instance_id": "huggingface__transformers-30556", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex b81e1f1757..f757f60d9f 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -590,6 +590,9 @@ class DataCollatorForSeq2Seq:\n         # same length to return tensors.\n         if labels is not None:\n             max_label_length = max(len(l) for l in labels)\n+            if self.padding == \"max_length\" or self.padding == PaddingStrategy.MAX_LENGTH:\n+                if self.max_length is not None:\n+                    max_label_length = self.max_length\n             if self.pad_to_multiple_of is not None:\n                 max_label_length = (\n                     (max_label_length + self.pad_to_multiple_of - 1)\n"}
{"instance_id": "huggingface__transformers-30934", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex 016fae4405..fc686b1e68 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -489,12 +489,13 @@ def center_crop(\n     right_pad = left_pad + orig_width\n     new_image[..., top_pad:bottom_pad, left_pad:right_pad] = image\n \n-    top += top_pad\n-    bottom += top_pad\n-    left += left_pad\n-    right += left_pad\n+    # Recalculate crop coordinates for the padded image\n+    top = (new_height - crop_height) // 2\n+    bottom = top + crop_height\n+    left = (new_width - crop_width) // 2\n+    right = left + crop_width\n \n-    new_image = new_image[..., max(0, top) : min(new_height, bottom), max(0, left) : min(new_width, right)]\n+    new_image = new_image[..., top:bottom, left:right]\n     new_image = to_channel_dimension_format(new_image, output_data_format, ChannelDimension.FIRST)\n \n     if not return_numpy:\n"}
{"instance_id": "huggingface__transformers-31448", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/generation/stopping_criteria.py b/src/transformers/generation/stopping_criteria.py\nindex 9cc485e460..0d864b0500 100644\n--- a/src/transformers/generation/stopping_criteria.py\n+++ b/src/transformers/generation/stopping_criteria.py\n@@ -374,9 +374,11 @@ class StopStringCriteria(StoppingCriteria):\n         )\n \n         max_valid_positions = max(\n-            len(val) for positions in token_valid_positions.values() for val in positions.values()\n+            (len(val) for positions in token_valid_positions.values() for val in positions.values()), default=1\n+        )\n+        max_valid_end_lens = max(\n+            (len(val) for positions in token_end_overlaps.values() for val in positions.values()), default=1\n         )\n-        max_valid_end_lens = max(len(val) for positions in token_end_overlaps.values() for val in positions.values())\n         vec_size = len(stop_strings) * (max_valid_positions + max_valid_end_lens) + 1\n         gather_vec = np.full((len(token_list), vec_size), dtype=np.int32, fill_value=-1)\n \n"}
{"instance_id": "huggingface__transformers-29688", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/whisper/generation_whisper.py b/src/transformers/models/whisper/generation_whisper.py\nindex b3865140f2..4428555f61 100644\n--- a/src/transformers/models/whisper/generation_whisper.py\n+++ b/src/transformers/models/whisper/generation_whisper.py\n@@ -262,7 +262,7 @@ class WhisperGenerationMixin:\n         synced_gpus: bool = False,\n         return_timestamps: Optional[bool] = None,\n         task: Optional[str] = None,\n-        language: Optional[str] = None,\n+        language: Optional[Union[str, List[str]]] = None,\n         is_multilingual: Optional[bool] = None,\n         prompt_ids: Optional[torch.Tensor] = None,\n         prompt_condition_type: Optional[str] = None,  # first-segment, all-segments\n@@ -329,8 +329,9 @@ class WhisperGenerationMixin:\n             task (`str`, *optional*):\n                 Task to use for generation, either \"translate\" or \"transcribe\". The `model.config.forced_decoder_ids`\n                 will be updated accordingly.\n-            language (`str`, *optional*):\n-                Language token to use for generation, can be either in the form of `<|en|>`, `en` or `english`. You can\n+            language (`str` or `list` of `str`, *optional*):\n+                Language token to use for generation, can be either in the form of `<|en|>`, `en` or `english`. For\n+                batched generation, a list of language tokens can be passed, one for each sample in the batch. You can\n                 find all the possible language tokens in the `model.generation_config.lang_to_id` dictionary.\n             is_multilingual (`bool`, *optional*):\n                 Whether or not the model is multilingual.\n@@ -529,6 +530,7 @@ class WhisperGenerationMixin:\n         # pass self.config for backward compatibility\n         init_tokens = self._retrieve_init_tokens(\n             input_features,\n+            batch_size=batch_size,\n             generation_config=generation_config,\n             config=self.config,\n             num_segment_frames=num_segment_frames,\n@@ -539,7 +541,10 @@ class WhisperGenerationMixin:\n         self._check_decoder_input_ids(kwargs=kwargs)\n \n         # 3. Retrieve logits processors\n-        begin_index = len(init_tokens)\n+        # init_tokens can be a list of lists (one per batch item) for multilingual batches\n+        # or a single list for single-language batches\n+        is_multilingual_batch = isinstance(init_tokens[0], (list, tuple))\n+        begin_index = len(init_tokens[0]) if is_multilingual_batch else len(init_tokens)\n         logits_processor = self._retrieve_logit_processors(\n             generation_config=generation_config,\n             logits_processor=logits_processor,\n@@ -555,8 +560,12 @@ class WhisperGenerationMixin:\n \n             decoder_input_ids = kwargs.pop(\"decoder_input_ids\", None)\n             if decoder_input_ids is None:\n-                one_tensor = torch.ones((batch_size, 1), device=self.device, dtype=torch.long)\n-                decoder_input_ids = torch.cat([t * one_tensor for t in init_tokens], dim=-1)\n+                if is_multilingual_batch:\n+                    # For multilingual batches, each batch item has its own init_tokens\n+                    decoder_input_ids = torch.tensor(init_tokens, device=self.device, dtype=torch.long)\n+                else:\n+                    one_tensor = torch.ones((batch_size, 1), device=self.device, dtype=torch.long)\n+                    decoder_input_ids = torch.cat([t * one_tensor for t in init_tokens], dim=-1)\n \n             if prompt_ids is not None:\n                 decoder_input_ids = torch.cat(\n@@ -1070,8 +1079,12 @@ class WhisperGenerationMixin:\n                     \"to `generate`. Either set the language using the `forced_decoder_ids` in the model config, \"\n                     \"or update the generation config as per the instructions https://github.com/huggingface/transformers/issues/25084#issuecomment-1664398224\"\n                 )\n-            language = language.lower()\n-            generation_config.language = language\n+            # language can be a list for batched generation\n+            if isinstance(language, (list, tuple)):\n+                generation_config.language = [lang.lower() for lang in language]\n+            else:\n+                language = language.lower()\n+                generation_config.language = language\n \n         if task is not None:\n             if not hasattr(generation_config, \"task_to_id\"):\n@@ -1082,7 +1095,7 @@ class WhisperGenerationMixin:\n                 )\n             generation_config.task = task\n \n-    def _retrieve_init_tokens(self, input_features, generation_config, config, num_segment_frames, kwargs):\n+    def _retrieve_init_tokens(self, input_features, batch_size, generation_config, config, num_segment_frames, kwargs):\n         def replace_or_add(lst: List[int], num: int, itr: Iterator[int]):\n             \"\"\"short function to replace num with a itr in lst\"\"\"\n             found = any(i in lst for i in itr)\n@@ -1092,6 +1105,27 @@ class WhisperGenerationMixin:\n                 lst.append(num)\n             return lst\n \n+        def language_to_id(language: str) -> int:\n+            \"\"\"Map a language string to its corresponding token id.\"\"\"\n+            if language in generation_config.lang_to_id.keys():\n+                language_token = language\n+            elif language in TO_LANGUAGE_CODE.keys():\n+                language_token = f\"<|{TO_LANGUAGE_CODE[language]}|>\"\n+            elif language in TO_LANGUAGE_CODE.values():\n+                language_token = f\"<|{language}|>\"\n+            else:\n+                is_language_code = len(language) == 2\n+                raise ValueError(\n+                    f\"Unsupported language: {language}. Language should be one of:\"\n+                    f\" {list(TO_LANGUAGE_CODE.values()) if is_language_code else list(TO_LANGUAGE_CODE.keys())}.\"\n+                )\n+            if language_token not in generation_config.lang_to_id:\n+                raise ValueError(\n+                    f\"{language_token} is not supported by this specific model as it is not in the `generation_config.lang_to_id`.\"\n+                    \"(You should just add it to the generation config)\"\n+                )\n+            return generation_config.lang_to_id[language_token]\n+\n         task = getattr(generation_config, \"task\", None)\n         language = getattr(generation_config, \"language\", None)\n \n@@ -1133,50 +1167,48 @@ class WhisperGenerationMixin:\n         generation_config.forced_decoder_ids = None\n \n         is_lang_id_undefined = len(init_tokens) <= 1 or (len(init_tokens) > 1 and init_tokens[1] is None)\n-        if language is not None:\n-            if language in generation_config.lang_to_id.keys():\n-                language_token = language\n-            elif language in TO_LANGUAGE_CODE.keys():\n-                language_token = f\"<|{TO_LANGUAGE_CODE[language]}|>\"\n-            elif language in TO_LANGUAGE_CODE.values():\n-                language_token = f\"<|{language}|>\"\n-            else:\n-                is_language_code = len(language) == 2\n-                raise ValueError(\n-                    f\"Unsupported language: {language}. Language should be one of:\"\n-                    f\" {list(TO_LANGUAGE_CODE.values()) if is_language_code else list(TO_LANGUAGE_CODE.keys())}.\"\n-                )\n-            if language_token not in generation_config.lang_to_id:\n+\n+        # language is a list of languages for batched generation\n+        multilingual = isinstance(language, (list, tuple))\n+        if multilingual:\n+            if batch_size != len(language):\n                 raise ValueError(\n-                    f\"{language_token} is not supported by this specific model as it is not in the `generation_config.lang_to_id`.\"\n-                    \"(You should just add it to the generation config)\"\n+                    f\"When passing a list of languages, the length of the list must match the batch size. \"\n+                    f\"Got batch size {batch_size} and {len(language)} languages.\"\n                 )\n-\n-            lang_id = generation_config.lang_to_id[language_token]\n-\n+            # Convert each language to its corresponding token id\n+            lang_ids = [language_to_id(lang) for lang in language]\n+\n+            # Check if all languages are the same - if so, we can use the single-language path\n+            if len(set(lang_ids)) == 1:\n+                lang_id = lang_ids[0]\n+                replace_or_add(init_tokens, lang_id, generation_config.lang_to_id.values())\n+                multilingual = False\n+        elif language is not None:\n+            lang_id = language_to_id(language)\n             # if language is defined it'll overwrite language ids that might have already been defined via the generation_config\n             replace_or_add(init_tokens, lang_id, generation_config.lang_to_id.values())\n         elif hasattr(generation_config, \"lang_to_id\") and is_lang_id_undefined:\n-            # language is not defined or intentially set to `None` to trigger language detection\n-            lang_ids = self.detect_language(\n+            # language is not defined or intentionally set to `None` to trigger language detection\n+            lang_ids_tensor = self.detect_language(\n                 input_features=input_features,\n                 encoder_outputs=kwargs.get(\"encoder_outputs\", None),\n                 generation_config=generation_config,\n                 num_segment_frames=num_segment_frames,\n             )\n \n-            if torch.unique(lang_ids).shape[0] > 1:\n-                raise ValueError(\n-                    \"Multiple languages detected when trying to predict the most likely target language for transcription. It is currently not supported to transcribe to different languages in a single batch. Please make sure to either force a single language by passing `language='...'` or make sure all input audio is of the same language.\"\n-                )\n-\n-            lang_id = lang_ids[0].item()\n-\n-            # append or replace lang_id to init_tokens\n-            if len(init_tokens) > 1:\n-                init_tokens[1] = lang_id\n+            # Check if all detected languages are the same\n+            if torch.unique(lang_ids_tensor).shape[0] > 1:\n+                # Multiple languages detected - use per-batch init tokens\n+                multilingual = True\n+                lang_ids = lang_ids_tensor.tolist()\n             else:\n-                init_tokens.append(lang_id)\n+                lang_id = lang_ids_tensor[0].item()\n+                # append or replace lang_id to init_tokens\n+                if len(init_tokens) > 1:\n+                    init_tokens[1] = lang_id\n+                else:\n+                    init_tokens.append(lang_id)\n \n         if task is not None:\n             if task in TASK_IDS:\n@@ -1207,6 +1239,24 @@ class WhisperGenerationMixin:\n         # let's make sure we don't pass `None` tokens as prompt tokens\n         init_tokens = [t for t in init_tokens if t is not None]\n \n+        # If multilingual, create per-batch init_tokens\n+        if multilingual:\n+            # Create a copy of init_tokens for each batch item with the appropriate language id\n+            all_init_tokens = []\n+            for lang_id in lang_ids:\n+                batch_init_tokens = init_tokens.copy()\n+                # Replace or add the language id at position 1 (after decoder_start_token_id)\n+                if len(batch_init_tokens) > 1:\n+                    # Check if position 1 is a language id and replace it\n+                    if batch_init_tokens[1] in generation_config.lang_to_id.values():\n+                        batch_init_tokens[1] = lang_id\n+                    else:\n+                        batch_init_tokens.insert(1, lang_id)\n+                else:\n+                    batch_init_tokens.append(lang_id)\n+                all_init_tokens.append(batch_init_tokens)\n+            return all_init_tokens\n+\n         return init_tokens\n \n     def detect_language(\n@@ -1458,8 +1508,16 @@ class WhisperGenerationMixin:\n     ):\n         cut_off_length = config.max_target_positions // 2 - 1\n \n-        one_tensor = torch.ones((cur_bsz, 1), device=device, dtype=torch.long)\n-        decoder_input_ids = torch.cat([t * one_tensor for t in init_tokens], dim=-1)\n+        # init_tokens can be a list of lists (one per batch item) for multilingual batches\n+        # or a single list for single-language batches\n+        is_multilingual_batch = isinstance(init_tokens[0], (list, tuple))\n+        if is_multilingual_batch:\n+            # For multilingual batches, select the init_tokens for the current batch items\n+            current_init_tokens = [init_tokens[i] for i in batch_idx_map]\n+            decoder_input_ids = torch.tensor(current_init_tokens, device=device, dtype=torch.long)\n+        else:\n+            one_tensor = torch.ones((cur_bsz, 1), device=device, dtype=torch.long)\n+            decoder_input_ids = torch.cat([t * one_tensor for t in init_tokens], dim=-1)\n \n         prev_start_of_text = getattr(generation_config, \"prev_sot_token_id\", None)\n         if prev_start_of_text is None:\n"}
{"instance_id": "huggingface__transformers-31217", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/pipelines/visual_question_answering.py b/src/transformers/pipelines/visual_question_answering.py\nindex 9106b19d33..f3ea507d19 100644\n--- a/src/transformers/pipelines/visual_question_answering.py\n+++ b/src/transformers/pipelines/visual_question_answering.py\n@@ -1,4 +1,4 @@\n-from typing import Union\n+from typing import List, Union\n \n from ..utils import add_end_docstrings, is_torch_available, is_vision_available, logging\n from .base import Pipeline, build_pipeline_init_args\n@@ -67,7 +67,9 @@ class VisualQuestionAnsweringPipeline(Pipeline):\n             postprocess_params[\"top_k\"] = top_k\n         return preprocess_params, {}, postprocess_params\n \n-    def __call__(self, image: Union[\"Image.Image\", str], question: str = None, **kwargs):\n+    def __call__(\n+        self, image: Union[\"Image.Image\", str, List[\"Image.Image\"], List[str]], question: Union[str, List[str]] = None, **kwargs\n+    ):\n         r\"\"\"\n         Answers open-ended questions about images. The pipeline accepts several types of inputs which are detailed\n         below:\n@@ -103,6 +105,17 @@ class VisualQuestionAnsweringPipeline(Pipeline):\n         \"\"\"\n         if isinstance(image, (Image.Image, str)) and isinstance(question, str):\n             inputs = {\"image\": image, \"question\": question}\n+        elif isinstance(image, list) and isinstance(question, str):\n+            # If image is a list and question is a string, broadcast the question to all images\n+            inputs = [{\"image\": img, \"question\": question} for img in image]\n+        elif isinstance(image, (Image.Image, str)) and isinstance(question, list):\n+            # If image is a string/Image and question is a list, broadcast the image to all questions\n+            inputs = [{\"image\": image, \"question\": q} for q in question]\n+        elif isinstance(image, list) and isinstance(question, list):\n+            # If both are lists, pair them up\n+            if len(image) != len(question):\n+                raise ValueError(\"When both image and question are lists, they must have the same length.\")\n+            inputs = [{\"image\": img, \"question\": q} for img, q in zip(image, question)]\n         else:\n             \"\"\"\n             Supports the following format\n"}
{"instance_id": "huggingface__transformers-31646", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/encodec/modeling_encodec.py b/src/transformers/models/encodec/modeling_encodec.py\nindex 9627742b9e..1d4efc54a4 100644\n--- a/src/transformers/models/encodec/modeling_encodec.py\n+++ b/src/transformers/models/encodec/modeling_encodec.py\n@@ -602,7 +602,7 @@ class EncodecModel(EncodecPreTrainedModel):\n             factors for each chunk when `normalize` is True. Each frames is a tuple `(codebook, scale)`, with\n             `codebook` of shape `[batch_size, num_codebooks, frames]`.\n         \"\"\"\n-        return_dict = return_dict if return_dict is not None else self.config.return_dict\n+        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         if bandwidth is None:\n             bandwidth = self.config.target_bandwidths[0]\n@@ -729,7 +729,7 @@ class EncodecModel(EncodecPreTrainedModel):\n                 Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n \n         \"\"\"\n-        return_dict = return_dict or self.config.return_dict\n+        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         chunk_length = self.config.chunk_length\n         if chunk_length is None:\n@@ -786,7 +786,7 @@ class EncodecModel(EncodecPreTrainedModel):\n         >>> audio_codes = outputs.audio_codes\n         >>> audio_values = outputs.audio_values\n         ```\"\"\"\n-        return_dict = return_dict or self.config.return_dict\n+        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         if padding_mask is None:\n             padding_mask = torch.ones_like(input_values).bool()\n"}
{"instance_id": "huggingface__transformers-30964", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/llama/tokenization_llama.py b/src/transformers/models/llama/tokenization_llama.py\nindex 5392afb763..631a4cf56a 100644\n--- a/src/transformers/models/llama/tokenization_llama.py\n+++ b/src/transformers/models/llama/tokenization_llama.py\n@@ -167,8 +167,8 @@ class LlamaTokenizer(PreTrainedTokenizer):\n         self.add_bos_token = add_bos_token\n         self.add_eos_token = add_eos_token\n         self.use_default_system_prompt = use_default_system_prompt\n-        self.sp_model = self.get_spm_processor(kwargs.pop(\"from_slow\", False))\n         self.add_prefix_space = add_prefix_space\n+        self.sp_model = self.get_spm_processor(kwargs.pop(\"from_slow\", False))\n \n         super().__init__(\n             bos_token=bos_token,\n@@ -190,10 +190,9 @@ class LlamaTokenizer(PreTrainedTokenizer):\n     def unk_token_length(self):\n         return len(self.sp_model.encode(str(self.unk_token)))\n \n-    # Copied from transformers.models.t5.tokenization_t5.T5Tokenizer.get_spm_processor\n     def get_spm_processor(self, from_slow=False):\n         tokenizer = spm.SentencePieceProcessor(**self.sp_model_kwargs)\n-        if self.legacy or from_slow:  # no dependency on protobuf\n+        if self.legacy and self.add_prefix_space:  # no dependency on protobuf\n             tokenizer.Load(self.vocab_file)\n             return tokenizer\n \ndiff --git a/src/transformers/models/llama/tokenization_llama_fast.py b/src/transformers/models/llama/tokenization_llama_fast.py\nindex 580290841c..568be24685 100644\n--- a/src/transformers/models/llama/tokenization_llama_fast.py\n+++ b/src/transformers/models/llama/tokenization_llama_fast.py\n@@ -164,6 +164,7 @@ class LlamaTokenizerFast(PreTrainedTokenizerFast):\n             add_eos_token=add_eos_token,\n             use_default_system_prompt=use_default_system_prompt,\n             legacy=legacy,\n+            add_prefix_space=add_prefix_space,\n             **kwargs,\n         )\n         self._add_bos_token = add_bos_token\n"}
{"instance_id": "huggingface__transformers-5122", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex 5e014d338b..d575f48d6c 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -42,10 +42,10 @@ def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Ten\n     # Special handling for labels.\n     # Ensure that tensor is created with the correct type\n     # (it should be automatically the case, but let's make sure of it.)\n-    if \"label\" in first:\n+    if \"label\" in first and first[\"label\"] is not None:\n         dtype = torch.long if type(first[\"label\"]) is int else torch.float\n         batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n-    elif \"label_ids\" in first:\n+    elif \"label_ids\" in first and first[\"label_ids\"] is not None:\n         if isinstance(first[\"label_ids\"], torch.Tensor):\n             batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n         else:\n"}
{"instance_id": "huggingface__transformers-3716", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/modeling_tf_transfo_xl.py b/src/transformers/modeling_tf_transfo_xl.py\nindex d0f589ed1a..e1a214c629 100644\n--- a/src/transformers/modeling_tf_transfo_xl.py\n+++ b/src/transformers/modeling_tf_transfo_xl.py\n@@ -847,7 +847,13 @@ class TFTransfoXLLMHeadModel(TFTransfoXLPreTrainedModel):\n         pred_hid = last_hidden[:, -tgt_len:]\n         outputs = transformer_outputs[1:]\n \n-        softmax_output = self.crit([pred_hid, labels], training=training)\n+        if labels is not None:\n+            # Shift so that tokens < n predict n\n+            shift_hidden = pred_hid[:, :-1]\n+            shift_labels = labels[:, 1:]\n+            softmax_output = self.crit([shift_hidden, shift_labels], training=training)\n+        else:\n+            softmax_output = self.crit([pred_hid, None], training=training)\n         outputs = [softmax_output] + outputs\n \n         return outputs  # logits, new_mems, (all hidden states), (all attentions)\ndiff --git a/src/transformers/modeling_transfo_xl.py b/src/transformers/modeling_transfo_xl.py\nindex 1ed8408966..901d8d39fa 100644\n--- a/src/transformers/modeling_transfo_xl.py\n+++ b/src/transformers/modeling_transfo_xl.py\n@@ -904,13 +904,17 @@ class TransfoXLLMHeadModel(TransfoXLPreTrainedModel):\n         pred_hid = last_hidden[:, -tgt_len:]\n         outputs = transformer_outputs[1:]\n \n-        softmax_output = self.crit(pred_hid.view(-1, pred_hid.size(-1)), labels)\n-        if labels is None:\n+        if labels is not None:\n+            # Shift so that tokens < n predict n\n+            shift_hidden = pred_hid[..., :-1, :].contiguous()\n+            shift_labels = labels[..., 1:].contiguous()\n+            softmax_output = self.crit(shift_hidden.view(-1, shift_hidden.size(-1)), shift_labels.view(-1))\n+            softmax_output = softmax_output.view(bsz, tgt_len - 1)\n+            outputs = [softmax_output, None] + outputs\n+        else:\n+            softmax_output = self.crit(pred_hid.view(-1, pred_hid.size(-1)), None)\n             softmax_output = softmax_output.view(bsz, tgt_len, -1)\n             outputs = [softmax_output] + outputs\n-        else:\n-            softmax_output = softmax_output.view(bsz, tgt_len)\n-            outputs = [softmax_output, None] + outputs\n \n         return outputs  # (loss), logits or None if labels is not None (speed up adaptive softmax), new_mems, (all hidden states), (all attentions)\n \n"}
{"instance_id": "huggingface__transformers-6098", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/tokenization_bart.py b/src/transformers/tokenization_bart.py\nindex c83ad0d333..8f4893e815 100644\n--- a/src/transformers/tokenization_bart.py\n+++ b/src/transformers/tokenization_bart.py\n@@ -124,10 +124,18 @@ class MBartTokenizer(XLMRobertaTokenizer):\n         self.cur_lang_code = self.lang_code_to_id[\"en_XX\"]\n \n         self.fairseq_tokens_to_ids.update(self.lang_code_to_id)\n+\n+        # The <mask> token should be added after all language codes (as in fairseq)\n+        self.fairseq_tokens_to_ids[\"<mask>\"] = len(self.sp_model) + len(FAIRSEQ_LANGUAGE_CODES) + self.fairseq_offset\n+\n         self.fairseq_ids_to_tokens = {v: k for k, v in self.fairseq_tokens_to_ids.items()}\n         self._additional_special_tokens = list(self.lang_code_to_id.keys())\n         self.set_src_lang_special_tokens(kwargs.get(\"src_lang\", \"en_XX\"))\n \n+    @property\n+    def vocab_size(self):\n+        return len(self.sp_model) + len(FAIRSEQ_LANGUAGE_CODES) + self.fairseq_offset + 1  # Plus 1 for the mask token\n+\n     def build_inputs_with_special_tokens(\n         self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n     ) -> List[int]:\n"}
{"instance_id": "huggingface__transformers-4759", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/modeling_transfo_xl.py b/src/transformers/modeling_transfo_xl.py\nindex 25c3592999..f89c7428b9 100644\n--- a/src/transformers/modeling_transfo_xl.py\n+++ b/src/transformers/modeling_transfo_xl.py\n@@ -20,6 +20,7 @@\n \n \n import logging\n+from typing import Optional\n \n import torch\n import torch.nn as nn\n@@ -457,6 +458,118 @@ class TransfoXLPreTrainedModel(PreTrainedModel):\n     load_tf_weights = load_tf_weights_in_transfo_xl\n     base_model_prefix = \"transformer\"\n \n+    def resize_token_embeddings(self, new_num_tokens: Optional[int] = None, layer: Optional[int] = -1):\n+        \"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n+        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n+\n+        Arguments:\n+\n+            new_num_tokens: (`optional`) int:\n+                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n+                If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n+            layer: (`optional`) int:\n+                Layer of the `AdaptiveEmbedding` where the resizing should be done. Per default the last layer will be resized.\n+                Be aware that when resizing other than the last layer, you have to ensure that the new token(s) in the tokenizer are at the corresponding position.\n+\n+        Return: ``bool``\n+            Whether or not the embeddings were resized.\n+        \"\"\"\n+        base_model = getattr(self, self.base_model_prefix, self)  # get the base model if needed\n+        new_embeddings = base_model._resize_token_embeddings(new_num_tokens, layer)\n+        if new_num_tokens is None:\n+            return new_embeddings\n+\n+        # Update base model and current model config\n+        self.config.vocab_size = new_num_tokens\n+        base_model.n_token = new_num_tokens\n+\n+        # Tie weights again if needed\n+        self.tie_weights()\n+\n+        return new_embeddings is not None\n+\n+    def _resize_token_embeddings(self, new_num_tokens, layer=-1):\n+        old_embeddings = self.get_input_embeddings()\n+        new_embeddings = self._get_resized_embeddings(old_embeddings, new_num_tokens, layer)\n+        self.set_input_embeddings(new_embeddings)\n+        return new_embeddings\n+\n+    def _get_resized_embeddings(self, old_embeddings, new_num_tokens, layer=-1):\n+        \"\"\" Build a resized Embedding Module from a provided AdaptiveEmbedding Module.\n+            Increasing the size will add newly initialized vectors at the end\n+            Reducing the size will remove vectors from the end\n+\n+        Args:\n+            old_embeddings: ``AdaptiveEmbedding``\n+                Old embeddings to be resized.\n+            new_num_tokens: (`optional`) int\n+                New number of tokens in the embedding matrix.\n+                Increasing the size will add newly initialized vectors at the end\n+                Reducing the size will remove vectors from the end\n+                If not provided or None: return the provided token Embedding Module.\n+            layer: int\n+                Layer of the `AdaptiveEmbedding` where the resizing should be done.\n+                Per default the last layer will be resized.\n+        Return: ``AdaptiveEmbedding``\n+            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n+        \"\"\"\n+        if new_num_tokens is None:\n+            return old_embeddings\n+\n+        old_num_tokens = old_embeddings.n_token\n+        if old_num_tokens == new_num_tokens:\n+            return old_embeddings\n+\n+        if not isinstance(old_embeddings, AdaptiveEmbedding):\n+            raise NotImplementedError(\n+                f\"The embeddings are of type {type(old_embeddings)} which is not supported. \"\n+                \"Only AdaptiveEmbedding is supported for resizing.\"\n+            )\n+\n+        # Build new embeddings\n+        new_embeddings = AdaptiveEmbedding(\n+            new_num_tokens,\n+            old_embeddings.d_embed,\n+            old_embeddings.d_proj,\n+            old_embeddings.cutoffs[:-1],  # cutoffs already includes n_token, so we remove it\n+            div_val=old_embeddings.div_val,\n+        )\n+        new_embeddings.to(old_embeddings.emb_layers[0].weight.device)\n+\n+        # Copy token embeddings from the previous weights\n+        self._copy_embeddings(new_embeddings, old_embeddings, layer)\n+\n+        return new_embeddings\n+\n+    def _copy_embeddings(self, new_embeddings, old_embeddings, layer=-1):\n+        \"\"\" Copy the embeddings from old_embeddings to new_embeddings.\n+\n+        Args:\n+            new_embeddings: ``AdaptiveEmbedding``\n+                New embeddings to copy to.\n+            old_embeddings: ``AdaptiveEmbedding``\n+                Old embeddings to copy from.\n+            layer: int\n+                Layer of the `AdaptiveEmbedding` where the resizing was done.\n+        \"\"\"\n+        # Copy all layers except the resized one\n+        for i in range(len(old_embeddings.emb_layers)):\n+            if i != layer and i != len(old_embeddings.emb_layers) + layer:\n+                # Copy the entire embedding layer\n+                new_embeddings.emb_layers[i].weight.data = old_embeddings.emb_layers[i].weight.data\n+\n+        # Copy the resized layer\n+        layer_idx = layer if layer >= 0 else len(old_embeddings.emb_layers) + layer\n+        old_layer = old_embeddings.emb_layers[layer_idx]\n+        new_layer = new_embeddings.emb_layers[layer_idx]\n+        num_tokens_to_copy = min(old_layer.weight.size(0), new_layer.weight.size(0))\n+        new_layer.weight.data[:num_tokens_to_copy, :] = old_layer.weight.data[:num_tokens_to_copy, :]\n+\n+        # Copy the projection layers\n+        for i in range(len(old_embeddings.emb_projs)):\n+            if old_embeddings.emb_projs[i] is not None:\n+                new_embeddings.emb_projs[i].data = old_embeddings.emb_projs[i].data\n+\n     def _init_weight(self, weight):\n         if self.config.init == \"uniform\":\n             nn.init.uniform_(weight, -self.config.init_range, self.config.init_range)\n@@ -820,6 +933,78 @@ class TransfoXLLMHeadModel(TransfoXLPreTrainedModel):\n \n         self.init_weights()\n \n+    def resize_token_embeddings(self, new_num_tokens: Optional[int] = None, layer: Optional[int] = -1):\n+        \"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n+        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n+\n+        Arguments:\n+\n+            new_num_tokens: (`optional`) int:\n+                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n+                If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n+            layer: (`optional`) int:\n+                Layer of the `AdaptiveEmbedding` where the resizing should be done. Per default the last layer will be resized.\n+                Be aware that when resizing other than the last layer, you have to ensure that the new token(s) in the tokenizer are at the corresponding position.\n+\n+        Return: ``bool``\n+            Whether or not the embeddings were resized.\n+        \"\"\"\n+        # Resize the input embeddings using the parent class method\n+        new_embeddings = super().resize_token_embeddings(new_num_tokens, layer)\n+\n+        # Resize the output embeddings (ProjectedAdaptiveLogSoftmax)\n+        if new_num_tokens is not None:\n+            self._resize_output_embeddings(new_num_tokens, layer)\n+\n+        return new_embeddings\n+\n+    def _resize_output_embeddings(self, new_num_tokens, layer=-1):\n+        \"\"\" Resize the output embeddings (ProjectedAdaptiveLogSoftmax) to match the new vocabulary size.\n+\n+        Args:\n+            new_num_tokens: int\n+                New number of tokens in the embedding matrix.\n+            layer: int\n+                Layer of the `ProjectedAdaptiveLogSoftmax` where the resizing should be done.\n+                Per default the last layer will be resized.\n+        \"\"\"\n+        old_crit = self.crit\n+        new_crit = ProjectedAdaptiveLogSoftmax(\n+            new_num_tokens,\n+            old_crit.d_embed,\n+            old_crit.d_proj,\n+            old_crit.cutoffs[:-1],  # cutoffs already includes n_token, so we remove it\n+            div_val=old_crit.div_val,\n+        )\n+        new_crit.to(old_crit.out_layers[0].weight.device)\n+\n+        # Copy the cluster weights and biases if they exist\n+        if old_crit.n_clusters > 0:\n+            new_crit.cluster_weight.data = old_crit.cluster_weight.data\n+            new_crit.cluster_bias.data = old_crit.cluster_bias.data\n+\n+        # Copy the output layers\n+        for i in range(len(old_crit.out_layers)):\n+            if i != layer and i != len(old_crit.out_layers) + layer:\n+                # Copy the entire layer\n+                new_crit.out_layers[i].weight.data = old_crit.out_layers[i].weight.data\n+                new_crit.out_layers[i].bias.data = old_crit.out_layers[i].bias.data\n+            else:\n+                # Copy the resized layer\n+                layer_idx = layer if layer >= 0 else len(old_crit.out_layers) + layer\n+                old_layer = old_crit.out_layers[layer_idx]\n+                new_layer = new_crit.out_layers[layer_idx]\n+                num_tokens_to_copy = min(old_layer.weight.size(0), new_layer.weight.size(0))\n+                new_layer.weight.data[:num_tokens_to_copy, :] = old_layer.weight.data[:num_tokens_to_copy, :]\n+                new_layer.bias.data[:num_tokens_to_copy] = old_layer.bias.data[:num_tokens_to_copy]\n+\n+        # Copy the projection layers\n+        for i in range(len(old_crit.out_projs)):\n+            if old_crit.out_projs[i] is not None:\n+                new_crit.out_projs[i].data = old_crit.out_projs[i].data\n+\n+        self.crit = new_crit\n+\n     def tie_weights(self):\n         \"\"\"\n         Run this to be sure output and input (adaptive) softmax weights are tied\n"}
{"instance_id": "huggingface__transformers-30899", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/generation/utils.py b/src/transformers/generation/utils.py\nindex 4b71fe9519..924831a46b 100644\n--- a/src/transformers/generation/utils.py\n+++ b/src/transformers/generation/utils.py\n@@ -1382,6 +1382,18 @@ class GenerationMixin:\n         eos_token_id = _tensor_or_none(generation_config.eos_token_id, device=device)\n         pad_token_id = _tensor_or_none(generation_config.pad_token_id, device=device)\n         decoder_start_token_id = _tensor_or_none(generation_config.decoder_start_token_id, device=device)\n+\n+        # For encoder-decoder models, fall back to the model's generation config for decoder_start_token_id\n+        # and bos_token_id if they are not set in the passed generation config. This is needed because\n+        # decoder_start_token_id is required for encoder-decoder generation.\n+        if self.config.is_encoder_decoder:\n+            if decoder_start_token_id is None:\n+                decoder_start_token_id = _tensor_or_none(\n+                    self.generation_config.decoder_start_token_id, device=device\n+                )\n+            if bos_token_id is None:\n+                bos_token_id = _tensor_or_none(self.generation_config.bos_token_id, device=device)\n+\n         decoder_start_token_id = decoder_start_token_id if decoder_start_token_id is not None else bos_token_id\n \n         # We can have more than one eos token. Always treat it as a 1D tensor (when it exists).\n"}
{"instance_id": "huggingface__transformers-7078", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/tokenization_t5.py b/src/transformers/tokenization_t5.py\nindex fa4ac65699..89fe6ec502 100644\n--- a/src/transformers/tokenization_t5.py\n+++ b/src/transformers/tokenization_t5.py\n@@ -358,8 +358,6 @@ class T5Tokenizer(PreTrainedTokenizer):\n         # Process tgt_texts\n         if max_target_length is None:\n             max_target_length = max_length\n-        # set prefix_tokens for target text\n-        self.prefix_tokens = [self.pad_token_id]\n         labels_and_decoder_mask = self(\n             tgt_texts,\n             add_special_tokens=True,\n"}
{"instance_id": "huggingface__transformers-7374", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/modeling_funnel.py b/src/transformers/modeling_funnel.py\nindex 8c8810d507..ed58ea6502 100644\n--- a/src/transformers/modeling_funnel.py\n+++ b/src/transformers/modeling_funnel.py\n@@ -465,9 +465,9 @@ class FunnelRelMultiheadAttention(nn.Module):\n             # phi and pi have shape seq_len x d_model, psi and omega have shape context_len x d_model\n             phi, pi, psi, omega = position_embeds\n             # Shape n_head x d_head\n-            u = self.r_r_bias * self.scale\n+            u = self.r_r_bias.to(q_head.dtype) * self.scale\n             # Shape d_model x n_head x d_head\n-            w_r = self.r_kernel\n+            w_r = self.r_kernel.to(q_head.dtype)\n \n             # Shape batch_size x sea_len x n_head x d_model\n             q_r_attention = torch.einsum(\"binh,dnh->bind\", q_head + u, w_r)\n@@ -484,9 +484,9 @@ class FunnelRelMultiheadAttention(nn.Module):\n             # Grab the proper positional encoding, shape max_rel_len x d_model\n             r = position_embeds[self.block_index][shift - 1]\n             # Shape n_head x d_head\n-            v = self.r_r_bias * self.scale\n+            v = self.r_r_bias.to(q_head.dtype) * self.scale\n             # Shape d_model x n_head x d_head\n-            w_r = self.r_kernel\n+            w_r = self.r_kernel.to(q_head.dtype)\n \n             # Shape max_rel_len x n_head x d_model\n             r_head = torch.einsum(\"td,dnh->tnh\", r, w_r)\n@@ -506,10 +506,10 @@ class FunnelRelMultiheadAttention(nn.Module):\n         batch_size, seq_len, context_len = token_type_mat.shape\n         # q_head has shape batch_size x seq_len x n_head x d_head\n         # Shape n_head x d_head\n-        r_s_bias = self.r_s_bias * self.scale\n+        r_s_bias = self.r_s_bias.to(q_head.dtype) * self.scale\n \n         # Shape batch_size x n_head x seq_len x 2\n-        token_type_bias = torch.einsum(\"bind,snd->bnis\", q_head + r_s_bias, self.seg_embed)\n+        token_type_bias = torch.einsum(\"bind,snd->bnis\", q_head + r_s_bias, self.seg_embed.to(q_head.dtype))\n         # Shape batch_size x n_head x seq_len x context_len\n         token_type_mat = token_type_mat[:, None].expand([batch_size, q_head.shape[2], seq_len, context_len])\n         # Shapes batch_size x n_head x seq_len\n@@ -540,7 +540,7 @@ class FunnelRelMultiheadAttention(nn.Module):\n \n         q_head = q_head * self.scale\n         # Shape n_head x d_head\n-        r_w_bias = self.r_w_bias * self.scale\n+        r_w_bias = self.r_w_bias.to(q_head.dtype) * self.scale\n         # Shapes batch_size x n_head x seq_len x context_len\n         content_score = torch.einsum(\"bind,bjnd->bnij\", q_head + r_w_bias, k_head)\n         positional_attn = self.relative_positional_attention(position_embeds, q_head, context_len, cls_mask)\n"}
{"instance_id": "huggingface__transformers-7075", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/benchmark/benchmark.py b/src/transformers/benchmark/benchmark.py\nindex d36f589ed1..8ad36e1d8b 100644\n--- a/src/transformers/benchmark/benchmark.py\n+++ b/src/transformers/benchmark/benchmark.py\n@@ -229,7 +229,7 @@ class PyTorchBenchmark(Benchmark):\n             if self.args.is_tpu:\n                 # tpu\n                 raise NotImplementedError(\n-                    \"Memory Benchmarking is currently not implemented for TPU. Please disable memory benchmarking with `--no_memory` or `args.no_memory=True`\"\n+                    \"Memory Benchmarking is currently not implemented for TPU. Please disable memory benchmarking with `--no-memory` or `args.memory=False`\"\n                 )\n             elif self.args.is_gpu:\n                 if not is_py3nvml_available():\ndiff --git a/src/transformers/benchmark/benchmark_args.py b/src/transformers/benchmark/benchmark_args.py\nindex aecefd8ba1..d46ba4f733 100644\n--- a/src/transformers/benchmark/benchmark_args.py\n+++ b/src/transformers/benchmark/benchmark_args.py\n@@ -50,7 +50,7 @@ class PyTorchBenchmarkArguments(BenchmarkArguments):\n     @torch_required\n     def _setup_devices(self) -> Tuple[\"torch.device\", int]:\n         logger.info(\"PyTorch: setting up devices\")\n-        if self.no_cuda:\n+        if not self.cuda:\n             device = torch.device(\"cpu\")\n             n_gpu = 0\n         elif is_torch_tpu_available():\n@@ -63,7 +63,7 @@ class PyTorchBenchmarkArguments(BenchmarkArguments):\n \n     @property\n     def is_tpu(self):\n-        return is_torch_tpu_available() and not self.no_tpu\n+        return is_torch_tpu_available() and self.tpu\n \n     @property\n     @torch_required\ndiff --git a/src/transformers/benchmark/benchmark_args_tf.py b/src/transformers/benchmark/benchmark_args_tf.py\nindex 2b005df68b..fbb4578ce9 100644\n--- a/src/transformers/benchmark/benchmark_args_tf.py\n+++ b/src/transformers/benchmark/benchmark_args_tf.py\n@@ -50,7 +50,8 @@ class TensorFlowBenchmarkArguments(BenchmarkArguments):\n     @cached_property\n     @tf_required\n     def _setup_tpu(self) -> Tuple[\"tf.distribute.cluster_resolver.TPUClusterResolver\"]:\n-        if not self.no_tpu:\n+        tpu = None\n+        if self.tpu:\n             try:\n                 if self.tpu_name:\n                     tpu = tf.distribute.cluster_resolver.TPUClusterResolver(self.tpu_name)\n@@ -98,7 +99,7 @@ class TensorFlowBenchmarkArguments(BenchmarkArguments):\n     @property\n     @tf_required\n     def n_gpu(self) -> int:\n-        if not self.no_cuda:\n+        if self.cuda:\n             return len(self.gpu_list)\n         return 0\n \ndiff --git a/src/transformers/benchmark/benchmark_args_utils.py b/src/transformers/benchmark/benchmark_args_utils.py\nindex afabee2794..3c4f2f6a15 100644\n--- a/src/transformers/benchmark/benchmark_args_utils.py\n+++ b/src/transformers/benchmark/benchmark_args_utils.py\n@@ -57,22 +57,22 @@ class BenchmarkArguments:\n         metadata={\"help\": \"List of sequence lengths for which memory and time performance will be evaluated\"},\n     )\n \n-    no_inference: bool = field(default=False, metadata={\"help\": \"Don't benchmark inference of model\"})\n-    no_cuda: bool = field(default=False, metadata={\"help\": \"Whether to run on available cuda devices\"})\n-    no_tpu: bool = field(default=False, metadata={\"help\": \"Whether to run on available tpu devices\"})\n+    inference: bool = field(default=True, metadata={\"help\": \"Whether to benchmark inference of model\"})\n+    cuda: bool = field(default=True, metadata={\"help\": \"Whether to run on available cuda devices\"})\n+    tpu: bool = field(default=True, metadata={\"help\": \"Whether to run on available tpu devices\"})\n     fp16: bool = field(default=False, metadata={\"help\": \"Use FP16 to accelerate inference.\"})\n     training: bool = field(default=False, metadata={\"help\": \"Benchmark training of model\"})\n     verbose: bool = field(default=False, metadata={\"help\": \"Verbose memory tracing\"})\n-    no_speed: bool = field(default=False, metadata={\"help\": \"Don't perform speed measurements\"})\n-    no_memory: bool = field(default=False, metadata={\"help\": \"Don't perform memory measurements\"})\n+    speed: bool = field(default=True, metadata={\"help\": \"Whether to perform speed measurements\"})\n+    memory: bool = field(default=True, metadata={\"help\": \"Whether to perform memory measurements\"})\n     trace_memory_line_by_line: bool = field(default=False, metadata={\"help\": \"Trace memory line by line\"})\n     save_to_csv: bool = field(default=False, metadata={\"help\": \"Save result to a CSV file\"})\n     log_print: bool = field(default=False, metadata={\"help\": \"Save all print statements in a log file\"})\n-    no_env_print: bool = field(default=False, metadata={\"help\": \"Don't print environment information\"})\n-    no_multi_process: bool = field(\n-        default=False,\n+    env_print: bool = field(default=True, metadata={\"help\": \"Whether to print environment information\"})\n+    multi_process: bool = field(\n+        default=True,\n         metadata={\n-            \"help\": \"Don't use multiprocessing for memory and speed measurement. It is highly recommended to use multiprocessing for accurate CPU and GPU memory measurements. This option should only be used for debugging / testing and on TPU.\"\n+            \"help\": \"Whether to use multiprocessing for memory and speed measurement. It is highly recommended to use multiprocessing for accurate CPU and GPU memory measurements. Disabling this option should only be done for debugging / testing and on TPU.\"\n         },\n     )\n     inference_time_csv_file: str = field(\n@@ -122,7 +122,7 @@ class BenchmarkArguments:\n \n     @property\n     def do_multi_processing(self):\n-        if self.no_multi_process:\n+        if not self.multi_process:\n             return False\n         elif self.is_tpu:\n             logger.info(\"Multiprocessing is currently not possible on TPU.\")\ndiff --git a/src/transformers/benchmark/benchmark_tf.py b/src/transformers/benchmark/benchmark_tf.py\nindex 93e0e35a83..debbd1c3fa 100644\n--- a/src/transformers/benchmark/benchmark_tf.py\n+++ b/src/transformers/benchmark/benchmark_tf.py\n@@ -248,7 +248,7 @@ class TensorFlowBenchmark(Benchmark):\n                 if self.args.is_tpu:\n                     # tpu\n                     raise NotImplementedError(\n-                        \"Memory Benchmarking is currently not implemented for TPU. Please disable memory benchmarking with `args.no_memory=True`\"\n+                        \"Memory Benchmarking is currently not implemented for TPU. Please disable memory benchmarking with `--no-memory` or `args.memory=False`\"\n                     )\n                 elif self.args.is_gpu:\n                     # gpu\ndiff --git a/src/transformers/benchmark/benchmark_utils.py b/src/transformers/benchmark/benchmark_utils.py\nindex 46ab489e86..91bfe35587 100644\n--- a/src/transformers/benchmark/benchmark_utils.py\n+++ b/src/transformers/benchmark/benchmark_utils.py\n@@ -584,9 +584,9 @@ class Benchmark(ABC):\n         else:\n             self.config_dict = {model_name: config for model_name, config in zip(self.args.model_names, configs)}\n \n-        if not self.args.no_memory and os.getenv(\"TRANSFORMERS_USE_MULTIPROCESSING\") == 0:\n+        if self.args.memory and os.getenv(\"TRANSFORMERS_USE_MULTIPROCESSING\") == 0:\n             logger.warning(\n-                \"Memory consumption will not be measured accurately if `args.no_multi_process` is set to `True.` The flag 'TRANSFORMERS_USE_MULTIPROCESSING' should only be disabled for debugging / testing.\"\n+                \"Memory consumption will not be measured accurately if `args.multi_process` is set to `False.` The flag 'TRANSFORMERS_USE_MULTIPROCESSING' should only be disabled for debugging / testing.\"\n             )\n \n         self._print_fn = None\n@@ -669,24 +669,24 @@ class Benchmark(ABC):\n \n             for batch_size in self.args.batch_sizes:\n                 for sequence_length in self.args.sequence_lengths:\n-                    if not self.args.no_inference:\n-                        if not self.args.no_memory:\n+                    if self.args.inference:\n+                        if self.args.memory:\n                             memory, inference_summary = self.inference_memory(model_name, batch_size, sequence_length)\n                             inference_result_memory[model_name][\"result\"][batch_size][sequence_length] = memory\n-                        if not self.args.no_speed:\n+                        if self.args.speed:\n                             time = self.inference_speed(model_name, batch_size, sequence_length)\n                             inference_result_time[model_name][\"result\"][batch_size][sequence_length] = time\n \n                     if self.args.training:\n-                        if not self.args.no_memory:\n+                        if self.args.memory:\n                             memory, train_summary = self.train_memory(model_name, batch_size, sequence_length)\n                             train_result_memory[model_name][\"result\"][batch_size][sequence_length] = memory\n-                        if not self.args.no_speed:\n+                        if self.args.speed:\n                             time = self.train_speed(model_name, batch_size, sequence_length)\n                             train_result_time[model_name][\"result\"][batch_size][sequence_length] = time\n \n-        if not self.args.no_inference:\n-            if not self.args.no_speed:\n+        if self.args.inference:\n+            if self.args.speed:\n                 self.print_fn(\"\\n\" + 20 * \"=\" + (\"INFERENCE - SPEED - RESULT\").center(40) + 20 * \"=\")\n                 self.print_results(inference_result_time, type_label=\"Time in s\")\n                 self.save_to_csv(inference_result_time, self.args.inference_time_csv_file)\n@@ -695,7 +695,7 @@ class Benchmark(ABC):\n                         \"TPU was used for inference. Note that the time after compilation stabilized (after ~10 inferences model.forward(..) calls) was measured.\"\n                     )\n \n-            if not self.args.no_memory:\n+            if self.args.memory:\n                 self.print_fn(\"\\n\" + 20 * \"=\" + (\"INFERENCE - MEMORY - RESULT\").center(40) + 20 * \"=\")\n                 self.print_results(inference_result_memory, type_label=\"Memory in MB\")\n                 self.save_to_csv(inference_result_memory, self.args.inference_memory_csv_file)\n@@ -705,7 +705,7 @@ class Benchmark(ABC):\n                 self.print_memory_trace_statistics(inference_summary)\n \n         if self.args.training:\n-            if not self.args.no_speed:\n+            if self.args.speed:\n                 self.print_fn(\"\\n\" + 20 * \"=\" + (\"TRAIN - SPEED - RESULTS\").center(40) + 20 * \"=\")\n                 self.print_results(train_result_time, \"Time in s\")\n                 self.save_to_csv(train_result_time, self.args.train_time_csv_file)\n@@ -714,7 +714,7 @@ class Benchmark(ABC):\n                         \"TPU was used for training. Note that the time after compilation stabilized (after ~10 train loss=model.forward(...) + loss.backward() calls) was measured.\"\n                     )\n \n-            if not self.args.no_memory:\n+            if self.args.memory:\n                 self.print_fn(\"\\n\" + 20 * \"=\" + (\"TRAIN - MEMORY - RESULTS\").center(40) + 20 * \"=\")\n                 self.print_results(train_result_memory, type_label=\"Memory in MB\")\n                 self.save_to_csv(train_result_memory, self.args.train_memory_csv_file)\n@@ -723,7 +723,7 @@ class Benchmark(ABC):\n                 self.print_fn(\"\\n\" + 20 * \"=\" + (\"TRAIN - MEMOMRY - LINE BY LINE - SUMMARY\").center(40) + 20 * \"=\")\n                 self.print_memory_trace_statistics(train_summary)\n \n-        if not self.args.no_env_print:\n+        if self.args.env_print:\n             self.print_fn(\"\\n\" + 20 * \"=\" + (\"ENVIRONMENT INFORMATION\").center(40) + 20 * \"=\")\n             self.print_fn(\n                 \"\\n\".join([\"- {}: {}\".format(prop, val) for prop, val in self.environment_info.items()]) + \"\\n\"\n"}
{"instance_id": "huggingface__transformers-8624", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/trainer.py b/src/transformers/trainer.py\nindex 0e1eef74cc..f5f8e4830b 100755\n--- a/src/transformers/trainer.py\n+++ b/src/transformers/trainer.py\n@@ -675,7 +675,9 @@ class Trainer:\n         if model_path and os.path.isfile(os.path.join(model_path, \"trainer_state.json\")):\n             self.state = TrainerState.load_from_json(os.path.join(model_path, \"trainer_state.json\"))\n             epochs_trained = self.state.global_step // num_update_steps_per_epoch\n-            steps_trained_in_current_epoch = self.state.global_step % (num_update_steps_per_epoch)\n+            steps_trained_in_current_epoch = (\n+                self.state.global_step % num_update_steps_per_epoch\n+            ) * self.args.gradient_accumulation_steps\n \n             logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n             logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n"}
{"instance_id": "huggingface__transformers-8554", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/prophetnet/modeling_prophetnet.py b/src/transformers/models/prophetnet/modeling_prophetnet.py\nindex 7117a5c858..d0da44b3aa 100644\n--- a/src/transformers/models/prophetnet/modeling_prophetnet.py\n+++ b/src/transformers/models/prophetnet/modeling_prophetnet.py\n@@ -1793,8 +1793,8 @@ class ProphetNetForConditionalGeneration(ProphetNetPreTrainedModel):\n                 encoder_attentions=outputs.encoder_attentions,\n             )\n \n-    def _compute_loss(self, logits, labels):\n-        expend_targets = labels.new_zeros(self.config.ngram, labels.size(0), labels.size(1)).fill_(self.padding_idx)\n+    def _compute_loss(self, logits, labels, ignore_index=-100):\n+        expend_targets = labels.new_zeros(self.config.ngram, labels.size(0), labels.size(1)).fill_(ignore_index)\n \n         for i in range(self.config.ngram):\n             if i > 0 and self.disable_ngram_loss:\n@@ -1807,11 +1807,11 @@ class ProphetNetForConditionalGeneration(ProphetNetPreTrainedModel):\n             dtype=torch.float32,\n         )\n \n-        loss = F.nll_loss(lprobs, expend_targets.view(-1), reduction=\"sum\")\n+        loss = F.nll_loss(lprobs, expend_targets.view(-1), reduction=\"sum\", ignore_index=ignore_index)\n \n         if self.config.eps > 0.0:\n             smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n-            non_pad_mask = expend_targets.ne(self.padding_idx).view(-1)\n+            non_pad_mask = expend_targets.ne(ignore_index).view(-1)\n             smooth_loss = smooth_loss[non_pad_mask]\n             smooth_loss = smooth_loss.sum()\n \n@@ -2010,8 +2010,8 @@ class ProphetNetForCausalLM(ProphetNetPreTrainedModel):\n                 cross_attentions=outputs.cross_attentions,\n             )\n \n-    def _compute_loss(self, logits, labels):\n-        expend_targets = labels.new_zeros(self.config.ngram, labels.size(0), labels.size(1)).fill_(self.padding_idx)\n+    def _compute_loss(self, logits, labels, ignore_index=-100):\n+        expend_targets = labels.new_zeros(self.config.ngram, labels.size(0), labels.size(1)).fill_(ignore_index)\n \n         for i in range(self.config.ngram):\n             if i > 0 and self.disable_ngram_loss:\n@@ -2024,11 +2024,11 @@ class ProphetNetForCausalLM(ProphetNetPreTrainedModel):\n             dtype=torch.float32,\n         )\n \n-        loss = F.nll_loss(lprobs, expend_targets.view(-1), reduction=\"sum\")\n+        loss = F.nll_loss(lprobs, expend_targets.view(-1), reduction=\"sum\", ignore_index=ignore_index)\n \n         if self.config.eps > 0.0:\n             smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n-            non_pad_mask = expend_targets.ne(self.padding_idx).view(-1)\n+            non_pad_mask = expend_targets.ne(ignore_index).view(-1)\n             smooth_loss = smooth_loss[non_pad_mask]\n             smooth_loss = smooth_loss.sum()\n \n"}
{"instance_id": "keras-team__keras-18871", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/models/model.py b/keras/models/model.py\nindex ee89bb424..44c5e38dc 100644\n--- a/keras/models/model.py\n+++ b/keras/models/model.py\n@@ -7,7 +7,6 @@ from keras import backend\n from keras import utils\n from keras.api_export import keras_export\n from keras.layers.layer import Layer\n-from keras.legacy.saving import legacy_h5_format\n from keras.models.variable_mapping import map_trackable_variables\n from keras.saving import saving_api\n from keras.saving import saving_lib\n@@ -303,60 +302,7 @@ class Model(Trainer, Layer):\n \n         Thus models can be reinstantiated in the exact same state.\n         \"\"\"\n-        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n-        save_format = kwargs.pop(\"save_format\", None)\n-        if kwargs:\n-            raise ValueError(\n-                \"The following argument(s) are not supported: \"\n-                f\"{list(kwargs.keys())}\"\n-            )\n-        if save_format:\n-            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(\n-                filepath\n-            ).endswith(\".keras\"):\n-                warnings.warn(\n-                    \"The `save_format` argument is deprecated in Keras 3. \"\n-                    \"We recommend removing this argument as it can be inferred \"\n-                    \"from the file path. \"\n-                    f\"Received: save_format={save_format}\"\n-                )\n-            else:\n-                raise ValueError(\n-                    \"The `save_format` argument is deprecated in Keras 3. \"\n-                    \"Please remove this argument and pass a file path with \"\n-                    \"either `.keras` or `.h5` extension.\"\n-                    f\"Received: save_format={save_format}\"\n-                )\n-        try:\n-            exists = os.path.exists(filepath)\n-        except TypeError:\n-            exists = False\n-        if exists and not overwrite:\n-            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n-            if not proceed:\n-                return\n-        if str(filepath).endswith(\".keras\"):\n-            saving_lib.save_model(self, filepath)\n-        elif str(filepath).endswith((\".h5\", \".hdf5\")):\n-            # Deprecation warnings\n-            warnings.warn(\n-                \"You are saving your model as an HDF5 file via `model.save()`. \"\n-                \"This file format is considered legacy. \"\n-                \"We recommend using instead the native Keras format, \"\n-                \"e.g. `model.save('my_model.keras')`.\"\n-            )\n-            legacy_h5_format.save_model_to_hdf5(\n-                self, filepath, overwrite, include_optimizer\n-            )\n-        else:\n-            raise ValueError(\n-                \"Invalid filepath extension for saving. \"\n-                \"Please add either a `.keras` extension for the native Keras \"\n-                f\"format (recommended) or a `.h5` extension. \"\n-                \"Use `tf.saved_model.save()` if you want to export a \"\n-                \"SavedModel for use with TFLite/TFServing/etc. \"\n-                f\"Received: filepath={filepath}.\"\n-            )\n+        saving_api.save_model(self, filepath, overwrite, **kwargs)\n \n     @traceback_utils.filter_traceback\n     def save_weights(self, filepath, overwrite=True):\n"}
{"instance_id": "keras-team__keras-19201", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/backend/jax/distribution_lib.py b/keras/backend/jax/distribution_lib.py\nindex 704b13a48..8e15e3c96 100644\n--- a/keras/backend/jax/distribution_lib.py\n+++ b/keras/backend/jax/distribution_lib.py\n@@ -200,12 +200,12 @@ def initialize(job_addresses, num_processes, process_id):\n                 f\"{len(job_addresses)} jobs, but num_processes is \"\n                 f\"{num_processes}\"\n             )\n-        corrdinator_address = job_addresses[0]\n+        coordinator_address = job_addresses[0]\n     else:\n-        corrdinator_address = job_addresses\n+        coordinator_address = job_addresses\n \n     jax.distributed.initialize(\n-        corrdinator_address=corrdinator_address,\n+        coordinator_address=coordinator_address,\n         num_processes=num_processes,\n         process_id=process_id,\n     )\n"}
{"instance_id": "huggingface__transformers-8435", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/tokenization_utils.py b/src/transformers/tokenization_utils.py\nindex 612616a515..795cc5398c 100644\n--- a/src/transformers/tokenization_utils.py\n+++ b/src/transformers/tokenization_utils.py\n@@ -737,9 +737,9 @@ class PreTrainedTokenizer(PreTrainedTokenizerBase):\n         sub_texts = []\n         current_sub_text = []\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n-            if token in self.added_tokens_encoder:\n+            if token in self.added_tokens_encoder or token in self.all_special_tokens:\n                 if current_sub_text:\n                     sub_texts.append(self.convert_tokens_to_string(current_sub_text))\n                     current_sub_text = []\n"}
{"instance_id": "keras-team__keras-19190", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/layers/preprocessing/text_vectorization.py b/keras/layers/preprocessing/text_vectorization.py\nindex 2e1fa4633..62ea55c3a 100644\n--- a/keras/layers/preprocessing/text_vectorization.py\n+++ b/keras/layers/preprocessing/text_vectorization.py\n@@ -280,6 +280,10 @@ class TextVectorization(Layer):\n         )\n \n         # 'ngrams' must be one of (None, int, tuple(int))\n+        # Note: we also accept list(int) to handle deserialization from JSON\n+        # which converts tuples to lists.\n+        if isinstance(ngrams, list):\n+            ngrams = tuple(ngrams)\n         if not (\n             ngrams is None\n             or isinstance(ngrams, int)\n"}
{"instance_id": "keras-team__keras-18975", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/trainers/compile_utils.py b/keras/trainers/compile_utils.py\nindex 8f830f4c9..e199c5c97 100644\n--- a/keras/trainers/compile_utils.py\n+++ b/keras/trainers/compile_utils.py\n@@ -444,6 +444,7 @@ class CompileLoss(losses_module.Loss):\n             num_outputs = len(output_names)\n \n         y_pred = self._flatten_y(y_pred)\n+        y_true = self._flatten_y(y_true)\n         loss = self._user_loss\n         loss_weights = self._user_loss_weights\n         flat_losses = []\n@@ -469,7 +470,7 @@ class CompileLoss(losses_module.Loss):\n                     f\"Received instead:\\nloss={loss} of type {type(loss)}\"\n                 )\n \n-        if is_function_like(loss) and tree.is_nested(y_pred):\n+        if is_function_like(loss) and len(y_pred) > 1:\n             # The model has multiple outputs but only one loss fn\n             # was provided. Broadcast loss to all outputs.\n             loss = tree.map_structure(lambda x: loss, y_pred)\n@@ -477,7 +478,7 @@ class CompileLoss(losses_module.Loss):\n         # Iterate over all possible loss formats:\n         # plain function, list/tuple, dict\n         if is_function_like(loss):\n-            flat_losses.append(get_loss(loss, y_true, y_pred))\n+            flat_losses.append(get_loss(loss, y_true[0], y_pred[0]))\n             if loss_weights:\n                 if not isinstance(loss_weights, float):\n                     raise ValueError(\n@@ -509,7 +510,8 @@ class CompileLoss(losses_module.Loss):\n                     f\"Received: loss={loss}\"\n                 )\n             flat_losses = [\n-                get_loss(fn, y_true, y_pred) for fn in loss if fn is not None\n+                get_loss(fn, yt, yp) if fn is not None else None\n+                for fn, yt, yp in zip(loss, y_true, y_pred)\n             ]\n             if loss_weights:\n                 if not isinstance(loss_weights, (list, tuple)):\n"}
{"instance_id": "keras-team__keras-19466", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/ops/numpy.py b/keras/ops/numpy.py\nindex 25f1809d6..2169f4dd6 100644\n--- a/keras/ops/numpy.py\n+++ b/keras/ops/numpy.py\n@@ -3992,6 +3992,15 @@ class Nonzero(Operation):\n     def call(self, x):\n         return backend.numpy.nonzero(x)\n \n+    def compute_output_spec(self, x):\n+        # nonzero returns a tuple of arrays, one for each dimension of x.\n+        # Each array contains the indices of non-zero elements along that\n+        # dimension. The number of non-zero elements is unknown at compile\n+        # time, so the shape of each output array is (None,).\n+        return tuple(\n+            KerasTensor(shape=(None,), dtype=\"int64\") for _ in range(len(x.shape))\n+        )\n+\n \n @keras_export([\"keras.ops.nonzero\", \"keras.ops.numpy.nonzero\"])\n def nonzero(x):\n@@ -4003,6 +4012,8 @@ def nonzero(x):\n     Returns:\n         Indices of elements that are non-zero.\n     \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Nonzero().symbolic_call(x)\n     return backend.numpy.nonzero(x)\n \n \n"}
{"instance_id": "keras-team__keras-19459", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/layers/regularization/gaussian_dropout.py b/keras/layers/regularization/gaussian_dropout.py\nindex 15f66781c..ac1a43446 100644\n--- a/keras/layers/regularization/gaussian_dropout.py\n+++ b/keras/layers/regularization/gaussian_dropout.py\n@@ -44,6 +44,7 @@ class GaussianDropout(layers.Layer):\n                 shape=ops.shape(inputs),\n                 mean=1.0,\n                 stddev=stddev,\n+                dtype=inputs.dtype,\n                 seed=self.seed_generator,\n             )\n         return inputs\ndiff --git a/keras/layers/regularization/gaussian_noise.py b/keras/layers/regularization/gaussian_noise.py\nindex 36d168e04..9936d463b 100644\n--- a/keras/layers/regularization/gaussian_noise.py\n+++ b/keras/layers/regularization/gaussian_noise.py\n@@ -44,6 +44,7 @@ class GaussianNoise(layers.Layer):\n                 shape=ops.shape(inputs),\n                 mean=0.0,\n                 stddev=self.stddev,\n+                dtype=inputs.dtype,\n                 seed=self.seed_generator,\n             )\n         return inputs\n"}
{"instance_id": "keras-team__keras-19773", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/layers/preprocessing/string_lookup.py b/keras/src/layers/preprocessing/string_lookup.py\nindex 848ac99b1..8e8f4ac4c 100644\n--- a/keras/src/layers/preprocessing/string_lookup.py\n+++ b/keras/src/layers/preprocessing/string_lookup.py\n@@ -316,6 +316,7 @@ class StringLookup(IndexLookup):\n             raise ValueError(\n                 \"`sparse=True` can only be used with the \" \"TensorFlow backend.\"\n             )\n+        self.encoding = encoding\n         super().__init__(\n             max_tokens=max_tokens,\n             num_oov_indices=num_oov_indices,\n@@ -331,7 +332,6 @@ class StringLookup(IndexLookup):\n             vocabulary_dtype=\"string\",\n             **kwargs,\n         )\n-        self.encoding = encoding\n         self._convert_input_args = False\n         self._allow_non_tensor_positional_args = True\n         self.supports_jit = False\n"}
{"instance_id": "keras-team__keras-19641", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/backend/tensorflow/nn.py b/keras/src/backend/tensorflow/nn.py\nindex cb6bff3b4..8040e3234 100644\n--- a/keras/src/backend/tensorflow/nn.py\n+++ b/keras/src/backend/tensorflow/nn.py\n@@ -226,14 +226,19 @@ def conv(\n     data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = backend.standardize_data_format(data_format)\n+    if data_format == \"channels_first\":\n+        # Tensorflow conv does not support `channels_first` format on CPU.\n+        # We need to transpose to `channels_last` format.\n+        inputs = _transpose_spatial_inputs(inputs)\n+\n     def _conv():\n-        tf_data_format = _convert_data_format(data_format, len(inputs.shape))\n         return tf.nn.convolution(\n             inputs,\n             kernel,\n             strides,\n             padding.upper(),\n-            data_format=tf_data_format,\n+            data_format=_convert_data_format(\"channels_last\", len(inputs.shape)),\n             dilations=dilation_rate,\n         )\n \n@@ -243,16 +248,18 @@ def conv(\n     def _conv_xla():\n         return _conv()\n \n-    data_format = backend.standardize_data_format(data_format)\n-    if data_format == \"channels_last\":\n-        channels = inputs.shape[-1]\n-    else:\n-        channels = inputs.shape[1]\n+    # After potential transpose, inputs is always in channels_last format\n+    channels = inputs.shape[-1]\n     if channels != kernel.shape[-2]:\n         # If kernel's in_channel does not match input's channels,  it indicates\n         # convolution is broken down into groups.\n-        return _conv_xla()\n-    return _conv()\n+        outputs = _conv_xla()\n+    else:\n+        outputs = _conv()\n+\n+    if data_format == \"channels_first\":\n+        outputs = _transpose_spatial_outputs(outputs)\n+    return outputs\n \n \n def depthwise_conv(\n"}
{"instance_id": "keras-team__keras-19636", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/dtype_policies/dtype_policy.py b/keras/src/dtype_policies/dtype_policy.py\nindex a55eaa4c0..195081527 100644\n--- a/keras/src/dtype_policies/dtype_policy.py\n+++ b/keras/src/dtype_policies/dtype_policy.py\n@@ -153,7 +153,14 @@ class DTypePolicy:\n                 x.dtype = dtype\n             return x\n         elif hasattr(x, \"__array__\"):\n-            return ops.convert_to_tensor(x, dtype=dtype)\n+            x = ops.convert_to_tensor(x)\n+            if (\n+                autocast\n+                and backend.is_float_dtype(x.dtype)\n+                and x.dtype != dtype\n+            ):\n+                x = backend.cast(x, dtype=dtype)\n+            return x\n         return x\n \n     def get_config(self):\n"}
{"instance_id": "keras-team__keras-19775", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/backend/tensorflow/numpy.py b/keras/src/backend/tensorflow/numpy.py\nindex 74920a624..feadfc7d0 100644\n--- a/keras/src/backend/tensorflow/numpy.py\n+++ b/keras/src/backend/tensorflow/numpy.py\n@@ -1329,11 +1329,11 @@ def linspace(\n     if endpoint:\n         result = tf.linspace(start, stop, num, axis=axis)\n         if num > 1:\n-            step = (stop - start) / (num - 1)\n+            step = (stop - start) / tf.cast(num - 1, dtype)\n     else:\n         # tf.linspace doesn't support endpoint=False, so we manually handle it\n         if num > 0:\n-            step = (stop - start) / num\n+            step = (stop - start) / tf.cast(num, dtype)\n         if num > 1:\n             new_stop = tf.cast(stop, step.dtype) - step\n             start = tf.cast(start, new_stop.dtype)\n"}
{"instance_id": "keras-team__keras-19484", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/optimizers/adam.py b/keras/optimizers/adam.py\nindex f1db87ff9..4499e8a6b 100644\n--- a/keras/optimizers/adam.py\n+++ b/keras/optimizers/adam.py\n@@ -113,11 +113,17 @@ class Adam(optimizer.Optimizer):\n         lr = ops.cast(learning_rate, variable.dtype)\n         gradient = ops.cast(gradient, variable.dtype)\n         local_step = ops.cast(self.iterations + 1, variable.dtype)\n+        beta_1 = self.beta_1\n+        beta_2 = self.beta_2\n+        if callable(beta_1):\n+            beta_1 = beta_1()\n+        if callable(beta_2):\n+            beta_2 = beta_2()\n         beta_1_power = ops.power(\n-            ops.cast(self.beta_1, variable.dtype), local_step\n+            ops.cast(beta_1, variable.dtype), local_step\n         )\n         beta_2_power = ops.power(\n-            ops.cast(self.beta_2, variable.dtype), local_step\n+            ops.cast(beta_2, variable.dtype), local_step\n         )\n \n         m = self._momentums[self._get_variable_index(variable)]\n@@ -126,12 +132,12 @@ class Adam(optimizer.Optimizer):\n         alpha = lr * ops.sqrt(1 - beta_2_power) / (1 - beta_1_power)\n \n         self.assign_add(\n-            m, ops.multiply(ops.subtract(gradient, m), 1 - self.beta_1)\n+            m, ops.multiply(ops.subtract(gradient, m), 1 - beta_1)\n         )\n         self.assign_add(\n             v,\n             ops.multiply(\n-                ops.subtract(ops.square(gradient), v), 1 - self.beta_2\n+                ops.subtract(ops.square(gradient), v), 1 - beta_2\n             ),\n         )\n         if self.amsgrad:\ndiff --git a/keras/optimizers/base_optimizer.py b/keras/optimizers/base_optimizer.py\nindex e18f3c1de..8709a95b9 100644\n--- a/keras/optimizers/base_optimizer.py\n+++ b/keras/optimizers/base_optimizer.py\n@@ -567,7 +567,7 @@ class BaseOptimizer:\n         ):\n             return self._learning_rate(self.iterations)\n         elif callable(self._learning_rate):\n-            return self._learning_rate(self.iterations)\n+            return self._learning_rate()\n         return self._learning_rate\n \n     def _filter_empty_gradients(self, grads, vars):\ndiff --git a/keras/optimizers/lion.py b/keras/optimizers/lion.py\nindex 49fb7f309..a2440055d 100644\n--- a/keras/optimizers/lion.py\n+++ b/keras/optimizers/lion.py\n@@ -70,7 +70,7 @@ class Lion(optimizer.Optimizer):\n         )\n         self.beta_1 = beta_1\n         self.beta_2 = beta_2\n-        if beta_1 <= 0 or beta_1 > 1:\n+        if not callable(beta_1) and (beta_1 <= 0 or beta_1 > 1):\n             raise ValueError(\n                 \"Argument `beta_1` must be in the [0, 1] range. Otherwise, the \"\n                 f\"optimizer degenerates to SignSGD. Received: beta_1={beta_1}.\"\n@@ -99,8 +99,14 @@ class Lion(optimizer.Optimizer):\n         \"\"\"Update step given gradient and the associated model variable.\"\"\"\n         lr = ops.cast(learning_rate, variable.dtype)\n         gradient = ops.cast(gradient, variable.dtype)\n-        beta_1 = ops.cast(self.beta_1, variable.dtype)\n-        beta_2 = ops.cast(self.beta_2, variable.dtype)\n+        beta_1 = self.beta_1\n+        beta_2 = self.beta_2\n+        if callable(beta_1):\n+            beta_1 = beta_1()\n+        if callable(beta_2):\n+            beta_2 = beta_2()\n+        beta_1 = ops.cast(beta_1, variable.dtype)\n+        beta_2 = ops.cast(beta_2, variable.dtype)\n         m = self._momentums[self._get_variable_index(variable)]\n \n         self.assign_sub(\ndiff --git a/keras/optimizers/nadam.py b/keras/optimizers/nadam.py\nindex d9b74d9d1..603247ec1 100644\n--- a/keras/optimizers/nadam.py\n+++ b/keras/optimizers/nadam.py\n@@ -101,10 +101,13 @@ class Nadam(optimizer.Optimizer):\n \n     def _backend_update_step(self, grads, trainable_variables, learning_rate):\n         dtype = self._u_product.dtype\n+        beta_1 = self.beta_1\n+        if callable(beta_1):\n+            beta_1 = beta_1()\n         self.assign(\n             self._u_product,\n             self._u_product\n-            * self.beta_1\n+            * beta_1\n             * (\n                 1.0\n                 - 0.5 * ops.power(0.96, ops.cast(self.iterations + 1, dtype))\n@@ -121,8 +124,14 @@ class Nadam(optimizer.Optimizer):\n         local_step = ops.cast(self.iterations + 1, var_dtype)\n         next_step = ops.cast(self.iterations + 2, var_dtype)\n         decay = ops.cast(0.96, var_dtype)\n-        beta_1 = ops.cast(self.beta_1, var_dtype)\n-        beta_2 = ops.cast(self.beta_2, var_dtype)\n+        beta_1 = self.beta_1\n+        beta_2 = self.beta_2\n+        if callable(beta_1):\n+            beta_1 = beta_1()\n+        if callable(beta_2):\n+            beta_2 = beta_2()\n+        beta_1 = ops.cast(beta_1, var_dtype)\n+        beta_2 = ops.cast(beta_2, var_dtype)\n         u_t = beta_1 * (1.0 - 0.5 * (ops.power(decay, local_step)))\n         u_t_1 = beta_1 * (1.0 - 0.5 * (ops.power(decay, next_step)))\n         u_product_t = ops.cast(self._u_product, var_dtype)\n"}
{"instance_id": "keras-team__keras-19838", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/losses/losses.py b/keras/src/losses/losses.py\nindex 8bb32c21b..a7a33f0e9 100644\n--- a/keras/src/losses/losses.py\n+++ b/keras/src/losses/losses.py\n@@ -1715,9 +1715,12 @@ def sparse_categorical_crossentropy(\n         res_shape = ops.shape(y_pred)[:-1]\n         valid_mask = ops.not_equal(y_true, ops.cast(ignore_class, y_pred.dtype))\n         y_true = y_true * ops.cast(valid_mask, y_true.dtype)\n-        y_pred = y_pred * ops.cast(\n-            ops.expand_dims(valid_mask, -1), y_pred.dtype\n-        )\n+        # Only expand dims if valid_mask has fewer dimensions than y_pred\n+        # This handles the case where y_true has a trailing dimension of 1\n+        # (e.g., segmentation masks with shape (B, H, W, 1))\n+        if len(valid_mask.shape) < len(y_pred.shape):\n+            valid_mask = ops.expand_dims(valid_mask, -1)\n+        y_pred = y_pred * ops.cast(valid_mask, y_pred.dtype)\n \n     res = ops.sparse_categorical_crossentropy(\n         y_true,\n"}
{"instance_id": "keras-team__keras-19826", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/ops/numpy.py b/keras/src/ops/numpy.py\nindex e8289ee2e..6890bc9a2 100644\n--- a/keras/src/ops/numpy.py\n+++ b/keras/src/ops/numpy.py\n@@ -4345,26 +4345,40 @@ class Repeat(Operation):\n \n     def compute_output_spec(self, x):\n         x_shape = list(x.shape)\n+        repeats = self.repeats\n         if self.axis is None:\n             if None in x_shape:\n                 return KerasTensor([None], dtype=x.dtype)\n \n             x_flatten_size = int(np.prod(x_shape))\n-            if isinstance(self.repeats, int):\n-                output_shape = [x_flatten_size * self.repeats]\n+            if isinstance(repeats, int):\n+                output_shape = [x_flatten_size * repeats]\n             else:\n-                output_shape = [int(np.sum(self.repeats))]\n+                repeats = list(repeats)\n+                if len(repeats) == 1:\n+                    # Broadcast single repeat value to all elements\n+                    output_shape = [x_flatten_size * int(repeats[0])]\n+                else:\n+                    output_shape = [int(np.sum(repeats))]\n             return KerasTensor(output_shape, dtype=x.dtype)\n \n         size_on_ax = x_shape[self.axis]\n         output_shape = x_shape\n-        if isinstance(self.repeats, int):\n+        if isinstance(repeats, int):\n             if size_on_ax is None:\n                 output_shape[self.axis] = None\n             else:\n-                output_shape[self.axis] = size_on_ax * self.repeats\n+                output_shape[self.axis] = size_on_ax * repeats\n         else:\n-            output_shape[self.axis] = int(np.sum(self.repeats))\n+            repeats = list(repeats)\n+            if len(repeats) == 1:\n+                # Broadcast single repeat value to all elements\n+                if size_on_ax is None:\n+                    output_shape[self.axis] = None\n+                else:\n+                    output_shape[self.axis] = size_on_ax * int(repeats[0])\n+            else:\n+                output_shape[self.axis] = int(np.sum(repeats))\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n"}
{"instance_id": "keras-team__keras-19915", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/export/export_lib.py b/keras/src/export/export_lib.py\nindex 02714c55c..1a52b1bb5 100644\n--- a/keras/src/export/export_lib.py\n+++ b/keras/src/export/export_lib.py\n@@ -657,7 +657,8 @@ def _get_input_signature(model):\n         if isinstance(structure, (list, tuple)):\n             if all(isinstance(d, (int, type(None))) for d in structure):\n                 return tf.TensorSpec(\n-                    shape=(None,) + structure[1:], dtype=model.input_dtype\n+                    shape=(None,) + tuple(structure[1:]),\n+                    dtype=model.input_dtype,\n                 )\n             result = [make_tensor_spec(v) for v in structure]\n             return tuple(result) if isinstance(structure, tuple) else result\n"}
{"instance_id": "keras-team__keras-19844", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/initializers/__init__.py b/keras/src/initializers/__init__.py\nindex af46b7ff9..7737cefa2 100644\n--- a/keras/src/initializers/__init__.py\n+++ b/keras/src/initializers/__init__.py\n@@ -48,6 +48,7 @@ ALL_OBJECTS_DICT.update(\n     {\n         \"uniform\": RandomUniform,\n         \"normal\": RandomNormal,\n+        \"Orthogonal\": OrthogonalInitializer,\n         \"orthogonal\": OrthogonalInitializer,\n         \"one\": Ones,\n         \"zero\": Zeros,\ndiff --git a/keras/src/layers/rnn/gru.py b/keras/src/layers/rnn/gru.py\nindex 8a516d0b4..7372d769b 100644\n--- a/keras/src/layers/rnn/gru.py\n+++ b/keras/src/layers/rnn/gru.py\n@@ -500,6 +500,7 @@ class GRU(RNN):\n             trainable=kwargs.get(\"trainable\", True),\n             name=\"gru_cell\",\n             seed=seed,\n+            implementation=kwargs.pop(\"implementation\", 2),\n         )\n         super().__init__(\n             cell,\n"}
{"instance_id": "keras-team__keras-19924", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/saving/saving_lib.py b/keras/src/saving/saving_lib.py\nindex 6aad62db5..ee2a8fbe5 100644\n--- a/keras/src/saving/saving_lib.py\n+++ b/keras/src/saving/saving_lib.py\n@@ -4,6 +4,7 @@ import datetime\n import io\n import json\n import pathlib\n+import shutil\n import tempfile\n import warnings\n import zipfile\n@@ -160,13 +161,18 @@ def _save_model_to_fileobj(model, fileobj, weights_format):\n             f.write(config_json.encode())\n \n         weights_file_path = None\n+        weights_tmp_dir = None\n         try:\n             if weights_format == \"h5\":\n                 if isinstance(fileobj, io.BufferedWriter):\n-                    # First, open the .h5 file, then write it to `zf` at the end\n-                    # of the function call.\n-                    working_dir = pathlib.Path(fileobj.name).parent\n-                    weights_file_path = working_dir / _VARS_FNAME_H5\n+                    # First, open the .h5 file, then write it to `zf` at the\n+                    # end of the function call. Use a unique temporary\n+                    # directory to avoid race conditions when saving models\n+                    # in parallel.\n+                    weights_tmp_dir = get_temp_dir()\n+                    weights_file_path = (\n+                        pathlib.Path(weights_tmp_dir) / _VARS_FNAME_H5\n+                    )\n                     weights_store = H5IOStore(weights_file_path, mode=\"w\")\n                 else:\n                     # Fall back when `fileobj` is an `io.BytesIO`. Typically,\n@@ -203,6 +209,8 @@ def _save_model_to_fileobj(model, fileobj, weights_format):\n             asset_store.close()\n             if weights_file_path:\n                 zf.write(weights_file_path, weights_file_path.name)\n+            if weights_tmp_dir:\n+                shutil.rmtree(weights_tmp_dir)\n \n \n def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n@@ -308,15 +316,18 @@ def _load_model_from_fileobj(fileobj, custom_objects, compile, safe_mode):\n         )\n \n         all_filenames = zf.namelist()\n-        weights_file_path = None\n+        extract_tmp_dir = None\n         try:\n             if _VARS_FNAME_H5 in all_filenames:\n                 if isinstance(fileobj, io.BufferedReader):\n                     # First, extract the model.weights.h5 file, then load it\n-                    # using h5py.\n-                    working_dir = pathlib.Path(fileobj.name).parent\n-                    zf.extract(_VARS_FNAME_H5, working_dir)\n-                    weights_file_path = working_dir / _VARS_FNAME_H5\n+                    # using h5py. Use a unique temporary directory to avoid\n+                    # race conditions when loading the same model in parallel.\n+                    extract_tmp_dir = get_temp_dir()\n+                    zf.extract(_VARS_FNAME_H5, extract_tmp_dir)\n+                    weights_file_path = (\n+                        pathlib.Path(extract_tmp_dir) / _VARS_FNAME_H5\n+                    )\n                     weights_store = H5IOStore(weights_file_path, mode=\"r\")\n                 else:\n                     # Fall back when `fileobj` is an `io.BytesIO`. Typically,\n@@ -349,8 +360,8 @@ def _load_model_from_fileobj(fileobj, custom_objects, compile, safe_mode):\n             weights_store.close()\n             if asset_store:\n                 asset_store.close()\n-            if weights_file_path:\n-                weights_file_path.unlink()\n+            if extract_tmp_dir:\n+                shutil.rmtree(extract_tmp_dir)\n \n         if failed_saveables:\n             _raise_loading_failure(error_msgs)\n"}
{"instance_id": "keras-team__keras-19937", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/dtype_policies/dtype_policy.py b/keras/src/dtype_policies/dtype_policy.py\nindex 9d37ac49f..da0b6da30 100644\n--- a/keras/src/dtype_policies/dtype_policy.py\n+++ b/keras/src/dtype_policies/dtype_policy.py\n@@ -196,6 +196,9 @@ class DTypePolicy:\n                 return False\n         return self._name == other._name\n \n+    def __hash__(self):\n+        return hash(self._name)\n+\n     def _should_cast(self, x, autocast, dtype):\n         x_dtype = backend.standardize_dtype(x.dtype)\n         if autocast and backend.is_float_dtype(x_dtype) and x_dtype != dtype:\n@@ -236,6 +239,9 @@ class QuantizedDTypePolicy(DTypePolicy):\n             and self._source_name == other._source_name\n         )\n \n+    def __hash__(self):\n+        return hash((self._name, self._quantization_mode, self._source_name))\n+\n     def get_config(self):\n         return {\n             \"mode\": self._quantization_mode,\n@@ -282,6 +288,16 @@ class QuantizedFloat8DTypePolicy(QuantizedDTypePolicy):\n             return False\n         return self._amax_history_length == other._amax_history_length\n \n+    def __hash__(self):\n+        return hash(\n+            (\n+                self._name,\n+                self._quantization_mode,\n+                self._source_name,\n+                self._amax_history_length,\n+            )\n+        )\n+\n     def get_config(self):\n         config = super().get_config()\n         config.update({\"amax_history_length\": self.amax_history_length})\n"}
{"instance_id": "keras-team__keras-19863", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/layers/layer.py b/keras/src/layers/layer.py\nindex dfff50867..6d267228f 100644\n--- a/keras/src/layers/layer.py\n+++ b/keras/src/layers/layer.py\n@@ -357,16 +357,30 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n     @utils.default\n     def build(self, input_shape):\n         self._check_super_called()\n-        if utils.is_default(self.build) and might_have_unbuilt_state(self):\n-            warnings.warn(\n-                f\"`build()` was called on layer '{self.name}', however \"\n-                \"the layer does not have a `build()` method implemented \"\n-                \"and it looks like it has unbuilt state. This will cause \"\n-                \"the layer to be marked as built, despite not being \"\n-                \"actually built, which may cause failures down the line. \"\n-                \"Make sure to implement a proper `build()` method.\"\n-            )\n-        self.built = True\n+        if might_have_unbuilt_state(self):\n+            # Attempt to build sublayers by tracing the call method\n+            # with a symbolic tensor created from the input shape.\n+            try:\n+                if input_shape is None:\n+                    raise ValueError(\n+                        \"You must provide an `input_shape` argument when \"\n+                        \"calling `build()` on a layer that has unbuilt \"\n+                        \"sublayers.\"\n+                    )\n+                input_tensors = tree.map_shape_structure(\n+                    lambda s: backend.KerasTensor(s), input_shape\n+                )\n+                backend.compute_output_spec(self.call, input_tensors)\n+            except Exception as e:\n+                warnings.warn(\n+                    f\"`build()` was called on layer '{self.name}', however \"\n+                    \"the layer does not have a `build()` method implemented \"\n+                    \"and it looks like it has unbuilt state. This will cause \"\n+                    \"the layer to be marked as built, despite not being \"\n+                    \"actually built, which may cause failures down the line. \"\n+                    \"Make sure to implement a proper `build()` method. \"\n+                    f\"Exception encountered: '{e}'\"\n+                )\n \n     def _lock_state(self):\n         \"\"\"Prevent further state updates, called automatically in `build()`.\"\"\"\n"}
{"instance_id": "keras-team__keras-19973", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/layers/attention/grouped_query_attention.py b/keras/src/layers/attention/grouped_query_attention.py\nindex fe09f0633..57302a45b 100644\n--- a/keras/src/layers/attention/grouped_query_attention.py\n+++ b/keras/src/layers/attention/grouped_query_attention.py\n@@ -392,13 +392,6 @@ class GroupedQueryAttention(Layer):\n         if key_shape is None:\n             key_shape = value_shape\n \n-        if query_shape[-1] != value_shape[-1]:\n-            raise ValueError(\n-                \"The last dimension of `query_shape` and `value_shape` \"\n-                f\"must be equal, but are {query_shape[-1]}, {value_shape[-1]}. \"\n-                \"Received: query_shape={query_shape}, value_shape={value_shape}\"\n-            )\n-\n         if value_shape[1:-1] != key_shape[1:-1]:\n             raise ValueError(\n                 \"All dimensions of `value` and `key`, except the last one, \"\ndiff --git a/keras/src/layers/attention/multi_head_attention.py b/keras/src/layers/attention/multi_head_attention.py\nindex 5fae13023..df627af20 100644\n--- a/keras/src/layers/attention/multi_head_attention.py\n+++ b/keras/src/layers/attention/multi_head_attention.py\n@@ -589,13 +589,6 @@ class MultiHeadAttention(Layer):\n         if key_shape is None:\n             key_shape = value_shape\n \n-        if query_shape[-1] != value_shape[-1]:\n-            raise ValueError(\n-                \"The last dimension of `query_shape` and `value_shape` \"\n-                f\"must be equal, but are {query_shape[-1]}, {value_shape[-1]}. \"\n-                \"Received: query_shape={query_shape}, value_shape={value_shape}\"\n-            )\n-\n         if value_shape[1:-1] != key_shape[1:-1]:\n             raise ValueError(\n                 \"All dimensions of `value` and `key`, except the last one, \"\n"}
{"instance_id": "keras-team__keras-20008", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/backend/tensorflow/nn.py b/keras/src/backend/tensorflow/nn.py\nindex 3eef471f7..d43f2249b 100644\n--- a/keras/src/backend/tensorflow/nn.py\n+++ b/keras/src/backend/tensorflow/nn.py\n@@ -254,7 +254,7 @@ def conv(\n         return _conv_xla()\n     if data_format == \"channels_first\" and len(inputs.shape) == 5:\n         inputs = convert_to_tensor(inputs)\n-        if inputs.device.split(\":\")[-2] == \"CPU\":\n+        if \"CPU\" in inputs.device:\n             inputs = tf.transpose(inputs, perm=(0, 2, 3, 4, 1))\n             data_format = \"channels_last\"\n             return tf.transpose(_conv(), perm=(0, 4, 1, 2, 3))\n"}
{"instance_id": "langchain-ai__langchain-20064", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/docs/modules/model_io/output_parsers/custom.ipynb b/docs/docs/modules/model_io/output_parsers/custom.ipynb\nindex ee028dcc1..ee4cf02cc 100644\n--- a/docs/docs/modules/model_io/output_parsers/custom.ipynb\n+++ b/docs/docs/modules/model_io/output_parsers/custom.ipynb\n@@ -263,14 +263,24 @@\n     \"    false_val: str = \\\"NO\\\"\\n\",\n     \"\\n\",\n     \"    def parse(self, text: str) -> bool:\\n\",\n-    \"        cleaned_text = text.strip().upper()\\n\",\n-    \"        if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\\n\",\n+    \"        cleaned_upper_text = text.strip().upper()\\n\",\n+    \"        if (\\n\",\n+    \"            self.true_val.upper() in cleaned_upper_text\\n\",\n+    \"            and self.false_val.upper() in cleaned_upper_text\\n\",\n+    \"        ):\\n\",\n     \"            raise OutputParserException(\\n\",\n-    \"                f\\\"BooleanOutputParser expected output value to either be \\\"\\n\",\n-    \"                f\\\"{self.true_val} or {self.false_val} (case-insensitive). \\\"\\n\",\n-    \"                f\\\"Received {cleaned_text}.\\\"\\n\",\n+    \"                f\\\"Ambiguous response. Both {self.true_val} and \\\"\\n\",\n+    \"                f\\\"{self.false_val} in received: {text}.\\\"\\n\",\n+    \"            )\\n\",\n+    \"        elif self.true_val.upper() in cleaned_upper_text:\\n\",\n+    \"            return True\\n\",\n+    \"        elif self.false_val.upper() in cleaned_upper_text:\\n\",\n+    \"            return False\\n\",\n+    \"        else:\\n\",\n+    \"            raise OutputParserException(\\n\",\n+    \"                f\\\"BooleanOutputParser expected output value to include either \\\"\\n\",\n+    \"                f\\\"{self.true_val} or {self.false_val}. Received {text}.\\\"\\n\",\n     \"            )\\n\",\n-    \"        return cleaned_text == self.true_val.upper()\\n\",\n     \"\\n\",\n     \"    @property\\n\",\n     \"    def _type(self) -> str:\\n\",\ndiff --git a/libs/core/langchain_core/output_parsers/base.py b/libs/core/langchain_core/output_parsers/base.py\nindex cad5da3b6..124af1152 100644\n--- a/libs/core/langchain_core/output_parsers/base.py\n+++ b/libs/core/langchain_core/output_parsers/base.py\n@@ -132,14 +132,25 @@ class BaseOutputParser(\n                 false_val: str = \"NO\"\n \n                 def parse(self, text: str) -> bool:\n-                    cleaned_text = text.strip().upper()\n-                    if cleaned_text not in (self.true_val.upper(), self.false_val.upper()):\n+                    cleaned_upper_text = text.strip().upper()\n+                    if (\n+                        self.true_val.upper() in cleaned_upper_text\n+                        and self.false_val.upper() in cleaned_upper_text\n+                    ):\n                         raise OutputParserException(\n-                            f\"BooleanOutputParser expected output value to either be \"\n-                            f\"{self.true_val} or {self.false_val} (case-insensitive). \"\n-                            f\"Received {cleaned_text}.\"\n+                            f\"Ambiguous response. Both {self.true_val} and \"\n+                            f\"{self.false_val} in received: {text}.\"\n+                        )\n+                    elif self.true_val.upper() in cleaned_upper_text:\n+                        return True\n+                    elif self.false_val.upper() in cleaned_upper_text:\n+                        return False\n+                    else:\n+                        raise OutputParserException(\n+                            f\"BooleanOutputParser expected output value to include \"\n+                            f\"either {self.true_val} or {self.false_val}. \"\n+                            f\"Received {text}.\"\n                         )\n-                    return cleaned_text == self.true_val.upper()\n \n                 @property\n                 def _type(self) -> str:\n"}
{"instance_id": "langchain-ai__langchain-4103", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/document_loaders/csv_loader.py b/langchain/document_loaders/csv_loader.py\nindex 54c0d8f56..a844f94b1 100644\n--- a/langchain/document_loaders/csv_loader.py\n+++ b/langchain/document_loaders/csv_loader.py\n@@ -36,13 +36,7 @@ class CSVLoader(BaseLoader):\n         self.file_path = file_path\n         self.source_column = source_column\n         self.encoding = encoding\n-        if csv_args is None:\n-            self.csv_args = {\n-                \"delimiter\": csv.Dialect.delimiter,\n-                \"quotechar\": csv.Dialect.quotechar,\n-            }\n-        else:\n-            self.csv_args = csv_args\n+        self.csv_args = csv_args or {}\n \n     def load(self) -> List[Document]:\n         \"\"\"Load data into document objects.\"\"\"\n"}
{"instance_id": "langchain-ai__langchain-3367", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/agents/conversational/output_parser.py b/langchain/agents/conversational/output_parser.py\nindex f11eb540b..cadaabe32 100644\n--- a/langchain/agents/conversational/output_parser.py\n+++ b/langchain/agents/conversational/output_parser.py\n@@ -17,8 +17,8 @@ class ConvoOutputParser(AgentOutputParser):\n             return AgentFinish(\n                 {\"output\": text.split(f\"{self.ai_prefix}:\")[-1].strip()}, text\n             )\n-        regex = r\"Action: (.*?)[\\n]*Action Input: (.*)\"\n-        match = re.search(regex, text)\n+        regex = r\"Action: (.*?)[\\r\\n]+Action Input:[\\s]*(.*)\"\n+        match = re.search(regex, text, re.DOTALL)\n         if not match:\n             raise OutputParserException(f\"Could not parse LLM output: `{text}`\")\n         action = match.group(1)\ndiff --git a/langchain/agents/mrkl/output_parser.py b/langchain/agents/mrkl/output_parser.py\nindex 0309609bb..178fefee1 100644\n--- a/langchain/agents/mrkl/output_parser.py\n+++ b/langchain/agents/mrkl/output_parser.py\n@@ -18,7 +18,7 @@ class MRKLOutputParser(AgentOutputParser):\n                 {\"output\": text.split(FINAL_ANSWER_ACTION)[-1].strip()}, text\n             )\n         # \\s matches against tab/newline/whitespace\n-        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n+        regex = r\"Action\\s*\\d*\\s*:(.*?)[\\r\\n]+Action\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n         match = re.search(regex, text, re.DOTALL)\n         if not match:\n             raise OutputParserException(f\"Could not parse LLM output: `{text}`\")\n"}
{"instance_id": "langchain-ai__langchain-4579", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/document_loaders/web_base.py b/langchain/document_loaders/web_base.py\nindex f39f361fa..d77dbad4e 100644\n--- a/langchain/document_loaders/web_base.py\n+++ b/langchain/document_loaders/web_base.py\n@@ -79,6 +79,8 @@ class WebBaseLoader(BaseLoader):\n                 \"fake_useragent not found, using default user agent. \"\n                 \"To get a realistic header for requests, `pip install fake_useragent`.\"\n             )\n+            headers = header_template or default_header_template\n+            self.session.headers = dict(headers)\n \n     @property\n     def web_path(self) -> str:\n"}
{"instance_id": "keras-team__keras-20002", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/src/utils/summary_utils.py b/keras/src/utils/summary_utils.py\nindex 7fe10f776..13b912583 100644\n--- a/keras/src/utils/summary_utils.py\n+++ b/keras/src/utils/summary_utils.py\n@@ -97,11 +97,11 @@ def format_layer_shape(layer):\n     else:\n         try:\n             outputs = layer.compute_output_shape(**layer._build_shapes_dict)\n-        except NotImplementedError:\n+            output_shapes = tree.map_shape_structure(\n+                lambda x: format_shape(x), outputs\n+            )\n+        except (NotImplementedError, ValueError):\n             return \"?\"\n-        output_shapes = tree.map_shape_structure(\n-            lambda x: format_shape(x), outputs\n-        )\n     if len(output_shapes) == 1:\n         return output_shapes[0]\n     out = str(output_shapes)\n"}
{"instance_id": "langchain-ai__langchain-19331", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/libs/core/langchain_core/language_models/llms.py b/libs/core/langchain_core/language_models/llms.py\nindex 7fe90a0ff..b2f874a07 100644\n--- a/libs/core/langchain_core/language_models/llms.py\n+++ b/libs/core/langchain_core/language_models/llms.py\n@@ -116,14 +116,26 @@ def create_base_retry_decorator(\n \n \n def get_prompts(\n-    params: Dict[str, Any], prompts: List[str]\n+    params: Dict[str, Any],\n+    prompts: List[str],\n+    cache: Optional[BaseCache] = None,\n ) -> Tuple[Dict[int, List], str, List[int], List[str]]:\n-    \"\"\"Get prompts that are already cached.\"\"\"\n+    \"\"\"Get prompts that are already cached.\n+\n+    Args:\n+        params: Dictionary of parameters.\n+        prompts: List of prompts.\n+        cache: Cache to use. If None, uses the global cache.\n+\n+    Returns:\n+        Tuple of existing prompts, llm_string, missing prompt indices,\n+        and missing prompts.\n+    \"\"\"\n     llm_string = str(sorted([(k, v) for k, v in params.items()]))\n     missing_prompts = []\n     missing_prompt_idxs = []\n     existing_prompts = {}\n-    llm_cache = get_llm_cache()\n+    llm_cache = cache if cache is not None else get_llm_cache()\n     for i, prompt in enumerate(prompts):\n         if llm_cache is not None:\n             cache_val = llm_cache.lookup(prompt, llm_string)\n@@ -136,14 +148,26 @@ def get_prompts(\n \n \n async def aget_prompts(\n-    params: Dict[str, Any], prompts: List[str]\n+    params: Dict[str, Any],\n+    prompts: List[str],\n+    cache: Optional[BaseCache] = None,\n ) -> Tuple[Dict[int, List], str, List[int], List[str]]:\n-    \"\"\"Get prompts that are already cached. Async version.\"\"\"\n+    \"\"\"Get prompts that are already cached. Async version.\n+\n+    Args:\n+        params: Dictionary of parameters.\n+        prompts: List of prompts.\n+        cache: Cache to use. If None, uses the global cache.\n+\n+    Returns:\n+        Tuple of existing prompts, llm_string, missing prompt indices,\n+        and missing prompts.\n+    \"\"\"\n     llm_string = str(sorted([(k, v) for k, v in params.items()]))\n     missing_prompts = []\n     missing_prompt_idxs = []\n     existing_prompts = {}\n-    llm_cache = get_llm_cache()\n+    llm_cache = cache if cache is not None else get_llm_cache()\n     for i, prompt in enumerate(prompts):\n         if llm_cache:\n             cache_val = await llm_cache.alookup(prompt, llm_string)\n@@ -161,9 +185,22 @@ def update_cache(\n     missing_prompt_idxs: List[int],\n     new_results: LLMResult,\n     prompts: List[str],\n+    cache: Optional[BaseCache] = None,\n ) -> Optional[dict]:\n-    \"\"\"Update the cache and get the LLM output.\"\"\"\n-    llm_cache = get_llm_cache()\n+    \"\"\"Update the cache and get the LLM output.\n+\n+    Args:\n+        existing_prompts: Dictionary of existing prompts.\n+        llm_string: LLM string.\n+        missing_prompt_idxs: List of missing prompt indices.\n+        new_results: LLMResult with new results.\n+        prompts: List of prompts.\n+        cache: Cache to use. If None, uses the global cache.\n+\n+    Returns:\n+        LLM output.\n+    \"\"\"\n+    llm_cache = cache if cache is not None else get_llm_cache()\n     for i, result in enumerate(new_results.generations):\n         existing_prompts[missing_prompt_idxs[i]] = result\n         prompt = prompts[missing_prompt_idxs[i]]\n@@ -179,9 +216,22 @@ async def aupdate_cache(\n     missing_prompt_idxs: List[int],\n     new_results: LLMResult,\n     prompts: List[str],\n+    cache: Optional[BaseCache] = None,\n ) -> Optional[dict]:\n-    \"\"\"Update the cache and get the LLM output. Async version\"\"\"\n-    llm_cache = get_llm_cache()\n+    \"\"\"Update the cache and get the LLM output. Async version.\n+\n+    Args:\n+        existing_prompts: Dictionary of existing prompts.\n+        llm_string: LLM string.\n+        missing_prompt_idxs: List of missing prompt indices.\n+        new_results: LLMResult with new results.\n+        prompts: List of prompts.\n+        cache: Cache to use. If None, uses the global cache.\n+\n+    Returns:\n+        LLM output.\n+    \"\"\"\n+    llm_cache = cache if cache is not None else get_llm_cache()\n     for i, result in enumerate(new_results.generations):\n         existing_prompts[missing_prompt_idxs[i]] = result\n         prompt = prompts[missing_prompt_idxs[i]]\n@@ -712,22 +762,39 @@ class BaseLLM(BaseLanguageModel[str], ABC):\n         params = self.dict()\n         params[\"stop\"] = stop\n         options = {\"stop\": stop}\n-        (\n-            existing_prompts,\n-            llm_string,\n-            missing_prompt_idxs,\n-            missing_prompts,\n-        ) = get_prompts(params, prompts)\n+\n+        # Determine which cache to use, if any\n+        # If cache is a BaseCache instance, use it\n+        # If cache is True, use the global cache\n+        # If cache is False, don't use any cache\n+        # If cache is None, use the global cache if it's set\n         if isinstance(self.cache, BaseCache):\n-            raise NotImplementedError(\n-                \"Local cache is not yet supported for \" \"LLMs (only chat models)\"\n-            )\n-        disregard_cache = self.cache is not None and not self.cache\n+            llm_cache = self.cache\n+        else:\n+            llm_cache = get_llm_cache()\n+\n+        # We should check the cache unless it's explicitly set to False\n+        # A None cache means we should use the default global cache if it's configured.\n+        check_cache = self.cache or self.cache is None\n+\n+        if check_cache:\n+            (\n+                existing_prompts,\n+                llm_string,\n+                missing_prompt_idxs,\n+                missing_prompts,\n+            ) = get_prompts(params, prompts, llm_cache)\n+        else:\n+            existing_prompts = {}\n+            llm_string = str(sorted([(k, v) for k, v in params.items()]))\n+            missing_prompt_idxs = list(range(len(prompts)))\n+            missing_prompts = prompts\n+\n         new_arg_supported = inspect.signature(self._generate).parameters.get(\n             \"run_manager\"\n         )\n-        if get_llm_cache() is None or disregard_cache:\n-            if self.cache is not None and self.cache:\n+        if llm_cache is None or not check_cache:\n+            if self.cache is True:\n                 raise ValueError(\n                     \"Asked to cache, but no cache found at `langchain.cache`.\"\n                 )\n@@ -765,7 +832,12 @@ class BaseLLM(BaseLanguageModel[str], ABC):\n                 missing_prompts, stop, run_managers, bool(new_arg_supported), **kwargs\n             )\n             llm_output = update_cache(\n-                existing_prompts, llm_string, missing_prompt_idxs, new_results, prompts\n+                existing_prompts,\n+                llm_string,\n+                missing_prompt_idxs,\n+                new_results,\n+                prompts,\n+                llm_cache,\n             )\n             run_info = (\n                 [RunInfo(run_id=run_manager.run_id) for run_manager in run_managers]\n@@ -925,23 +997,39 @@ class BaseLLM(BaseLanguageModel[str], ABC):\n         params = self.dict()\n         params[\"stop\"] = stop\n         options = {\"stop\": stop}\n-        (\n-            existing_prompts,\n-            llm_string,\n-            missing_prompt_idxs,\n-            missing_prompts,\n-        ) = await aget_prompts(params, prompts)\n+\n+        # Determine which cache to use, if any\n+        # If cache is a BaseCache instance, use it\n+        # If cache is True, use the global cache\n+        # If cache is False, don't use any cache\n+        # If cache is None, use the global cache if it's set\n         if isinstance(self.cache, BaseCache):\n-            raise NotImplementedError(\n-                \"Local cache is not yet supported for \" \"LLMs (only chat models)\"\n-            )\n+            llm_cache = self.cache\n+        else:\n+            llm_cache = get_llm_cache()\n+\n+        # We should check the cache unless it's explicitly set to False\n+        # A None cache means we should use the default global cache if it's configured.\n+        check_cache = self.cache or self.cache is None\n+\n+        if check_cache:\n+            (\n+                existing_prompts,\n+                llm_string,\n+                missing_prompt_idxs,\n+                missing_prompts,\n+            ) = await aget_prompts(params, prompts, llm_cache)\n+        else:\n+            existing_prompts = {}\n+            llm_string = str(sorted([(k, v) for k, v in params.items()]))\n+            missing_prompt_idxs = list(range(len(prompts)))\n+            missing_prompts = prompts\n \n-        disregard_cache = self.cache is not None and not self.cache\n         new_arg_supported = inspect.signature(self._agenerate).parameters.get(\n             \"run_manager\"\n         )\n-        if get_llm_cache() is None or disregard_cache:\n-            if self.cache is not None and self.cache:\n+        if llm_cache is None or not check_cache:\n+            if self.cache is True:\n                 raise ValueError(\n                     \"Asked to cache, but no cache found at `langchain.cache`.\"\n                 )\n@@ -993,7 +1081,12 @@ class BaseLLM(BaseLanguageModel[str], ABC):\n                 **kwargs,  # type: ignore[arg-type]\n             )\n             llm_output = await aupdate_cache(\n-                existing_prompts, llm_string, missing_prompt_idxs, new_results, prompts\n+                existing_prompts,\n+                llm_string,\n+                missing_prompt_idxs,\n+                new_results,\n+                prompts,\n+                llm_cache,\n             )\n             run_info = (\n                 [RunInfo(run_id=run_manager.run_id) for run_manager in run_managers]  # type: ignore[attr-defined]\n"}
{"instance_id": "huggingface__transformers-8747", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/bart/modeling_bart.py b/src/transformers/models/bart/modeling_bart.py\nindex afa006a542..74133d609c 100644\n--- a/src/transformers/models/bart/modeling_bart.py\n+++ b/src/transformers/models/bart/modeling_bart.py\n@@ -375,14 +375,17 @@ class BartEncoder(nn.Module):\n \n         if self.layer_norm:\n             x = self.layer_norm(x)\n-        if output_hidden_states:\n-            encoder_states.append(x)\n-            # T x B x C -> B x T x C\n-            encoder_states = tuple(hidden_state.transpose(0, 1) for hidden_state in encoder_states)\n \n         # T x B x C -> B x T x C\n         x = x.transpose(0, 1)\n \n+        if output_hidden_states:\n+            # Convert hidden states from T x B x C to B x T x C format.\n+            # We transpose intermediate hidden states and append the final x (already transposed)\n+            # to ensure the last hidden state is the same object as x, which allows gradient\n+            # computation on the last hidden state.\n+            encoder_states = tuple(hidden_state.transpose(0, 1) for hidden_state in encoder_states) + (x,)\n+\n         if not return_dict:\n             return tuple(v for v in [x, encoder_states, all_attentions] if v is not None)\n         return BaseModelOutput(last_hidden_state=x, hidden_states=encoder_states, attentions=all_attentions)\n@@ -576,14 +579,14 @@ class BartDecoder(nn.Module):\n         encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n \n         # decoder layers\n-        all_hidden_states = () if output_hidden_states else None\n+        all_hidden_states = [] if output_hidden_states else None\n         all_self_attns = () if output_attentions else None\n         all_cross_attentions = () if output_attentions else None\n         next_decoder_cache: List[Dict] = []\n         for idx, decoder_layer in enumerate(self.layers):\n             # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n             if output_hidden_states:\n-                all_hidden_states += (x,)\n+                all_hidden_states.append(x)\n             dropout_probability = random.uniform(0, 1)\n             if self.training and (dropout_probability < self.layerdrop):\n                 continue\n@@ -611,11 +614,16 @@ class BartDecoder(nn.Module):\n             x = self.layer_norm(x)\n \n         # Convert to standard output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\n-        if output_hidden_states:\n-            all_hidden_states = tuple(hidden_state.transpose(0, 1) for hidden_state in all_hidden_states)\n         x = x.transpose(0, 1)\n         encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n \n+        if output_hidden_states:\n+            # Convert hidden states from T x B x C to B x T x C format.\n+            # We transpose intermediate hidden states and append the final x (already transposed)\n+            # to ensure the last hidden state is the same object as x, which allows gradient\n+            # computation on the last hidden state.\n+            all_hidden_states = tuple(hidden_state.transpose(0, 1) for hidden_state in all_hidden_states) + (x,)\n+\n         next_cache = next_decoder_cache if use_cache else None\n         if not return_dict:\n             return tuple(\ndiff --git a/src/transformers/models/fsmt/modeling_fsmt.py b/src/transformers/models/fsmt/modeling_fsmt.py\nindex 0c9337e30a..cf8e768ace 100644\n--- a/src/transformers/models/fsmt/modeling_fsmt.py\n+++ b/src/transformers/models/fsmt/modeling_fsmt.py\n@@ -477,14 +477,16 @@ class FSMTEncoder(nn.Module):\n             if output_attentions:\n                 all_attentions = all_attentions + (attn,)\n \n-        if output_hidden_states:\n-            encoder_states.append(x)\n-            # T x B x C -> B x T x C\n-            encoder_states = tuple(hidden_state.transpose(0, 1) for hidden_state in encoder_states)\n-\n         # T x B x C -> B x T x C\n         x = x.transpose(0, 1)\n \n+        if output_hidden_states:\n+            # Convert hidden states from T x B x C to B x T x C format.\n+            # We transpose intermediate hidden states and append the final x (already transposed)\n+            # to ensure the last hidden state is the same object as x, which allows gradient\n+            # computation on the last hidden state.\n+            encoder_states = tuple(hidden_state.transpose(0, 1) for hidden_state in encoder_states) + (x,)\n+\n         if not return_dict:\n             return tuple(v for v in [x, encoder_states, all_attentions] if v is not None)\n         return BaseModelOutput(last_hidden_state=x, hidden_states=encoder_states, attentions=all_attentions)\n@@ -659,14 +661,14 @@ class FSMTDecoder(nn.Module):\n         encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n \n         # decoder layers\n-        all_hidden_states = () if output_hidden_states else None\n+        all_hidden_states = [] if output_hidden_states else None\n         all_self_attns = () if output_attentions else None\n         all_cross_attns = () if output_attentions else None\n         next_decoder_cache = []\n         for idx, decoder_layer in enumerate(self.layers):\n             # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n             if output_hidden_states:\n-                all_hidden_states += (x,)\n+                all_hidden_states.append(x)\n             dropout_probability = random.uniform(0, 1)\n             if self.training and (dropout_probability < self.layerdrop):\n                 continue\n@@ -691,11 +693,16 @@ class FSMTDecoder(nn.Module):\n                 all_cross_attns += (layer_cross_attn,)\n \n         # Convert to standard output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\n-        if output_hidden_states:\n-            all_hidden_states = tuple(hidden_state.transpose(0, 1) for hidden_state in all_hidden_states)\n         x = x.transpose(0, 1)\n         encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n \n+        if output_hidden_states:\n+            # Convert hidden states from T x B x C to B x T x C format.\n+            # We transpose intermediate hidden states and append the final x (already transposed)\n+            # to ensure the last hidden state is the same object as x, which allows gradient\n+            # computation on the last hidden state.\n+            all_hidden_states = tuple(hidden_state.transpose(0, 1) for hidden_state in all_hidden_states) + (x,)\n+\n         x = self.output_projection(x)\n \n         next_cache = next_decoder_cache if use_cache else None\ndiff --git a/src/transformers/trainer_pt_utils.py b/src/transformers/trainer_pt_utils.py\nindex cb3d4a5bfe..38dd818770 100644\n--- a/src/transformers/trainer_pt_utils.py\n+++ b/src/transformers/trainer_pt_utils.py\n@@ -37,7 +37,10 @@ if is_torch_tpu_available():\n if version.parse(torch.__version__) <= version.parse(\"1.4.1\"):\n     SAVE_STATE_WARNING = \"\"\n else:\n-    from torch.optim.lr_scheduler import SAVE_STATE_WARNING\n+    try:\n+        from torch.optim.lr_scheduler import SAVE_STATE_WARNING\n+    except ImportError:\n+        SAVE_STATE_WARNING = \"\"\n \n logger = logging.get_logger(__name__)\n \n"}
{"instance_id": "langchain-ai__langchain-4646", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/output_parsers/pydantic.py b/langchain/output_parsers/pydantic.py\nindex 4b0fa53d5..52619dd49 100644\n--- a/langchain/output_parsers/pydantic.py\n+++ b/langchain/output_parsers/pydantic.py\n@@ -22,7 +22,7 @@ class PydanticOutputParser(BaseOutputParser[T]):\n             json_str = \"\"\n             if match:\n                 json_str = match.group()\n-            json_object = json.loads(json_str)\n+            json_object = json.loads(json_str, strict=False)\n             return self.pydantic_object.parse_obj(json_object)\n \n         except (json.JSONDecodeError, ValidationError) as e:\ndiff --git a/langchain/output_parsers/structured.py b/langchain/output_parsers/structured.py\nindex 345950f9d..061eab950 100644\n--- a/langchain/output_parsers/structured.py\n+++ b/langchain/output_parsers/structured.py\n@@ -31,7 +31,7 @@ def parse_json_markdown(text: str, expected_keys: List[str]) -> Any:\n \n     json_string = text.split(\"```json\")[1].strip().strip(\"```\").strip()\n     try:\n-        json_obj = json.loads(json_string)\n+        json_obj = json.loads(json_string, strict=False)\n     except json.JSONDecodeError as e:\n         raise OutputParserException(f\"Got invalid JSON object. Error: {e}\")\n     for key in expected_keys:\n"}
{"instance_id": "langchain-ai__langchain-4420", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/document_loaders/whatsapp_chat.py b/langchain/document_loaders/whatsapp_chat.py\nindex 4cbac88cc..bd59258f3 100644\n--- a/langchain/document_loaders/whatsapp_chat.py\n+++ b/langchain/document_loaders/whatsapp_chat.py\n@@ -30,9 +30,9 @@ class WhatsAppChatLoader(BaseLoader):\n             \\[?\n             (\n                 \\d{1,2}\n-                [\\/.]\n+                [\\/.\\-]\n                 \\d{1,2}\n-                [\\/.]\n+                [\\/.\\-]\n                 \\d{2,4}\n                 ,\\s\n                 \\d{1,2}\n@@ -40,13 +40,12 @@ class WhatsAppChatLoader(BaseLoader):\n                 (?:\n                     :\\d{2}\n                 )?\n-                (?:[ _](?:AM|PM))?\n+                (?:[\\s\\u202f_](?:AM|PM|am|pm))?\n             )\n             \\]?\n-            [\\s-]*\n-            ([\\w\\s]+)\n-            [:]+\n-            \\s\n+            [\\s\\-]*\n+            ([^:]+)\n+            :\\s\n             (.+)\n         \"\"\"\n         for line in lines:\n"}
{"instance_id": "langchain-ai__langchain-4009", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/callbacks/openai_info.py b/langchain/callbacks/openai_info.py\nindex 3c77f1f22..ad64db36e 100644\n--- a/langchain/callbacks/openai_info.py\n+++ b/langchain/callbacks/openai_info.py\n@@ -5,9 +5,13 @@ from langchain.callbacks.base import BaseCallbackHandler\n from langchain.schema import AgentAction, AgentFinish, LLMResult\n \n \n-def get_openai_model_cost_per_1k_tokens(\n+def _get_openai_model_cost_per_1k_tokens_base(\n     model_name: str, is_completion: bool = False\n ) -> float:\n+    \"\"\"Get the cost per 1k tokens for a known OpenAI model.\n+    \n+    Returns the cost or raises ValueError if model is not known.\n+    \"\"\"\n     model_cost_mapping = {\n         \"gpt-4\": 0.03,\n         \"gpt-4-0314\": 0.03,\n@@ -21,13 +25,22 @@ def get_openai_model_cost_per_1k_tokens(\n         \"gpt-3.5-turbo-0301\": 0.002,\n         \"text-ada-001\": 0.0004,\n         \"ada\": 0.0004,\n+        \"ada-finetuned\": 0.0016,\n         \"text-babbage-001\": 0.0005,\n         \"babbage\": 0.0005,\n+        \"babbage-finetuned\": 0.0024,\n+        \"babbage-002\": 0.0004,\n+        \"babbage-002-finetuned\": 0.0016,\n         \"text-curie-001\": 0.002,\n         \"curie\": 0.002,\n+        \"curie-finetuned\": 0.012,\n         \"text-davinci-003\": 0.02,\n         \"text-davinci-002\": 0.02,\n         \"code-davinci-002\": 0.02,\n+        \"davinci\": 0.02,\n+        \"davinci-finetuned\": 0.12,\n+        \"davinci-002\": 0.002,\n+        \"davinci-002-finetuned\": 0.012,\n     }\n \n     cost = model_cost_mapping.get(\n@@ -44,6 +57,84 @@ def get_openai_model_cost_per_1k_tokens(\n     return cost\n \n \n+def _standardize_model_name(\n+    model_name: str, is_finetuned_model: bool = False\n+) -> str:\n+    \"\"\"Standardize the model name to a known model name.\n+    \n+    This handles fine-tuned model names that have the format:\n+    - ft:base-model:org:custom_suffix:id (new format)\n+    - base-model:ft-org-date (old format)\n+    \n+    Args:\n+        model_name: The model name to standardize.\n+        is_finetuned_model: Whether the model is a fine-tuned model.\n+            If True, returns the base model name with \"-finetuned\" suffix.\n+    \n+    Returns:\n+        The standardized model name.\n+    \"\"\"\n+    model_name = model_name.lower()\n+    suffix = \"-finetuned\" if is_finetuned_model else \"\"\n+    # Handle new fine-tuned model format: ft:base-model:org:custom_suffix:id\n+    if model_name.startswith(\"ft:\"):\n+        # Extract the base model from the fine-tuned model name\n+        # Format: ft:base-model:org:custom_suffix:id\n+        parts = model_name.split(\":\")\n+        if len(parts) >= 2:\n+            return parts[1] + suffix\n+    # Handle old fine-tuned model format: base-model:ft-org-date\n+    if \":ft-\" in model_name:\n+        return model_name.split(\":\")[0] + suffix\n+    return model_name\n+\n+\n+def get_openai_model_cost_per_1k_tokens(\n+    model_name: str, is_completion: bool = False\n+) -> float:\n+    \"\"\"Get the cost per 1k tokens for an OpenAI model.\n+    \n+    This function handles both standard and fine-tuned model names.\n+    For fine-tuned models, it uses the cost of the base model with\n+    fine-tuned pricing.\n+    \"\"\"\n+    # First, try to get the cost for the model as-is\n+    try:\n+        return _get_openai_model_cost_per_1k_tokens_base(model_name, is_completion)\n+    except ValueError:\n+        pass\n+    \n+    # If that fails, try to standardize the model name (for fine-tuned models)\n+    # First try with finetuned pricing\n+    standardized_name = _standardize_model_name(model_name, is_finetuned_model=True)\n+    if standardized_name != model_name.lower():\n+        try:\n+            return _get_openai_model_cost_per_1k_tokens_base(\n+                standardized_name, is_completion\n+            )\n+        except ValueError:\n+            pass\n+    \n+    # If finetuned pricing is not available, try with base model pricing\n+    standardized_name = _standardize_model_name(model_name, is_finetuned_model=False)\n+    if standardized_name != model_name.lower():\n+        try:\n+            return _get_openai_model_cost_per_1k_tokens_base(\n+                standardized_name, is_completion\n+            )\n+        except ValueError:\n+            pass\n+    \n+    # If we still can't find the cost, raise an error\n+    raise ValueError(\n+        f\"Unknown model: {model_name}. Please provide a valid OpenAI model name.\"\n+        \"Known models are: gpt-4, gpt-4-0314, gpt-4-32k, gpt-4-32k-0314, \"\n+        \"gpt-3.5-turbo, gpt-3.5-turbo-0301, text-ada-001, ada, text-babbage-001, \"\n+        \"babbage, text-curie-001, curie, text-davinci-003, text-davinci-002, \"\n+        \"code-davinci-002, davinci-002, babbage-002, davinci\"\n+    )\n+\n+\n class OpenAICallbackHandler(BaseCallbackHandler):\n     \"\"\"Callback Handler that tracks OpenAI info.\"\"\"\n \n"}
{"instance_id": "langchain-ai__langchain-5584", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/vectorstores/chroma.py b/langchain/vectorstores/chroma.py\nindex 39577b0cf..9c6307d0e 100644\n--- a/langchain/vectorstores/chroma.py\n+++ b/langchain/vectorstores/chroma.py\n@@ -356,7 +356,7 @@ class Chroma(VectorStore):\n             raise ValueError(\n                 \"For update, you must specify an embedding function on creation.\"\n             )\n-        embeddings = self._embedding_function.embed_documents(list(text))\n+        embeddings = self._embedding_function.embed_documents([text])\n \n         self._collection.update(\n             ids=[document_id],\n"}
{"instance_id": "langchain-ai__langchain-6765", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/agents/initialize.py b/langchain/agents/initialize.py\nindex cb26fb630..a28e5e4e3 100644\n--- a/langchain/agents/initialize.py\n+++ b/langchain/agents/initialize.py\n@@ -51,7 +51,10 @@ def initialize_agent(\n                 f\"Got unknown agent type: {agent}. \"\n                 f\"Valid types are: {AGENT_TO_CLASS.keys()}.\"\n             )\n-        tags_.append(agent.value)\n+        if isinstance(agent, AgentType):\n+            tags_.append(agent.value)\n+        else:\n+            tags_.append(agent)\n         agent_cls = AGENT_TO_CLASS[agent]\n         agent_kwargs = agent_kwargs or {}\n         agent_obj = agent_cls.from_llm_and_tools(\n"}
{"instance_id": "langchain-ai__langchain-5625", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/text_splitter.py b/langchain/text_splitter.py\nindex 77f34d063..f999eb9b8 100644\n--- a/langchain/text_splitter.py\n+++ b/langchain/text_splitter.py\n@@ -35,7 +35,7 @@ def _split_text(text: str, separator: str, keep_separator: bool) -> List[str]:\n     if separator:\n         if keep_separator:\n             # The parentheses in the pattern keep the delimiters in the result.\n-            _splits = re.split(f\"({separator})\", text)\n+            _splits = re.split(f\"({re.escape(separator)})\", text)\n             splits = [_splits[i] + _splits[i + 1] for i in range(1, len(_splits), 2)]\n             if len(_splits) % 2 == 0:\n                 splits += _splits[-1:]\n"}
{"instance_id": "langchain-ai__langchain-5450", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/embeddings/huggingface.py b/langchain/embeddings/huggingface.py\nindex 04e0c76e6..4420484fe 100644\n--- a/langchain/embeddings/huggingface.py\n+++ b/langchain/embeddings/huggingface.py\n@@ -25,7 +25,12 @@ class HuggingFaceEmbeddings(BaseModel, Embeddings):\n \n             model_name = \"sentence-transformers/all-mpnet-base-v2\"\n             model_kwargs = {'device': 'cpu'}\n-            hf = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n+            encode_kwargs = {'normalize_embeddings': False}\n+            hf = HuggingFaceEmbeddings(\n+                model_name=model_name,\n+                model_kwargs=model_kwargs,\n+                encode_kwargs=encode_kwargs\n+            )\n     \"\"\"\n \n     client: Any  #: :meta private:\n@@ -100,8 +105,11 @@ class HuggingFaceInstructEmbeddings(BaseModel, Embeddings):\n \n             model_name = \"hkunlp/instructor-large\"\n             model_kwargs = {'device': 'cpu'}\n+            encode_kwargs = {'normalize_embeddings': True}\n             hf = HuggingFaceInstructEmbeddings(\n-                model_name=model_name, model_kwargs=model_kwargs\n+                model_name=model_name,\n+                model_kwargs=model_kwargs,\n+                encode_kwargs=encode_kwargs\n             )\n     \"\"\"\n \n@@ -113,6 +121,8 @@ class HuggingFaceInstructEmbeddings(BaseModel, Embeddings):\n     Can be also set by SENTENCE_TRANSFORMERS_HOME environment variable.\"\"\"\n     model_kwargs: Dict[str, Any] = Field(default_factory=dict)\n     \"\"\"Key word arguments to pass to the model.\"\"\"\n+    encode_kwargs: Dict[str, Any] = Field(default_factory=dict)\n+    \"\"\"Key word arguments to pass when calling the `encode` method of the model.\"\"\"\n     embed_instruction: str = DEFAULT_EMBED_INSTRUCTION\n     \"\"\"Instruction to use for embedding documents.\"\"\"\n     query_instruction: str = DEFAULT_QUERY_INSTRUCTION\n@@ -145,7 +155,7 @@ class HuggingFaceInstructEmbeddings(BaseModel, Embeddings):\n             List of embeddings, one for each text.\n         \"\"\"\n         instruction_pairs = [[self.embed_instruction, text] for text in texts]\n-        embeddings = self.client.encode(instruction_pairs)\n+        embeddings = self.client.encode(instruction_pairs, **self.encode_kwargs)\n         return embeddings.tolist()\n \n     def embed_query(self, text: str) -> List[float]:\n@@ -158,5 +168,5 @@ class HuggingFaceInstructEmbeddings(BaseModel, Embeddings):\n             Embeddings for the text.\n         \"\"\"\n         instruction_pair = [self.query_instruction, text]\n-        embedding = self.client.encode([instruction_pair])[0]\n+        embedding = self.client.encode([instruction_pair], **self.encode_kwargs)[0]\n         return embedding.tolist()\n"}
{"instance_id": "langchain-ai__langchain-5609", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/langchain/agents/chat/output_parser.py b/langchain/agents/chat/output_parser.py\nindex 9f143d076..eb8d63a7b 100644\n--- a/langchain/agents/chat/output_parser.py\n+++ b/langchain/agents/chat/output_parser.py\n@@ -13,17 +13,29 @@ class ChatOutputParser(AgentOutputParser):\n         return FORMAT_INSTRUCTIONS\n \n     def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n-        if FINAL_ANSWER_ACTION in text:\n-            return AgentFinish(\n-                {\"output\": text.split(FINAL_ANSWER_ACTION)[-1].strip()}, text\n-            )\n+        includes_answer = FINAL_ANSWER_ACTION in text\n         try:\n             action = text.split(\"```\")[1]\n             response = json.loads(action.strip())\n+            includes_action = True\n+        except Exception:\n+            includes_action = False\n+\n+        if includes_answer and includes_action:\n+            raise OutputParserException(\n+                f\"Parsing LLM output produced both a final answer \"\n+                f\"and a parse-able action: {text}\"\n+            )\n+\n+        if includes_answer:\n+            return AgentFinish(\n+                {\"output\": text.split(FINAL_ANSWER_ACTION)[-1].strip()}, text\n+            )\n+\n+        if includes_action:\n             return AgentAction(response[\"action\"], response[\"action_input\"], text)\n \n-        except Exception:\n-            raise OutputParserException(f\"Could not parse LLM output: {text}\")\n+        raise OutputParserException(f\"Could not parse LLM output: {text}\")\n \n     @property\n     def _type(self) -> str:\ndiff --git a/langchain/agents/conversational/output_parser.py b/langchain/agents/conversational/output_parser.py\nindex 84c4fec58..ed14beed5 100644\n--- a/langchain/agents/conversational/output_parser.py\n+++ b/langchain/agents/conversational/output_parser.py\n@@ -13,16 +13,32 @@ class ConvoOutputParser(AgentOutputParser):\n         return FORMAT_INSTRUCTIONS\n \n     def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n-        if f\"{self.ai_prefix}:\" in text:\n+        regex = r\"Action: (.*?)[\\n]*Action Input: (.*)\"\n+        action_match = re.search(regex, text)\n+        includes_answer = f\"{self.ai_prefix}:\" in text\n+\n+        if action_match:\n+            if includes_answer:\n+                # Check if the AI prefix (final answer) appears after the action\n+                # without an \"Observation:\" in between (which would indicate the\n+                # action was already executed and the LLM is hallucinating).\n+                after_action = text[action_match.end():]\n+                if f\"{self.ai_prefix}:\" in after_action:\n+                    if \"Observation:\" not in after_action:\n+                        raise OutputParserException(\n+                            f\"Parsing LLM output produced both a final answer \"\n+                            f\"and a parse-able action: {text}\"\n+                        )\n+\n+        if includes_answer:\n             return AgentFinish(\n                 {\"output\": text.split(f\"{self.ai_prefix}:\")[-1].strip()}, text\n             )\n-        regex = r\"Action: (.*?)[\\n]*Action Input: (.*)\"\n-        match = re.search(regex, text)\n-        if not match:\n+\n+        if not action_match:\n             raise OutputParserException(f\"Could not parse LLM output: `{text}`\")\n-        action = match.group(1)\n-        action_input = match.group(2)\n+        action = action_match.group(1)\n+        action_input = action_match.group(2)\n         return AgentAction(action.strip(), action_input.strip(\" \").strip('\"'), text)\n \n     @property\ndiff --git a/langchain/agents/mrkl/output_parser.py b/langchain/agents/mrkl/output_parser.py\nindex 3ef3ed0e3..589afb377 100644\n--- a/langchain/agents/mrkl/output_parser.py\n+++ b/langchain/agents/mrkl/output_parser.py\n@@ -13,16 +13,34 @@ class MRKLOutputParser(AgentOutputParser):\n         return FORMAT_INSTRUCTIONS\n \n     def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n-        if FINAL_ANSWER_ACTION in text:\n-            return AgentFinish(\n-                {\"output\": text.split(FINAL_ANSWER_ACTION)[-1].strip()}, text\n-            )\n+        includes_answer = FINAL_ANSWER_ACTION in text\n         # \\s matches against tab/newline/whitespace\n         regex = (\n             r\"Action\\s*\\d*\\s*:[\\s]*(.*?)[\\s]*Action\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n         )\n-        match = re.search(regex, text, re.DOTALL)\n-        if not match:\n+        action_match = re.search(regex, text, re.DOTALL)\n+\n+        if action_match:\n+            if includes_answer:\n+                # The action_input (group 2) may contain \"Final Answer:\" if the LLM\n+                # hallucinated both an action and a final answer in one response.\n+                # Check if \"Final Answer:\" appears in the action_input without\n+                # an \"Observation:\" in between (which would indicate the action\n+                # was already executed).\n+                action_input = action_match.group(2)\n+                if FINAL_ANSWER_ACTION in action_input:\n+                    if \"Observation:\" not in action_input:\n+                        raise OutputParserException(\n+                            f\"Parsing LLM output produced both a final answer \"\n+                            f\"and a parse-able action: {text}\"\n+                        )\n+\n+        if includes_answer:\n+            return AgentFinish(\n+                {\"output\": text.split(FINAL_ANSWER_ACTION)[-1].strip()}, text\n+            )\n+\n+        if not action_match:\n             if not re.search(r\"Action\\s*\\d*\\s*:[\\s]*(.*?)\", text, re.DOTALL):\n                 raise OutputParserException(\n                     f\"Could not parse LLM output: `{text}`\",\n@@ -42,8 +60,8 @@ class MRKLOutputParser(AgentOutputParser):\n                 )\n             else:\n                 raise OutputParserException(f\"Could not parse LLM output: `{text}`\")\n-        action = match.group(1).strip()\n-        action_input = match.group(2)\n+        action = action_match.group(1).strip()\n+        action_input = action_match.group(2)\n \n         tool_input = action_input.strip(\" \")\n         # ensure if its a well formed SQL query we don't remove any trailing \" chars\n"}
{"instance_id": "microsoft__vscode-110094", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/common/controller/cursorTypeOperations.ts b/src/vs/editor/common/controller/cursorTypeOperations.ts\nindex cf538a83386..6fc84dfacef 100644\n--- a/src/vs/editor/common/controller/cursorTypeOperations.ts\n+++ b/src/vs/editor/common/controller/cursorTypeOperations.ts\n@@ -615,11 +615,60 @@ export class TypeOperations {\n \t\treturn autoClosingPair;\n \t}\n \n+\t/**\n+\t * Determine if the character before the cursor is part of a shorter auto-closing pair\n+\t * that conflicts with the current one. If so, return the length of the closing string\n+\t * that needs to be deleted.\n+\t */\n+\tprivate static _getAutoClosingPairClose(config: CursorConfiguration, model: ITextModel, selections: Selection[], autoClosingPair: StandardAutoClosingPairConditional, insertOpenCharacter: boolean): string {\n+\t\t// Only relevant for multi-character auto-closing pairs\n+\t\tif (autoClosingPair.open.length <= 1) {\n+\t\t\treturn '';\n+\t\t}\n+\n+\t\t// Check each prefix of the opening string to see if it matches a shorter auto-closing pair\n+\t\tconst prefix = autoClosingPair.open.substring(0, autoClosingPair.open.length - 1);\n+\t\tfor (let prefixLen = prefix.length; prefixLen >= 1; prefixLen--) {\n+\t\t\tconst prefixToCheck = prefix.substring(prefix.length - prefixLen);\n+\t\t\tconst lastChar = prefixToCheck.charAt(prefixToCheck.length - 1);\n+\t\t\tconst shorterPairCandidates = config.autoClosingPairsOpen2.get(lastChar);\n+\t\t\tif (!shorterPairCandidates) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n+\n+\t\t\tfor (const shorterPair of shorterPairCandidates) {\n+\t\t\t\tif (shorterPair.open === prefixToCheck) {\n+\t\t\t\t\t// Found a shorter pair that matches the prefix\n+\t\t\t\t\t// Check if its closing string is immediately after the cursor for all selections\n+\t\t\t\t\tlet allMatch = true;\n+\t\t\t\t\tfor (const selection of selections) {\n+\t\t\t\t\t\tconst position = selection.getPosition();\n+\t\t\t\t\t\tconst lineText = model.getLineContent(position.lineNumber);\n+\t\t\t\t\t\t// When insertOpenCharacter is true, the cursor is at position.column\n+\t\t\t\t\t\t// When insertOpenCharacter is false, the character has already been inserted\n+\t\t\t\t\t\tconst startCol = insertOpenCharacter ? position.column : position.column;\n+\t\t\t\t\t\tconst endCol = startCol + shorterPair.close.length;\n+\t\t\t\t\t\tconst textAfter = lineText.substring(startCol - 1, endCol - 1);\n+\t\t\t\t\t\tif (textAfter !== shorterPair.close) {\n+\t\t\t\t\t\t\tallMatch = false;\n+\t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t\tif (allMatch) {\n+\t\t\t\t\t\treturn shorterPair.close;\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\treturn '';\n+\t}\n+\n \tprivate static _runAutoClosingOpenCharType(prevEditOperationType: EditOperationType, config: CursorConfiguration, model: ITextModel, selections: Selection[], ch: string, insertOpenCharacter: boolean, autoClosingPair: StandardAutoClosingPairConditional): EditOperationResult {\n \t\tlet commands: ICommand[] = [];\n+\t\tconst charsToDelete = this._getAutoClosingPairClose(config, model, selections, autoClosingPair, insertOpenCharacter);\n \t\tfor (let i = 0, len = selections.length; i < len; i++) {\n \t\t\tconst selection = selections[i];\n-\t\t\tcommands[i] = new TypeWithAutoClosingCommand(selection, ch, insertOpenCharacter, autoClosingPair.close);\n+\t\t\tcommands[i] = new TypeWithAutoClosingCommand(selection, ch, insertOpenCharacter, autoClosingPair.close, charsToDelete.length);\n \t\t}\n \t\treturn new EditOperationResult(EditOperationType.Typing, commands, {\n \t\t\tshouldPushStackElementBefore: true,\n@@ -934,8 +983,18 @@ export class TypeWithAutoClosingCommand extends ReplaceCommandWithOffsetCursorSt\n \tpublic closeCharacterRange: Range | null;\n \tpublic enclosingRange: Range | null;\n \n-\tconstructor(selection: Selection, openCharacter: string, insertOpenCharacter: boolean, closeCharacter: string) {\n-\t\tsuper(selection, (insertOpenCharacter ? openCharacter : '') + closeCharacter, 0, -closeCharacter.length);\n+\tconstructor(selection: Selection, openCharacter: string, insertOpenCharacter: boolean, closeCharacter: string, charsToDeleteAfterCursor: number = 0) {\n+\t\t// If we need to delete characters after the cursor (e.g., closing chars from a shorter auto-closing pair),\n+\t\t// extend the selection to include those characters\n+\t\tconst adjustedSelection = charsToDeleteAfterCursor > 0\n+\t\t\t? new Selection(\n+\t\t\t\tselection.selectionStartLineNumber,\n+\t\t\t\tselection.selectionStartColumn,\n+\t\t\t\tselection.positionLineNumber,\n+\t\t\t\tselection.positionColumn + charsToDeleteAfterCursor\n+\t\t\t)\n+\t\t\t: selection;\n+\t\tsuper(adjustedSelection, (insertOpenCharacter ? openCharacter : '') + closeCharacter, 0, -closeCharacter.length);\n \t\tthis._openCharacter = openCharacter;\n \t\tthis._closeCharacter = closeCharacter;\n \t\tthis.closeCharacterRange = null;\n"}
{"instance_id": "microsoft__vscode-108964", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/contrib/snippet/snippetSession.ts b/src/vs/editor/contrib/snippet/snippetSession.ts\nindex 7f91f835c4c..fd46e8c62e9 100644\n--- a/src/vs/editor/contrib/snippet/snippetSession.ts\n+++ b/src/vs/editor/contrib/snippet/snippetSession.ts\n@@ -114,7 +114,7 @@ export class OneSnippet {\n \t\t\t\t\tconst range = this._editor.getModel().getDecorationRange(id)!;\n \t\t\t\t\tconst currentValue = this._editor.getModel().getValueInRange(range);\n \n-\t\t\t\t\toperations.push(EditOperation.replaceMove(range, placeholder.transform.resolve(currentValue)));\n+\t\t\t\t\toperations.push(EditOperation.replace(range, placeholder.transform.resolve(currentValue)));\n \t\t\t\t}\n \t\t\t}\n \t\t\tif (operations.length > 0) {\n"}
{"instance_id": "microsoft__vscode-123294", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/common/modes/linkComputer.ts b/src/vs/editor/common/modes/linkComputer.ts\nindex c0ca979fb9b..29b505fab8b 100644\n--- a/src/vs/editor/common/modes/linkComputer.ts\n+++ b/src/vs/editor/common/modes/linkComputer.ts\n@@ -154,7 +154,7 @@ function getClassifier(): CharacterClassifier<CharacterClass> {\n \tif (_classifier === null) {\n \t\t_classifier = new CharacterClassifier<CharacterClass>(CharacterClass.None);\n \n-\t\tconst FORCE_TERMINATION_CHARACTERS = ' \\t<>\\'\\\"\u3001\u3002\uff61\uff64\uff0c\uff0e\uff1a\uff1b\u2018\u201c\u3008\u300a\u300c\u300e\u3010\u3014\uff08\uff3b\uff5b\uff62\uff63\uff5d\uff3d\uff09\u3015\u3011\u300f\u300d\u300b\u3009\u201d\u2019\uff40\uff5e\u2026';\n+\t\tconst FORCE_TERMINATION_CHARACTERS = ' \\t<>\\'\\\"\u3001\u3002\uff61\uff64\uff0c\uff0e\uff1a\uff1b\u2018\u201c\u3008\u300a\u300c\u300e\u3014\uff08\uff3b\uff5b\uff62\uff63\uff5d\uff3d\uff09\u3015\u300f\u300d\u300b\u3009\u201d\u2019\uff40\uff5e\u2026';\n \t\tfor (let i = 0; i < FORCE_TERMINATION_CHARACTERS.length; i++) {\n \t\t\t_classifier.set(FORCE_TERMINATION_CHARACTERS.charCodeAt(i), CharacterClass.ForceTermination);\n \t\t}\n@@ -190,6 +190,7 @@ export class LinkComputer {\n \t\t\t\t(charCodeBeforeLink === CharCode.OpenParen && lastCharCodeInLink === CharCode.CloseParen)\n \t\t\t\t|| (charCodeBeforeLink === CharCode.OpenSquareBracket && lastCharCodeInLink === CharCode.CloseSquareBracket)\n \t\t\t\t|| (charCodeBeforeLink === CharCode.OpenCurlyBrace && lastCharCodeInLink === CharCode.CloseCurlyBrace)\n+\t\t\t\t|| (charCodeBeforeLink === 0x3010 /* \u3010 */ && lastCharCodeInLink === 0x3011 /* \u3011 */)\n \t\t\t) {\n \t\t\t\t// Do not end in ) if ( is before the link start\n \t\t\t\t// Do not end in ] if [ is before the link start\n@@ -225,6 +226,7 @@ export class LinkComputer {\n \t\t\tlet hasOpenSquareBracket = false;\n \t\t\tlet inSquareBrackets = false;\n \t\t\tlet hasOpenCurlyBracket = false;\n+\t\t\tlet hasOpenAngleBracket = false;\n \n \t\t\twhile (j < len) {\n \n@@ -257,6 +259,15 @@ export class LinkComputer {\n \t\t\t\t\t\tcase CharCode.CloseCurlyBrace:\n \t\t\t\t\t\t\tchClass = (hasOpenCurlyBracket ? CharacterClass.None : CharacterClass.ForceTermination);\n \t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\t// U+3010 LEFT BLACK LENTICULAR BRACKET\n+\t\t\t\t\t\t// U+3011 RIGHT BLACK LENTICULAR BRACKET\n+\t\t\t\t\t\tcase 0x3010:\n+\t\t\t\t\t\t\thasOpenAngleBracket = true;\n+\t\t\t\t\t\t\tchClass = CharacterClass.None;\n+\t\t\t\t\t\t\tbreak;\n+\t\t\t\t\t\tcase 0x3011:\n+\t\t\t\t\t\t\tchClass = (hasOpenAngleBracket ? CharacterClass.None : CharacterClass.ForceTermination);\n+\t\t\t\t\t\t\tbreak;\n \t\t\t\t\t\t/* The following three rules make it that ' or \" or ` are allowed inside links if the link began with a different one */\n \t\t\t\t\t\tcase CharCode.SingleQuote:\n \t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.DoubleQuote || linkBeginChCode === CharCode.BackTick) ? CharacterClass.None : CharacterClass.ForceTermination;\n@@ -317,6 +328,7 @@ export class LinkComputer {\n \t\t\t\t\thasOpenParens = false;\n \t\t\t\t\thasOpenSquareBracket = false;\n \t\t\t\t\thasOpenCurlyBracket = false;\n+\t\t\t\t\thasOpenAngleBracket = false;\n \n \t\t\t\t\t// Record where the link started\n \t\t\t\t\tlinkBeginIndex = j + 1;\n"}
{"instance_id": "microsoft__vscode-106767", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/contrib/suggest/suggestModel.ts b/src/vs/editor/contrib/suggest/suggestModel.ts\nindex bb4f269ece8..4dc911ff3a0 100644\n--- a/src/vs/editor/contrib/suggest/suggestModel.ts\n+++ b/src/vs/editor/contrib/suggest/suggestModel.ts\n@@ -557,9 +557,16 @@ export class SuggestModel implements IDisposable {\n \t\t}\n \n \t\tif (ctx.leadingWord.word.length !== 0 && ctx.leadingWord.startColumn > this._context.leadingWord.startColumn) {\n-\t\t\t// started a new word while IntelliSense shows -> retrigger\n-\t\t\tthis.trigger({ auto: this._context.auto, shy: false }, true);\n-\t\t\treturn;\n+\t\t\t// started a new word while IntelliSense shows -> retrigger but only if the new\n+\t\t\t// temporary word isn't included in the replace-range of the current completion item\n+\t\t\tconst relevantItem = this._completionModel.items[0];\n+\t\t\tif (relevantItem && relevantItem.editStart.column <= ctx.leadingWord.startColumn) {\n+\t\t\t\t// the new word is within the replace-range of the current completion item\n+\t\t\t\t// -> keep the current completion\n+\t\t\t} else {\n+\t\t\t\tthis.trigger({ auto: this._context.auto, shy: false }, true);\n+\t\t\t\treturn;\n+\t\t\t}\n \t\t}\n \n \t\tif (ctx.column > this._context.column && this._completionModel.incomplete.size > 0 && ctx.leadingWord.word.length !== 0) {\n"}
{"instance_id": "microsoft__vscode-132628", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/contrib/inlineCompletions/inlineCompletionsModel.ts b/src/vs/editor/contrib/inlineCompletions/inlineCompletionsModel.ts\nindex cdccdbda1be..bacae66a66b 100644\n--- a/src/vs/editor/contrib/inlineCompletions/inlineCompletionsModel.ts\n+++ b/src/vs/editor/contrib/inlineCompletions/inlineCompletionsModel.ts\n@@ -299,6 +299,9 @@ export class InlineCompletionsSession extends BaseGhostTextWidgetModel {\n \t//#endregion\n \n \tpublic get ghostText(): GhostText | undefined {\n+\t\tif (!this.isValid) {\n+\t\t\treturn undefined;\n+\t\t}\n \t\tconst currentCompletion = this.currentCompletion;\n \t\tconst mode = this.editor.getOptions().get(EditorOption.inlineSuggest).mode;\n \t\treturn currentCompletion ? inlineCompletionToGhostText(currentCompletion, this.editor.getModel(), mode, this.editor.getPosition()) : undefined;\n"}
{"instance_id": "microsoft__vscode-127071", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/base/browser/ui/tree/objectTreeModel.ts b/src/vs/base/browser/ui/tree/objectTreeModel.ts\nindex 6b7f452d376..d0b1fcf076c 100644\n--- a/src/vs/base/browser/ui/tree/objectTreeModel.ts\n+++ b/src/vs/base/browser/ui/tree/objectTreeModel.ts\n@@ -148,7 +148,7 @@ export class ObjectTreeModel<T extends NonNullable<any>, TFilterData extends Non\n \t\t\t}\n \n \t\t\tconst collapsible = typeof treeElement.collapsible === 'boolean' ? treeElement.collapsible : node.collapsible;\n-\t\t\tconst collapsed = typeof treeElement.collapsed !== 'undefined' ? treeElement.collapsed : node.collapsed;\n+\t\t\tconst collapsed = typeof treeElement.collapsed !== 'undefined' ? treeElement.collapsed : (collapsible !== node.collapsible ? undefined : node.collapsed);\n \n \t\t\treturn {\n \t\t\t\t...treeElement,\n"}
{"instance_id": "microsoft__vscode-148971", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/base/browser/markdownRenderer.ts b/src/vs/base/browser/markdownRenderer.ts\nindex 72c25e77c2b..51db7d676e9 100644\n--- a/src/vs/base/browser/markdownRenderer.ts\n+++ b/src/vs/base/browser/markdownRenderer.ts\n@@ -198,7 +198,7 @@ export function renderMarkdown(markdown: IMarkdownString, options: MarkdownRende\n \t\t\t\t}\n \t\t\t}\n \t\t\ttry {\n-\t\t\t\tlet href = target.dataset['href'];\n+\t\t\t\tlet href = target.dataset['href'] || target.getAttribute('href');\n \t\t\t\tif (href) {\n \t\t\t\t\tif (markdown.baseUri) {\n \t\t\t\t\t\thref = resolveWithBaseUri(URI.from(markdown.baseUri), href);\n"}
{"instance_id": "microsoft__vscode-149380", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/workbench/contrib/debug/node/terminals.ts b/src/vs/workbench/contrib/debug/node/terminals.ts\nindex 5390b15a8ec..5b3c27941b0 100644\n--- a/src/vs/workbench/contrib/debug/node/terminals.ts\n+++ b/src/vs/workbench/contrib/debug/node/terminals.ts\n@@ -157,8 +157,16 @@ export function prepareCommand(shell: string, args: string[], cwd?: string, env?\n \t\tcase ShellType.bash: {\n \n \t\t\tquote = (s: string) => {\n-\t\t\t\ts = s.replace(/([\"'\\\\\\$!><#()\\[\\]*&^|])/g, '\\\\$1');\n-\t\t\t\treturn (' ;'.split('').some(char => s.includes(char)) || s.length === 0) ? `\"${s}\"` : s;\n+\t\t\t\tconst needsQuotes = s.length === 0 || ' ;'.split('').some(char => s.includes(char));\n+\t\t\t\tif (needsQuotes) {\n+\t\t\t\t\t// Inside double quotes, only escape: $, `, \\, \", !\n+\t\t\t\t\ts = s.replace(/([\"'\\\\\\$!`])/g, '\\\\$1');\n+\t\t\t\t\treturn `\"${s}\"`;\n+\t\t\t\t} else {\n+\t\t\t\t\t// Outside quotes, escape all shell metacharacters\n+\t\t\t\t\ts = s.replace(/([\"'\\\\\\$!><#()\\[\\]*&^| ;`])/g, '\\\\$1');\n+\t\t\t\t\treturn s;\n+\t\t\t\t}\n \t\t\t};\n \n \t\t\tconst hardQuote = (s: string) => {\n"}
{"instance_id": "microsoft__vscode-135197", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/common/controller/cursorTypeOperations.ts b/src/vs/editor/common/controller/cursorTypeOperations.ts\nindex 3f2e81ed0e1..202fb6bc0c8 100644\n--- a/src/vs/editor/common/controller/cursorTypeOperations.ts\n+++ b/src/vs/editor/common/controller/cursorTypeOperations.ts\n@@ -598,7 +598,7 @@ export class TypeOperations {\n \t\t\t}\n \n \t\t\t// Do not auto-close ' or \" after a word character\n-\t\t\tif (autoClosingPair.open.length === 1 && chIsQuote && autoCloseConfig !== 'always') {\n+\t\t\tif (autoClosingPair.open.length === 1 && (ch === '\\'' || ch === '\"') && autoCloseConfig !== 'always') {\n \t\t\t\tconst wordSeparators = getMapForWordSeparators(config.wordSeparators);\n \t\t\t\tif (insertOpenCharacter && position.column > 1 && wordSeparators.get(lineText.charCodeAt(position.column - 2)) === WordCharacterClass.Regular) {\n \t\t\t\t\treturn null;\n"}
{"instance_id": "microsoft__vscode-136347", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/base/common/strings.ts b/src/vs/base/common/strings.ts\nindex 8a6bc0c28a2..94f9c2d7863 100644\n--- a/src/vs/base/common/strings.ts\n+++ b/src/vs/base/common/strings.ts\n@@ -1031,3 +1031,64 @@ const enum CodePoint {\n \t */\n \tenclosingKeyCap = 0x20E3,\n }\n+\n+const enum Constants {\n+\tUNICODE_SUPPLEMENTARY_PLANE_BEGIN = 0x010000\n+}\n+\n+/**\n+ * Checks if a character code is a unicode control character (Cc or Cf category).\n+ * This includes:\n+ * - C0 controls: U+0000-U+001F\n+ * - DEL: U+007F\n+ * - C1 controls: U+0080-U+009F\n+ * - Unicode format characters (Cf category) that are invisible or can be used maliciously\n+ */\n+export function isControlCharacter(charCode: number): boolean {\n+\t// C0 controls (U+0000-U+001F)\n+\tif (charCode < 32) {\n+\t\treturn true;\n+\t}\n+\t// DEL (U+007F)\n+\tif (charCode === 127) {\n+\t\treturn true;\n+\t}\n+\t// C1 controls (U+0080-U+009F)\n+\tif (charCode >= 0x80 && charCode <= 0x9F) {\n+\t\treturn true;\n+\t}\n+\t// Unicode format characters (Cf category) that are invisible or can be used maliciously\n+\t// Soft Hyphen\n+\tif (charCode === 0x00AD) {\n+\t\treturn true;\n+\t}\n+\t// Arabic format characters\n+\tif (charCode === 0x061C) {\n+\t\treturn true;\n+\t}\n+\t// Zero-width characters and directional marks\n+\tif (charCode >= 0x200B && charCode <= 0x200F) {\n+\t\treturn true;\n+\t}\n+\t// Bidirectional text control (LRE, RLE, PDF, LRO, RLO)\n+\tif (charCode >= 0x202A && charCode <= 0x202E) {\n+\t\treturn true;\n+\t}\n+\t// Word joiner and other format characters\n+\tif (charCode >= 0x2060 && charCode <= 0x2064) {\n+\t\treturn true;\n+\t}\n+\t// Bidirectional isolates and other format characters\n+\tif (charCode >= 0x2066 && charCode <= 0x206F) {\n+\t\treturn true;\n+\t}\n+\t// Zero Width No-Break Space (BOM when at start of text)\n+\tif (charCode === 0xFEFF) {\n+\t\treturn true;\n+\t}\n+\t// Interlinear annotation anchors\n+\tif (charCode >= 0xFFF9 && charCode <= 0xFFFB) {\n+\t\treturn true;\n+\t}\n+\treturn false;\n+}\ndiff --git a/src/vs/editor/browser/view/domLineBreaksComputer.ts b/src/vs/editor/browser/view/domLineBreaksComputer.ts\nindex 0d8f1683bff..02b322276b5 100644\n--- a/src/vs/editor/browser/view/domLineBreaksComputer.ts\n+++ b/src/vs/editor/browser/view/domLineBreaksComputer.ts\n@@ -270,8 +270,17 @@ function renderLine(lineContent: string, initialVisibleColumn: number, tabSize:\n \t\t\t\tif (strings.isFullWidthCharacter(charCode)) {\n \t\t\t\t\tcharWidth++;\n \t\t\t\t}\n-\t\t\t\tif (charCode < 32) {\n-\t\t\t\t\tsb.write1(9216 + charCode);\n+\t\t\t\tif (strings.isControlCharacter(charCode)) {\n+\t\t\t\t\t// See https://unicode-table.com/en/blocks/control-pictures/\n+\t\t\t\t\tif (charCode < 32) {\n+\t\t\t\t\t\tsb.write1(9216 + charCode);\n+\t\t\t\t\t} else if (charCode === 127) {\n+\t\t\t\t\t\t// DEL\n+\t\t\t\t\t\tsb.write1(9249);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\t// Render as replacement character for other control characters\n+\t\t\t\t\t\tsb.write1(0xFFFD);\n+\t\t\t\t\t}\n \t\t\t\t} else {\n \t\t\t\t\tsb.write1(charCode);\n \t\t\t\t}\ndiff --git a/src/vs/editor/common/viewLayout/viewLineRenderer.ts b/src/vs/editor/common/viewLayout/viewLineRenderer.ts\nindex 6c070c5af72..c16cc0b2d93 100644\n--- a/src/vs/editor/common/viewLayout/viewLineRenderer.ts\n+++ b/src/vs/editor/common/viewLayout/viewLineRenderer.ts\n@@ -999,12 +999,17 @@ function _renderLine(input: ResolvedRenderLineInput, sb: IStringBuilder): Render\n \t\t\t\t\t\tif (strings.isFullWidthCharacter(charCode)) {\n \t\t\t\t\t\t\tcharWidth++;\n \t\t\t\t\t\t}\n-\t\t\t\t\t\t// See https://unicode-table.com/en/blocks/control-pictures/\n-\t\t\t\t\t\tif (renderControlCharacters && charCode < 32) {\n-\t\t\t\t\t\t\tsb.write1(9216 + charCode);\n-\t\t\t\t\t\t} else if (renderControlCharacters && charCode === 127) {\n-\t\t\t\t\t\t\t// DEL\n-\t\t\t\t\t\t\tsb.write1(9249);\n+\t\t\t\t\t\tif (renderControlCharacters && strings.isControlCharacter(charCode)) {\n+\t\t\t\t\t\t\t// See https://unicode-table.com/en/blocks/control-pictures/\n+\t\t\t\t\t\t\tif (charCode < 32) {\n+\t\t\t\t\t\t\t\tsb.write1(9216 + charCode);\n+\t\t\t\t\t\t\t} else if (charCode === 127) {\n+\t\t\t\t\t\t\t\t// DEL\n+\t\t\t\t\t\t\t\tsb.write1(9249);\n+\t\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t\t// Render as replacement character for other control characters\n+\t\t\t\t\t\t\t\tsb.write1(0xFFFD);\n+\t\t\t\t\t\t\t}\n \t\t\t\t\t\t} else {\n \t\t\t\t\t\t\tsb.write1(charCode);\n \t\t\t\t\t\t}\ndiff --git a/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts b/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\nindex 6b8f0644953..6c36fd6ca9c 100644\n--- a/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\n+++ b/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\n@@ -475,7 +475,7 @@ function computeCharWidth(charCode: number, visibleColumn: number, tabSize: numb\n \tif (strings.isFullWidthCharacter(charCode)) {\n \t\treturn columnsForFullWidthChar;\n \t}\n-\tif (charCode < 32) {\n+\tif (strings.isControlCharacter(charCode)) {\n \t\t// when using `editor.renderControlCharacters`, the substitutions are often wide\n \t\treturn columnsForFullWidthChar;\n \t}\n"}
{"instance_id": "microsoft__vscode-135805", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/browser/controller/coreCommands.ts b/src/vs/editor/browser/controller/coreCommands.ts\nindex 7f69de6a65d..5762ca6e014 100644\n--- a/src/vs/editor/browser/controller/coreCommands.ts\n+++ b/src/vs/editor/browser/controller/coreCommands.ts\n@@ -602,11 +602,17 @@ export namespace CoreNavigationCommands {\n \t\t\t\t};\n \t\t\t}\n \n+\t\t\t// Check if we should use logical lines instead of wrapped lines for up/down movement\n+\t\t\tlet unit = args.unit;\n+\t\t\tif (unit === CursorMove_.Unit.WrappedLine && viewModel.cursorConfig.wordWrapCursorMovement === 'logical') {\n+\t\t\t\tunit = CursorMove_.Unit.Line;\n+\t\t\t}\n+\n \t\t\tviewModel.model.pushStackElement();\n \t\t\tviewModel.setCursorStates(\n \t\t\t\tdynamicArgs.source,\n \t\t\t\tCursorChangeReason.Explicit,\n-\t\t\t\tCursorMoveCommands.simpleMove(viewModel, viewModel.getCursorStates(), args.direction, args.select, args.value, args.unit)\n+\t\t\t\tCursorMoveCommands.simpleMove(viewModel, viewModel.getCursorStates(), args.direction, args.select, args.value, unit)\n \t\t\t);\n \t\t\tviewModel.revealPrimaryCursor(dynamicArgs.source, true);\n \t\t}\ndiff --git a/src/vs/editor/common/config/editorOptions.ts b/src/vs/editor/common/config/editorOptions.ts\nindex 45b8fc9753a..2ef7f35685f 100644\n--- a/src/vs/editor/common/config/editorOptions.ts\n+++ b/src/vs/editor/common/config/editorOptions.ts\n@@ -91,6 +91,11 @@ export interface IEditorOptions {\n \t * by mouse.\n \t*/\n \tcursorSurroundingLinesStyle?: 'default' | 'all';\n+\t/**\n+\t * Controls whether the cursor should move by logical lines or by wrapped lines.\n+\t * Defaults to `default`, the cursor moves by wrapped lines.\n+\t*/\n+\twordWrapCursorMovement?: 'default' | 'logical';\n \t/**\n \t * Render last line number when the file ends with a newline.\n \t * Defaults to true.\n@@ -4229,6 +4234,7 @@ export const enum EditorOption {\n \twordWrapBreakAfterCharacters,\n \twordWrapBreakBeforeCharacters,\n \twordWrapColumn,\n+\twordWrapCursorMovement,\n \twordWrapOverride1,\n \twordWrapOverride2,\n \twrappingIndent,\n@@ -4885,6 +4891,18 @@ export const EditorOptions = {\n \t\t\t}, \"Controls the wrapping column of the editor when `#editor.wordWrap#` is `wordWrapColumn` or `bounded`.\")\n \t\t}\n \t)),\n+\twordWrapCursorMovement: register(new EditorStringEnumOption(\n+\t\tEditorOption.wordWrapCursorMovement, 'wordWrapCursorMovement',\n+\t\t'default' as 'default' | 'logical',\n+\t\t['default', 'logical'] as const,\n+\t\t{\n+\t\t\tenumDescriptions: [\n+\t\t\t\tnls.localize('wordWrapCursorMovement.default', \"Cursor up/down moves by wrapped lines.\"),\n+\t\t\t\tnls.localize('wordWrapCursorMovement.logical', \"Cursor up/down moves by logical lines.\")\n+\t\t\t],\n+\t\t\tdescription: nls.localize('wordWrapCursorMovement', \"Controls whether the cursor should move by logical lines or by wrapped lines when word wrap is enabled.\")\n+\t\t}\n+\t)),\n \twordWrapOverride1: register(new EditorStringEnumOption(\n \t\tEditorOption.wordWrapOverride1, 'wordWrapOverride1',\n \t\t'inherit' as 'off' | 'on' | 'inherit',\ndiff --git a/src/vs/editor/common/controller/cursorCommon.ts b/src/vs/editor/common/controller/cursorCommon.ts\nindex f1d27757e25..447963499d4 100644\n--- a/src/vs/editor/common/controller/cursorCommon.ts\n+++ b/src/vs/editor/common/controller/cursorCommon.ts\n@@ -79,6 +79,7 @@ export class CursorConfiguration {\n \tpublic readonly autoClosingPairs: AutoClosingPairs;\n \tpublic readonly surroundingPairs: CharacterMap;\n \tpublic readonly shouldAutoCloseBefore: { quote: (ch: string) => boolean, bracket: (ch: string) => boolean };\n+\tpublic readonly wordWrapCursorMovement: 'default' | 'logical';\n \n \tprivate readonly _languageId: string;\n \tprivate _electricChars: { [key: string]: boolean; } | null;\n@@ -98,6 +99,7 @@ export class CursorConfiguration {\n \t\t\t|| e.hasChanged(EditorOption.useTabStops)\n \t\t\t|| e.hasChanged(EditorOption.lineHeight)\n \t\t\t|| e.hasChanged(EditorOption.readOnly)\n+\t\t\t|| e.hasChanged(EditorOption.wordWrapCursorMovement)\n \t\t);\n \t}\n \n@@ -130,6 +132,7 @@ export class CursorConfiguration {\n \t\tthis.autoClosingOvertype = options.get(EditorOption.autoClosingOvertype);\n \t\tthis.autoSurround = options.get(EditorOption.autoSurround);\n \t\tthis.autoIndent = options.get(EditorOption.autoIndent);\n+\t\tthis.wordWrapCursorMovement = options.get(EditorOption.wordWrapCursorMovement);\n \n \t\tthis.surroundingPairs = {};\n \t\tthis._electricChars = null;\ndiff --git a/src/vs/editor/common/standalone/standaloneEnums.ts b/src/vs/editor/common/standalone/standaloneEnums.ts\nindex 70221dfa79a..d4d1795cde7 100644\n--- a/src/vs/editor/common/standalone/standaloneEnums.ts\n+++ b/src/vs/editor/common/standalone/standaloneEnums.ts\n@@ -287,17 +287,18 @@ export enum EditorOption {\n \twordWrapBreakAfterCharacters = 117,\n \twordWrapBreakBeforeCharacters = 118,\n \twordWrapColumn = 119,\n-\twordWrapOverride1 = 120,\n-\twordWrapOverride2 = 121,\n-\twrappingIndent = 122,\n-\twrappingStrategy = 123,\n-\tshowDeprecated = 124,\n-\tinlayHints = 125,\n-\teditorClassName = 126,\n-\tpixelRatio = 127,\n-\ttabFocusMode = 128,\n-\tlayoutInfo = 129,\n-\twrappingInfo = 130\n+\twordWrapCursorMovement = 120,\n+\twordWrapOverride1 = 121,\n+\twordWrapOverride2 = 122,\n+\twrappingIndent = 123,\n+\twrappingStrategy = 124,\n+\tshowDeprecated = 125,\n+\tinlayHints = 126,\n+\teditorClassName = 127,\n+\tpixelRatio = 128,\n+\ttabFocusMode = 129,\n+\tlayoutInfo = 130,\n+\twrappingInfo = 131\n }\n \n /**\n"}
{"instance_id": "microsoft__vscode-153857", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/common/languages/linkComputer.ts b/src/vs/editor/common/languages/linkComputer.ts\nindex 0ee39a20229..9952831fd5b 100644\n--- a/src/vs/editor/common/languages/linkComputer.ts\n+++ b/src/vs/editor/common/languages/linkComputer.ts\n@@ -258,15 +258,15 @@ export class LinkComputer {\n \t\t\t\t\t\tcase CharCode.CloseCurlyBrace:\n \t\t\t\t\t\t\tchClass = (hasOpenCurlyBracket ? CharacterClass.None : CharacterClass.ForceTermination);\n \t\t\t\t\t\t\tbreak;\n-\t\t\t\t\t\t/* The following three rules make it that ' or \" or ` are allowed inside links if the link began with a different one */\n+\t\t\t\t\t\t/* The following three rules make it that ' or \" or ` are allowed inside links only if the link did not begin with them */\n \t\t\t\t\t\tcase CharCode.SingleQuote:\n-\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.DoubleQuote || linkBeginChCode === CharCode.BackTick) ? CharacterClass.None : CharacterClass.ForceTermination;\n+\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.SingleQuote) ? CharacterClass.ForceTermination : CharacterClass.None;\n \t\t\t\t\t\t\tbreak;\n \t\t\t\t\t\tcase CharCode.DoubleQuote:\n-\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.SingleQuote || linkBeginChCode === CharCode.BackTick) ? CharacterClass.None : CharacterClass.ForceTermination;\n+\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.DoubleQuote) ? CharacterClass.ForceTermination : CharacterClass.None;\n \t\t\t\t\t\t\tbreak;\n \t\t\t\t\t\tcase CharCode.BackTick:\n-\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.SingleQuote || linkBeginChCode === CharCode.DoubleQuote) ? CharacterClass.None : CharacterClass.ForceTermination;\n+\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.BackTick) ? CharacterClass.ForceTermination : CharacterClass.None;\n \t\t\t\t\t\t\tbreak;\n \t\t\t\t\t\tcase CharCode.Asterisk:\n \t\t\t\t\t\t\t// `*` terminates a link if the link began with `*`\n"}
{"instance_id": "huggingface__transformers-30602", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/modeling_utils.py b/src/transformers/modeling_utils.py\nindex 1ed8040f88..c34d67a65d 100644\n--- a/src/transformers/modeling_utils.py\n+++ b/src/transformers/modeling_utils.py\n@@ -3261,6 +3261,13 @@ class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix\n                         f\"Error no file named {_add_variant(SAFE_WEIGHTS_NAME, variant)} found in directory\"\n                         f\" {pretrained_model_name_or_path}.\"\n                     )\n+                elif use_safetensors is None:\n+                    raise EnvironmentError(\n+                        f\"Error no file named {_add_variant(SAFE_WEIGHTS_NAME, variant)},\"\n+                        f\" {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME},\"\n+                        f\" {TF_WEIGHTS_NAME + '.index'} or {FLAX_WEIGHTS_NAME} found in directory\"\n+                        f\" {pretrained_model_name_or_path}.\"\n+                    )\n                 else:\n                     raise EnvironmentError(\n                         f\"Error no file named {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME},\"\n@@ -3408,24 +3415,41 @@ class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix\n                                 f\" {variant}. Use `variant=None` to load this model from those weights.\"\n                             )\n                         else:\n-                            raise EnvironmentError(\n-                                f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n-                                f\" {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or\"\n-                                f\" {FLAX_WEIGHTS_NAME}.\"\n-                            )\n+                            if use_safetensors is None:\n+                                raise EnvironmentError(\n+                                    f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n+                                    f\" {_add_variant(SAFE_WEIGHTS_NAME, variant)}, {_add_variant(WEIGHTS_NAME, variant)},\"\n+                                    f\" {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or {FLAX_WEIGHTS_NAME}.\"\n+                                )\n+                            else:\n+                                raise EnvironmentError(\n+                                    f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n+                                    f\" {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or\"\n+                                    f\" {FLAX_WEIGHTS_NAME}.\"\n+                                )\n                 except EnvironmentError:\n                     # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\n                     # to the original exception.\n                     raise\n                 except Exception as e:\n                     # For any other exception, we throw a generic error.\n-                    raise EnvironmentError(\n-                        f\"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it\"\n-                        \" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n-                        f\" same name. Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a\"\n-                        f\" directory containing a file named {_add_variant(WEIGHTS_NAME, variant)},\"\n-                        f\" {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or {FLAX_WEIGHTS_NAME}.\"\n-                    ) from e\n+                    if use_safetensors is None:\n+                        raise EnvironmentError(\n+                            f\"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it\"\n+                            \" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n+                            f\" same name. Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a\"\n+                            f\" directory containing a file named {_add_variant(SAFE_WEIGHTS_NAME, variant)},\"\n+                            f\" {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or\"\n+                            f\" {FLAX_WEIGHTS_NAME}.\"\n+                        ) from e\n+                    else:\n+                        raise EnvironmentError(\n+                            f\"Can't load the model for '{pretrained_model_name_or_path}'. If you were trying to load it\"\n+                            \" from 'https://huggingface.co/models', make sure you don't have a local directory with the\"\n+                            f\" same name. Otherwise, make sure '{pretrained_model_name_or_path}' is the correct path to a\"\n+                            f\" directory containing a file named {_add_variant(WEIGHTS_NAME, variant)},\"\n+                            f\" {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or {FLAX_WEIGHTS_NAME}.\"\n+                        ) from e\n \n             if is_local:\n                 logger.info(f\"loading weights file {archive_file}\")\n"}
{"instance_id": "microsoft__vscode-153121", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts b/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\nindex f61919b4ceb..8647457b4b6 100644\n--- a/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\n+++ b/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\n@@ -489,7 +489,7 @@ function canBreak(prevCharCode: number, prevCharCodeClass: CharacterClass, charC\n \treturn (\n \t\tcharCode !== CharCode.Space\n \t\t&& (\n-\t\t\t(prevCharCodeClass === CharacterClass.BREAK_AFTER)\n+\t\t\t(prevCharCodeClass === CharacterClass.BREAK_AFTER && charCodeClass !== CharacterClass.BREAK_AFTER)\n \t\t\t|| (prevCharCodeClass === CharacterClass.BREAK_IDEOGRAPHIC && charCodeClass !== CharacterClass.BREAK_AFTER)\n \t\t\t|| (charCodeClass === CharacterClass.BREAK_BEFORE)\n \t\t\t|| (charCodeClass === CharacterClass.BREAK_IDEOGRAPHIC && prevCharCodeClass !== CharacterClass.BREAK_BEFORE)\n"}
{"instance_id": "huggingface__transformers-27114", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/llama/modeling_llama.py b/src/transformers/models/llama/modeling_llama.py\nindex 703ebf0d95..b1c7bd14b5 100644\n--- a/src/transformers/models/llama/modeling_llama.py\n+++ b/src/transformers/models/llama/modeling_llama.py\n@@ -64,7 +64,7 @@ def _get_unpad_data(attention_mask):\n     seqlens_in_batch = attention_mask.sum(dim=-1, dtype=torch.int32)\n     indices = torch.nonzero(attention_mask.flatten(), as_tuple=False).flatten()\n     max_seqlen_in_batch = seqlens_in_batch.max().item()\n-    cu_seqlens = F.pad(torch.cumsum(seqlens_in_batch, dim=0, dtype=torch.torch.int32), (1, 0))\n+    cu_seqlens = F.pad(torch.cumsum(seqlens_in_batch, dim=0, dtype=torch.int32), (1, 0))\n     return (\n         indices,\n         cu_seqlens,\n@@ -584,9 +584,16 @@ class LlamaFlashAttention2(LlamaAttention):\n         return attn_output\n \n     def _upad_input(self, query_layer, key_layer, value_layer, attention_mask, query_length):\n-        indices_k, cu_seqlens_k, max_seqlen_in_batch_k = _get_unpad_data(attention_mask)\n         batch_size, kv_seq_len, num_key_value_heads, head_dim = key_layer.shape\n \n+        # On the first iteration we need to properly re-create the padding mask\n+        # by slicing it on the proper place\n+        if kv_seq_len != attention_mask.shape[-1]:\n+            attention_mask_num_tokens = attention_mask.shape[-1]\n+            attention_mask = attention_mask[:, attention_mask_num_tokens - kv_seq_len :]\n+\n+        indices_k, cu_seqlens_k, max_seqlen_in_batch_k = _get_unpad_data(attention_mask)\n+\n         key_layer = index_first_axis(\n             key_layer.reshape(batch_size * kv_seq_len, num_key_value_heads, head_dim), indices_k\n         )\n"}
{"instance_id": "microsoft__vscode-122991", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/common/controller/cursorDeleteOperations.ts b/src/vs/editor/common/controller/cursorDeleteOperations.ts\nindex 6854a4e6386..1192bf0cb9d 100644\n--- a/src/vs/editor/common/controller/cursorDeleteOperations.ts\n+++ b/src/vs/editor/common/controller/cursorDeleteOperations.ts\n@@ -199,7 +199,9 @@ export class DeleteOperations {\n \n \tprivate static decreasePositionInModelBy1Column(position: Position, model: ICursorSimpleModel): Position | undefined {\n \t\tif (position.column > 1) {\n-\t\t\treturn position.delta(0, -1);\n+\t\t\tconst lineContent = model.getLineContent(position.lineNumber);\n+\t\t\tconst column = position.column - strings.prevCharLength(lineContent, position.column - 1);\n+\t\t\treturn new Position(position.lineNumber, column);\n \t\t} else if (position.lineNumber > 1) {\n \t\t\tconst newLine = position.lineNumber - 1;\n \t\t\treturn new Position(newLine, model.getLineMaxColumn(newLine));\n"}
{"instance_id": "microsoft__vscode-160342", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/workbench/contrib/files/browser/views/explorerView.ts b/src/vs/workbench/contrib/files/browser/views/explorerView.ts\nindex 8aae18473ee..4e401cb79b6 100644\n--- a/src/vs/workbench/contrib/files/browser/views/explorerView.ts\n+++ b/src/vs/workbench/contrib/files/browser/views/explorerView.ts\n@@ -137,7 +137,7 @@ export function getContext(focus: ExplorerItem[], selection: ExplorerItem[], res\n \t\t}\n \t}\n \n-\tif (respectMultiSelection && selectedStats.indexOf(focusedStat) >= 0) {\n+\tif (respectMultiSelection && selectedStats.length) {\n \t\treturn selectedStats;\n \t}\n \n"}
{"instance_id": "microsoft__vscode-164396", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/common/services/modelService.ts b/src/vs/editor/common/services/modelService.ts\nindex c03821b7b0c..ae4e3cb376d 100644\n--- a/src/vs/editor/common/services/modelService.ts\n+++ b/src/vs/editor/common/services/modelService.ts\n@@ -770,6 +770,7 @@ export class ModelSemanticColoring extends Disposable {\n \tprivate _currentDocumentResponse: SemanticTokensResponse | null;\n \tprivate _currentDocumentRequestCancellationTokenSource: CancellationTokenSource | null;\n \tprivate _documentProvidersChangeListeners: IDisposable[];\n+\tprivate _documentSemanticTokensRequestPending: boolean;\n \n \tconstructor(\n \t\tmodel: ITextModel,\n@@ -789,6 +790,7 @@ export class ModelSemanticColoring extends Disposable {\n \t\tthis._currentDocumentResponse = null;\n \t\tthis._currentDocumentRequestCancellationTokenSource = null;\n \t\tthis._documentProvidersChangeListeners = [];\n+\t\tthis._documentSemanticTokensRequestPending = false;\n \n \t\tthis._register(this._model.onDidChangeContent(() => {\n \t\t\tif (!this._fetchDocumentSemanticTokens.isScheduled()) {\n@@ -851,8 +853,10 @@ export class ModelSemanticColoring extends Disposable {\n \tprivate _fetchDocumentSemanticTokensNow(): void {\n \t\tif (this._currentDocumentRequestCancellationTokenSource) {\n \t\t\t// there is already a request running, let it finish...\n+\t\t\tthis._documentSemanticTokensRequestPending = true;\n \t\t\treturn;\n \t\t}\n+\t\tthis._documentSemanticTokensRequestPending = false;\n \n \t\tif (!hasDocumentSemanticTokensProvider(this._provider, this._model)) {\n \t\t\t// there is no provider\n@@ -898,7 +902,7 @@ export class ModelSemanticColoring extends Disposable {\n \t\t\tthis._currentDocumentRequestCancellationTokenSource = null;\n \t\t\tcontentChangeListener.dispose();\n \n-\t\t\tif (pendingChanges.length > 0) {\n+\t\t\tif (pendingChanges.length > 0 || this._documentSemanticTokensRequestPending) {\n \t\t\t\t// More changes occurred while the request was running\n \t\t\t\tif (!this._fetchDocumentSemanticTokens.isScheduled()) {\n \t\t\t\t\tthis._fetchDocumentSemanticTokens.schedule(this._debounceInformation.get(this._model));\n@@ -918,7 +922,7 @@ export class ModelSemanticColoring extends Disposable {\n \tprivate _setDocumentSemanticTokens(provider: DocumentSemanticTokensProvider | null, tokens: SemanticTokens | SemanticTokensEdits | null, styling: SemanticTokensProviderStyling | null, pendingChanges: IModelContentChangedEvent[]): void {\n \t\tconst currentResponse = this._currentDocumentResponse;\n \t\tconst rescheduleIfNeeded = () => {\n-\t\t\tif (pendingChanges.length > 0 && !this._fetchDocumentSemanticTokens.isScheduled()) {\n+\t\t\tif ((pendingChanges.length > 0 || this._documentSemanticTokensRequestPending) && !this._fetchDocumentSemanticTokens.isScheduled()) {\n \t\t\t\tthis._fetchDocumentSemanticTokens.schedule(this._debounceInformation.get(this._model));\n \t\t\t}\n \t\t};\n"}
{"instance_id": "mrdoob__three.js-14836", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/math/Box3.js b/src/math/Box3.js\nindex 8784d7b2ae..ef2c17cc93 100644\n--- a/src/math/Box3.js\n+++ b/src/math/Box3.js\n@@ -384,7 +384,7 @@ Object.assign( Box3.prototype, {\n \n \t\t}\n \n-\t\treturn ( min <= plane.constant && max >= plane.constant );\n+\t\treturn ( min <= - plane.constant && max >= - plane.constant );\n \n \t},\n \n"}
{"instance_id": "microsoft__vscode-168752", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/common/languages/linkComputer.ts b/src/vs/editor/common/languages/linkComputer.ts\nindex 52f4eaee2fb..8928b4b1c5c 100644\n--- a/src/vs/editor/common/languages/linkComputer.ts\n+++ b/src/vs/editor/common/languages/linkComputer.ts\n@@ -155,12 +155,12 @@ function getClassifier(): CharacterClassifier<CharacterClass> {\n \t\t_classifier = new CharacterClassifier<CharacterClass>(CharacterClass.None);\n \n \t\t// allow-any-unicode-next-line\n-\t\tconst FORCE_TERMINATION_CHARACTERS = ' \\t<>\\'\\\"\u3001\u3002\uff61\uff64\uff0c\uff0e\uff1a\uff1b\u2018\u3008\u300c\u300e\u3014\uff08\uff3b\uff5b\uff62\uff63\uff5d\uff3d\uff09\u3015\u300f\u300d\u3009\u2019\uff40\uff5e\u2026';\n+\t\tconst FORCE_TERMINATION_CHARACTERS = ' \\t<>,\\'\\\"\u3001\u3002\uff61\uff64\uff0c\uff0e\uff1a\uff1b\u2018\u3008\u300c\u300e\u3014\uff08\uff3b\uff5b\uff62\uff63\uff5d\uff3d\uff09\u3015\u300f\u300d\u3009\u2019\uff40\uff5e\u2026';\n \t\tfor (let i = 0; i < FORCE_TERMINATION_CHARACTERS.length; i++) {\n \t\t\t_classifier.set(FORCE_TERMINATION_CHARACTERS.charCodeAt(i), CharacterClass.ForceTermination);\n \t\t}\n \n-\t\tconst CANNOT_END_WITH_CHARACTERS = '.,;:';\n+\t\tconst CANNOT_END_WITH_CHARACTERS = '.;:';\n \t\tfor (let i = 0; i < CANNOT_END_WITH_CHARACTERS.length; i++) {\n \t\t\t_classifier.set(CANNOT_END_WITH_CHARACTERS.charCodeAt(i), CharacterClass.CannotEndIn);\n \t\t}\n"}
{"instance_id": "microsoft__vscode-189223", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\nindex a94483ab0e3..9644b4b3c9d 100644\n--- a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\n+++ b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\n@@ -189,7 +189,11 @@ function parseIntOptional(value: string | undefined): number | undefined {\n // characters the path is not allowed to _start_ with, the second `[]` includes characters not\n // allowed at all in the path. If the characters show up in both regexes the link will stop at that\n // character, otherwise it will stop at a space character.\n-const linkWithSuffixPathCharacters = /(?<path>[^\\s\\|<>\\[\\({][^\\s\\|<>]*)$/;\n+//\n+// This intentionally does not include the full set of characters that are valid in paths, as the\n+// goal is to detect links in the terminal, not to validate paths. Powerline symbols are excluded\n+// as they are often adjacent to paths in prompts.\n+const linkWithSuffixPathCharacters = /(?<path>[^\\s\\|<>\\[\\({\\uE000-\\uF8FF][^\\s\\|<>\\uE000-\\uF8FF]*)$/;\n \n export function detectLinks(line: string, os: OperatingSystem) {\n \t// 1: Detect all links on line via suffixes first\n@@ -300,13 +304,14 @@ enum RegexPathConstants {\n \tPathSeparatorClause = '\\\\/',\n \t// '\":; are allowed in paths but they are often separators so ignore them\n \t// Also disallow \\\\ to prevent a catastropic backtracking case #24795\n-\tExcludedPathCharactersClause = '[^\\\\0<>\\\\?\\\\s!`&*()\\'\":;\\\\\\\\]',\n-\tExcludedStartPathCharactersClause = '[^\\\\0<>\\\\s!`&*()\\\\[\\\\]\\'\":;\\\\\\\\]',\n+\t// Exclude the Private Use Area (U+E000-U+F8FF) which includes powerline symbols\n+\tExcludedPathCharactersClause = '[^\\\\0<>\\\\?\\\\s!`&*()\\'\":;\\\\\\\\\\uE000-\\uF8FF]',\n+\tExcludedStartPathCharactersClause = '[^\\\\0<>\\\\s!`&*()\\\\[\\\\]\\'\":;\\\\\\\\\\uE000-\\uF8FF]',\n \n \tWinOtherPathPrefix = '\\\\.\\\\.?|\\\\~',\n \tWinPathSeparatorClause = '(?:\\\\\\\\|\\\\/)',\n-\tWinExcludedPathCharactersClause = '[^\\\\0<>\\\\?\\\\|\\\\/\\\\s!`&*()\\'\":;]',\n-\tWinExcludedStartPathCharactersClause = '[^\\\\0<>\\\\?\\\\|\\\\/\\\\s!`&*()\\\\[\\\\]\\'\":;]',\n+\tWinExcludedPathCharactersClause = '[^\\\\0<>\\\\?\\\\|\\\\/\\\\s!`&*()\\'\":;\\uE000-\\uF8FF]',\n+\tWinExcludedStartPathCharactersClause = '[^\\\\0<>\\\\?\\\\|\\\\/\\\\s!`&*()\\\\[\\\\]\\'\":;\\uE000-\\uF8FF]',\n }\n \n /**\ndiff --git a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalWordLinkDetector.ts b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalWordLinkDetector.ts\nindex 1991ba84eac..4d3cd46fa0d 100644\n--- a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalWordLinkDetector.ts\n+++ b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalWordLinkDetector.ts\n@@ -127,6 +127,8 @@ export class TerminalWordLinkDetector extends Disposable implements ITerminalLin\n \n \tprivate _refreshSeparatorCodes(): void {\n \t\tconst separators = this._configurationService.getValue<ITerminalConfiguration>(TERMINAL_CONFIG_SECTION).wordSeparators;\n-\t\tthis._separatorRegex = new RegExp(`[${escapeRegExpCharacters(separators)}]`, 'g');\n+\t\t// Add the Private Use Area (U+E000-U+F8FF) which includes powerline symbols to the\n+\t\t// bracked expression to ensure they are treated as separators.\n+\t\tthis._separatorRegex = new RegExp(`[${escapeRegExpCharacters(separators)}\\uE000-\\uF8FF]`, 'g');\n \t}\n }\n"}
{"instance_id": "mrdoob__three.js-24461", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/math/Color.js b/src/math/Color.js\nindex e2c45f974f..60db44d847 100644\n--- a/src/math/Color.js\n+++ b/src/math/Color.js\n@@ -202,12 +202,12 @@ class Color {\n \n \t\t\t\t\t}\n \n-\t\t\t\t\tif ( color = /^\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n+\t\t\t\t\tif ( color = /^\\s*(\\d*\\.?\\d+)\\%\\s*,\\s*(\\d*\\.?\\d+)\\%\\s*,\\s*(\\d*\\.?\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n \n \t\t\t\t\t\t// rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\n-\t\t\t\t\t\tthis.r = Math.min( 100, parseInt( color[ 1 ], 10 ) ) / 100;\n-\t\t\t\t\t\tthis.g = Math.min( 100, parseInt( color[ 2 ], 10 ) ) / 100;\n-\t\t\t\t\t\tthis.b = Math.min( 100, parseInt( color[ 3 ], 10 ) ) / 100;\n+\t\t\t\t\t\tthis.r = Math.min( 100, parseFloat( color[ 1 ] ) ) / 100;\n+\t\t\t\t\t\tthis.g = Math.min( 100, parseFloat( color[ 2 ] ) ) / 100;\n+\t\t\t\t\t\tthis.b = Math.min( 100, parseFloat( color[ 3 ] ) ) / 100;\n \n \t\t\t\t\t\tColorManagement.toWorkingColorSpace( this, colorSpace );\n \n@@ -222,12 +222,12 @@ class Color {\n \t\t\t\tcase 'hsl':\n \t\t\t\tcase 'hsla':\n \n-\t\t\t\t\tif ( color = /^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n+\t\t\t\t\tif ( color = /^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d*\\.?\\d+)\\%\\s*,\\s*(\\d*\\.?\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n \n \t\t\t\t\t\t// hsl(120,50%,50%) hsla(120,50%,50%,0.5)\n \t\t\t\t\t\tconst h = parseFloat( color[ 1 ] ) / 360;\n-\t\t\t\t\t\tconst s = parseInt( color[ 2 ], 10 ) / 100;\n-\t\t\t\t\t\tconst l = parseInt( color[ 3 ], 10 ) / 100;\n+\t\t\t\t\t\tconst s = parseFloat( color[ 2 ] ) / 100;\n+\t\t\t\t\t\tconst l = parseFloat( color[ 3 ] ) / 100;\n \n \t\t\t\t\t\thandleAlpha( color[ 4 ] );\n \n"}
{"instance_id": "mrdoob__three.js-20991", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/math/Euler.d.ts b/src/math/Euler.d.ts\nindex da395c0215..1103b40be9 100644\n--- a/src/math/Euler.d.ts\n+++ b/src/math/Euler.d.ts\n@@ -1,3 +1,4 @@\n+import { Matrix3 } from './Matrix3';\n import { Matrix4 } from './Matrix4';\n import { Quaternion } from './Quaternion';\n import { Vector3 } from './Vector3';\n@@ -32,7 +33,7 @@ export class Euler {\n \tset( x: number, y: number, z: number, order?: string ): Euler;\n \tclone(): Euler;\n \tcopy( euler: Euler ): this;\n-\tsetFromRotationMatrix( m: Matrix4, order?: string ): Euler;\n+\tsetFromRotationMatrix( m: Matrix3 | Matrix4, order?: string ): Euler;\n \tsetFromQuaternion( q: Quaternion, order?: string ): Euler;\n \tsetFromVector3( v: Vector3, order?: string ): Euler;\n \treorder( newOrder: string ): Euler;\ndiff --git a/src/math/Euler.js b/src/math/Euler.js\nindex 483f271542..ad5715334a 100644\n--- a/src/math/Euler.js\n+++ b/src/math/Euler.js\n@@ -107,9 +107,24 @@ class Euler {\n \t\t// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n \n \t\tconst te = m.elements;\n-\t\tconst m11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ];\n-\t\tconst m21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ];\n-\t\tconst m31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ];\n+\n+\t\tlet m11, m12, m13;\n+\t\tlet m21, m22, m23;\n+\t\tlet m31, m32, m33;\n+\n+\t\tif ( m.isMatrix4 ) {\n+\n+\t\t\tm11 = te[ 0 ]; m12 = te[ 4 ]; m13 = te[ 8 ];\n+\t\t\tm21 = te[ 1 ]; m22 = te[ 5 ]; m23 = te[ 9 ];\n+\t\t\tm31 = te[ 2 ]; m32 = te[ 6 ]; m33 = te[ 10 ];\n+\n+\t\t} else {\n+\n+\t\t\tm11 = te[ 0 ]; m12 = te[ 3 ]; m13 = te[ 6 ];\n+\t\t\tm21 = te[ 1 ]; m22 = te[ 4 ]; m23 = te[ 7 ];\n+\t\t\tm31 = te[ 2 ]; m32 = te[ 5 ]; m33 = te[ 8 ];\n+\n+\t\t}\n \n \t\torder = order || this._order;\n \ndiff --git a/src/math/Quaternion.d.ts b/src/math/Quaternion.d.ts\nindex 6ea08ae87b..6b97add022 100644\n--- a/src/math/Quaternion.d.ts\n+++ b/src/math/Quaternion.d.ts\n@@ -1,5 +1,6 @@\n import { Euler } from './Euler';\n import { Vector3 } from './Vector3';\n+import { Matrix3 } from './Matrix3';\n import { Matrix4 } from './Matrix4';\n \n /**\n@@ -72,7 +73,7 @@ export class Quaternion {\n \t/**\n \t * Sets this quaternion from rotation component of m. Adapted from http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/index.htm.\n \t */\n-\tsetFromRotationMatrix( m: Matrix4 ): Quaternion;\n+\tsetFromRotationMatrix( m: Matrix3 | Matrix4 ): Quaternion;\n \tsetFromUnitVectors( vFrom: Vector3, vTo: Vector3 ): Quaternion;\n \tangleTo( q: Quaternion ): number;\n \trotateTowards( q: Quaternion, step: number ): Quaternion;\ndiff --git a/src/math/Quaternion.js b/src/math/Quaternion.js\nindex bbf48af501..6e4b994d36 100644\n--- a/src/math/Quaternion.js\n+++ b/src/math/Quaternion.js\n@@ -289,13 +289,27 @@ class Quaternion {\n \n \t\t// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n \n-\t\tconst te = m.elements,\n+\t\tconst te = m.elements;\n \n-\t\t\tm11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ],\n-\t\t\tm21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ],\n-\t\t\tm31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ],\n+\t\tlet m11, m12, m13;\n+\t\tlet m21, m22, m23;\n+\t\tlet m31, m32, m33;\n \n-\t\t\ttrace = m11 + m22 + m33;\n+\t\tif ( m.isMatrix4 ) {\n+\n+\t\t\tm11 = te[ 0 ]; m12 = te[ 4 ]; m13 = te[ 8 ];\n+\t\t\tm21 = te[ 1 ]; m22 = te[ 5 ]; m23 = te[ 9 ];\n+\t\t\tm31 = te[ 2 ]; m32 = te[ 6 ]; m33 = te[ 10 ];\n+\n+\t\t} else {\n+\n+\t\t\tm11 = te[ 0 ]; m12 = te[ 3 ]; m13 = te[ 6 ];\n+\t\t\tm21 = te[ 1 ]; m22 = te[ 4 ]; m23 = te[ 7 ];\n+\t\t\tm31 = te[ 2 ]; m32 = te[ 5 ]; m33 = te[ 8 ];\n+\n+\t\t}\n+\n+\t\tconst trace = m11 + m22 + m33;\n \n \t\tif ( trace > 0 ) {\n \n"}
{"instance_id": "mrdoob__three.js-18648", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/api/en/core/Raycaster.html b/docs/api/en/core/Raycaster.html\nindex 3ba8d30a75..c98ba2dfcf 100644\n--- a/docs/api/en/core/Raycaster.html\n+++ b/docs/api/en/core/Raycaster.html\n@@ -93,11 +93,6 @@\n \t\tThis value shouldn't be negative and should be larger than the near property.\n \t\t</p>\n \n-\t\t<h3>[property:float linePrecision]</h3>\n-\t\t<p>\n-\t\tThe precision factor of the raycaster when intersecting [page:Line] objects.\n-\t\t</p>\n-\n \t\t<h3>[property:float near]</h3>\n \t\t<p>\n \t\tThe near factor of the raycaster. This value indicates which objects can be discarded based on the distance.\n@@ -119,13 +114,15 @@\n \t\t\t<code>\n {\n \tMesh: {},\n-\tLine: {},\n+\tLine: { threshold: 1 },\n \tLOD: {},\n \tPoints: { threshold: 1 },\n \tSprite: {}\n }\n \t\t\t</code>\n \n+\t\tWhere threshold is the precision of the raycaster when intersecting objects, in world units.\n+\n \t\t</p>\n \n \t\t<h3>[property:Ray ray]</h3>\ndiff --git a/docs/api/zh/core/Raycaster.html b/docs/api/zh/core/Raycaster.html\nindex 18ec261137..414646d9aa 100644\n--- a/docs/api/zh/core/Raycaster.html\n+++ b/docs/api/zh/core/Raycaster.html\n@@ -91,13 +91,6 @@\n \t\t\t\u8fd9\u4e2a\u503c\u4e0d\u5e94\u5f53\u4e3a\u8d1f\uff0c\u5e76\u4e14\u5e94\u5f53\u6bd4near\u5c5e\u6027\u5927\u3002\n \t\t</p>\n \n-\t\t<h3>[property:float linePrecision]</h3>\n-\t\t<p>\n-\n-\t\t\traycaster\u4e0e[page:Line]\uff08\u7ebf\uff09\u7269\u4f53\u76f8\u4ea4\u65f6\u7684\u7cbe\u5ea6\u56e0\u6570\u3002\n-\n-\t\t</p>\n-\n \t\t<h3>[property:float near]</h3>\n \t\t<p>\n \t\t\traycaster\u7684\u8fd1\u8ddd\u79bb\u56e0\u6570\uff08\u6295\u5c04\u8fd1\u70b9\uff09\u3002\u8fd9\u4e2a\u503c\u8868\u660e\u54ea\u4e9b\u5bf9\u8c61\u53ef\u4ee5\u57fa\u4e8e\u8be5\u8ddd\u79bb\u800c\u88abraycaster\u6240\u4e22\u5f03\u3002\n@@ -117,13 +110,15 @@\n \t\t\t\u5177\u6709\u4ee5\u4e0b\u5c5e\u6027\u7684\u5bf9\u8c61\uff1a<code>\n {\n \tMesh: {},\n-\tLine: {},\n+\tLine: { threshold: 1 },\n \tLOD: {},\n \tPoints: { threshold: 1 },\n \tSprite: {}\n }\n \t\t\t</code>\n \n+\t\t\u5176\u4e2d\u7684threshold\u8868\u793araycaster\u4e0e\u7269\u4f53\u76f8\u4ea4\u65f6\u7684\u7cbe\u5ea6\uff0c\u4ee5\u4e16\u754c\u5750\u6807\u7cfb\u7684\u5355\u4f4d\u4e3a\u5355\u4f4d\u3002\n+\n \t\t</p>\n \n \t\t<h3>[property:Ray ray]</h3>\ndiff --git a/examples/webgl_interactive_lines.html b/examples/webgl_interactive_lines.html\nindex 5366ca8561..db16acb701 100644\n--- a/examples/webgl_interactive_lines.html\n+++ b/examples/webgl_interactive_lines.html\n@@ -125,7 +125,7 @@\n \t\t\t\tscene.add( parentTransform );\n \n \t\t\t\traycaster = new THREE.Raycaster();\n-\t\t\t\traycaster.linePrecision = 3;\n+\t\t\t\traycaster.params.Line.threshold = 3;\n \n \t\t\t\trenderer = new THREE.WebGLRenderer( { antialias: true } );\n \t\t\t\trenderer.setPixelRatio( window.devicePixelRatio );\ndiff --git a/src/core/Raycaster.d.ts b/src/core/Raycaster.d.ts\nindex 30b21de2f6..9d7a10f0f4 100644\n--- a/src/core/Raycaster.d.ts\n+++ b/src/core/Raycaster.d.ts\n@@ -19,7 +19,7 @@ export interface Intersection {\n \n export interface RaycasterParameters {\n \tMesh?: any;\n-\tLine?: any;\n+\tLine?: { threshold: number };\n \tLOD?: any;\n \tPoints?: { threshold: number };\n \tSprite?: any;\n@@ -65,7 +65,7 @@ export class Raycaster {\n \tparams: RaycasterParameters;\n \n \t/**\n-\t * The precision factor of the raycaster when intersecting Line objects.\n+\t * @deprecated Use {@link Raycaster#params.Line.threshold} instead.\n \t */\n \tlinePrecision: number;\n \ndiff --git a/src/core/Raycaster.js b/src/core/Raycaster.js\nindex 926884f245..077c01e9b2 100644\n--- a/src/core/Raycaster.js\n+++ b/src/core/Raycaster.js\n@@ -17,7 +17,7 @@ function Raycaster( origin, direction, near, far ) {\n \n \tthis.params = {\n \t\tMesh: {},\n-\t\tLine: {},\n+\t\tLine: { threshold: 1 },\n \t\tLOD: {},\n \t\tPoints: { threshold: 1 },\n \t\tSprite: {}\n@@ -64,8 +64,6 @@ function intersectObject( object, raycaster, intersects, recursive ) {\n \n Object.assign( Raycaster.prototype, {\n \n-\tlinePrecision: 1,\n-\n \tset: function ( origin, direction ) {\n \n \t\t// direction is assumed to be normalized (for accurate distance calculations)\n@@ -133,5 +131,23 @@ Object.assign( Raycaster.prototype, {\n \n } );\n \n+Object.defineProperty( Raycaster.prototype, 'linePrecision', {\n+\n+\tget: function () {\n+\n+\t\tconsole.warn( 'THREE.Raycaster: .linePrecision has been deprecated. Use .params.Line.threshold instead.' );\n+\t\treturn this.params.Line.threshold;\n+\n+\t},\n+\n+\tset: function ( value ) {\n+\n+\t\tconsole.warn( 'THREE.Raycaster: .linePrecision has been deprecated. Use .params.Line.threshold instead.' );\n+\t\tthis.params.Line.threshold = value;\n+\n+\t}\n+\n+} );\n+\n \n export { Raycaster };\ndiff --git a/src/objects/Line.js b/src/objects/Line.js\nindex 3a8575d903..07fa624c04 100644\n--- a/src/objects/Line.js\n+++ b/src/objects/Line.js\n@@ -93,7 +93,7 @@ Line.prototype = Object.assign( Object.create( Object3D.prototype ), {\n \n \traycast: function ( raycaster, intersects ) {\n \n-\t\tvar precision = raycaster.linePrecision;\n+\t\tvar threshold = raycaster.params.Line.threshold;\n \n \t\tvar geometry = this.geometry;\n \t\tvar matrixWorld = this.matrixWorld;\n@@ -104,7 +104,7 @@ Line.prototype = Object.assign( Object.create( Object3D.prototype ), {\n \n \t\t_sphere.copy( geometry.boundingSphere );\n \t\t_sphere.applyMatrix4( matrixWorld );\n-\t\t_sphere.radius += precision;\n+\t\t_sphere.radius += threshold;\n \n \t\tif ( raycaster.ray.intersectsSphere( _sphere ) === false ) return;\n \n@@ -113,8 +113,8 @@ Line.prototype = Object.assign( Object.create( Object3D.prototype ), {\n \t\t_inverseMatrix.getInverse( matrixWorld );\n \t\t_ray.copy( raycaster.ray ).applyMatrix4( _inverseMatrix );\n \n-\t\tvar localPrecision = precision / ( ( this.scale.x + this.scale.y + this.scale.z ) / 3 );\n-\t\tvar localPrecisionSq = localPrecision * localPrecision;\n+\t\tvar localThreshold = threshold / ( ( this.scale.x + this.scale.y + this.scale.z ) / 3 );\n+\t\tvar localThresholdSq = localThreshold * localThreshold;\n \n \t\tvar vStart = new Vector3();\n \t\tvar vEnd = new Vector3();\n@@ -142,7 +142,7 @@ Line.prototype = Object.assign( Object.create( Object3D.prototype ), {\n \n \t\t\t\t\tvar distSq = _ray.distanceSqToSegment( vStart, vEnd, interRay, interSegment );\n \n-\t\t\t\t\tif ( distSq > localPrecisionSq ) continue;\n+\t\t\t\t\tif ( distSq > localThresholdSq ) continue;\n \n \t\t\t\t\tinterRay.applyMatrix4( this.matrixWorld ); //Move back to world space for distance calculation\n \n@@ -174,7 +174,7 @@ Line.prototype = Object.assign( Object.create( Object3D.prototype ), {\n \n \t\t\t\t\tvar distSq = _ray.distanceSqToSegment( vStart, vEnd, interRay, interSegment );\n \n-\t\t\t\t\tif ( distSq > localPrecisionSq ) continue;\n+\t\t\t\t\tif ( distSq > localThresholdSq ) continue;\n \n \t\t\t\t\tinterRay.applyMatrix4( this.matrixWorld ); //Move back to world space for distance calculation\n \n@@ -208,7 +208,7 @@ Line.prototype = Object.assign( Object.create( Object3D.prototype ), {\n \n \t\t\t\tvar distSq = _ray.distanceSqToSegment( vertices[ i ], vertices[ i + 1 ], interRay, interSegment );\n \n-\t\t\t\tif ( distSq > localPrecisionSq ) continue;\n+\t\t\t\tif ( distSq > localThresholdSq ) continue;\n \n \t\t\t\tinterRay.applyMatrix4( this.matrixWorld ); //Move back to world space for distance calculation\n \n"}
{"instance_id": "mui__material-ui-12303", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex aae5134121..a4f8e54c94 100644\n--- a/package.json\n+++ b/package.json\n@@ -54,7 +54,6 @@\n     \"react\": \"*\",\n     \"react-dom\": \"*\"\n   },\n-  \"dependencies\": {},\n   \"devDependencies\": {\n     \"@babel/cli\": \"7.0.0-beta.42\",\n     \"@babel/core\": \"7.0.0-beta.42\",\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex ec774e14c9..eca67dfa9f 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/codemod\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.1.0\",\n   \"description\": \"Codemod scripts for Material-UI.\",\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex 0c5250ad4b..943a2bde5d 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/docs\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0-alpha.3\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n@@ -39,7 +38,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex 6124e9b430..1bf3384a56 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/icons\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"2.0.0\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex a6b93cf66b..8fa8a74d69 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -38,8 +38,6 @@\n     \"react\": \"^16.3.0\",\n     \"react-dom\": \"^16.3.0\"\n   },\n-  \"dependencies\": {},\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/src/FormControlLabel/FormControlLabel.d.ts b/packages/material-ui/src/FormControlLabel/FormControlLabel.d.ts\nindex 9a24077fa4..5e43601621 100644\n--- a/packages/material-ui/src/FormControlLabel/FormControlLabel.d.ts\n+++ b/packages/material-ui/src/FormControlLabel/FormControlLabel.d.ts\n@@ -12,12 +12,19 @@ export interface FormControlLabelProps\n   disabled?: boolean;\n   inputRef?: React.Ref<any>;\n   label: React.ReactNode;\n+  labelPlacement?: 'end' | 'start' | 'top' | 'bottom';\n   name?: string;\n   onChange?: (event: React.ChangeEvent<{}>, checked: boolean) => void;\n   value?: string;\n }\n \n-export type FormControlLabelClassKey = 'root' | 'disabled' | 'label';\n+export type FormControlLabelClassKey =\n+  | 'root'\n+  | 'labelPlacementStart'\n+  | 'labelPlacementTop'\n+  | 'labelPlacementBottom'\n+  | 'disabled'\n+  | 'label';\n \n declare const FormControlLabel: React.ComponentType<FormControlLabelProps>;\n \ndiff --git a/packages/material-ui/src/FormControlLabel/FormControlLabel.js b/packages/material-ui/src/FormControlLabel/FormControlLabel.js\nindex fb7f8204d1..9b67c2fb97 100644\n--- a/packages/material-ui/src/FormControlLabel/FormControlLabel.js\n+++ b/packages/material-ui/src/FormControlLabel/FormControlLabel.js\n@@ -22,6 +22,22 @@ export const styles = theme => ({\n       cursor: 'default',\n     },\n   },\n+  /* Styles applied to the root element if `labelPlacement=\"start\"`. */\n+  labelPlacementStart: {\n+    flexDirection: 'row-reverse',\n+    marginLeft: 16, // used for row presentation of radio/checkbox\n+    marginRight: -14,\n+  },\n+  /* Styles applied to the root element if `labelPlacement=\"top\"`. */\n+  labelPlacementTop: {\n+    flexDirection: 'column-reverse',\n+    marginLeft: 16,\n+  },\n+  /* Styles applied to the root element if `labelPlacement=\"bottom\"`. */\n+  labelPlacementBottom: {\n+    flexDirection: 'column',\n+    marginLeft: 16,\n+  },\n   /* Styles applied to the root element if `disabled={true}`. */\n   disabled: {},\n   /* Styles applied to the label's Typography component. */\n@@ -45,6 +61,7 @@ function FormControlLabel(props, context) {\n     disabled: disabledProp,\n     inputRef,\n     label,\n+    labelPlacement,\n     name,\n     onChange,\n     value,\n@@ -74,6 +91,9 @@ function FormControlLabel(props, context) {\n       className={classNames(\n         classes.root,\n         {\n+          [classes.labelPlacementStart]: labelPlacement === 'start',\n+          [classes.labelPlacementTop]: labelPlacement === 'top',\n+          [classes.labelPlacementBottom]: labelPlacement === 'bottom',\n           [classes.disabled]: disabled,\n         },\n         classNameProp,\n@@ -121,6 +141,10 @@ FormControlLabel.propTypes = {\n    * The text to be used in an enclosing label element.\n    */\n   label: PropTypes.node,\n+  /**\n+   * The position of the label.\n+   */\n+  labelPlacement: PropTypes.oneOf(['end', 'start', 'top', 'bottom']),\n   /*\n    * @ignore\n    */\n@@ -139,6 +163,10 @@ FormControlLabel.propTypes = {\n   value: PropTypes.string,\n };\n \n+FormControlLabel.defaultProps = {\n+  labelPlacement: 'end',\n+};\n+\n FormControlLabel.contextTypes = {\n   muiFormControl: PropTypes.object,\n };\n"}
{"instance_id": "mui__material-ui-12236", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/src/pages/layout/breakpoints/breakpoints.md b/docs/src/pages/layout/breakpoints/breakpoints.md\nindex 7755155081..e3e861609a 100644\n--- a/docs/src/pages/layout/breakpoints/breakpoints.md\n+++ b/docs/src/pages/layout/breakpoints/breakpoints.md\n@@ -90,6 +90,16 @@ const theme = createMuiTheme({\n ```\n   - `options.resizeInterval` (*Number* [optional]): Defaults to 166, corresponds to 10 frames at 60 Hz. Number of milliseconds to wait before responding to a screen resize event.\n \n+#### Props\n+\n+These properties are applied to the returned component:\n+\n+| Name | Type | Default | Description |\n+|:-----|:-----|:--------|:------------|\n+| <span class=\"prop-name\">initialWidth</span> | <span class=\"prop-type\">Breakpoint</span> |  | As `window.innerWidth` is unavailable on the server, we default to rendering an empty component during the first mount. You can use an heuristic to approximate the screen width. |\n+| <span class=\"prop-name\">innerRef</span> | <span class=\"prop-type\">func \\| object</span> |  | Use that property to pass a ref callback to the decorated component. |\n+| <span class=\"prop-name\">width</span> | <span class=\"prop-type\">Breakpoint</span> |  | Bypass the width calculation logic. |\n+\n #### Returns\n \n `higher-order component`: Should be used to wrap a component.\ndiff --git a/package.json b/package.json\nindex bbb82de73a..0af46af716 100644\n--- a/package.json\n+++ b/package.json\n@@ -54,7 +54,6 @@\n     \"react\": \"*\",\n     \"react-dom\": \"*\"\n   },\n-  \"dependencies\": {},\n   \"devDependencies\": {\n     \"@babel/cli\": \"7.0.0-beta.42\",\n     \"@babel/core\": \"7.0.0-beta.42\",\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex ec774e14c9..eca67dfa9f 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/codemod\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.1.0\",\n   \"description\": \"Codemod scripts for Material-UI.\",\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex 0c5250ad4b..943a2bde5d 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/docs\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0-alpha.3\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n@@ -39,7 +38,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex 838c1046ab..be5bc8d74b 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/icons\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"2.0.0-beta.1\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex c83b9b2ee1..e9d27019f5 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -38,8 +38,6 @@\n     \"react\": \"^16.3.0\",\n     \"react-dom\": \"^16.3.0\"\n   },\n-  \"dependencies\": {},\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/src/withWidth/withWidth.js b/packages/material-ui/src/withWidth/withWidth.js\nindex 670c3d36c2..0de4edc53a 100644\n--- a/packages/material-ui/src/withWidth/withWidth.js\n+++ b/packages/material-ui/src/withWidth/withWidth.js\n@@ -98,7 +98,7 @@ const withWidth = (options = {}) => Component => {\n     }\n \n     render() {\n-      const { initialWidth, theme, width, ...other } = this.props;\n+      const { initialWidth, innerRef, theme, width, ...other } = this.props;\n \n       const props = {\n         width:\n@@ -127,7 +127,7 @@ const withWidth = (options = {}) => Component => {\n \n       return (\n         <EventListener target=\"window\" onResize={this.handleResize}>\n-          <Component {...more} {...props} />\n+          <Component {...more} {...props} ref={innerRef} />\n         </EventListener>\n       );\n     }\n@@ -144,6 +144,10 @@ const withWidth = (options = {}) => Component => {\n      * http://caniuse.com/#search=client%20hint\n      */\n     initialWidth: PropTypes.oneOf(['xs', 'sm', 'md', 'lg', 'xl']),\n+    /**\n+     * Use that property to pass a ref callback to the decorated component.\n+     */\n+    innerRef: PropTypes.oneOfType([PropTypes.func, PropTypes.object]),\n     /**\n      * @ignore\n      */\n"}
{"instance_id": "mui__material-ui-11858", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex dba8872f1e..86f3dcf1b2 100644\n--- a/package.json\n+++ b/package.json\n@@ -53,7 +53,6 @@\n     \"react\": \"*\",\n     \"react-dom\": \"*\"\n   },\n-  \"dependencies\": {},\n   \"devDependencies\": {\n     \"@babel/cli\": \"7.0.0-beta.42\",\n     \"@babel/core\": \"7.0.0-beta.42\",\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex ec774e14c9..eca67dfa9f 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/codemod\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.1.0\",\n   \"description\": \"Codemod scripts for Material-UI.\",\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex dedc87c989..781ce4f2b3 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/docs\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0-alpha.3\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n@@ -40,7 +39,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex e223d70c80..acb99e8578 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/icons\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.1.0\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex 246ef1ce39..eb6320f835 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -33,13 +33,11 @@\n     \"release\": \"yarn build && npm publish build\"\n   },\n   \"peerDependencies\": {\n-    \"@material-ui/icons\": \"^1.0.0\",\n     \"@material-ui/core\": \"^1.0.0\",\n+    \"@material-ui/icons\": \"^1.0.0\",\n     \"react\": \"^16.3.0\",\n     \"react-dom\": \"^16.3.0\"\n   },\n-  \"dependencies\": {},\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/package.json b/packages/material-ui/package.json\nindex 248ffc0008..3a6a036d56 100644\n--- a/packages/material-ui/package.json\n+++ b/packages/material-ui/package.json\n@@ -62,7 +62,6 @@\n     \"scroll\": \"^2.0.3\",\n     \"warning\": \"^4.0.1\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/src/ListItemText/ListItemText.d.ts b/packages/material-ui/src/ListItemText/ListItemText.d.ts\nindex c52c1d3f66..fdf47942be 100644\n--- a/packages/material-ui/src/ListItemText/ListItemText.d.ts\n+++ b/packages/material-ui/src/ListItemText/ListItemText.d.ts\n@@ -1,12 +1,15 @@\n import * as React from 'react';\n import { StandardProps } from '..';\n+import { TypographyProps } from '../Typography';\n \n export interface ListItemTextProps\n   extends StandardProps<React.HTMLAttributes<HTMLDivElement>, ListItemTextClassKey> {\n   disableTypography?: boolean;\n   inset?: boolean;\n   primary?: React.ReactNode;\n+  primaryTypographyProps?: Partial<TypographyProps>;\n   secondary?: React.ReactNode;\n+  secondaryTypographyProps?: Partial<TypographyProps>;\n }\n \n export type ListItemTextClassKey =\ndiff --git a/packages/material-ui/src/ListItemText/ListItemText.js b/packages/material-ui/src/ListItemText/ListItemText.js\nindex a6a02f34df..ecdba460a5 100644\n--- a/packages/material-ui/src/ListItemText/ListItemText.js\n+++ b/packages/material-ui/src/ListItemText/ListItemText.js\n@@ -42,7 +42,9 @@ function ListItemText(props, context) {\n     disableTypography,\n     inset,\n     primary: primaryProp,\n+    primaryTypographyProps,\n     secondary: secondaryProp,\n+    secondaryTypographyProps,\n     ...other\n   } = props;\n   const { dense } = context;\n@@ -54,6 +56,7 @@ function ListItemText(props, context) {\n         variant=\"subheading\"\n         className={classNames(classes.primary, { [classes.textDense]: dense })}\n         component=\"span\"\n+        {...primaryTypographyProps}\n       >\n         {primary}\n       </Typography>\n@@ -69,6 +72,7 @@ function ListItemText(props, context) {\n           [classes.textDense]: dense,\n         })}\n         color=\"textSecondary\"\n+        {...secondaryTypographyProps}\n       >\n         {secondary}\n       </Typography>\n@@ -123,10 +127,20 @@ ListItemText.propTypes = {\n    * The main content element.\n    */\n   primary: PropTypes.node,\n+  /**\n+   * These props will be forwarded to the primary typography component\n+   * (as long as disableTypography is not `true`).\n+   */\n+  primaryTypographyProps: PropTypes.object,\n   /**\n    * The secondary content element.\n    */\n   secondary: PropTypes.node,\n+  /**\n+   * These props will be forwarded to the secondary typography component\n+   * (as long as disableTypography is not `true`).\n+   */\n+  secondaryTypographyProps: PropTypes.object,\n };\n \n ListItemText.defaultProps = {\ndiff --git a/pages/api/list-item-text.md b/pages/api/list-item-text.md\nindex 23d8c99e0d..ce0850d80e 100644\n--- a/pages/api/list-item-text.md\n+++ b/pages/api/list-item-text.md\n@@ -17,7 +17,9 @@ filename: /packages/material-ui/src/ListItemText/ListItemText.js\n | <span class=\"prop-name\">disableTypography</span> | <span class=\"prop-type\">bool | <span class=\"prop-default\">false</span> | If `true`, the children won't be wrapped by a Typography component. This can be useful to render an alternative Typography variant by wrapping the `children` (or `primary`) text, and optional `secondary` text with the Typography component. |\n | <span class=\"prop-name\">inset</span> | <span class=\"prop-type\">bool | <span class=\"prop-default\">false</span> | If `true`, the children will be indented. This should be used if there is no left avatar or left icon. |\n | <span class=\"prop-name\">primary</span> | <span class=\"prop-type\">node | \u00a0 | The main content element. |\n+| <span class=\"prop-name\">primaryTypographyProps</span> | <span class=\"prop-type\">object | \u00a0 | These props will be forwarded to the primary typography component (as long as disableTypography is not `true`). |\n | <span class=\"prop-name\">secondary</span> | <span class=\"prop-type\">node | \u00a0 | The secondary content element. |\n+| <span class=\"prop-name\">secondaryTypographyProps</span> | <span class=\"prop-type\">object | \u00a0 | These props will be forwarded to the secondary typography component (as long as disableTypography is not `true`). |\n \n Any other properties supplied will be spread to the root element (native element).\n \n"}
{"instance_id": "mui__material-ui-12406", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 94d17b2a41..cd31bf7842 100644\n--- a/package.json\n+++ b/package.json\n@@ -54,18 +54,17 @@\n     \"react\": \"*\",\n     \"react-dom\": \"*\"\n   },\n-  \"dependencies\": {},\n   \"devDependencies\": {\n     \"@babel/cli\": \"7.0.0-beta.42\",\n     \"@babel/core\": \"7.0.0-beta.42\",\n     \"@babel/node\": \"7.0.0-beta.42\",\n     \"@babel/plugin-transform-object-assign\": \"7.0.0-beta.42\",\n     \"@babel/plugin-transform-runtime\": \"7.0.0-beta.42\",\n-    \"@babel/preset-env\": \"7.0.0-beta.42\",\n+    \"@babel/preset-env\": \"^7.0.0-beta.42\",\n     \"@babel/preset-flow\": \"7.0.0-beta.42\",\n-    \"@babel/preset-react\": \"7.0.0-beta.42\",\n+    \"@babel/preset-react\": \"^7.0.0-beta.42\",\n     \"@babel/preset-stage-1\": \"7.0.0-beta.42\",\n-    \"@babel/register\": \"7.0.0-beta.42\",\n+    \"@babel/register\": \"^7.0.0-beta.42\",\n     \"@types/enzyme\": \"^3.1.4\",\n     \"@types/react\": \"^16.3.14\",\n     \"argos-cli\": \"^0.0.9\",\n@@ -137,7 +136,7 @@\n     \"react-router-dom\": \"^4.2.2\",\n     \"react-select\": \"^2.0.0\",\n     \"react-swipeable-views\": \"^0.12.10\",\n-    \"react-test-renderer\": \"^16.1.1\",\n+    \"react-test-renderer\": \"^16.14.0\",\n     \"react-text-mask\": \"^5.0.2\",\n     \"recast\": \"^0.15.0\",\n     \"redux\": \"^4.0.0\",\n@@ -176,5 +175,8 @@\n   },\n   \"workspaces\": [\n     \"packages/*\"\n-  ]\n+  ],\n+  \"dependencies\": {\n+    \"@babel/plugin-proposal-class-properties\": \"^7.18.6\"\n+  }\n }\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex ec774e14c9..eca67dfa9f 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/codemod\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.1.0\",\n   \"description\": \"Codemod scripts for Material-UI.\",\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex 9acca2c766..9d78ff789a 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/docs\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0-alpha.4\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n@@ -39,7 +38,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex 6124e9b430..1bf3384a56 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/icons\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"2.0.0\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex 31ac88ba2f..f1237f4953 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -38,8 +38,6 @@\n     \"react\": \"^16.3.0\",\n     \"react-dom\": \"^16.3.0\"\n   },\n-  \"dependencies\": {},\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/src/Input/Textarea.js b/packages/material-ui/src/Input/Textarea.js\nindex 8dfa1a7aeb..4882669ee9 100644\n--- a/packages/material-ui/src/Input/Textarea.js\n+++ b/packages/material-ui/src/Input/Textarea.js\n@@ -109,7 +109,9 @@ class Textarea extends React.Component {\n \n     if (!this.isControlled) {\n       // The component is not controlled, we need to update the shallow value.\n-      this.shadowRef.value = this.value;\n+      if (this.shadowRef) {\n+        this.shadowRef.value = this.value;\n+      }\n       this.syncHeightWithShadow();\n     }\n \n@@ -121,6 +123,11 @@ class Textarea extends React.Component {\n   syncHeightWithShadow() {\n     const props = this.props;\n \n+    // Guarding for react-test-renderer, where refs aren't available.\n+    if (!this.shadowRef || !this.singlelineShadowRef) {\n+      return;\n+    }\n+\n     if (this.isControlled) {\n       // The component is controlled, we need to update the shallow value.\n       this.shadowRef.value = props.value == null ? '' : String(props.value);\n"}
{"instance_id": "mui__material-ui-11987", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 0eb1b97b85..d7f9e2c4af 100644\n--- a/package.json\n+++ b/package.json\n@@ -54,7 +54,6 @@\n     \"react\": \"*\",\n     \"react-dom\": \"*\"\n   },\n-  \"dependencies\": {},\n   \"devDependencies\": {\n     \"@babel/cli\": \"7.0.0-beta.42\",\n     \"@babel/core\": \"7.0.0-beta.42\",\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex ec774e14c9..eca67dfa9f 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/codemod\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.1.0\",\n   \"description\": \"Codemod scripts for Material-UI.\",\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex dedc87c989..781ce4f2b3 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/docs\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0-alpha.3\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n@@ -40,7 +39,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex e223d70c80..acb99e8578 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/icons\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.1.0\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\ndiff --git a/packages/material-ui-icons/src/utils/createSvgIcon.js b/packages/material-ui-icons/src/utils/createSvgIcon.js\nindex f06884e164..9316966a43 100644\n--- a/packages/material-ui-icons/src/utils/createSvgIcon.js\n+++ b/packages/material-ui-icons/src/utils/createSvgIcon.js\n@@ -3,11 +3,15 @@ import pure from 'recompose/pure';\n import SvgIcon from '@material-ui/core/SvgIcon';\n \n function createSvgIcon(path, displayName) {\n-  let Icon = props => (\n-    <SvgIcon {...props}>\n-      {path}\n-    </SvgIcon>\n-  );\n+  let Icon = props => {\n+    const { children, ...other } = props;\n+    return (\n+      <SvgIcon {...other}>\n+        {children}\n+        {path}\n+      </SvgIcon>\n+    );\n+  };\n \n   Icon.displayName = displayName;\n   Icon = pure(Icon);\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex 246ef1ce39..eb6320f835 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -33,13 +33,11 @@\n     \"release\": \"yarn build && npm publish build\"\n   },\n   \"peerDependencies\": {\n-    \"@material-ui/icons\": \"^1.0.0\",\n     \"@material-ui/core\": \"^1.0.0\",\n+    \"@material-ui/icons\": \"^1.0.0\",\n     \"react\": \"^16.3.0\",\n     \"react-dom\": \"^16.3.0\"\n   },\n-  \"dependencies\": {},\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\n"}
{"instance_id": "mui__material-ui-11451", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 58947d7751..c16ef4492a 100644\n--- a/package.json\n+++ b/package.json\n@@ -54,18 +54,17 @@\n     \"react\": \"*\",\n     \"react-dom\": \"*\"\n   },\n-  \"dependencies\": {},\n   \"devDependencies\": {\n     \"@babel/cli\": \"7.0.0-beta.42\",\n-    \"@babel/core\": \"7.0.0-beta.42\",\n+    \"@babel/core\": \"^7.0.0-beta.42\",\n     \"@babel/node\": \"7.0.0-beta.42\",\n     \"@babel/plugin-transform-object-assign\": \"7.0.0-beta.42\",\n     \"@babel/plugin-transform-runtime\": \"7.0.0-beta.42\",\n-    \"@babel/preset-env\": \"7.0.0-beta.42\",\n+    \"@babel/preset-env\": \"^7.0.0-beta.42\",\n     \"@babel/preset-flow\": \"7.0.0-beta.42\",\n-    \"@babel/preset-react\": \"7.0.0-beta.42\",\n+    \"@babel/preset-react\": \"^7.0.0-beta.42\",\n     \"@babel/preset-stage-1\": \"7.0.0-beta.42\",\n-    \"@babel/register\": \"7.0.0-beta.42\",\n+    \"@babel/register\": \"^7.0.0-beta.42\",\n     \"@types/enzyme\": \"^3.1.4\",\n     \"@types/react\": \"^16.3.14\",\n     \"argos-cli\": \"^0.0.9\",\n@@ -80,14 +79,14 @@\n     \"babel-plugin-transform-dev-warning\": \"^0.1.0\",\n     \"babel-plugin-transform-react-constant-elements\": \"^6.23.0\",\n     \"babel-plugin-transform-react-remove-prop-types\": \"^0.4.10\",\n-    \"chai\": \"^4.1.2\",\n+    \"chai\": \"^4.5.0\",\n     \"clean-css\": \"^4.1.11\",\n     \"clipboard-copy\": \"^2.0.0\",\n     \"cross-env\": \"^5.1.1\",\n     \"doctrine\": \"^2.0.0\",\n     \"downshift\": \"^1.22.1\",\n-    \"enzyme\": \"^3.2.0\",\n-    \"enzyme-adapter-react-16\": \"^1.1.0\",\n+    \"enzyme\": \"^3.11.0\",\n+    \"enzyme-adapter-react-16\": \"^1.15.8\",\n     \"eslint\": \"^4.11.0\",\n     \"eslint-config-airbnb\": \"^16.1.0\",\n     \"eslint-import-resolver-webpack\": \"^0.9.0\",\n@@ -108,7 +107,7 @@\n     \"glob\": \"^7.1.2\",\n     \"gm\": \"^1.23.0\",\n     \"isomorphic-fetch\": \"^2.2.1\",\n-    \"jsdom\": \"^11.3.0\",\n+    \"jsdom\": \"^11.12.0\",\n     \"json-loader\": \"^0.5.7\",\n     \"jss-rtl\": \"^0.2.1\",\n     \"karma\": \"^2.0.0\",\n@@ -120,16 +119,16 @@\n     \"karma-webpack\": \"^3.0.0\",\n     \"lerna\": \"^2.9.0\",\n     \"lz-string\": \"^1.4.4\",\n-    \"mocha\": \"^5.0.0\",\n+    \"mocha\": \"^5.2.0\",\n     \"next\": \"^6.0.1\",\n     \"nyc\": \"^11.3.0\",\n     \"postcss\": \"^6.0.16\",\n     \"prettier\": \"^1.8.2\",\n     \"raw-loader\": \"^0.5.1\",\n-    \"react\": \"^16.3.0\",\n+    \"react\": \"^16.14.0\",\n     \"react-autosuggest\": \"^9.3.2\",\n     \"react-docgen\": \"^3.0.0-beta10\",\n-    \"react-dom\": \"^16.3.0\",\n+    \"react-dom\": \"^16.14.0\",\n     \"react-inspector\": \"^2.2.2\",\n     \"react-number-format\": \"^3.0.2\",\n     \"react-redux\": \"^5.0.6\",\n@@ -149,7 +148,7 @@\n     \"rollup-plugin-node-resolve\": \"^3.3.0\",\n     \"rollup-plugin-size-snapshot\": \"^0.4.1\",\n     \"rollup-plugin-uglify\": \"^3.0.0\",\n-    \"sinon\": \"^5.0.3\",\n+    \"sinon\": \"^5.1.1\",\n     \"size-limit\": \"^0.18.0\",\n     \"typescript\": \"^2.6.1\",\n     \"url-loader\": \"^1.0.1\",\n@@ -175,5 +174,9 @@\n   },\n   \"workspaces\": [\n     \"packages/*\"\n-  ]\n+  ],\n+  \"dependencies\": {\n+    \"classnames\": \"^2.5.1\",\n+    \"prop-types\": \"^15.8.1\"\n+  }\n }\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex a959314050..5c56fb59eb 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/codemod\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0\",\n   \"description\": \"Codemod scripts for Material-UI.\",\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex 0c5784fe20..5c68a9438f 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/docs\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0-alpha.2\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n@@ -40,7 +39,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex 5c0912e672..72868cd085 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/icons\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex 263c604664..d57995aa5d 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/lab\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"1.0.0-alpha.2\",\n   \"description\": \"Material-UI Lab - Incubator for Material-UI React components.\",\n@@ -33,13 +32,11 @@\n     \"release\": \"yarn build && npm publish build\"\n   },\n   \"peerDependencies\": {\n-    \"@material-ui/icons\": \"^1.0.0-rc.0\",\n     \"@material-ui/core\": \"^1.0.0-rc.0\",\n+    \"@material-ui/icons\": \"^1.0.0-rc.0\",\n     \"react\": \"^16.3.0\",\n     \"react-dom\": \"^16.3.0\"\n   },\n-  \"dependencies\": {},\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/package.json b/packages/material-ui/package.json\nindex 5bc3149d30..f79a12f22d 100644\n--- a/packages/material-ui/package.json\n+++ b/packages/material-ui/package.json\n@@ -62,7 +62,6 @@\n     \"scroll\": \"^2.0.3\",\n     \"warning\": \"^3.0.0\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/src/ListItem/ListItem.js b/packages/material-ui/src/ListItem/ListItem.js\nindex 9918957705..dd4957bb39 100644\n--- a/packages/material-ui/src/ListItem/ListItem.js\n+++ b/packages/material-ui/src/ListItem/ListItem.js\n@@ -78,6 +78,7 @@ class ListItem extends React.Component {\n       disabled,\n       disableGutters,\n       divider,\n+      focusVisibleClassName,\n       ...other\n     } = this.props;\n \n@@ -105,7 +106,7 @@ class ListItem extends React.Component {\n \n     if (button) {\n       componentProps.component = componentProp || 'div';\n-      componentProps.focusVisibleClassName = classes.focusVisible;\n+      componentProps.focusVisibleClassName = classNames(classes.focusVisible, focusVisibleClassName);\n       Component = ButtonBase;\n     }\n \n"}
{"instance_id": "mui__material-ui-13778", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Modal/ModalManager.js b/packages/material-ui/src/Modal/ModalManager.js\nindex eac18c250c..ce0509f732 100644\n--- a/packages/material-ui/src/Modal/ModalManager.js\n+++ b/packages/material-ui/src/Modal/ModalManager.js\n@@ -50,6 +50,11 @@ function setContainerStyle(data) {\n }\n \n function removeContainerStyle(data) {\n+  // The modal might not have been mounted yet.\n+  if (!data.style) {\n+    return;\n+  }\n+\n   Object.keys(data.style).forEach(key => {\n     data.container.style[key] = data.style[key];\n   });\n"}
{"instance_id": "mui__material-ui-14364", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/InputAdornment/InputAdornment.js b/packages/material-ui/src/InputAdornment/InputAdornment.js\nindex 52493e3b08..9d683d37d2 100644\n--- a/packages/material-ui/src/InputAdornment/InputAdornment.js\n+++ b/packages/material-ui/src/InputAdornment/InputAdornment.js\n@@ -5,6 +5,7 @@ import { componentPropType } from '@material-ui/utils';\n import warning from 'warning';\n import Typography from '../Typography';\n import withStyles from '../styles/withStyles';\n+import FormControlContext from '../FormControl/FormControlContext';\n import withFormControlContext from '../FormControl/withFormControlContext';\n \n export const styles = {\n@@ -64,25 +65,27 @@ function InputAdornment(props) {\n   }\n \n   return (\n-    <Component\n-      className={classNames(\n-        classes.root,\n-        {\n-          [classes.filled]: variant === 'filled',\n-          [classes.positionStart]: position === 'start',\n-          [classes.positionEnd]: position === 'end',\n-          [classes.disablePointerEvents]: disablePointerEvents,\n-        },\n-        className,\n-      )}\n-      {...other}\n-    >\n-      {typeof children === 'string' && !disableTypography ? (\n-        <Typography color=\"textSecondary\">{children}</Typography>\n-      ) : (\n-        children\n-      )}\n-    </Component>\n+    <FormControlContext.Provider value={null}>\n+      <Component\n+        className={classNames(\n+          classes.root,\n+          {\n+            [classes.filled]: variant === 'filled',\n+            [classes.positionStart]: position === 'start',\n+            [classes.positionEnd]: position === 'end',\n+            [classes.disablePointerEvents]: disablePointerEvents,\n+          },\n+          className,\n+        )}\n+        {...other}\n+      >\n+        {typeof children === 'string' && !disableTypography ? (\n+          <Typography color=\"textSecondary\">{children}</Typography>\n+        ) : (\n+          children\n+        )}\n+      </Component>\n+    </FormControlContext.Provider>\n   );\n }\n \n"}
{"instance_id": "mui__material-ui-13534", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Badge/Badge.d.ts b/packages/material-ui/src/Badge/Badge.d.ts\nindex 45a15eef11..be9d234202 100644\n--- a/packages/material-ui/src/Badge/Badge.d.ts\n+++ b/packages/material-ui/src/Badge/Badge.d.ts\n@@ -7,9 +7,10 @@ export interface BadgeProps\n   children: React.ReactNode;\n   color?: PropTypes.Color | 'error';\n   component?: React.ReactType<BadgeProps>;\n+  invisible?: boolean;\n }\n \n-export type BadgeClassKey = 'root' | 'badge' | 'colorPrimary' | 'colorSecondary';\n+export type BadgeClassKey = 'root' | 'badge' | 'colorPrimary' | 'colorSecondary' | 'colorError' | 'invisible';\n \n declare const Badge: React.ComponentType<BadgeProps>;\n \ndiff --git a/packages/material-ui/src/Badge/Badge.js b/packages/material-ui/src/Badge/Badge.js\nindex ba646a49b6..491aaaa4a9 100644\n--- a/packages/material-ui/src/Badge/Badge.js\n+++ b/packages/material-ui/src/Badge/Badge.js\n@@ -50,6 +50,10 @@ export const styles = theme => ({\n     backgroundColor: theme.palette.error.main,\n     color: theme.palette.error.contrastText,\n   },\n+  /* Styles applied to the badge `span` element if `invisible={true}`. */\n+  invisible: {\n+    visibility: 'hidden',\n+  },\n });\n \n function Badge(props) {\n@@ -60,11 +64,13 @@ function Badge(props) {\n     className,\n     color,\n     component: ComponentProp,\n+    invisible,\n     ...other\n   } = props;\n \n   const badgeClassName = classNames(classes.badge, {\n     [classes[`color${capitalize(color)}`]]: color !== 'default',\n+    [classes.invisible]: invisible,\n   });\n \n   return (\n@@ -102,11 +108,16 @@ Badge.propTypes = {\n    * Either a string to use a DOM element or a component.\n    */\n   component: PropTypes.oneOfType([PropTypes.string, PropTypes.func, PropTypes.object]),\n+  /**\n+   * If `true`, the badge will be invisible.\n+   */\n+  invisible: PropTypes.bool,\n };\n \n Badge.defaultProps = {\n   color: 'default',\n   component: 'span',\n+  invisible: false,\n };\n \n export default withStyles(styles, { name: 'MuiBadge' })(Badge);\n"}
{"instance_id": "mui__material-ui-13690", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Tooltip/Tooltip.js b/packages/material-ui/src/Tooltip/Tooltip.js\nindex de16c64fd2..8f34236ffc 100644\n--- a/packages/material-ui/src/Tooltip/Tooltip.js\n+++ b/packages/material-ui/src/Tooltip/Tooltip.js\n@@ -280,7 +280,7 @@ class Tooltip extends React.Component {\n \n     const childrenProps = {\n       'aria-describedby': open ? id || this.defaultId : null,\n-      title: !open && typeof title === 'string' ? title : null,\n+      title: !open && !disableHoverListener && typeof title === 'string' ? title : null,\n       ...other,\n       ...children.props,\n       className: classNames(other.className, children.props.className),\n"}
{"instance_id": "mui__material-ui-14638", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Tab/Tab.js b/packages/material-ui/src/Tab/Tab.js\nindex 225674eb58..4d0a2ab0d7 100644\n--- a/packages/material-ui/src/Tab/Tab.js\n+++ b/packages/material-ui/src/Tab/Tab.js\n@@ -98,8 +98,10 @@ export const styles = theme => ({\n   },\n   /* Styles applied to the label wrapper element if `label` is provided. */\n   label: {},\n-  /* Deprecated, the styles will be removed in v4. */\n-  labelWrapped: {},\n+  /* Styles applied to the label wrapper element if `label` is provided and the text is wrapped. */\n+  labelWrapped: {\n+    lineHeight: 1.2,\n+  },\n });\n \n class Tab extends React.Component {\n"}
{"instance_id": "mui__material-ui-14391", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/styles/colorManipulator.d.ts b/packages/material-ui/src/styles/colorManipulator.d.ts\nindex c15ee157ea..5391d36226 100644\n--- a/packages/material-ui/src/styles/colorManipulator.d.ts\n+++ b/packages/material-ui/src/styles/colorManipulator.d.ts\n@@ -7,6 +7,7 @@ export interface ColorObject {\n export function recomposeColor(color: ColorObject): string;\n export function convertHexToRGB(hex: string): string;\n export function rgbToHex(color: string): string;\n+export function hslToRgb(color: string | ColorObject): string;\n export function decomposeColor(color: string): ColorObject;\n export function getContrastRatio(foreground: string, background: string): number;\n export function getLuminance(color: string): number;\ndiff --git a/packages/material-ui/src/styles/colorManipulator.js b/packages/material-ui/src/styles/colorManipulator.js\nindex 694f3f638b..2bc3230913 100644\n--- a/packages/material-ui/src/styles/colorManipulator.js\n+++ b/packages/material-ui/src/styles/colorManipulator.js\n@@ -66,6 +66,32 @@ export function rgbToHex(color) {\n   return `#${values.join('')}`;\n }\n \n+/**\n+ * Converts an hsl color to an rgb color.\n+ *\n+ * @param {string | object} color - HSL color, i.e. hsl(0, 100%, 50%) or { type: 'hsl', values: [0, 100, 50] }\n+ * @returns {string} - RGB color string, i.e. rgb(255, 0, 0)\n+ */\n+export function hslToRgb(color) {\n+  color = typeof color === 'string' ? decomposeColor(color) : color;\n+  const { values } = color;\n+  const h = values[0];\n+  const s = values[1] / 100;\n+  const l = values[2] / 100;\n+  const a = s * Math.min(l, 1 - l);\n+  const f = (n, k = (n + h / 30) % 12) => l - a * Math.max(Math.min(k - 3, 9 - k, 1), -1);\n+\n+  let type = 'rgb';\n+  const rgb = [Math.round(f(0) * 255), Math.round(f(8) * 255), Math.round(f(4) * 255)];\n+\n+  if (color.type === 'hsla') {\n+    type += 'a';\n+    rgb.push(values[3]);\n+  }\n+\n+  return recomposeColor({ type, values: rgb });\n+}\n+\n /**\n  * Returns an object with the type and values of a color.\n  *\n@@ -159,19 +185,16 @@ export function getContrastRatio(foreground, background) {\n export function getLuminance(color) {\n   warning(color, `Material-UI: missing color argument in getLuminance(${color}).`);\n \n-  const decomposedColor = decomposeColor(color);\n+  color = decomposeColor(color);\n \n-  if (decomposedColor.type.indexOf('rgb') !== -1) {\n-    const rgb = decomposedColor.values.map(val => {\n-      val /= 255; // normalized\n-      return val <= 0.03928 ? val / 12.92 : ((val + 0.055) / 1.055) ** 2.4;\n-    });\n-    // Truncate at 3 digits\n-    return Number((0.2126 * rgb[0] + 0.7152 * rgb[1] + 0.0722 * rgb[2]).toFixed(3));\n-  }\n+  let rgb = color.type === 'hsl' || color.type === 'hsla' ? decomposeColor(hslToRgb(color)).values : color.values;\n+  rgb = rgb.map(val => {\n+    val /= 255; // normalized\n+    return val < 0.04045 ? val / 12.92 : ((val + 0.055) / 1.055) ** 2.4;\n+  });\n \n-  // else if (decomposedColor.type.indexOf('hsl') !== -1)\n-  return decomposedColor.values[2] / 100;\n+  // Truncate at 3 digits\n+  return Number((0.2126 * rgb[0] + 0.7152 * rgb[1] + 0.0722 * rgb[2]).toFixed(3));\n }\n \n /**\n"}
{"instance_id": "mui__material-ui-13430", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/CircularProgress/CircularProgress.d.ts b/packages/material-ui/src/CircularProgress/CircularProgress.d.ts\nindex 423791d43d..898764051f 100644\n--- a/packages/material-ui/src/CircularProgress/CircularProgress.d.ts\n+++ b/packages/material-ui/src/CircularProgress/CircularProgress.d.ts\n@@ -4,6 +4,7 @@ import { StandardProps } from '..';\n export interface CircularProgressProps\n   extends StandardProps<React.HTMLAttributes<HTMLDivElement>, CircularProgressClassKey> {\n   color?: 'primary' | 'secondary' | 'inherit';\n+  disableShrink?: boolean;\n   size?: number | string;\n   thickness?: number;\n   value?: number;\n@@ -19,7 +20,8 @@ export type CircularProgressClassKey =\n   | 'svg'\n   | 'circle'\n   | 'circleStatic'\n-  | 'circleIndeterminate';\n+  | 'circleIndeterminate'\n+  | 'circleDisableShrink';\n \n declare const CircularProgress: React.ComponentType<CircularProgressProps>;\n \ndiff --git a/packages/material-ui/src/CircularProgress/CircularProgress.js b/packages/material-ui/src/CircularProgress/CircularProgress.js\nindex bf32f77980..898a5ebaa4 100644\n--- a/packages/material-ui/src/CircularProgress/CircularProgress.js\n+++ b/packages/material-ui/src/CircularProgress/CircularProgress.js\n@@ -63,6 +63,10 @@ export const styles = theme => ({\n     strokeDasharray: '80px, 200px',\n     strokeDashoffset: '0px', // Add the unit to fix a Edge 16 and below bug.\n   },\n+  /* Styles applied to the `circle` svg path if `disableShrink={true}`. */\n+  circleDisableShrink: {\n+    animation: 'none',\n+  },\n   '@keyframes mui-progress-circular-rotate': {\n     '100%': {\n       transform: 'rotate(360deg)',\n@@ -92,7 +96,18 @@ export const styles = theme => ({\n  * attribute to `true` on that region until it has finished loading.\n  */\n function CircularProgress(props) {\n-  const { classes, className, color, size, style, thickness, value, variant, ...other } = props;\n+  const {\n+    classes,\n+    className,\n+    color,\n+    disableShrink,\n+    size,\n+    style,\n+    thickness,\n+    value,\n+    variant,\n+    ...other\n+  } = props;\n \n   const circleStyle = {};\n   const rootStyle = {};\n@@ -135,6 +150,7 @@ function CircularProgress(props) {\n           className={classNames(classes.circle, {\n             [classes.circleIndeterminate]: variant === 'indeterminate',\n             [classes.circleStatic]: variant === 'static',\n+            [classes.circleDisableShrink]: disableShrink,\n           })}\n           style={circleStyle}\n           cx={SIZE}\n@@ -162,6 +178,11 @@ CircularProgress.propTypes = {\n    * The color of the component. It supports those theme colors that make sense for this component.\n    */\n   color: PropTypes.oneOf(['primary', 'secondary', 'inherit']),\n+  /**\n+   * If `true`, the shrink animation is disabled.\n+   * This only works if variant is `indeterminate`.\n+   */\n+  disableShrink: PropTypes.bool,\n   /**\n    * The size of the circle.\n    */\n@@ -188,6 +209,7 @@ CircularProgress.propTypes = {\n \n CircularProgress.defaultProps = {\n   color: 'primary',\n+  disableShrink: false,\n   size: 40,\n   thickness: 3.6,\n   value: 0,\n"}
{"instance_id": "mui__material-ui-14496", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Tooltip/Tooltip.js b/packages/material-ui/src/Tooltip/Tooltip.js\nindex 5d1ceb6048..010e490ba1 100644\n--- a/packages/material-ui/src/Tooltip/Tooltip.js\n+++ b/packages/material-ui/src/Tooltip/Tooltip.js\n@@ -130,7 +130,7 @@ class Tooltip extends React.Component {\n     // We need to account for this eventuality.\n     this.focusTimer = setTimeout(() => {\n       // We need to make sure the focus hasn't moved since the event was triggered.\n-      if (this.childrenRef === document.activeElement) {\n+      if (this.childrenRef.contains(document.activeElement)) {\n         this.handleEnter(event);\n       }\n     });\n"}
{"instance_id": "mui__material-ui-14882", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/LinearProgress/LinearProgress.js b/packages/material-ui/src/LinearProgress/LinearProgress.js\nindex e29a58959e..7605d24aad 100644\n--- a/packages/material-ui/src/LinearProgress/LinearProgress.js\n+++ b/packages/material-ui/src/LinearProgress/LinearProgress.js\n@@ -92,12 +92,12 @@ export const styles = theme => ({\n   },\n   /* Styles applied to the bar1 element if `variant=\"determinate\"`. */\n   bar1Determinate: {\n-    transition: `transform .${TRANSITION_DURATION}s linear`,\n+    transition: `width .${TRANSITION_DURATION}s linear`,\n   },\n   /* Styles applied to the bar1 element if `variant=\"buffer\"`. */\n   bar1Buffer: {\n     zIndex: 1,\n-    transition: `transform .${TRANSITION_DURATION}s linear`,\n+    transition: `width .${TRANSITION_DURATION}s linear`,\n   },\n   /* Styles applied to the bar2 element if `variant=\"indeterminate or query\"`. */\n   bar2Indeterminate: {\n@@ -110,7 +110,7 @@ export const styles = theme => ({\n   },\n   /* Styles applied to the bar2 element if `variant=\"buffer\"`. */\n   bar2Buffer: {\n-    transition: `transform .${TRANSITION_DURATION}s linear`,\n+    transition: `width .${TRANSITION_DURATION}s linear`,\n   },\n   // Legends:\n   // || represents the viewport\n@@ -211,7 +211,7 @@ const LinearProgress = React.forwardRef(function LinearProgress(props, ref) {\n   if (variant === 'determinate' || variant === 'buffer') {\n     if (value !== undefined) {\n       rootProps['aria-valuenow'] = Math.round(value);\n-      inlineStyles.bar1.transform = `scaleX(${value / 100})`;\n+      inlineStyles.bar1.width = `${value}%`;\n     } else {\n       warning(\n         false,\n@@ -222,7 +222,7 @@ const LinearProgress = React.forwardRef(function LinearProgress(props, ref) {\n   }\n   if (variant === 'buffer') {\n     if (valueBuffer !== undefined) {\n-      inlineStyles.bar2.transform = `scaleX(${(valueBuffer || 0) / 100})`;\n+      inlineStyles.bar2.width = `${valueBuffer || 0}%`;\n     } else {\n       warning(\n         false,\n"}
{"instance_id": "mui__material-ui-15526", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex a28679a61f..61e6fd45b7 100644\n--- a/package.json\n+++ b/package.json\n@@ -210,8 +210,7 @@\n     \"webpack-cli\": \"^3.2.3\"\n   },\n   \"resolutions\": {\n-    \"@material-ui/core\": \"^4.0.0-alpha.7\",\n-    \"**/hoist-non-react-statics\": \"^3.2.1\"\n+    \"@material-ui/core\": \"^4.0.0-alpha.7\"\n   },\n   \"sideEffects\": false,\n   \"nyc\": {\ndiff --git a/packages/material-ui-benchmark/package.json b/packages/material-ui-benchmark/package.json\nindex 5e25d85142..5c5cfbb6a9 100644\n--- a/packages/material-ui-benchmark/package.json\n+++ b/packages/material-ui-benchmark/package.json\n@@ -19,7 +19,6 @@\n     \"system\": \"cd ../../ && NODE_ENV=production BABEL_ENV=docs-production babel-node packages/material-ui-benchmark/src/system.js --inspect=0.0.0.0:9229\",\n     \"test\": \"exit 0\"\n   },\n-  \"devDependencies\": {},\n   \"engines\": {\n     \"node\": \">=8.0.0\"\n   },\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex be858555b2..1e3b1ea6af 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/codemod\",\n   \"version\": \"4.0.0-alpha.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Codemod scripts for Material-UI.\",\n   \"keywords\": [\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex f8a933a5c8..3680f6158e 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/docs\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n   \"main\": \"./src/index.js\",\n@@ -43,7 +42,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex eb636f254d..11323149b9 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/icons\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\n   \"main\": \"./src/index.js\",\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex 0e6dc33e88..5abc3b07bb 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/lab\",\n   \"version\": \"4.0.0-alpha.9\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI Lab - Incubator for Material-UI React components.\",\n   \"main\": \"./src/index.js\",\n@@ -44,7 +43,6 @@\n     \"keycode\": \"^2.1.9\",\n     \"prop-types\": \"^15.7.2\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui-styles/package.json b/packages/material-ui-styles/package.json\nindex e394973c45..7509373f1a 100644\n--- a/packages/material-ui-styles/package.json\n+++ b/packages/material-ui-styles/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/styles\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI Styles - The styling solution of Material-UI.\",\n   \"main\": \"./src/index.js\",\ndiff --git a/packages/material-ui-system/package.json b/packages/material-ui-system/package.json\nindex 56b3bcfa3c..92c8e58233 100644\n--- a/packages/material-ui-system/package.json\n+++ b/packages/material-ui-system/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/system\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI System - Design system for Material-UI.\",\n   \"main\": \"./src/index.js\",\n@@ -41,7 +40,6 @@\n     \"prop-types\": \"^15.7.2\",\n     \"warning\": \"^4.0.1\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui-utils/package.json b/packages/material-ui-utils/package.json\nindex 4a17b285d8..ee3cee03f1 100644\n--- a/packages/material-ui-utils/package.json\n+++ b/packages/material-ui-utils/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/utils\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI Utils - Utility functions for Material-UI.\",\n   \"main\": \"./src/index.js\",\n@@ -40,7 +39,6 @@\n     \"prop-types\": \"^15.7.2\",\n     \"react-is\": \"^16.8.0\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/package.json b/packages/material-ui/package.json\nindex 3b1baf6ca6..fe5dbfbf02 100644\n--- a/packages/material-ui/package.json\n+++ b/packages/material-ui/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/core\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"React components that implement Google's Material Design.\",\n   \"keywords\": [\ndiff --git a/packages/material-ui/src/Fade/Fade.js b/packages/material-ui/src/Fade/Fade.js\nindex f3160bd659..5f7f0e8752 100644\n--- a/packages/material-ui/src/Fade/Fade.js\n+++ b/packages/material-ui/src/Fade/Fade.js\n@@ -73,8 +73,10 @@ const Fade = React.forwardRef(function Fade(props, ref) {\n Fade.propTypes = {\n   /**\n    * A single child content element.\n+   *\n+   * \u26a0\ufe0fThe component used as a child [must be able to hold a ref](/guides/composition/#children).\n    */\n-  children: PropTypes.element,\n+  children: PropTypes.element.isRequired,\n   /**\n    * If `true`, the component will transition in.\n    */\ndiff --git a/packages/material-ui/src/Grow/Grow.js b/packages/material-ui/src/Grow/Grow.js\nindex a4fcfd98bf..00b5881277 100644\n--- a/packages/material-ui/src/Grow/Grow.js\n+++ b/packages/material-ui/src/Grow/Grow.js\n@@ -139,8 +139,10 @@ const Grow = React.forwardRef(function Grow(props, ref) {\n Grow.propTypes = {\n   /**\n    * A single child content element.\n+   *\n+   * \u26a0\ufe0fThe component used as a child [must be able to hold a ref](/guides/composition/#children).\n    */\n-  children: PropTypes.element,\n+  children: PropTypes.element.isRequired,\n   /**\n    * If `true`, show the component; triggers the enter or exit animation.\n    */\ndiff --git a/packages/material-ui/src/Modal/TrapFocus.js b/packages/material-ui/src/Modal/TrapFocus.js\nindex 99a8b0d777..c1d7a20b6f 100644\n--- a/packages/material-ui/src/Modal/TrapFocus.js\n+++ b/packages/material-ui/src/Modal/TrapFocus.js\n@@ -129,6 +129,8 @@ function TrapFocus(props) {\n TrapFocus.propTypes = {\n   /**\n    * A single child content element.\n+   *\n+   * \u26a0\ufe0fThe component used as a child [must be able to hold a ref](/guides/composition/#children).\n    */\n   children: PropTypes.element.isRequired,\n   /**\ndiff --git a/packages/material-ui/src/Slide/Slide.js b/packages/material-ui/src/Slide/Slide.js\nindex ac93b39f2c..0ccc6e2109 100644\n--- a/packages/material-ui/src/Slide/Slide.js\n+++ b/packages/material-ui/src/Slide/Slide.js\n@@ -229,7 +229,7 @@ Slide.propTypes = {\n    *\n    * \u26a0\ufe0fThe component used as a child [must be able to hold a ref](/guides/composition/#children).\n    */\n-  children: PropTypes.element,\n+  children: PropTypes.element.isRequired,\n   /**\n    * Direction the child node will enter from.\n    */\ndiff --git a/packages/material-ui/src/Tooltip/Tooltip.js b/packages/material-ui/src/Tooltip/Tooltip.js\nindex 350224631f..908a44b47f 100644\n--- a/packages/material-ui/src/Tooltip/Tooltip.js\n+++ b/packages/material-ui/src/Tooltip/Tooltip.js\n@@ -379,6 +379,8 @@ function Tooltip(props) {\n Tooltip.propTypes = {\n   /**\n    * Tooltip reference element.\n+   *\n+   * \u26a0\ufe0fThe component used as a child [must be able to hold a ref](/guides/composition/#children).\n    */\n   children: PropTypes.element.isRequired,\n   /**\ndiff --git a/packages/material-ui/src/Zoom/Zoom.js b/packages/material-ui/src/Zoom/Zoom.js\nindex b0e37b1534..5b810ad734 100644\n--- a/packages/material-ui/src/Zoom/Zoom.js\n+++ b/packages/material-ui/src/Zoom/Zoom.js\n@@ -74,8 +74,10 @@ const Zoom = React.forwardRef(function Zoom(props, ref) {\n Zoom.propTypes = {\n   /**\n    * A single child content element.\n+   *\n+   * \u26a0\ufe0fThe component used as a child [must be able to hold a ref](/guides/composition/#children).\n    */\n-  children: PropTypes.element,\n+  children: PropTypes.element.isRequired,\n   /**\n    * If `true`, the component will transition in.\n    */\n"}
{"instance_id": "mui__material-ui-17301", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/SpeedDialAction/SpeedDialAction.js b/packages/material-ui-lab/src/SpeedDialAction/SpeedDialAction.js\nindex dbcbebb7a0..e9ebb7d286 100644\n--- a/packages/material-ui-lab/src/SpeedDialAction/SpeedDialAction.js\n+++ b/packages/material-ui-lab/src/SpeedDialAction/SpeedDialAction.js\n@@ -12,9 +12,9 @@ export const styles = theme => ({\n   button: {\n     margin: 8,\n     color: theme.palette.text.secondary,\n-    backgroundColor: theme.palette.common.white,\n+    backgroundColor: theme.palette.background.paper,\n     '&:hover': {\n-      backgroundColor: emphasize(theme.palette.common.white, 0.15),\n+      backgroundColor: emphasize(theme.palette.background.paper, 0.15),\n     },\n     transition: `${theme.transitions.create('transform', {\n       duration: theme.transitions.duration.shorter,\n"}
{"instance_id": "mui__material-ui-15534", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex a28679a61f..61e6fd45b7 100644\n--- a/package.json\n+++ b/package.json\n@@ -210,8 +210,7 @@\n     \"webpack-cli\": \"^3.2.3\"\n   },\n   \"resolutions\": {\n-    \"@material-ui/core\": \"^4.0.0-alpha.7\",\n-    \"**/hoist-non-react-statics\": \"^3.2.1\"\n+    \"@material-ui/core\": \"^4.0.0-alpha.7\"\n   },\n   \"sideEffects\": false,\n   \"nyc\": {\ndiff --git a/packages/material-ui-benchmark/package.json b/packages/material-ui-benchmark/package.json\nindex 5e25d85142..5c5cfbb6a9 100644\n--- a/packages/material-ui-benchmark/package.json\n+++ b/packages/material-ui-benchmark/package.json\n@@ -19,7 +19,6 @@\n     \"system\": \"cd ../../ && NODE_ENV=production BABEL_ENV=docs-production babel-node packages/material-ui-benchmark/src/system.js --inspect=0.0.0.0:9229\",\n     \"test\": \"exit 0\"\n   },\n-  \"devDependencies\": {},\n   \"engines\": {\n     \"node\": \">=8.0.0\"\n   },\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex be858555b2..1e3b1ea6af 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/codemod\",\n   \"version\": \"4.0.0-alpha.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Codemod scripts for Material-UI.\",\n   \"keywords\": [\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex f8a933a5c8..3680f6158e 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/docs\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n   \"main\": \"./src/index.js\",\n@@ -43,7 +42,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex eb636f254d..11323149b9 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/icons\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\n   \"main\": \"./src/index.js\",\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex 0e6dc33e88..5abc3b07bb 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/lab\",\n   \"version\": \"4.0.0-alpha.9\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI Lab - Incubator for Material-UI React components.\",\n   \"main\": \"./src/index.js\",\n@@ -44,7 +43,6 @@\n     \"keycode\": \"^2.1.9\",\n     \"prop-types\": \"^15.7.2\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui-styles/package.json b/packages/material-ui-styles/package.json\nindex e394973c45..7509373f1a 100644\n--- a/packages/material-ui-styles/package.json\n+++ b/packages/material-ui-styles/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/styles\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI Styles - The styling solution of Material-UI.\",\n   \"main\": \"./src/index.js\",\ndiff --git a/packages/material-ui-system/package.json b/packages/material-ui-system/package.json\nindex 56b3bcfa3c..92c8e58233 100644\n--- a/packages/material-ui-system/package.json\n+++ b/packages/material-ui-system/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/system\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI System - Design system for Material-UI.\",\n   \"main\": \"./src/index.js\",\n@@ -41,7 +40,6 @@\n     \"prop-types\": \"^15.7.2\",\n     \"warning\": \"^4.0.1\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui-utils/package.json b/packages/material-ui-utils/package.json\nindex 4a17b285d8..ee3cee03f1 100644\n--- a/packages/material-ui-utils/package.json\n+++ b/packages/material-ui-utils/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/utils\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"Material-UI Utils - Utility functions for Material-UI.\",\n   \"main\": \"./src/index.js\",\n@@ -40,7 +39,6 @@\n     \"prop-types\": \"^15.7.2\",\n     \"react-is\": \"^16.8.0\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/package.json b/packages/material-ui/package.json\nindex 3b1baf6ca6..fe5dbfbf02 100644\n--- a/packages/material-ui/package.json\n+++ b/packages/material-ui/package.json\n@@ -1,7 +1,6 @@\n {\n   \"name\": \"@material-ui/core\",\n   \"version\": \"4.0.0-beta.0\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"description\": \"React components that implement Google's Material Design.\",\n   \"keywords\": [\ndiff --git a/packages/material-ui/src/ExpansionPanel/ExpansionPanel.js b/packages/material-ui/src/ExpansionPanel/ExpansionPanel.js\nindex 2589ac46a5..3ba7c5a93b 100644\n--- a/packages/material-ui/src/ExpansionPanel/ExpansionPanel.js\n+++ b/packages/material-ui/src/ExpansionPanel/ExpansionPanel.js\n@@ -51,6 +51,9 @@ export const styles = theme => {\n           display: 'none',\n         },\n       },\n+      '&$disabled': {\n+        backgroundColor: theme.palette.action.disabledBackground,\n+      },\n     },\n     /* Styles applied to the root element if `square={false}`. */\n     rounded: {\n@@ -71,10 +74,8 @@ export const styles = theme => {\n     },\n     /* Styles applied to the root element if `expanded={true}`. */\n     expanded: {},\n-    /* Styles applied to the root element if `disabled={true}`. */\n-    disabled: {\n-      backgroundColor: theme.palette.action.disabledBackground,\n-    },\n+    /* Pseudo-class applied to the root element if `disabled={true}`. */\n+    disabled: {},\n   };\n };\n \ndiff --git a/packages/material-ui/src/ListItem/ListItem.js b/packages/material-ui/src/ListItem/ListItem.js\nindex bd056e7e75..eca579eccd 100644\n--- a/packages/material-ui/src/ListItem/ListItem.js\n+++ b/packages/material-ui/src/ListItem/ListItem.js\n@@ -25,6 +25,9 @@ export const styles = theme => ({\n     '&$selected, &$selected:hover': {\n       backgroundColor: theme.palette.action.selected,\n     },\n+    '&$disabled': {\n+      opacity: 0.5,\n+    },\n   },\n   /* Styles applied to the `container` element if `children` includes `ListItemSecondaryAction`. */\n   container: {\n@@ -43,10 +46,8 @@ export const styles = theme => ({\n   alignItemsFlexStart: {\n     alignItems: 'flex-start',\n   },\n-  /* Styles applied to the inner `component` element if `disabled={true}`. */\n-  disabled: {\n-    opacity: 0.5,\n-  },\n+  /* Pseudo-class applied to the `component` element if `disabled={true}`. */\n+  disabled: {},\n   /* Styles applied to the inner `component` element if `divider={true}`. */\n   divider: {\n     borderBottom: `1px solid ${theme.palette.divider}`,\n"}
{"instance_id": "mui__material-ui-15359", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 0fc9b8282d..fd267c96f2 100644\n--- a/package.json\n+++ b/package.json\n@@ -205,9 +205,6 @@\n     \"webpack-bundle-analyzer\": \"^3.0.0\",\n     \"webpack-cli\": \"^3.2.3\"\n   },\n-  \"resolutions\": {\n-    \"**/hoist-non-react-statics\": \"^3.2.1\"\n-  },\n   \"sideEffects\": false,\n   \"nyc\": {\n     \"include\": [\ndiff --git a/packages/material-ui-benchmark/package.json b/packages/material-ui-benchmark/package.json\nindex da0849118e..278dc943c3 100644\n--- a/packages/material-ui-benchmark/package.json\n+++ b/packages/material-ui-benchmark/package.json\n@@ -19,7 +19,6 @@\n     \"system\": \"cd ../../ && NODE_ENV=production BABEL_ENV=docs-production babel-node packages/material-ui-benchmark/src/system.js --inspect=0.0.0.0:9229\",\n     \"test\": \"exit 0\"\n   },\n-  \"devDependencies\": {},\n   \"engines\": {\n     \"node\": \">=8.0.0\"\n   },\ndiff --git a/packages/material-ui-codemod/package.json b/packages/material-ui-codemod/package.json\nindex 25005dc2a5..0b90c6f999 100644\n--- a/packages/material-ui-codemod/package.json\n+++ b/packages/material-ui-codemod/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/codemod\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"4.0.0-alpha.0\",\n   \"description\": \"Codemod scripts for Material-UI.\",\ndiff --git a/packages/material-ui-docs/package.json b/packages/material-ui-docs/package.json\nindex 7d29d0bce0..b3f4dcd0ae 100644\n--- a/packages/material-ui-docs/package.json\n+++ b/packages/material-ui-docs/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/docs\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"4.0.0-alpha.0\",\n   \"description\": \"Material-UI Docs - Documentation building blocks.\",\n@@ -43,7 +42,6 @@\n     \"nprogress\": \"^0.2.0\",\n     \"prismjs\": \"^1.8.4\"\n   },\n-  \"devDependencies\": {},\n   \"publishConfig\": {\n     \"access\": \"public\"\n   },\ndiff --git a/packages/material-ui-icons/package.json b/packages/material-ui-icons/package.json\nindex ab0a2f2b96..43202d7ae7 100644\n--- a/packages/material-ui-icons/package.json\n+++ b/packages/material-ui-icons/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/icons\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"4.0.0-alpha.1\",\n   \"description\": \"Material Design Svg Icons converted to Material-UI React components.\",\ndiff --git a/packages/material-ui-lab/package.json b/packages/material-ui-lab/package.json\nindex 96325f2cf0..ce8354c778 100644\n--- a/packages/material-ui-lab/package.json\n+++ b/packages/material-ui-lab/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/lab\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"4.0.0-alpha.6\",\n   \"description\": \"Material-UI Lab - Incubator for Material-UI React components.\",\n@@ -44,7 +43,6 @@\n     \"keycode\": \"^2.1.9\",\n     \"prop-types\": \"^15.7.2\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui-styles/package.json b/packages/material-ui-styles/package.json\nindex abf56f3a8c..9b55fb0138 100644\n--- a/packages/material-ui-styles/package.json\n+++ b/packages/material-ui-styles/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/styles\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"4.0.0-alpha.7\",\n   \"description\": \"Material-UI Styles - The styling solution of Material-UI.\",\ndiff --git a/packages/material-ui-system/package.json b/packages/material-ui-system/package.json\nindex 13d825e976..02e9349fa4 100644\n--- a/packages/material-ui-system/package.json\n+++ b/packages/material-ui-system/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/system\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"4.0.0-alpha.0\",\n   \"description\": \"Material-UI System - Design system for Material-UI.\",\n@@ -41,7 +40,6 @@\n     \"prop-types\": \"^15.7.2\",\n     \"warning\": \"^4.0.1\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui-utils/package.json b/packages/material-ui-utils/package.json\nindex 4ebd156a37..035f1d4fc1 100644\n--- a/packages/material-ui-utils/package.json\n+++ b/packages/material-ui-utils/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/utils\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"4.0.0-alpha.4\",\n   \"description\": \"Material-UI Utils - Utility functions for Material-UI.\",\n@@ -40,7 +39,6 @@\n     \"prop-types\": \"^15.7.2\",\n     \"react-is\": \"^16.8.0\"\n   },\n-  \"devDependencies\": {},\n   \"sideEffects\": false,\n   \"publishConfig\": {\n     \"access\": \"public\"\ndiff --git a/packages/material-ui/package.json b/packages/material-ui/package.json\nindex 7f3e84cb03..ee6303e932 100644\n--- a/packages/material-ui/package.json\n+++ b/packages/material-ui/package.json\n@@ -1,6 +1,5 @@\n {\n   \"name\": \"@material-ui/core\",\n-  \"private\": false,\n   \"author\": \"Material-UI Team\",\n   \"version\": \"4.0.0-alpha.7\",\n   \"description\": \"React components that implement Google's Material Design.\",\ndiff --git a/packages/material-ui/src/Popper/Popper.js b/packages/material-ui/src/Popper/Popper.js\nindex ce37362db8..ba2a428996 100644\n--- a/packages/material-ui/src/Popper/Popper.js\n+++ b/packages/material-ui/src/Popper/Popper.js\n@@ -96,17 +96,33 @@ class Popper extends React.Component {\n       },\n       // We could have been using a custom modifier like react-popper is doing.\n       // But it seems this is the best public API for this use case.\n-      onCreate: this.handlePopperUpdate,\n-      onUpdate: this.handlePopperUpdate,\n+      onCreate: this.handlePopperCreated(popperOptions.onCreate),\n+      onUpdate: this.handlePopperUpdate(popperOptions.onUpdate),\n     });\n   };\n \n-  handlePopperUpdate = data => {\n+  handlePopperUpdate = popperOptionsOnUpdate => data => {\n     if (data.placement !== this.state.placement) {\n       this.setState({\n         placement: data.placement,\n       });\n     }\n+\n+    if (popperOptionsOnUpdate) {\n+      popperOptionsOnUpdate(data);\n+    }\n+  };\n+\n+  handlePopperCreated = popperOptionsOnCreate => data => {\n+    if (data.placement !== this.state.placement) {\n+      this.setState({\n+        placement: data.placement,\n+      });\n+    }\n+\n+    if (popperOptionsOnCreate) {\n+      popperOptionsOnCreate(data);\n+    }\n   };\n \n   handleEnter = () => {\n"}
{"instance_id": "mui__material-ui-18257", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Select/Select.js b/packages/material-ui/src/Select/Select.js\nindex 0fec819d6f..4ac2b5dba9 100644\n--- a/packages/material-ui/src/Select/Select.js\n+++ b/packages/material-ui/src/Select/Select.js\n@@ -69,7 +69,7 @@ const Select = React.forwardRef(function Select(props, ref) {\n       type: undefined, // We render a select. We can ignore the type provided by the `Input`.\n       multiple,\n       ...(native\n-        ? {}\n+        ? { id }\n         : {\n             autoWidth,\n             displayEmpty,\n"}
{"instance_id": "mui__material-ui-17829", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex bed625ee9c..680fd3b9e7 100644\n--- a/package.json\n+++ b/package.json\n@@ -50,7 +50,7 @@\n     \"@babel/plugin-transform-runtime\": \"~7.5.5\",\n     \"@babel/preset-env\": \"^7.6.0\",\n     \"@babel/preset-react\": \"^7.0.0\",\n-    \"@babel/register\": \"^7.6.2\",\n+    \"@babel/register\": \"^7.28.3\",\n     \"@testing-library/dom\": \"^6.8.1\",\n     \"@testing-library/react\": \"^9.2.0\",\n     \"@types/chai\": \"^4.2.3\",\n@@ -76,15 +76,15 @@\n     \"babel-plugin-transform-dev-warning\": \"^0.1.0\",\n     \"babel-plugin-transform-react-constant-elements\": \"^6.23.0\",\n     \"babel-plugin-transform-react-remove-prop-types\": \"^0.4.21\",\n-    \"chai\": \"^4.1.2\",\n+    \"chai\": \"^4.5.0\",\n     \"chai-dom\": \"^1.8.1\",\n     \"compression-webpack-plugin\": \"^3.0.0\",\n     \"confusing-browser-globals\": \"^1.0.9\",\n     \"cross-env\": \"^6.0.0\",\n     \"danger\": \"^9.1.8\",\n     \"dtslint\": \"^0.9.3\",\n-    \"enzyme\": \"^3.9.0\",\n-    \"enzyme-adapter-react-16\": \"^1.14.0\",\n+    \"enzyme\": \"^3.11.0\",\n+    \"enzyme-adapter-react-16\": \"^1.15.8\",\n     \"eslint\": \"^5.9.0\",\n     \"eslint-config-airbnb\": \"^17.1.1\",\n     \"eslint-config-prettier\": \"^6.2.0\",\n@@ -99,7 +99,7 @@\n     \"fs-extra\": \"^8.1.0\",\n     \"glob\": \"^7.1.2\",\n     \"glob-gitignore\": \"^1.0.11\",\n-    \"jsdom\": \"^15.1.1\",\n+    \"jsdom\": \"^15.2.1\",\n     \"jsonlint\": \"^1.6.3\",\n     \"karma\": \"^4.3.0\",\n     \"karma-browserstack-launcher\": \"~1.4.0\",\n@@ -109,7 +109,7 @@\n     \"karma-sourcemap-loader\": \"^0.3.7\",\n     \"karma-webpack\": \"^4.0.2\",\n     \"lerna\": \"^3.16.4\",\n-    \"mocha\": \"^6.2.0\",\n+    \"mocha\": \"^6.2.3\",\n     \"nyc\": \"^14.1.1\",\n     \"prettier\": \"1.17.0\",\n     \"pretty-bytes\": \"^5.3.0\",\n@@ -125,7 +125,7 @@\n     \"rollup-plugin-node-resolve\": \"^5.2.0\",\n     \"rollup-plugin-size-snapshot\": \"^0.10.0\",\n     \"rollup-plugin-terser\": \"^5.1.1\",\n-    \"sinon\": \"^7.0.0\",\n+    \"sinon\": \"^7.5.0\",\n     \"size-limit\": \"^0.21.0\",\n     \"ts-node\": \"^8.3.0\",\n     \"tslint\": \"5.14.0\",\n@@ -165,6 +165,5 @@\n   \"workspaces\": [\n     \"packages/*\",\n     \"docs\"\n-  ],\n-  \"dependencies\": {}\n+  ]\n }\ndiff --git a/packages/material-ui/src/Chip/Chip.d.ts b/packages/material-ui/src/Chip/Chip.d.ts\nindex 03b02df927..2e17cfd275 100644\n--- a/packages/material-ui/src/Chip/Chip.d.ts\n+++ b/packages/material-ui/src/Chip/Chip.d.ts\n@@ -9,6 +9,10 @@ export interface ChipTypeMap<P = {}, D extends React.ElementType = 'div'> {\n     color?: PropTypes.Color;\n     deleteIcon?: React.ReactElement;\n     disabled?: boolean;\n+    /**\n+     * If `true`, the ripple effect will be disabled.\n+     */\n+    disableRipple?: boolean;\n     icon?: React.ReactElement;\n     label?: React.ReactNode;\n     onDelete?: React.EventHandler<any>;\ndiff --git a/packages/material-ui/src/Chip/Chip.js b/packages/material-ui/src/Chip/Chip.js\nindex 5a7d605d72..ce397d9d7c 100644\n--- a/packages/material-ui/src/Chip/Chip.js\n+++ b/packages/material-ui/src/Chip/Chip.js\n@@ -5,9 +5,11 @@ import CancelIcon from '../internal/svg-icons/Cancel';\n import withStyles from '../styles/withStyles';\n import { emphasize, fade } from '../styles/colorManipulator';\n import useForkRef from '../utils/useForkRef';\n+import useEventCallback from '../utils/useEventCallback';\n import unsupportedProp from '../utils/unsupportedProp';\n import capitalize from '../utils/capitalize';\n import '../Avatar'; // So we don't have any override priority issue.\n+import TouchRipple from '../ButtonBase/TouchRipple';\n \n export const styles = theme => {\n   const backgroundColor =\n@@ -41,6 +43,9 @@ export const styles = theme => {\n         opacity: 0.5,\n         pointerEvents: 'none',\n       },\n+      // Required for the ripple effect to work properly\n+      position: 'relative',\n+      overflow: 'hidden',\n     },\n     /* Styles applied to the root element if `size=\"small\"`. */\n     sizeSmall: {\n@@ -275,12 +280,20 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n     component: Component = 'div',\n     deleteIcon: deleteIconProp,\n     disabled = false,\n+    disableRipple = false,\n     icon: iconProp,\n     label,\n     onClick,\n     onDelete,\n     onKeyDown,\n     onKeyUp,\n+    onMouseDown,\n+    onMouseLeave,\n+    onMouseUp,\n+    onTouchEnd,\n+    onTouchMove,\n+    onTouchStart,\n+    onDragLeave,\n     size = 'medium',\n     variant = 'default',\n     ...other\n@@ -289,6 +302,31 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n   const chipRef = React.useRef(null);\n   const handleRef = useForkRef(chipRef, ref);\n \n+  const rippleRef = React.useRef(null);\n+\n+  function useRippleHandler(rippleAction, eventCallback, skipRippleAction = disableRipple) {\n+    return useEventCallback(event => {\n+      if (eventCallback) {\n+        eventCallback(event);\n+      }\n+\n+      const ignore = event.defaultPrevented || skipRippleAction;\n+      if (!ignore && rippleRef.current) {\n+        rippleRef.current[rippleAction](event);\n+      }\n+\n+      return true;\n+    });\n+  }\n+\n+  const handleMouseDown = useRippleHandler('start', onMouseDown);\n+  const handleDragLeave = useRippleHandler('stop', onDragLeave);\n+  const handleMouseUp = useRippleHandler('stop', onMouseUp);\n+  const handleMouseLeave = useRippleHandler('stop', onMouseLeave);\n+  const handleTouchStart = useRippleHandler('start', onTouchStart);\n+  const handleTouchEnd = useRippleHandler('stop', onTouchEnd);\n+  const handleTouchMove = useRippleHandler('stop', onTouchMove);\n+\n   const handleDeleteIconClick = event => {\n     // Stop the event from bubbling up to the `Chip`\n     event.stopPropagation();\n@@ -388,6 +426,8 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n     }\n   }\n \n+  const enableRipple = clickable && !disabled && !disableRipple;\n+\n   return (\n     <Component\n       role={clickable || onDelete ? 'button' : undefined}\n@@ -411,6 +451,13 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n       onClick={onClick}\n       onKeyDown={handleKeyDown}\n       onKeyUp={handleKeyUp}\n+      onMouseDown={enableRipple ? handleMouseDown : onMouseDown}\n+      onMouseLeave={enableRipple ? handleMouseLeave : onMouseLeave}\n+      onMouseUp={enableRipple ? handleMouseUp : onMouseUp}\n+      onDragLeave={enableRipple ? handleDragLeave : onDragLeave}\n+      onTouchStart={enableRipple ? handleTouchStart : onTouchStart}\n+      onTouchEnd={enableRipple ? handleTouchEnd : onTouchEnd}\n+      onTouchMove={enableRipple ? handleTouchMove : onTouchMove}\n       ref={handleRef}\n       {...other}\n     >\n@@ -423,6 +470,7 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n         {label}\n       </span>\n       {deleteIcon}\n+      {enableRipple ? <TouchRipple ref={rippleRef} center={false} /> : null}\n     </Component>\n   );\n });\n@@ -471,6 +519,10 @@ Chip.propTypes = {\n    * If `true`, the chip should be displayed in a disabled state.\n    */\n   disabled: PropTypes.bool,\n+  /**\n+   * If `true`, the ripple effect will be disabled.\n+   */\n+  disableRipple: PropTypes.bool,\n   /**\n    * Icon element.\n    */\n"}
{"instance_id": "mui__material-ui-18141", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Select/Select.js b/packages/material-ui/src/Select/Select.js\nindex 0fec819d6f..4ac2b5dba9 100644\n--- a/packages/material-ui/src/Select/Select.js\n+++ b/packages/material-ui/src/Select/Select.js\n@@ -69,7 +69,7 @@ const Select = React.forwardRef(function Select(props, ref) {\n       type: undefined, // We render a select. We can ignore the type provided by the `Input`.\n       multiple,\n       ...(native\n-        ? {}\n+        ? { id }\n         : {\n             autoWidth,\n             displayEmpty,\n"}
{"instance_id": "mui__material-ui-16397", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/ButtonBase/ButtonBase.js b/packages/material-ui/src/ButtonBase/ButtonBase.js\nindex d157b568e3..ae8041fb40 100644\n--- a/packages/material-ui/src/ButtonBase/ButtonBase.js\n+++ b/packages/material-ui/src/ButtonBase/ButtonBase.js\n@@ -268,7 +268,9 @@ const ButtonBase = React.forwardRef(function ButtonBase(props, ref) {\n     buttonProps.type = type;\n     buttonProps.disabled = disabled;\n   } else {\n-    buttonProps.role = 'button';\n+    if (!(ComponentProp === 'a' && other.href)) {\n+      buttonProps.role = 'button';\n+    }\n     buttonProps['aria-disabled'] = disabled;\n   }\n \n"}
{"instance_id": "mui__material-ui-18796", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/Autocomplete/Autocomplete.js b/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\nindex 991500fc58..b1b9a88b5b 100644\n--- a/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\n+++ b/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\n@@ -622,7 +622,8 @@ Autocomplete.propTypes = {\n    * Callback fired when the input value changes.\n    *\n    * @param {object} event The event source of the callback.\n-   * @param {string} value\n+   * @param {string} value The new value of the text input.\n+   * @param {string} reason Can be: `\"input\"` (user input), `\"reset\"` (programmatic change), `\"clear\"`.\n    */\n   onInputChange: PropTypes.func,\n   /**\ndiff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.d.ts b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.d.ts\nindex 310167c6c7..d3273e6716 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.d.ts\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.d.ts\n@@ -138,9 +138,10 @@ export interface UseAutocompleteProps {\n    * Callback fired when the input value changes.\n    *\n    * @param {object} event The event source of the callback.\n-   * @param {string} value\n+   * @param {string} value The new value of the text input.\n+   * @param {string} reason Can be: `\"input\"` (user input), `\"reset\"` (programmatic change), `\"clear\"`.\n    */\n-  onInputChange?: (event: React.ChangeEvent<{}>, value: any) => void;\n+  onInputChange?: (event: React.ChangeEvent<{}>, value: string, reason: 'input' | 'reset' | 'clear') => void;\n   /**\n    * Callback fired when the popup requests to be opened.\n    * Use in controlled mode (see open).\ndiff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 38f9ee430a..1ed4e3f9b0 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -218,7 +218,7 @@ export default function useAutocomplete(props) {\n     setInputValue(newInputValue);\n \n     if (onInputChange) {\n-      onInputChange(event, newInputValue);\n+      onInputChange(event, newInputValue, 'reset');\n     }\n   });\n \n@@ -512,7 +512,14 @@ export default function useAutocomplete(props) {\n     if (disableOpenOnFocus) {\n       handleClose();\n     }\n-    setInputValue('');\n+\n+    if (inputValue !== '') {\n+      setInputValue('');\n+\n+      if (onInputChange) {\n+        onInputChange(event, '', 'clear');\n+      }\n+    }\n   };\n \n   const handleKeyDown = event => {\n@@ -657,7 +664,7 @@ export default function useAutocomplete(props) {\n     setInputValue(newValue);\n \n     if (onInputChange) {\n-      onInputChange(event, newValue);\n+      onInputChange(event, newValue, 'input');\n     }\n   };\n \n"}
{"instance_id": "mui__material-ui-18683", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/useMediaQuery/useMediaQuery.js b/packages/material-ui/src/useMediaQuery/useMediaQuery.js\nindex e969caa2fa..d7dadb9c16 100644\n--- a/packages/material-ui/src/useMediaQuery/useMediaQuery.js\n+++ b/packages/material-ui/src/useMediaQuery/useMediaQuery.js\n@@ -1,9 +1,6 @@\n import React from 'react';\n import { getThemeProps, useTheme } from '@material-ui/styles';\n \n-// This variable will be true once the server-side hydration is completed.\n-let hydrationCompleted = false;\n-\n function useMediaQuery(queryInput, options = {}) {\n   const theme = useTheme();\n   const props = getThemeProps({\n@@ -39,8 +36,14 @@ function useMediaQuery(queryInput, options = {}) {\n     ...options,\n   };\n \n+  // Use a ref to track if the component has mounted.\n+  // This ensures each component instance tracks its own hydration state,\n+  // rather than relying on a global variable that can cause issues\n+  // when multiple React roots exist on the same page.\n+  const mountedRef = React.useRef(false);\n+\n   const [match, setMatch] = React.useState(() => {\n-    if ((hydrationCompleted || noSsr) && supportMatchMedia) {\n+    if ((mountedRef.current || noSsr) && supportMatchMedia) {\n       return window.matchMedia(query).matches;\n     }\n     if (ssrMatchMedia) {\n@@ -54,7 +57,7 @@ function useMediaQuery(queryInput, options = {}) {\n \n   React.useEffect(() => {\n     let active = true;\n-    hydrationCompleted = true;\n+    mountedRef.current = true;\n \n     if (!supportMatchMedia) {\n       return undefined;\n@@ -81,7 +84,8 @@ function useMediaQuery(queryInput, options = {}) {\n }\n \n export function testReset() {\n-  hydrationCompleted = false;\n+  // This function is kept for backward compatibility with tests,\n+  // but it no longer has any effect since we removed the global hydrationCompleted variable.\n }\n \n export default useMediaQuery;\n"}
{"instance_id": "mui__material-ui-19278", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/pages/api/skeleton.md b/docs/pages/api/skeleton.md\nindex 3d19574440..64d9ee615a 100644\n--- a/docs/pages/api/skeleton.md\n+++ b/docs/pages/api/skeleton.md\n@@ -26,7 +26,7 @@ You can learn more about the difference by [reading this guide](/guides/minimizi\n |:-----|:-----|:--------|:------------|\n | <span class=\"prop-name\">animation</span> | <span class=\"prop-type\">'pulse'<br>&#124;&nbsp;'wave'<br>&#124;&nbsp;false</span> | <span class=\"prop-default\">'pulse'</span> | The animation. If `false` the animation effect is disabled. |\n | <span class=\"prop-name\">classes</span> | <span class=\"prop-type\">object</span> |  | Override or extend the styles applied to the component. See [CSS API](#css) below for more details. |\n-| <span class=\"prop-name\">component</span> | <span class=\"prop-type\">elementType</span> | <span class=\"prop-default\">'div'</span> | The component used for the root node. Either a string to use a DOM element or a component. |\n+| <span class=\"prop-name\">component</span> | <span class=\"prop-type\">elementType</span> | <span class=\"prop-default\">'span'</span> | The component used for the root node. Either a string to use a DOM element or a component. |\n | <span class=\"prop-name\">height</span> | <span class=\"prop-type\">number<br>&#124;&nbsp;string</span> |  | Height of the skeleton. Useful when you don't want to adapt the skeleton to a text element but for instance a card. |\n | <span class=\"prop-name\">variant</span> | <span class=\"prop-type\">'text'<br>&#124;&nbsp;'rect'<br>&#124;&nbsp;'circle'</span> | <span class=\"prop-default\">'text'</span> | The type of content that will be rendered. |\n | <span class=\"prop-name\">width</span> | <span class=\"prop-type\">number<br>&#124;&nbsp;string</span> |  | Width of the skeleton. Useful when the skeleton is inside an inline element with no width of its own. |\ndiff --git a/packages/material-ui-lab/src/Skeleton/Skeleton.d.ts b/packages/material-ui-lab/src/Skeleton/Skeleton.d.ts\nindex 1401fec029..d60a20afdd 100644\n--- a/packages/material-ui-lab/src/Skeleton/Skeleton.d.ts\n+++ b/packages/material-ui-lab/src/Skeleton/Skeleton.d.ts\n@@ -8,7 +8,7 @@ export interface SkeletonTypeMap<P = {}, D extends React.ElementType = 'hr'> {\n     variant?: 'text' | 'rect' | 'circle';\n     width?: number | string;\n   };\n-  defaultComponent: 'div';\n+  defaultComponent: 'span';\n   classKey: SkeletonClassKey;\n }\n \ndiff --git a/packages/material-ui-lab/src/Skeleton/Skeleton.js b/packages/material-ui-lab/src/Skeleton/Skeleton.js\nindex c4696edc76..56b0ecf513 100644\n--- a/packages/material-ui-lab/src/Skeleton/Skeleton.js\n+++ b/packages/material-ui-lab/src/Skeleton/Skeleton.js\n@@ -74,7 +74,7 @@ const Skeleton = React.forwardRef(function Skeleton(props, ref) {\n     animation = 'pulse',\n     classes,\n     className,\n-    component: Component = 'div',\n+    component: Component = 'span',\n     height,\n     variant = 'text',\n     width,\n"}
{"instance_id": "mui__material-ui-19072", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex bfa880b3d5..19f0d09c43 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -612,6 +612,8 @@ export default function useAutocomplete(props) {\n             );\n           }\n         } else if (freeSolo && inputValue !== '' && inputValueIsSelectedValue === false) {\n+          // We don't want to validate the form.\n+          event.preventDefault();\n           selectNewValue(event, inputValue);\n         }\n         break;\n"}
{"instance_id": "mui__material-ui-19257", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/Autocomplete/Autocomplete.d.ts b/packages/material-ui-lab/src/Autocomplete/Autocomplete.d.ts\nindex 90e798807e..541f8fe593 100644\n--- a/packages/material-ui-lab/src/Autocomplete/Autocomplete.d.ts\n+++ b/packages/material-ui-lab/src/Autocomplete/Autocomplete.d.ts\n@@ -157,6 +157,8 @@ export type AutocompleteClassKey =\n   | 'focused'\n   | 'tag'\n   | 'tagSizeSmall'\n+  | 'hasPopupIcon'\n+  | 'hasClearIcon'\n   | 'inputRoot'\n   | 'input'\n   | 'inputFocused'\ndiff --git a/packages/material-ui-lab/src/Autocomplete/Autocomplete.js b/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\nindex eebefc7301..d4f777e69e 100644\n--- a/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\n+++ b/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\n@@ -35,7 +35,12 @@ export const styles = theme => ({\n   /* Styles applied to the Input element. */\n   inputRoot: {\n     flexWrap: 'wrap',\n-    paddingRight: 62,\n+    '$hasPopupIcon &, $hasClearIcon &': {\n+      paddingRight: 30,\n+    },\n+    '$hasPopupIcon$hasClearIcon &': {\n+      paddingRight: 56,\n+    },\n     '& $input': {\n       width: 0,\n       minWidth: 30,\n@@ -59,7 +64,12 @@ export const styles = theme => ({\n     },\n     '&[class*=\"MuiOutlinedInput-root\"]': {\n       padding: 9,\n-      paddingRight: 62,\n+      '$hasPopupIcon &, $hasClearIcon &': {\n+        paddingRight: 39,\n+      },\n+      '$hasPopupIcon$hasClearIcon &': {\n+        paddingRight: 65,\n+      },\n       '& $input': {\n         padding: '9.5px 4px',\n       },\n@@ -72,7 +82,12 @@ export const styles = theme => ({\n     },\n     '&[class*=\"MuiOutlinedInput-root\"][class*=\"MuiOutlinedInput-marginDense\"]': {\n       padding: 6,\n-      paddingRight: 62,\n+      '$hasPopupIcon &, $hasClearIcon &': {\n+        paddingRight: 36,\n+      },\n+      '$hasPopupIcon$hasClearIcon &': {\n+        paddingRight: 62,\n+      },\n       '& $input': {\n         padding: '4.5px 4px',\n       },\n@@ -80,6 +95,12 @@ export const styles = theme => ({\n     '&[class*=\"MuiFilledInput-root\"]': {\n       paddingTop: 19,\n       paddingLeft: 8,\n+      '$hasPopupIcon &, $hasClearIcon &': {\n+        paddingRight: 39,\n+      },\n+      '$hasPopupIcon$hasClearIcon &': {\n+        paddingRight: 65,\n+      },\n       '& $input': {\n         padding: '9px 4px',\n       },\n@@ -94,6 +115,10 @@ export const styles = theme => ({\n       },\n     },\n   },\n+  /* Styles applied to the root element if the popup icon is rendered. */\n+  hasPopupIcon: {},\n+  /* Styles applied to the root element if the clear icon is rendered. */\n+  hasClearIcon: {},\n   /* Styles applied to the input element. */\n   input: {\n     flexGrow: 1,\n@@ -345,6 +370,9 @@ const Autocomplete = React.forwardRef(function Autocomplete(props, ref) {\n     );\n   };\n \n+  const hasClearIcon = !disableClearable && !disabled;\n+  const hasPopupIcon = (!freeSolo || forcePopupIcon === true) && forcePopupIcon !== false;\n+\n   return (\n     <React.Fragment>\n       <div\n@@ -353,6 +381,8 @@ const Autocomplete = React.forwardRef(function Autocomplete(props, ref) {\n           classes.root,\n           {\n             [classes.focused]: focused,\n+            [classes.hasClearIcon]: hasClearIcon,\n+            [classes.hasPopupIcon]: hasPopupIcon,\n           },\n           className,\n         )}\n@@ -369,7 +399,7 @@ const Autocomplete = React.forwardRef(function Autocomplete(props, ref) {\n             startAdornment,\n             endAdornment: (\n               <div className={classes.endAdornment}>\n-                {disableClearable || disabled ? null : (\n+                {hasClearIcon ? (\n                   <IconButton\n                     {...getClearProps()}\n                     aria-label={clearText}\n@@ -380,9 +410,9 @@ const Autocomplete = React.forwardRef(function Autocomplete(props, ref) {\n                   >\n                     {closeIcon}\n                   </IconButton>\n-                )}\n+                ) : null}\n \n-                {(!freeSolo || forcePopupIcon === true) && forcePopupIcon !== false ? (\n+                {hasPopupIcon ? (\n                   <IconButton\n                     {...getPopupIndicatorProps()}\n                     disabled={disabled}\n"}
{"instance_id": "mui__material-ui-19121", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 4037be9ee9..8206e7c6f7 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -782,21 +782,49 @@ export default function useAutocomplete(props) {\n \n   let groupedOptions = filteredOptions;\n   if (groupBy) {\n+    // used to keep track of key and indexes in the result array\n+    const indexBy = new Map();\n+    let warn = false;\n+\n     groupedOptions = filteredOptions.reduce((acc, option, index) => {\n       const key = groupBy(option);\n \n-      if (acc.length > 0 && acc[acc.length - 1].key === key) {\n-        acc[acc.length - 1].options.push(option);\n-      } else {\n+      if (indexBy.get(key) === undefined) {\n+        indexBy.set(key, acc.length);\n         acc.push({\n           key,\n           index,\n           options: [option],\n         });\n+      } else {\n+        const existingGroupIndex = indexBy.get(key);\n+        acc[existingGroupIndex].options.push(option);\n+        // Options not sorted by group, need to warn and recalculate indices\n+        if (existingGroupIndex !== acc.length - 1) {\n+          warn = true;\n+        }\n       }\n \n       return acc;\n     }, []);\n+\n+    if (warn) {\n+      // Fixes index for groups with options not in a row.\n+      let indexCounter = 0;\n+      groupedOptions.forEach(option => {\n+        option.index = indexCounter;\n+        indexCounter += option.options.length;\n+      });\n+    }\n+\n+    if (process.env.NODE_ENV !== 'production') {\n+      if (warn) {\n+        console.warn(\n+          `Material-UI: The options provided combined with the \\`groupBy\\` method of Autocomplete returns duplicated headers.`,\n+          'You can solve the issue by sorting the options with the output of `groupBy`.',\n+        );\n+      }\n+    }\n   }\n \n   return {\n"}
{"instance_id": "mui__material-ui-13789", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Dialog/Dialog.js b/packages/material-ui/src/Dialog/Dialog.js\nindex 669a80c29a..4a81f84287 100644\n--- a/packages/material-ui/src/Dialog/Dialog.js\n+++ b/packages/material-ui/src/Dialog/Dialog.js\n@@ -117,11 +117,24 @@ export const styles = theme => ({\n  * Dialogs are overlaid modal paper based components with a backdrop.\n  */\n class Dialog extends React.Component {\n+  mouseDownTarget = null;\n+\n+  handleMouseDown = event => {\n+    this.mouseDownTarget = event.target;\n+  };\n+\n   handleBackdropClick = event => {\n     if (event.target !== event.currentTarget) {\n       return;\n     }\n \n+    // Make sure the event starts and ends on the same DOM element.\n+    if (this.mouseDownTarget !== event.target) {\n+      return;\n+    }\n+\n+    this.mouseDownTarget = null;\n+\n     if (this.props.onBackdropClick) {\n       this.props.onBackdropClick(event);\n     }\n@@ -191,6 +204,7 @@ class Dialog extends React.Component {\n         >\n           <div\n             className={classNames(classes.container, classes[`scroll${capitalize(scroll)}`])}\n+            onMouseDown={this.handleMouseDown}\n             onClick={this.handleBackdropClick}\n             role=\"document\"\n           >\ndiff --git a/packages/material-ui/src/Modal/Modal.js b/packages/material-ui/src/Modal/Modal.js\nindex 8f122acffe..78cca98cf4 100644\n--- a/packages/material-ui/src/Modal/Modal.js\n+++ b/packages/material-ui/src/Modal/Modal.js\n@@ -59,6 +59,8 @@ if (process.env.NODE_ENV !== 'production' && !React.createContext) {\n class Modal extends React.Component {\n   mounted = false;\n \n+  mouseDownTarget = null;\n+\n   constructor(props) {\n     super();\n     this.state = {\n@@ -152,11 +154,22 @@ class Modal extends React.Component {\n     this.setState({ exited: true });\n   };\n \n+  handleMouseDown = event => {\n+    this.mouseDownTarget = event.target;\n+  };\n+\n   handleBackdropClick = event => {\n     if (event.target !== event.currentTarget) {\n       return;\n     }\n \n+    // Make sure the event starts and ends on the same DOM element.\n+    if (this.mouseDownTarget !== event.target) {\n+      return;\n+    }\n+\n+    this.mouseDownTarget = null;\n+\n     if (this.props.onBackdropClick) {\n       this.props.onBackdropClick(event);\n     }\n@@ -332,7 +345,12 @@ class Modal extends React.Component {\n           {...other}\n         >\n           {hideBackdrop ? null : (\n-            <BackdropComponent open={open} onClick={this.handleBackdropClick} {...BackdropProps} />\n+            <BackdropComponent\n+              open={open}\n+              onClick={this.handleBackdropClick}\n+              onMouseDown={this.handleMouseDown}\n+              {...BackdropProps}\n+            />\n           )}\n           <RootRef rootRef={this.onRootRef}>{React.cloneElement(children, childProps)}</RootRef>\n         </div>\n"}
{"instance_id": "mui__material-ui-18824", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Paper/Paper.d.ts b/packages/material-ui/src/Paper/Paper.d.ts\nindex 02de56d360..3d1a5fd31b 100644\n--- a/packages/material-ui/src/Paper/Paper.d.ts\n+++ b/packages/material-ui/src/Paper/Paper.d.ts\n@@ -6,11 +6,13 @@ export interface PaperProps\n   component?: React.ElementType<React.HTMLAttributes<HTMLElement>>;\n   elevation?: number;\n   square?: boolean;\n+  variant?: 'elevation' | 'outlined';\n }\n \n export type PaperClassKey =\n   | 'root'\n   | 'rounded'\n+  | 'outlined'\n   | 'elevation0'\n   | 'elevation1'\n   | 'elevation2'\ndiff --git a/packages/material-ui/src/Paper/Paper.js b/packages/material-ui/src/Paper/Paper.js\nindex 9b1a9ee36c..32a7c304c9 100644\n--- a/packages/material-ui/src/Paper/Paper.js\n+++ b/packages/material-ui/src/Paper/Paper.js\n@@ -22,6 +22,10 @@ export const styles = theme => {\n     rounded: {\n       borderRadius: theme.shape.borderRadius,\n     },\n+    /* Styles applied to the root element if `variant=\"outlined\"`. */\n+    outlined: {\n+      border: `1px solid ${theme.palette.divider}`,\n+    },\n     ...elevations,\n   };\n };\n@@ -33,6 +37,7 @@ const Paper = React.forwardRef(function Paper(props, ref) {\n     component: Component = 'div',\n     square = false,\n     elevation = 1,\n+    variant = 'elevation',\n     ...other\n   } = props;\n \n@@ -46,9 +51,10 @@ const Paper = React.forwardRef(function Paper(props, ref) {\n     <Component\n       className={clsx(\n         classes.root,\n-        classes[`elevation${elevation}`],\n         {\n           [classes.rounded]: !square,\n+          [classes[`elevation${elevation}`]]: variant === 'elevation',\n+          [classes.outlined]: variant === 'outlined',\n         },\n         className,\n       )}\n@@ -86,6 +92,10 @@ Paper.propTypes = {\n    * If `true`, rounded corners are disabled.\n    */\n   square: PropTypes.bool,\n+  /**\n+   * The variant to use.\n+   */\n+  variant: PropTypes.oneOf(['elevation', 'outlined']),\n };\n \n export default withStyles(styles, { name: 'MuiPaper' })(Paper);\n"}
{"instance_id": "mui__material-ui-19849", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.js b/packages/material-ui-lab/src/TreeItem/TreeItem.js\nindex 1b3c568b7c..3b7b8c5dba 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.js\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.js\n@@ -338,7 +338,12 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n   };\n \n   React.useEffect(() => {\n-    const childIds = React.Children.map(children, child => child.props.nodeId) || [];\n+    const childIds = [];\n+    React.Children.forEach(children, child => {\n+      if (React.isValidElement(child)) {\n+        childIds.push(child.props.nodeId);\n+      }\n+    });\n     if (addNodeToNodeMap) {\n       addNodeToNodeMap(nodeId, childIds);\n     }\ndiff --git a/packages/material-ui-lab/src/TreeView/TreeView.js b/packages/material-ui-lab/src/TreeView/TreeView.js\nindex ef214967de..9b2bed355c 100644\n--- a/packages/material-ui-lab/src/TreeView/TreeView.js\n+++ b/packages/material-ui-lab/src/TreeView/TreeView.js\n@@ -417,7 +417,12 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n   const prevChildIds = React.useRef([]);\n   const [childrenCalculated, setChildrenCalculated] = React.useState(false);\n   React.useEffect(() => {\n-    const childIds = React.Children.map(children, child => child.props.nodeId) || [];\n+    const childIds = [];\n+    React.Children.forEach(children, child => {\n+      if (React.isValidElement(child)) {\n+        childIds.push(child.props.nodeId);\n+      }\n+    });\n     if (arrayDiff(prevChildIds.current, childIds)) {\n       nodeMap.current[-1] = { parent: null, children: childIds };\n \n"}
{"instance_id": "mui__material-ui-20232", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex e1b6c999e4..02e3b69607 100644\n--- a/package.json\n+++ b/package.json\n@@ -144,7 +144,6 @@\n     \"typescript\": \"^3.8.2\",\n     \"typescript-to-proptypes\": \"^1.4.0\",\n     \"unist-util-visit\": \"^2.0.2\",\n-    \"vrtest-mui\": \"^0.3.3\",\n     \"webpack\": \"^4.41.0\",\n     \"webpack-cli\": \"^3.3.9\",\n     \"yargs\": \"^15.2.0\",\ndiff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.js b/packages/material-ui-lab/src/TreeItem/TreeItem.js\nindex d6f8a835ee..76b09b88a1 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.js\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.js\n@@ -120,6 +120,7 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n     isExpanded,\n     isFocused,\n     isSelected,\n+    isTreeFocused,\n     isTabbable,\n     multiSelect,\n     selectionDisabled,\n@@ -360,10 +361,10 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n   }, [mapFirstChar, nodeId, label]);\n \n   React.useEffect(() => {\n-    if (focused) {\n+    if (focused && isTreeFocused()) {\n       nodeRef.current.focus();\n     }\n-  }, [focused]);\n+  }, [focused, isTreeFocused]);\n \n   let ariaSelected;\n   if (multiSelect) {\ndiff --git a/packages/material-ui-lab/src/TreeView/TreeView.js b/packages/material-ui-lab/src/TreeView/TreeView.js\nindex b60bd18019..65a6ab3ae5 100644\n--- a/packages/material-ui-lab/src/TreeView/TreeView.js\n+++ b/packages/material-ui-lab/src/TreeView/TreeView.js\n@@ -3,7 +3,7 @@ import clsx from 'clsx';\n import PropTypes from 'prop-types';\n import TreeViewContext from './TreeViewContext';\n import { withStyles } from '@material-ui/core/styles';\n-import { useControlled } from '@material-ui/core/utils';\n+import { useControlled, useForkRef } from '@material-ui/core/utils';\n \n export const styles = {\n   /* Styles applied to the root element. */\n@@ -58,6 +58,9 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n   const [tabbable, setTabbable] = React.useState(null);\n   const [focused, setFocused] = React.useState(null);\n \n+  const treeRef = React.useRef(null);\n+  const handleRef = useForkRef(treeRef, ref);\n+\n   const nodeMap = React.useRef({});\n   const firstCharMap = React.useRef({});\n   const visibleNodes = React.useRef([]);\n@@ -133,6 +136,11 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n     }\n   };\n \n+  const isTreeFocused = () =>\n+    treeRef.current &&\n+    (treeRef.current === document.activeElement ||\n+      treeRef.current.contains(document.activeElement));\n+\n   const focusNextNode = (id) => focus(getNextNode(id));\n   const focusPreviousNode = (id) => focus(getPreviousNode(id));\n   const focusFirstNode = () => focus(getFirstNode());\n@@ -498,6 +506,7 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n         isExpanded,\n         isFocused,\n         isSelected,\n+        isTreeFocused,\n         selectNode,\n         selectRange,\n         selectNextNode,\n@@ -518,7 +527,7 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n         role=\"tree\"\n         aria-multiselectable={multiSelect}\n         className={clsx(classes.root, className)}\n-        ref={ref}\n+        ref={handleRef}\n         {...other}\n       >\n         {children}\n"}
{"instance_id": "mui__material-ui-20356", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Select/SelectInput.js b/packages/material-ui/src/Select/SelectInput.js\nindex 4bc58297fa..e7fcc950d6 100644\n--- a/packages/material-ui/src/Select/SelectInput.js\n+++ b/packages/material-ui/src/Select/SelectInput.js\n@@ -324,7 +324,7 @@ const SelectInput = React.forwardRef(function SelectInput(props, ref) {\n         tabIndex={tabIndex}\n         role=\"button\"\n         aria-expanded={open ? 'true' : undefined}\n-        aria-labelledby={`${labelId || ''} ${buttonId || ''}`}\n+        aria-labelledby={[labelId, buttonId].filter(Boolean).join(' ') || undefined}\n         aria-haspopup=\"listbox\"\n         onKeyDown={handleKeyDown}\n         onMouseDown={disabled || readOnly ? null : handleMouseDown}\n"}
{"instance_id": "mui__material-ui-19511", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 632fb2bf45..8eb76943a0 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -656,7 +656,7 @@ export default function useAutocomplete(props) {\n       return;\n     }\n \n-    if (autoSelect && selectedIndexRef.current !== -1) {\n+    if (autoSelect && selectedIndexRef.current !== -1 && filteredOptions[selectedIndexRef.current]) {\n       selectNewValue(event, filteredOptions[selectedIndexRef.current]);\n     } else if (autoSelect && freeSolo && inputValue !== '') {\n       selectNewValue(event, inputValue, 'freeSolo');\n"}
{"instance_id": "mui__material-ui-20252", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Tooltip/Tooltip.js b/packages/material-ui/src/Tooltip/Tooltip.js\nindex 1d8154194b..e5afc4dc20 100644\n--- a/packages/material-ui/src/Tooltip/Tooltip.js\n+++ b/packages/material-ui/src/Tooltip/Tooltip.js\n@@ -340,7 +340,7 @@ const Tooltip = React.forwardRef(function Tooltip(props, ref) {\n     }\n \n     const childrenProps = children.props;\n-    if (childrenProps.onFocus && event.currentTarget === childNode) {\n+    if (childrenProps.onFocus && (!childNode || event.currentTarget === childNode)) {\n       childrenProps.onFocus(event);\n     }\n   };\n@@ -366,7 +366,7 @@ const Tooltip = React.forwardRef(function Tooltip(props, ref) {\n     const childrenProps = children.props;\n \n     if (event.type === 'blur') {\n-      if (childrenProps.onBlur && event.currentTarget === childNode) {\n+      if (childrenProps.onBlur && (!childNode || event.currentTarget === childNode)) {\n         childrenProps.onBlur(event);\n       }\n       handleBlur(event);\n"}
{"instance_id": "mui__material-ui-20657", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.d.ts b/packages/material-ui-lab/src/TreeItem/TreeItem.d.ts\nindex a5598cba51..7e47c1ffca 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.d.ts\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.d.ts\n@@ -28,6 +28,14 @@ export interface TreeItemProps\n    * The id of the node.\n    */\n   nodeId: string;\n+  /**\n+   * `onClick` handler for the icon container. Call `event.stopPropagation()` to prevent `onNodeToggle` from being called.\n+   */\n+  onIconClick?: React.MouseEventHandler;\n+  /**\n+   * `onClick` handler for the label container. Call `event.stopPropagation()` to prevent `onNodeToggle` from being called.\n+   */\n+  onLabelClick?: React.MouseEventHandler;\n   /**\n    * The component used for the transition.\n    * [Follow this guide](/components/transitions/#transitioncomponent-prop) to learn more about the requirements for this component.\ndiff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.js b/packages/material-ui-lab/src/TreeItem/TreeItem.js\nindex 6b29a4c902..61255dd1e6 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.js\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.js\n@@ -92,6 +92,8 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n     label,\n     nodeId,\n     onClick,\n+    onIconClick,\n+    onLabelClick,\n     onFocus,\n     onKeyDown,\n     onMouseDown,\n@@ -195,6 +197,18 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n     }\n   };\n \n+  const handleIconClick = (event) => {\n+    if (onIconClick) {\n+      onIconClick(event);\n+    }\n+  };\n+\n+  const handleLabelClick = (event) => {\n+    if (onLabelClick) {\n+      onLabelClick(event);\n+    }\n+  };\n+\n   const handleNextArrow = (event) => {\n     if (expandable) {\n       if (expanded) {\n@@ -386,8 +400,10 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n         onMouseDown={handleMouseDown}\n         ref={contentRef}\n       >\n-        <div className={classes.iconContainer}>{icon}</div>\n-        <Typography component=\"div\" className={classes.label}>\n+        <div onClick={handleIconClick} className={classes.iconContainer}>\n+          {icon}\n+        </div>\n+        <Typography onClick={handleLabelClick} component=\"div\" className={classes.label}>\n           {label}\n         </Typography>\n       </div>\n@@ -457,10 +473,18 @@ TreeItem.propTypes = {\n    * @ignore\n    */\n   onFocus: PropTypes.func,\n+  /**\n+   * `onClick` handler for the icon container. Call `event.stopPropagation()` to prevent `onNodeToggle` from being called.\n+   */\n+  onIconClick: PropTypes.func,\n   /**\n    * @ignore\n    */\n   onKeyDown: PropTypes.func,\n+  /**\n+   * `onClick` handler for the label container. Call `event.stopPropagation()` to prevent `onNodeToggle` from being called.\n+   */\n+  onLabelClick: PropTypes.func,\n   /**\n    * @ignore\n    */\n"}
{"instance_id": "mui__material-ui-20368", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 61c8aa2fe4..fe29257445 100644\n--- a/package.json\n+++ b/package.json\n@@ -144,7 +144,6 @@\n     \"typescript\": \"^3.8.2\",\n     \"typescript-to-proptypes\": \"^1.4.2\",\n     \"unist-util-visit\": \"^2.0.2\",\n-    \"vrtest-mui\": \"^0.3.3\",\n     \"webpack\": \"^4.41.0\",\n     \"webpack-cli\": \"^3.3.9\",\n     \"yargs\": \"^15.2.0\",\ndiff --git a/packages/material-ui/src/Chip/Chip.js b/packages/material-ui/src/Chip/Chip.js\nindex f80d27599e..d76b7422ea 100644\n--- a/packages/material-ui/src/Chip/Chip.js\n+++ b/packages/material-ui/src/Chip/Chip.js\n@@ -299,10 +299,13 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n     keyboardEvent.key === 'Backspace' || keyboardEvent.key === 'Delete';\n \n   const handleKeyDown = (event) => {\n-    if (isDeleteKeyboardEvent(event)) {\n-      // will be handled in keyUp, otherwise some browsers\n-      // might init navigation\n-      event.preventDefault();\n+    // Ignore events from children of `Chip`.\n+    if (event.currentTarget === event.target) {\n+      if (isDeleteKeyboardEvent(event)) {\n+        // will be handled in keyUp, otherwise some browsers\n+        // might init navigation\n+        event.preventDefault();\n+      }\n     }\n \n     if (onKeyDown) {\n"}
{"instance_id": "mui__material-ui-20377", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/MenuItem/MenuItem.d.ts b/packages/material-ui/src/MenuItem/MenuItem.d.ts\nindex a412b4cbc0..00e334d2c2 100644\n--- a/packages/material-ui/src/MenuItem/MenuItem.d.ts\n+++ b/packages/material-ui/src/MenuItem/MenuItem.d.ts\n@@ -3,7 +3,7 @@ import { OverridableComponent, OverrideProps } from '../OverridableComponent';\n import { ExtendButtonBase } from '../ButtonBase';\n import { Omit } from '@material-ui/types';\n \n-export type MenuItemClassKey = 'root' | 'gutters' | 'selected' | 'dense';\n+export type MenuItemClassKey = 'root' | 'gutters' | 'selected' | 'dense' | 'disabled';\n \n export type MenuItemTypeMap<P = {}, D extends React.ElementType = 'li'> = Omit<\n   ListItemTypeMap<P, D>,\ndiff --git a/packages/material-ui/src/MenuItem/MenuItem.js b/packages/material-ui/src/MenuItem/MenuItem.js\nindex fa0eee22a6..7dee4c91e6 100644\n--- a/packages/material-ui/src/MenuItem/MenuItem.js\n+++ b/packages/material-ui/src/MenuItem/MenuItem.js\n@@ -29,6 +29,8 @@ export const styles = (theme) => ({\n     ...theme.typography.body2,\n     minHeight: 'auto',\n   },\n+  /* Pseudo-class applied to the root element if `disabled={true}`. */\n+  disabled: {},\n });\n \n const MenuItem = React.forwardRef(function MenuItem(props, ref) {\n@@ -55,7 +57,7 @@ const MenuItem = React.forwardRef(function MenuItem(props, ref) {\n       component={component}\n       selected={selected}\n       disableGutters={disableGutters}\n-      classes={{ dense: classes.dense }}\n+      classes={{ dense: classes.dense, disabled: classes.disabled }}\n       className={clsx(\n         classes.root,\n         {\n"}
{"instance_id": "mui__material-ui-20732", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 76a1fb32dc..b675c922d1 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -860,7 +860,7 @@ export default function useAutocomplete(props) {\n   };\n \n   const handleInputMouseDown = (event) => {\n-    if (inputValue === '') {\n+    if (inputValue === '' || inputValueIsSelectedValue) {\n       handlePopupIndicator(event);\n     }\n   };\n"}
{"instance_id": "mui__material-ui-22696", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex a9d8d48de3..a9041ac5d7 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -563,7 +563,7 @@ export default function useAutocomplete(props) {\n     resetInputValue(event, newValue);\n \n     handleValue(event, newValue, reason, { option });\n-    if (!disableCloseOnSelect) {\n+    if (!disableCloseOnSelect && !(event.ctrlKey || event.metaKey || event.shiftKey)) {\n       handleClose(event, reason);\n     }\n \n"}
{"instance_id": "mui__material-ui-23701", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/DateRangePicker/DateRangePickerView.tsx b/packages/material-ui-lab/src/DateRangePicker/DateRangePickerView.tsx\nindex 2a73bedbee..4f91133819 100644\n--- a/packages/material-ui-lab/src/DateRangePicker/DateRangePickerView.tsx\n+++ b/packages/material-ui-lab/src/DateRangePicker/DateRangePickerView.tsx\n@@ -47,6 +47,7 @@ interface DateRangePickerViewProps<TDate>\n  */\n export function DateRangePickerView<TDate>(props: DateRangePickerViewProps<TDate>) {\n   const {\n+    allowSameDateSelection,\n     calendars = 2,\n     className,\n     currentlySelectingRangeEnd,\n@@ -150,7 +151,7 @@ export function DateRangePickerView<TDate>(props: DateRangePickerViewProps<TDate\n       setCurrentlySelectingRangeEnd(nextSelection);\n \n       const isFullRangeSelected =\n-        currentlySelectingRangeEnd === 'end' && isRangeValid(utils, newRange);\n+        currentlySelectingRangeEnd === 'end' && isRangeValid(utils, newRange, allowSameDateSelection);\n \n       onDateChange(\n         newRange as DateRange<TDate>,\n@@ -159,6 +160,7 @@ export function DateRangePickerView<TDate>(props: DateRangePickerViewProps<TDate\n       );\n     },\n     [\n+      allowSameDateSelection,\n       currentlySelectingRangeEnd,\n       date,\n       onDateChange,\n@@ -170,6 +172,7 @@ export function DateRangePickerView<TDate>(props: DateRangePickerViewProps<TDate\n \n   const renderView = () => {\n     const sharedCalendarProps = {\n+      allowSameDateSelection,\n       date,\n       isDateDisabled,\n       changeFocusedDay,\ndiff --git a/packages/material-ui-lab/src/DateRangePicker/DateRangePickerViewDesktop.tsx b/packages/material-ui-lab/src/DateRangePicker/DateRangePickerViewDesktop.tsx\nindex 62d31fcd58..648c654df3 100644\n--- a/packages/material-ui-lab/src/DateRangePicker/DateRangePickerViewDesktop.tsx\n+++ b/packages/material-ui-lab/src/DateRangePicker/DateRangePickerViewDesktop.tsx\n@@ -88,6 +88,7 @@ function DateRangePickerViewDesktop<TDate>(\n   props: DesktopDateRangeCalendarProps<TDate> & WithStyles<typeof styles>,\n ) {\n   const {\n+    allowSameDateSelection,\n     date,\n     classes,\n     calendars = 2,\n@@ -196,8 +197,8 @@ function DateRangePickerViewDesktop<TDate>(\n                   isStartOfPreviewing: isStartOfRange(utils, day, previewingRange),\n                   isEndOfPreviewing: isEndOfRange(utils, day, previewingRange),\n                   isHighlighting: isWithinRange(utils, day, date),\n-                  isStartOfHighlighting: isStartOfRange(utils, day, date),\n-                  isEndOfHighlighting: isEndOfRange(utils, day, date),\n+                  isStartOfHighlighting: isStartOfRange(utils, day, date, allowSameDateSelection),\n+                  isEndOfHighlighting: isEndOfRange(utils, day, date, allowSameDateSelection),\n                   onMouseEnter: () => handlePreviewDayChange(day),\n                   ...DayProps,\n                 })\ndiff --git a/packages/material-ui-lab/src/DateRangePicker/DateRangePickerViewMobile.tsx b/packages/material-ui-lab/src/DateRangePicker/DateRangePickerViewMobile.tsx\nindex 7badee5233..6a2754ca5c 100644\n--- a/packages/material-ui-lab/src/DateRangePicker/DateRangePickerViewMobile.tsx\n+++ b/packages/material-ui-lab/src/DateRangePicker/DateRangePickerViewMobile.tsx\n@@ -35,6 +35,7 @@ const onlyDateView = ['date'] as ['date'];\n  */\n export function DateRangePickerViewMobile<TDate>(props: DesktopDateRangeCalendarProps<TDate>) {\n   const {\n+    allowSameDateSelection,\n     changeMonth,\n     date,\n     leftArrowButtonProps,\n@@ -83,8 +84,8 @@ export function DateRangePickerViewMobile<TDate>(props: DesktopDateRangeCalendar\n             isStartOfPreviewing: false,\n             isEndOfPreviewing: false,\n             isHighlighting: isWithinRange(utils, day, date),\n-            isStartOfHighlighting: isStartOfRange(utils, day, date),\n-            isEndOfHighlighting: isEndOfRange(utils, day, date),\n+            isStartOfHighlighting: isStartOfRange(utils, day, date, allowSameDateSelection),\n+            isEndOfHighlighting: isEndOfRange(utils, day, date, allowSameDateSelection),\n             ...DayProps,\n           })\n         }\ndiff --git a/packages/material-ui-lab/src/internal/pickers/date-utils.ts b/packages/material-ui-lab/src/internal/pickers/date-utils.ts\nindex c3d17b5703..0ac238aa1c 100644\n--- a/packages/material-ui-lab/src/internal/pickers/date-utils.ts\n+++ b/packages/material-ui-lab/src/internal/pickers/date-utils.ts\n@@ -127,8 +127,11 @@ export function parseRangeInputValue<TDate>(\n export const isRangeValid = <TDate>(\n   utils: MuiPickersAdapter<TDate>,\n   range: DateRange<TDate> | null,\n+  allowSameDateSelection?: boolean,\n ): range is NonEmptyDateRange<TDate> => {\n-  return Boolean(range && range[0] && range[1] && utils.isBefore(range[0], range[1]));\n+  return Boolean(\n+    range && range[0] && range[1] && (utils.isBefore(range[0], range[1]) || (allowSameDateSelection && utils.isSameDay(range[0], range[1]))),\n+  );\n };\n \n export const isWithinRange = <TDate>(\n@@ -143,16 +146,18 @@ export const isStartOfRange = <TDate>(\n   utils: MuiPickersAdapter<TDate>,\n   day: TDate,\n   range: DateRange<TDate> | null,\n+  allowSameDateSelection?: boolean,\n ) => {\n-  return isRangeValid(utils, range) && utils.isSameDay(day, range[0]!);\n+  return isRangeValid(utils, range, allowSameDateSelection) && utils.isSameDay(day, range[0]!);\n };\n \n export const isEndOfRange = <TDate>(\n   utils: MuiPickersAdapter<TDate>,\n   day: TDate,\n   range: DateRange<TDate> | null,\n+  allowSameDateSelection?: boolean,\n ) => {\n-  return isRangeValid(utils, range) && utils.isSameDay(day, range[1]!);\n+  return isRangeValid(utils, range, allowSameDateSelection) && utils.isSameDay(day, range[1]!);\n };\n \n export interface DateValidationProps<TDate> {\n@@ -222,10 +227,18 @@ export type DateValidationError = ReturnType<typeof validateDate>;\n \n type DateRangeValidationErrorValue = DateValidationError | 'invalidRange' | null;\n \n+export interface DateRangeValidationProps<TDate> extends DateValidationProps<TDate> {\n+  /**\n+   * If `true`, `onChange` is fired on click even if the same date is selected.\n+   * @default false\n+   */\n+  allowSameDateSelection?: boolean;\n+}\n+\n export const validateDateRange = <TDate>(\n   utils: MuiPickersAdapter<TDate>,\n   value: RangeInput<TDate>,\n-  dateValidationProps: DateValidationProps<TDate>,\n+  dateRangeValidationProps: DateRangeValidationProps<TDate>,\n ): [DateRangeValidationErrorValue, DateRangeValidationErrorValue] => {\n   const [start, end] = value;\n \n@@ -234,6 +247,8 @@ export const validateDateRange = <TDate>(\n     return [null, null];\n   }\n \n+  const { allowSameDateSelection, ...dateValidationProps } = dateRangeValidationProps;\n+\n   const dateValidations = [\n     validateDate(utils, start, dateValidationProps),\n     validateDate(utils, end, dateValidationProps),\n@@ -243,7 +258,7 @@ export const validateDateRange = <TDate>(\n     return dateValidations;\n   }\n \n-  if (!isRangeValid(utils, [utils.date(start), utils.date(end)])) {\n+  if (!isRangeValid(utils, [utils.date(start), utils.date(end)], allowSameDateSelection)) {\n     return ['invalidRange', 'invalidRange'];\n   }\n \n"}
{"instance_id": "mui__material-ui-23229", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 24d15ac4a0..6568bf4a95 100644\n--- a/package.json\n+++ b/package.json\n@@ -151,7 +151,6 @@\n     \"typescript\": \"^4.0.2\",\n     \"unist-util-visit\": \"^2.0.2\",\n     \"url-loader\": \"^4.1.0\",\n-    \"vrtest-mui\": \"^0.3.4\",\n     \"webpack\": \"^4.41.0\",\n     \"webpack-bundle-analyzer\": \"^3.9.0\",\n     \"webpack-cli\": \"^4.0.0\",\ndiff --git a/packages/material-ui/src/useAutocomplete/useAutocomplete.js b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\nindex 52d5598729..bdea7267d3 100644\n--- a/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n@@ -880,7 +880,7 @@ export default function useAutocomplete(props) {\n   };\n \n   // Focus the input when interacting with the combobox\n-  const handleClick = () => {\n+  const handleClick = (event) => {\n     inputRef.current.focus();\n \n     if (\n@@ -892,6 +892,20 @@ export default function useAutocomplete(props) {\n     }\n \n     firstFocus.current = false;\n+\n+    // Open the popup if clicking on the input wrapper (not the input itself, buttons, or chips)\n+    // This handles the case where the user clicks on the gap between the input and the endAdornment\n+    if (\n+      anchorEl &&\n+      anchorEl.contains(event.target) &&\n+      event.target.getAttribute('id') !== id &&\n+      event.target.closest('button') === null &&\n+      event.target.closest('[data-tag-index]') === null\n+    ) {\n+      if (inputValue === '' || !open) {\n+        handlePopupIndicator(event);\n+      }\n+    }\n   };\n \n   const handleInputMouseDown = (event) => {\n"}
{"instance_id": "mui__material-ui-24105", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.js b/packages/material-ui-lab/src/TreeItem/TreeItem.js\nindex 742f6663e5..54b960cebf 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.js\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.js\n@@ -223,7 +223,7 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n   function handleFocus(event) {\n     // DOM focus stays on the tree which manages focus with aria-activedescendant\n     if (event.target === event.currentTarget) {\n-      ownerDocument(event.target).getElementById(treeId).focus();\n+      ownerDocument(event.target).getElementById(treeId).focus({ preventScroll: true });\n     }\n \n     const unfocusable = !disabledItemsFocusable && disabled;\n"}
{"instance_id": "mui__material-ui-24213", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/useAutocomplete/useAutocomplete.js b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\nindex a47295e97d..3255705e2c 100644\n--- a/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n@@ -285,7 +285,7 @@ export default function useAutocomplete(props) {\n     if (index === -1) {\n       inputRef.current.removeAttribute('aria-activedescendant');\n     } else {\n-      inputRef.current.setAttribute('aria-activedescendant', `${id}-option-${index}`);\n+      inputRef.current.setAttribute('aria-activedescendant', `${id}-option-${options.indexOf(filteredOptions[index])}`);\n     }\n \n     if (onHighlightChange) {\n@@ -1005,10 +1005,10 @@ export default function useAutocomplete(props) {\n       const disabled = getOptionDisabled ? getOptionDisabled(option) : false;\n \n       return {\n-        key: index,\n+        key: options.indexOf(option),\n         tabIndex: -1,\n         role: 'option',\n-        id: `${id}-option-${index}`,\n+        id: `${id}-option-${options.indexOf(option)}`,\n         onMouseOver: handleOptionMouseOver,\n         onClick: handleOptionClick,\n         onTouchStart: handleOptionTouchStart,\n"}
{"instance_id": "mui__material-ui-25072", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Button/Button.js b/packages/material-ui/src/Button/Button.js\nindex 11a700c67b..f1bab3f855 100644\n--- a/packages/material-ui/src/Button/Button.js\n+++ b/packages/material-ui/src/Button/Button.js\n@@ -34,7 +34,7 @@ const overridesResolver = (props, styles) => {\n };\n \n const useUtilityClasses = (styleProps) => {\n-  const { color, disableElevation, fullWidth, size, variant, classes } = styleProps;\n+  const { color, disableElevation, fullWidth, size, variant, disabled, classes } = styleProps;\n \n   const slots = {\n     root: [\n@@ -46,6 +46,7 @@ const useUtilityClasses = (styleProps) => {\n       color === 'inherit' && 'colorInherit',\n       disableElevation && 'disableElevation',\n       fullWidth && 'fullWidth',\n+      disabled && 'disabled',\n     ],\n     label: ['label'],\n     startIcon: ['startIcon', `iconSize${capitalize(size)}`],\n"}
{"instance_id": "mui__material-ui-25874", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/pages/api-docs/loading-button.json b/docs/pages/api-docs/loading-button.json\nindex 2f40fbf015..4859f67236 100644\n--- a/docs/pages/api-docs/loading-button.json\n+++ b/docs/pages/api-docs/loading-button.json\n@@ -3,12 +3,12 @@\n     \"children\": { \"type\": { \"name\": \"node\" } },\n     \"classes\": { \"type\": { \"name\": \"object\" } },\n     \"disabled\": { \"type\": { \"name\": \"bool\" } },\n-    \"pending\": { \"type\": { \"name\": \"bool\" } },\n-    \"pendingIndicator\": {\n+    \"loading\": { \"type\": { \"name\": \"bool\" } },\n+    \"loadingIndicator\": {\n       \"type\": { \"name\": \"node\" },\n       \"default\": \"<CircularProgress color=\\\"inherit\\\" size={16} />\"\n     },\n-    \"pendingPosition\": {\n+    \"loadingPosition\": {\n       \"type\": {\n         \"name\": \"custom\",\n         \"description\": \"'start'<br>&#124;&nbsp;'end'<br>&#124;&nbsp;'center'\"\n@@ -20,14 +20,14 @@\n   \"styles\": {\n     \"classes\": [\n       \"root\",\n-      \"pending\",\n-      \"pendingIndicator\",\n-      \"pendingIndicatorCenter\",\n-      \"pendingIndicatorStart\",\n-      \"pendingIndicatorEnd\",\n-      \"endIconPendingEnd\",\n-      \"startIconPendingStart\",\n-      \"labelPendingCenter\"\n+      \"loading\",\n+      \"loadingIndicator\",\n+      \"loadingIndicatorCenter\",\n+      \"loadingIndicatorStart\",\n+      \"loadingIndicatorEnd\",\n+      \"endIconLoadingEnd\",\n+      \"startIconLoadingStart\",\n+      \"labelLoadingCenter\"\n     ],\n     \"globalClasses\": {},\n     \"name\": \"MuiLoadingButton\"\ndiff --git a/docs/src/pages/components/buttons/LoadingButtons.js b/docs/src/pages/components/buttons/LoadingButtons.js\nindex a92d24aecc..a32fe565bc 100644\n--- a/docs/src/pages/components/buttons/LoadingButtons.js\n+++ b/docs/src/pages/components/buttons/LoadingButtons.js\n@@ -10,15 +10,15 @@ export default function LoadingButtons() {\n         '& > :not(style)': { m: 1 },\n       }}\n     >\n-      <LoadingButton pending variant=\"outlined\">\n+      <LoadingButton loading variant=\"outlined\">\n         Submit\n       </LoadingButton>\n-      <LoadingButton pending pendingIndicator=\"Loading...\" variant=\"outlined\">\n+      <LoadingButton loading loadingIndicator=\"Loading...\" variant=\"outlined\">\n         Fetch data\n       </LoadingButton>\n       <LoadingButton\n-        pending\n-        pendingPosition=\"start\"\n+        loading\n+        loadingPosition=\"start\"\n         startIcon={<SaveIcon />}\n         variant=\"outlined\"\n       >\ndiff --git a/docs/src/pages/components/buttons/LoadingButtons.tsx b/docs/src/pages/components/buttons/LoadingButtons.tsx\nindex a92d24aecc..a32fe565bc 100644\n--- a/docs/src/pages/components/buttons/LoadingButtons.tsx\n+++ b/docs/src/pages/components/buttons/LoadingButtons.tsx\n@@ -10,15 +10,15 @@ export default function LoadingButtons() {\n         '& > :not(style)': { m: 1 },\n       }}\n     >\n-      <LoadingButton pending variant=\"outlined\">\n+      <LoadingButton loading variant=\"outlined\">\n         Submit\n       </LoadingButton>\n-      <LoadingButton pending pendingIndicator=\"Loading...\" variant=\"outlined\">\n+      <LoadingButton loading loadingIndicator=\"Loading...\" variant=\"outlined\">\n         Fetch data\n       </LoadingButton>\n       <LoadingButton\n-        pending\n-        pendingPosition=\"start\"\n+        loading\n+        loadingPosition=\"start\"\n         startIcon={<SaveIcon />}\n         variant=\"outlined\"\n       >\ndiff --git a/docs/src/pages/components/buttons/LoadingButtonsTransition.js b/docs/src/pages/components/buttons/LoadingButtonsTransition.js\nindex f39906f727..5d04cab623 100644\n--- a/docs/src/pages/components/buttons/LoadingButtonsTransition.js\n+++ b/docs/src/pages/components/buttons/LoadingButtonsTransition.js\n@@ -7,9 +7,9 @@ import SaveIcon from '@material-ui/icons/Save';\n import SendIcon from '@material-ui/icons/Send';\n \n export default function LoadingButtonsTransition() {\n-  const [pending, setPending] = React.useState(false);\n+  const [loading, setLoading] = React.useState(false);\n   function handleClick() {\n-    setPending(true);\n+    setLoading(true);\n   }\n \n   return (\n@@ -26,21 +26,21 @@ export default function LoadingButtonsTransition() {\n         }}\n         control={\n           <Switch\n-            checked={pending}\n-            onChange={() => setPending(!pending)}\n-            name=\"pending\"\n+            checked={loading}\n+            onChange={() => setLoading(!loading)}\n+            name=\"loading\"\n             color=\"primary\"\n           />\n         }\n-        label=\"Pending\"\n+        label=\"Loading\"\n       />\n-      <LoadingButton onClick={handleClick} pending={pending} variant=\"outlined\">\n+      <LoadingButton onClick={handleClick} loading={loading} variant=\"outlined\">\n         Submit\n       </LoadingButton>\n       <LoadingButton\n         onClick={handleClick}\n-        pending={pending}\n-        pendingIndicator=\"Loading...\"\n+        loading={loading}\n+        loadingIndicator=\"Loading...\"\n         variant=\"outlined\"\n       >\n         Fetch data\n@@ -48,8 +48,8 @@ export default function LoadingButtonsTransition() {\n       <LoadingButton\n         onClick={handleClick}\n         endIcon={<SendIcon />}\n-        pending={pending}\n-        pendingPosition=\"end\"\n+        loading={loading}\n+        loadingPosition=\"end\"\n         variant=\"contained\"\n       >\n         Send\n@@ -57,8 +57,8 @@ export default function LoadingButtonsTransition() {\n       <LoadingButton\n         color=\"secondary\"\n         onClick={handleClick}\n-        pending={pending}\n-        pendingPosition=\"start\"\n+        loading={loading}\n+        loadingPosition=\"start\"\n         startIcon={<SaveIcon />}\n         variant=\"contained\"\n       >\ndiff --git a/docs/src/pages/components/buttons/LoadingButtonsTransition.tsx b/docs/src/pages/components/buttons/LoadingButtonsTransition.tsx\nindex f39906f727..5d04cab623 100644\n--- a/docs/src/pages/components/buttons/LoadingButtonsTransition.tsx\n+++ b/docs/src/pages/components/buttons/LoadingButtonsTransition.tsx\n@@ -7,9 +7,9 @@ import SaveIcon from '@material-ui/icons/Save';\n import SendIcon from '@material-ui/icons/Send';\n \n export default function LoadingButtonsTransition() {\n-  const [pending, setPending] = React.useState(false);\n+  const [loading, setLoading] = React.useState(false);\n   function handleClick() {\n-    setPending(true);\n+    setLoading(true);\n   }\n \n   return (\n@@ -26,21 +26,21 @@ export default function LoadingButtonsTransition() {\n         }}\n         control={\n           <Switch\n-            checked={pending}\n-            onChange={() => setPending(!pending)}\n-            name=\"pending\"\n+            checked={loading}\n+            onChange={() => setLoading(!loading)}\n+            name=\"loading\"\n             color=\"primary\"\n           />\n         }\n-        label=\"Pending\"\n+        label=\"Loading\"\n       />\n-      <LoadingButton onClick={handleClick} pending={pending} variant=\"outlined\">\n+      <LoadingButton onClick={handleClick} loading={loading} variant=\"outlined\">\n         Submit\n       </LoadingButton>\n       <LoadingButton\n         onClick={handleClick}\n-        pending={pending}\n-        pendingIndicator=\"Loading...\"\n+        loading={loading}\n+        loadingIndicator=\"Loading...\"\n         variant=\"outlined\"\n       >\n         Fetch data\n@@ -48,8 +48,8 @@ export default function LoadingButtonsTransition() {\n       <LoadingButton\n         onClick={handleClick}\n         endIcon={<SendIcon />}\n-        pending={pending}\n-        pendingPosition=\"end\"\n+        loading={loading}\n+        loadingPosition=\"end\"\n         variant=\"contained\"\n       >\n         Send\n@@ -57,8 +57,8 @@ export default function LoadingButtonsTransition() {\n       <LoadingButton\n         color=\"secondary\"\n         onClick={handleClick}\n-        pending={pending}\n-        pendingPosition=\"start\"\n+        loading={loading}\n+        loadingPosition=\"start\"\n         startIcon={<SaveIcon />}\n         variant=\"contained\"\n       >\ndiff --git a/docs/translations/api-docs/loading-button/loading-button-de.json b/docs/translations/api-docs/loading-button/loading-button-de.json\nindex 0429d63e77..2634b567d6 100644\n--- a/docs/translations/api-docs/loading-button/loading-button-de.json\n+++ b/docs/translations/api-docs/loading-button/loading-button-de.json\n@@ -4,52 +4,52 @@\n     \"children\": \"The content of the component.\",\n     \"classes\": \"Override or extend the styles applied to the component. See <a href=\\\"#css\\\">CSS API</a> below for more details.\",\n     \"disabled\": \"If <code>true</code>, the accordion is displayed in a disabled state.\",\n-    \"pending\": \"If <code>true</code>, the pending indicator is shown.\",\n-    \"pendingIndicator\": \"Element placed before the children if the button is in pending state.\",\n-    \"pendingPosition\": \"The pending indicator can be positioned on the start, end, or the center of the button.\"\n+    \"loading\": \"If <code>true</code>, the loading indicator is shown.\",\n+    \"loadingIndicator\": \"Element placed before the children if the button is in loading state.\",\n+    \"loadingPosition\": \"The loading indicator can be positioned on the start, end, or the center of the button.\"\n   },\n   \"classDescriptions\": {\n     \"root\": {\n       \"description\": \"Styles applied to the root element.\"\n     },\n-    \"pending\": {\n+    \"loading\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n-      \"conditions\": \"<code>pending={true}</code>\"\n+      \"conditions\": \"<code>loading={true}</code>\"\n     },\n-    \"pendingIndicator\": {\n+    \"loadingIndicator\": {\n       \"description\": \"Styles applied to {{nodeName}}.\",\n-      \"nodeName\": \"the pendingIndicator element\"\n+      \"nodeName\": \"the loadingIndicator element\"\n     },\n-    \"pendingIndicatorCenter\": {\n+    \"loadingIndicatorCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"center\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"center\\\"</code>\"\n     },\n-    \"pendingIndicatorStart\": {\n+    \"loadingIndicatorStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"start\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"pendingIndicatorEnd\": {\n+    \"loadingIndicatorEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"end\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"endIconPendingEnd\": {\n+    \"endIconLoadingEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the endIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"end\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"startIconPendingStart\": {\n+    \"startIconLoadingStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the startIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"start\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"labelPendingCenter\": {\n+    \"labelLoadingCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the label element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"center\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"center\\\"</code>\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/loading-button/loading-button-es.json b/docs/translations/api-docs/loading-button/loading-button-es.json\nindex 0429d63e77..2634b567d6 100644\n--- a/docs/translations/api-docs/loading-button/loading-button-es.json\n+++ b/docs/translations/api-docs/loading-button/loading-button-es.json\n@@ -4,52 +4,52 @@\n     \"children\": \"The content of the component.\",\n     \"classes\": \"Override or extend the styles applied to the component. See <a href=\\\"#css\\\">CSS API</a> below for more details.\",\n     \"disabled\": \"If <code>true</code>, the accordion is displayed in a disabled state.\",\n-    \"pending\": \"If <code>true</code>, the pending indicator is shown.\",\n-    \"pendingIndicator\": \"Element placed before the children if the button is in pending state.\",\n-    \"pendingPosition\": \"The pending indicator can be positioned on the start, end, or the center of the button.\"\n+    \"loading\": \"If <code>true</code>, the loading indicator is shown.\",\n+    \"loadingIndicator\": \"Element placed before the children if the button is in loading state.\",\n+    \"loadingPosition\": \"The loading indicator can be positioned on the start, end, or the center of the button.\"\n   },\n   \"classDescriptions\": {\n     \"root\": {\n       \"description\": \"Styles applied to the root element.\"\n     },\n-    \"pending\": {\n+    \"loading\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n-      \"conditions\": \"<code>pending={true}</code>\"\n+      \"conditions\": \"<code>loading={true}</code>\"\n     },\n-    \"pendingIndicator\": {\n+    \"loadingIndicator\": {\n       \"description\": \"Styles applied to {{nodeName}}.\",\n-      \"nodeName\": \"the pendingIndicator element\"\n+      \"nodeName\": \"the loadingIndicator element\"\n     },\n-    \"pendingIndicatorCenter\": {\n+    \"loadingIndicatorCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"center\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"center\\\"</code>\"\n     },\n-    \"pendingIndicatorStart\": {\n+    \"loadingIndicatorStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"start\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"pendingIndicatorEnd\": {\n+    \"loadingIndicatorEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"end\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"endIconPendingEnd\": {\n+    \"endIconLoadingEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the endIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"end\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"startIconPendingStart\": {\n+    \"startIconLoadingStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the startIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"start\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"labelPendingCenter\": {\n+    \"labelLoadingCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the label element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"center\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"center\\\"</code>\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/loading-button/loading-button-fr.json b/docs/translations/api-docs/loading-button/loading-button-fr.json\nindex c75238e698..c3edc130c9 100644\n--- a/docs/translations/api-docs/loading-button/loading-button-fr.json\n+++ b/docs/translations/api-docs/loading-button/loading-button-fr.json\n@@ -4,52 +4,52 @@\n     \"children\": \"Le contenu du composant.\",\n     \"classes\": \"Override or extend the styles applied to the component. See <a href=\\\"#css\\\">CSS API</a> below for more details.\",\n     \"disabled\": \"If <code>true</code>, the accordion is displayed in a disabled state.\",\n-    \"pending\": \"If <code>true</code>, the pending indicator is shown.\",\n-    \"pendingIndicator\": \"Element placed before the children if the button is in pending state.\",\n-    \"pendingPosition\": \"The pending indicator can be positioned on the start, end, or the center of the button.\"\n+    \"loading\": \"If <code>true</code>, the loading indicator is shown.\",\n+    \"loadingIndicator\": \"Element placed before the children if the button is in loading state.\",\n+    \"loadingPosition\": \"The loading indicator can be positioned on the start, end, or the center of the button.\"\n   },\n   \"classDescriptions\": {\n     \"root\": {\n       \"description\": \"Styles applied to the root element.\"\n     },\n-    \"pending\": {\n+    \"loading\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n-      \"conditions\": \"<code>pending={true}</code>\"\n+      \"conditions\": \"<code>loading={true}</code>\"\n     },\n-    \"pendingIndicator\": {\n+    \"loadingIndicator\": {\n       \"description\": \"Styles applied to {{nodeName}}.\",\n-      \"nodeName\": \"the pendingIndicator element\"\n+      \"nodeName\": \"the loadingIndicator element\"\n     },\n-    \"pendingIndicatorCenter\": {\n+    \"loadingIndicatorCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"center\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"center\\\"</code>\"\n     },\n-    \"pendingIndicatorStart\": {\n+    \"loadingIndicatorStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"start\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"pendingIndicatorEnd\": {\n+    \"loadingIndicatorEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"end\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"endIconPendingEnd\": {\n+    \"endIconLoadingEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the endIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"end\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"startIconPendingStart\": {\n+    \"startIconLoadingStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the startIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"start\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"labelPendingCenter\": {\n+    \"labelLoadingCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the label element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"center\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"center\\\"</code>\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/loading-button/loading-button-ja.json b/docs/translations/api-docs/loading-button/loading-button-ja.json\nindex 0429d63e77..2634b567d6 100644\n--- a/docs/translations/api-docs/loading-button/loading-button-ja.json\n+++ b/docs/translations/api-docs/loading-button/loading-button-ja.json\n@@ -4,52 +4,52 @@\n     \"children\": \"The content of the component.\",\n     \"classes\": \"Override or extend the styles applied to the component. See <a href=\\\"#css\\\">CSS API</a> below for more details.\",\n     \"disabled\": \"If <code>true</code>, the accordion is displayed in a disabled state.\",\n-    \"pending\": \"If <code>true</code>, the pending indicator is shown.\",\n-    \"pendingIndicator\": \"Element placed before the children if the button is in pending state.\",\n-    \"pendingPosition\": \"The pending indicator can be positioned on the start, end, or the center of the button.\"\n+    \"loading\": \"If <code>true</code>, the loading indicator is shown.\",\n+    \"loadingIndicator\": \"Element placed before the children if the button is in loading state.\",\n+    \"loadingPosition\": \"The loading indicator can be positioned on the start, end, or the center of the button.\"\n   },\n   \"classDescriptions\": {\n     \"root\": {\n       \"description\": \"Styles applied to the root element.\"\n     },\n-    \"pending\": {\n+    \"loading\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n-      \"conditions\": \"<code>pending={true}</code>\"\n+      \"conditions\": \"<code>loading={true}</code>\"\n     },\n-    \"pendingIndicator\": {\n+    \"loadingIndicator\": {\n       \"description\": \"Styles applied to {{nodeName}}.\",\n-      \"nodeName\": \"the pendingIndicator element\"\n+      \"nodeName\": \"the loadingIndicator element\"\n     },\n-    \"pendingIndicatorCenter\": {\n+    \"loadingIndicatorCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"center\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"center\\\"</code>\"\n     },\n-    \"pendingIndicatorStart\": {\n+    \"loadingIndicatorStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"start\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"pendingIndicatorEnd\": {\n+    \"loadingIndicatorEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"end\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"endIconPendingEnd\": {\n+    \"endIconLoadingEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the endIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"end\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"startIconPendingStart\": {\n+    \"startIconLoadingStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the startIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"start\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"labelPendingCenter\": {\n+    \"labelLoadingCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the label element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"center\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"center\\\"</code>\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/loading-button/loading-button-pt.json b/docs/translations/api-docs/loading-button/loading-button-pt.json\nindex 0429d63e77..2634b567d6 100644\n--- a/docs/translations/api-docs/loading-button/loading-button-pt.json\n+++ b/docs/translations/api-docs/loading-button/loading-button-pt.json\n@@ -4,52 +4,52 @@\n     \"children\": \"The content of the component.\",\n     \"classes\": \"Override or extend the styles applied to the component. See <a href=\\\"#css\\\">CSS API</a> below for more details.\",\n     \"disabled\": \"If <code>true</code>, the accordion is displayed in a disabled state.\",\n-    \"pending\": \"If <code>true</code>, the pending indicator is shown.\",\n-    \"pendingIndicator\": \"Element placed before the children if the button is in pending state.\",\n-    \"pendingPosition\": \"The pending indicator can be positioned on the start, end, or the center of the button.\"\n+    \"loading\": \"If <code>true</code>, the loading indicator is shown.\",\n+    \"loadingIndicator\": \"Element placed before the children if the button is in loading state.\",\n+    \"loadingPosition\": \"The loading indicator can be positioned on the start, end, or the center of the button.\"\n   },\n   \"classDescriptions\": {\n     \"root\": {\n       \"description\": \"Styles applied to the root element.\"\n     },\n-    \"pending\": {\n+    \"loading\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n-      \"conditions\": \"<code>pending={true}</code>\"\n+      \"conditions\": \"<code>loading={true}</code>\"\n     },\n-    \"pendingIndicator\": {\n+    \"loadingIndicator\": {\n       \"description\": \"Styles applied to {{nodeName}}.\",\n-      \"nodeName\": \"the pendingIndicator element\"\n+      \"nodeName\": \"the loadingIndicator element\"\n     },\n-    \"pendingIndicatorCenter\": {\n+    \"loadingIndicatorCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"center\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"center\\\"</code>\"\n     },\n-    \"pendingIndicatorStart\": {\n+    \"loadingIndicatorStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"start\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"pendingIndicatorEnd\": {\n+    \"loadingIndicatorEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"end\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"endIconPendingEnd\": {\n+    \"endIconLoadingEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the endIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"end\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"startIconPendingStart\": {\n+    \"startIconLoadingStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the startIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"start\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"labelPendingCenter\": {\n+    \"labelLoadingCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the label element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"center\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"center\\\"</code>\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/loading-button/loading-button-ru.json b/docs/translations/api-docs/loading-button/loading-button-ru.json\nindex 0429d63e77..2634b567d6 100644\n--- a/docs/translations/api-docs/loading-button/loading-button-ru.json\n+++ b/docs/translations/api-docs/loading-button/loading-button-ru.json\n@@ -4,52 +4,52 @@\n     \"children\": \"The content of the component.\",\n     \"classes\": \"Override or extend the styles applied to the component. See <a href=\\\"#css\\\">CSS API</a> below for more details.\",\n     \"disabled\": \"If <code>true</code>, the accordion is displayed in a disabled state.\",\n-    \"pending\": \"If <code>true</code>, the pending indicator is shown.\",\n-    \"pendingIndicator\": \"Element placed before the children if the button is in pending state.\",\n-    \"pendingPosition\": \"The pending indicator can be positioned on the start, end, or the center of the button.\"\n+    \"loading\": \"If <code>true</code>, the loading indicator is shown.\",\n+    \"loadingIndicator\": \"Element placed before the children if the button is in loading state.\",\n+    \"loadingPosition\": \"The loading indicator can be positioned on the start, end, or the center of the button.\"\n   },\n   \"classDescriptions\": {\n     \"root\": {\n       \"description\": \"Styles applied to the root element.\"\n     },\n-    \"pending\": {\n+    \"loading\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n-      \"conditions\": \"<code>pending={true}</code>\"\n+      \"conditions\": \"<code>loading={true}</code>\"\n     },\n-    \"pendingIndicator\": {\n+    \"loadingIndicator\": {\n       \"description\": \"Styles applied to {{nodeName}}.\",\n-      \"nodeName\": \"the pendingIndicator element\"\n+      \"nodeName\": \"the loadingIndicator element\"\n     },\n-    \"pendingIndicatorCenter\": {\n+    \"loadingIndicatorCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"center\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"center\\\"</code>\"\n     },\n-    \"pendingIndicatorStart\": {\n+    \"loadingIndicatorStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"start\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"pendingIndicatorEnd\": {\n+    \"loadingIndicatorEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"end\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"endIconPendingEnd\": {\n+    \"endIconLoadingEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the endIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"end\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"startIconPendingStart\": {\n+    \"startIconLoadingStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the startIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"start\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"labelPendingCenter\": {\n+    \"labelLoadingCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the label element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"center\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"center\\\"</code>\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/loading-button/loading-button-zh.json b/docs/translations/api-docs/loading-button/loading-button-zh.json\nindex 26838367fa..fa361f7cb1 100644\n--- a/docs/translations/api-docs/loading-button/loading-button-zh.json\n+++ b/docs/translations/api-docs/loading-button/loading-button-zh.json\n@@ -4,52 +4,52 @@\n     \"children\": \"The content of the component.\",\n     \"classes\": \"Override or extend the styles applied to the component. See <a href=\\\"#css\\\">CSS API</a> below for more details.\",\n     \"disabled\": \"\u5982\u679c\u88ab\u8bbe\u7f6e\u4e3a <code>true</code>\uff0c\u90a3\u4e48\u8be5\u7ec4\u4ef6\u5c06\u4f1a\u88ab\u7981\u7528\u3002\",\n-    \"pending\": \"If <code>true</code>, the pending indicator is shown.\",\n-    \"pendingIndicator\": \"Element placed before the children if the button is in pending state.\",\n-    \"pendingPosition\": \"The pending indicator can be positioned on the start, end, or the center of the button.\"\n+    \"loading\": \"If <code>true</code>, the loading indicator is shown.\",\n+    \"loadingIndicator\": \"Element placed before the children if the button is in loading state.\",\n+    \"loadingPosition\": \"The loading indicator can be positioned on the start, end, or the center of the button.\"\n   },\n   \"classDescriptions\": {\n     \"root\": {\n       \"description\": \"Styles applied to the root element.\"\n     },\n-    \"pending\": {\n+    \"loading\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n-      \"conditions\": \"<code>pending={true}</code>\"\n+      \"conditions\": \"<code>loading={true}</code>\"\n     },\n-    \"pendingIndicator\": {\n+    \"loadingIndicator\": {\n       \"description\": \"Styles applied to {{nodeName}}.\",\n-      \"nodeName\": \"the pendingIndicator element\"\n+      \"nodeName\": \"the loadingIndicator element\"\n     },\n-    \"pendingIndicatorCenter\": {\n+    \"loadingIndicatorCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"center\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"center\\\"</code>\"\n     },\n-    \"pendingIndicatorStart\": {\n+    \"loadingIndicatorStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"start\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"pendingIndicatorEnd\": {\n+    \"loadingIndicatorEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"end\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"endIconPendingEnd\": {\n+    \"endIconLoadingEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the endIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"end\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"startIconPendingStart\": {\n+    \"startIconLoadingStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the startIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"start\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"labelPendingCenter\": {\n+    \"labelLoadingCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the label element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"center\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"center\\\"</code>\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/loading-button/loading-button.json b/docs/translations/api-docs/loading-button/loading-button.json\nindex 1b6d51e03d..8eef9bc0fc 100644\n--- a/docs/translations/api-docs/loading-button/loading-button.json\n+++ b/docs/translations/api-docs/loading-button/loading-button.json\n@@ -4,50 +4,50 @@\n     \"children\": \"The content of the component.\",\n     \"classes\": \"Override or extend the styles applied to the component. See <a href=\\\"#css\\\">CSS API</a> below for more details.\",\n     \"disabled\": \"If <code>true</code>, the component is disabled.\",\n-    \"pending\": \"If <code>true</code>, the pending indicator is shown.\",\n-    \"pendingIndicator\": \"Element placed before the children if the button is in pending state.\",\n-    \"pendingPosition\": \"The pending indicator can be positioned on the start, end, or the center of the button.\"\n+    \"loading\": \"If <code>true</code>, the loading indicator is shown.\",\n+    \"loadingIndicator\": \"Element placed before the children if the button is in loading state.\",\n+    \"loadingPosition\": \"The loading indicator can be positioned on the start, end, or the center of the button.\"\n   },\n   \"classDescriptions\": {\n     \"root\": { \"description\": \"Styles applied to the root element.\" },\n-    \"pending\": {\n+    \"loading\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n-      \"conditions\": \"<code>pending={true}</code>\"\n+      \"conditions\": \"<code>loading={true}</code>\"\n     },\n-    \"pendingIndicator\": {\n+    \"loadingIndicator\": {\n       \"description\": \"Styles applied to {{nodeName}}.\",\n-      \"nodeName\": \"the pendingIndicator element\"\n+      \"nodeName\": \"the loadingIndicator element\"\n     },\n-    \"pendingIndicatorCenter\": {\n+    \"loadingIndicatorCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"center\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"center\\\"</code>\"\n     },\n-    \"pendingIndicatorStart\": {\n+    \"loadingIndicatorStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"start\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"pendingIndicatorEnd\": {\n+    \"loadingIndicatorEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n-      \"nodeName\": \"the pendingIndicator element\",\n-      \"conditions\": \"<code>pendingPosition=\\\"end\\\"</code>\"\n+      \"nodeName\": \"the loadingIndicator element\",\n+      \"conditions\": \"<code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"endIconPendingEnd\": {\n+    \"endIconLoadingEnd\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the endIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"end\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"end\\\"</code>\"\n     },\n-    \"startIconPendingStart\": {\n+    \"startIconLoadingStart\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the startIcon element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"start\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"start\\\"</code>\"\n     },\n-    \"labelPendingCenter\": {\n+    \"labelLoadingCenter\": {\n       \"description\": \"Styles applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the label element\",\n-      \"conditions\": \"<code>pending={true}</code> and <code>pendingPosition=\\\"center\\\"</code>\"\n+      \"conditions\": \"<code>loading={true}</code> and <code>loadingPosition=\\\"center\\\"</code>\"\n     }\n   }\n }\ndiff --git a/packages/material-ui-lab/src/LoadingButton/LoadingButton.d.ts b/packages/material-ui-lab/src/LoadingButton/LoadingButton.d.ts\nindex 5edb30d84b..2ff980292a 100644\n--- a/packages/material-ui-lab/src/LoadingButton/LoadingButton.d.ts\n+++ b/packages/material-ui-lab/src/LoadingButton/LoadingButton.d.ts\n@@ -12,38 +12,38 @@ export type LoadingButtonTypeMap<\n     classes?: {\n       /** Styles applied to the root element. */\n       root?: string;\n-      /** Styles applied to the root element if `pending={true}`. */\n-      pending?: string;\n-      /** Styles applied to the pendingIndicator element. */\n-      pendingIndicator?: string;\n-      /** Styles applied to the pendingIndicator element if `pendingPosition=\"center\"`. */\n-      pendingIndicatorCenter?: string;\n-      /** Styles applied to the pendingIndicator element if `pendingPosition=\"start\"`. */\n-      pendingIndicatorStart?: string;\n-      /** Styles applied to the pendingIndicator element if `pendingPosition=\"end\"`. */\n-      pendingIndicatorEnd?: string;\n-      /** Styles applied to the endIcon element if `pending={true}` and `pendingPosition=\"end\"`. */\n-      endIconPendingEnd?: string;\n-      /** Styles applied to the startIcon element if `pending={true}` and `pendingPosition=\"start\"`. */\n-      startIconPendingStart?: string;\n-      /** Styles applied to the label element if `pending={true}` and `pendingPosition=\"center\"`. */\n-      labelPendingCenter?: string;\n+      /** Styles applied to the root element if `loading={true}`. */\n+      loading?: string;\n+      /** Styles applied to the loadingIndicator element. */\n+      loadingIndicator?: string;\n+      /** Styles applied to the loadingIndicator element if `loadingPosition=\"center\"`. */\n+      loadingIndicatorCenter?: string;\n+      /** Styles applied to the loadingIndicator element if `loadingPosition=\"start\"`. */\n+      loadingIndicatorStart?: string;\n+      /** Styles applied to the loadingIndicator element if `loadingPosition=\"end\"`. */\n+      loadingIndicatorEnd?: string;\n+      /** Styles applied to the endIcon element if `loading={true}` and `loadingPosition=\"end\"`. */\n+      endIconLoadingEnd?: string;\n+      /** Styles applied to the startIcon element if `loading={true}` and `loadingPosition=\"start\"`. */\n+      startIconLoadingStart?: string;\n+      /** Styles applied to the label element if `loading={true}` and `loadingPosition=\"center\"`. */\n+      labelLoadingCenter?: string;\n     };\n     /**\n-     * If `true`, the pending indicator is shown.\n+     * If `true`, the loading indicator is shown.\n      * @default false\n      */\n-    pending?: boolean;\n+    loading?: boolean;\n     /**\n-     * Element placed before the children if the button is in pending state.\n+     * Element placed before the children if the button is in loading state.\n      * @default <CircularProgress color=\"inherit\" size={16} />\n      */\n-    pendingIndicator?: React.ReactNode;\n+    loadingIndicator?: React.ReactNode;\n     /**\n-     * The pending indicator can be positioned on the start, end, or the center of the button.\n+     * The loading indicator can be positioned on the start, end, or the center of the button.\n      * @default 'center'\n      */\n-    pendingPosition?: 'start' | 'end' | 'center';\n+    loadingPosition?: 'start' | 'end' | 'center';\n   };\n   defaultComponent: D;\n }>;\ndiff --git a/packages/material-ui-lab/src/LoadingButton/LoadingButton.js b/packages/material-ui-lab/src/LoadingButton/LoadingButton.js\nindex dc35fd06de..be5f7b9c58 100644\n--- a/packages/material-ui-lab/src/LoadingButton/LoadingButton.js\n+++ b/packages/material-ui-lab/src/LoadingButton/LoadingButton.js\n@@ -10,42 +10,42 @@ import CircularProgress from '@material-ui/core/CircularProgress';\n export const styles = () => ({\n   /* Styles applied to the root element. */\n   root: {},\n-  /* Styles applied to the root element if `pending={true}`. */\n-  pending: {},\n-  /* Styles applied to the pendingIndicator element. */\n-  pendingIndicator: {\n+  /* Styles applied to the root element if `loading={true}`. */\n+  loading: {},\n+  /* Styles applied to the loadingIndicator element. */\n+  loadingIndicator: {\n     position: 'absolute',\n     visibility: 'visible',\n     display: 'flex',\n   },\n-  /* Styles applied to the pendingIndicator element if `pendingPosition=\"center\"`. */\n-  pendingIndicatorCenter: {\n+  /* Styles applied to the loadingIndicator element if `loadingPosition=\"center\"`. */\n+  loadingIndicatorCenter: {\n     left: '50%',\n     transform: 'translate(-50%)',\n   },\n-  /* Styles applied to the pendingIndicator element if `pendingPosition=\"start\"`. */\n-  pendingIndicatorStart: {\n+  /* Styles applied to the loadingIndicator element if `loadingPosition=\"start\"`. */\n+  loadingIndicatorStart: {\n     left: 14,\n   },\n-  /* Styles applied to the pendingIndicator element if `pendingPosition=\"end\"`. */\n-  pendingIndicatorEnd: {\n+  /* Styles applied to the loadingIndicator element if `loadingPosition=\"end\"`. */\n+  loadingIndicatorEnd: {\n     right: 14,\n   },\n-  /* Styles applied to the endIcon element if `pending={true}` and `pendingPosition=\"end\"`. */\n-  endIconPendingEnd: {\n+  /* Styles applied to the endIcon element if `loading={true}` and `loadingPosition=\"end\"`. */\n+  endIconLoadingEnd: {\n     visibility: 'hidden',\n   },\n-  /* Styles applied to the startIcon element if `pending={true}` and `pendingPosition=\"start\"`. */\n-  startIconPendingStart: {\n+  /* Styles applied to the startIcon element if `loading={true}` and `loadingPosition=\"start\"`. */\n+  startIconLoadingStart: {\n     visibility: 'hidden',\n   },\n-  /* Styles applied to the label element if `pending={true}` and `pendingPosition=\"center\"`. */\n-  labelPendingCenter: {\n+  /* Styles applied to the label element if `loading={true}` and `loadingPosition=\"center\"`. */\n+  labelLoadingCenter: {\n     visibility: 'hidden',\n   },\n });\n \n-const PendingIndicator = <CircularProgress color=\"inherit\" size={16} />;\n+const LoadingIndicator = <CircularProgress color=\"inherit\" size={16} />;\n \n const LoadingButton = React.forwardRef(function LoadingButton(props, ref) {\n   const {\n@@ -53,9 +53,9 @@ const LoadingButton = React.forwardRef(function LoadingButton(props, ref) {\n     classes,\n     className,\n     disabled = false,\n-    pending = false,\n-    pendingIndicator = PendingIndicator,\n-    pendingPosition = 'center',\n+    loading = false,\n+    loadingIndicator = LoadingIndicator,\n+    loadingPosition = 'center',\n     ...other\n   } = props;\n \n@@ -64,27 +64,27 @@ const LoadingButton = React.forwardRef(function LoadingButton(props, ref) {\n       className={clsx(\n         classes.root,\n         {\n-          [classes.pending]: pending,\n+          [classes.loading]: loading,\n         },\n         className,\n       )}\n-      disabled={disabled || pending}\n+      disabled={disabled || loading}\n       ref={ref}\n       classes={{\n-        startIcon: classes[`startIcon${pending ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n-        endIcon: classes[`endIcon${pending ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n-        label: classes[`label${pending ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n+        startIcon: classes[`startIcon${loading ? 'Loading' : ''}${capitalize(loadingPosition)}`],\n+        endIcon: classes[`endIcon${loading ? 'Loading' : ''}${capitalize(loadingPosition)}`],\n+        label: classes[`label${loading ? 'Loading' : ''}${capitalize(loadingPosition)}`],\n       }}\n       {...other}\n     >\n-      {pending && (\n+      {loading && (\n         <div\n           className={clsx(\n-            classes.pendingIndicator,\n-            classes[`pendingIndicator${capitalize(pendingPosition)}`],\n+            classes.loadingIndicator,\n+            classes[`loadingIndicator${capitalize(loadingPosition)}`],\n           )}\n         >\n-          {pendingIndicator}\n+          {loadingIndicator}\n         </div>\n       )}\n \n@@ -116,28 +116,28 @@ LoadingButton.propTypes /* remove-proptypes */ = {\n    */\n   disabled: PropTypes.bool,\n   /**\n-   * If `true`, the pending indicator is shown.\n+   * If `true`, the loading indicator is shown.\n    * @default false\n    */\n-  pending: PropTypes.bool,\n+  loading: PropTypes.bool,\n   /**\n-   * Element placed before the children if the button is in pending state.\n+   * Element placed before the children if the button is in loading state.\n    * @default <CircularProgress color=\"inherit\" size={16} />\n    */\n-  pendingIndicator: PropTypes.node,\n+  loadingIndicator: PropTypes.node,\n   /**\n-   * The pending indicator can be positioned on the start, end, or the center of the button.\n+   * The loading indicator can be positioned on the start, end, or the center of the button.\n    * @default 'center'\n    */\n-  pendingPosition: chainPropTypes(PropTypes.oneOf(['start', 'end', 'center']), (props) => {\n-    if (props.pendingPosition === 'start' && !props.startIcon) {\n+  loadingPosition: chainPropTypes(PropTypes.oneOf(['start', 'end', 'center']), (props) => {\n+    if (props.loadingPosition === 'start' && !props.startIcon) {\n       return new Error(\n-        `Material-UI: The pendingPosition=\"start\" should be used in combination with startIcon.`,\n+        `Material-UI: The loadingPosition=\"start\" should be used in combination with startIcon.`,\n       );\n     }\n-    if (props.pendingPosition === 'end' && !props.endIcon) {\n+    if (props.loadingPosition === 'end' && !props.endIcon) {\n       return new Error(\n-        `Material-UI: The pendingPosition=\"end\" should be used in combination with endIcon.`,\n+        `Material-UI: The loadingPosition=\"end\" should be used in combination with endIcon.`,\n       );\n     }\n     return null;\n"}
{"instance_id": "mui__material-ui-24742", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/InputAdornment/InputAdornment.js b/packages/material-ui/src/InputAdornment/InputAdornment.js\nindex 4d04077933..bc59345a71 100644\n--- a/packages/material-ui/src/InputAdornment/InputAdornment.js\n+++ b/packages/material-ui/src/InputAdornment/InputAdornment.js\n@@ -9,7 +9,6 @@ export const styles = {\n   /* Styles applied to the root element. */\n   root: {\n     display: 'flex',\n-    height: '0.01em', // Fix IE11 flexbox alignment. To remove at some point.\n     maxHeight: '2em',\n     alignItems: 'center',\n     whiteSpace: 'nowrap',\n@@ -27,6 +26,7 @@ export const styles = {\n   /* Styles applied to the root element if `position=\"end\"`. */\n   positionEnd: {\n     marginLeft: 8,\n+    height: '0.01em', // Fix IE11 flexbox alignment. To remove at some point.\n   },\n   /* Styles applied to the root element if `disablePointerEvents={true}`. */\n   disablePointerEvents: {\n"}
{"instance_id": "mui__material-ui-26061", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 8657c912fd..6adc263eb2 100644\n--- a/package.json\n+++ b/package.json\n@@ -136,7 +136,7 @@\n     \"fs-extra\": \"^9.0.0\",\n     \"globby\": \"^11.0.1\",\n     \"html-webpack-plugin\": \"^4.5.0\",\n-    \"jsdom\": \"^16.0.0\",\n+    \"jsdom\": \"^16.7.0\",\n     \"karma\": \"^5.0.1\",\n     \"karma-browserstack-launcher\": \"~1.4.0\",\n     \"karma-chrome-launcher\": \"^3.0.0\",\ndiff --git a/packages/material-ui/src/Tabs/Tabs.js b/packages/material-ui/src/Tabs/Tabs.js\nindex bfc1558613..694b567def 100644\n--- a/packages/material-ui/src/Tabs/Tabs.js\n+++ b/packages/material-ui/src/Tabs/Tabs.js\n@@ -194,6 +194,53 @@ const TabsScrollbarSize = experimentalStyled(\n \n const defaultIndicatorStyle = {};\n \n+function nextItem(list, item) {\n+  if (list === item) {\n+    return list.firstChild;\n+  }\n+  if (item && item.nextElementSibling) {\n+    return item.nextElementSibling;\n+  }\n+  return list.firstChild;\n+}\n+\n+function previousItem(list, item) {\n+  if (list === item) {\n+    return list.lastChild;\n+  }\n+  if (item && item.previousElementSibling) {\n+    return item.previousElementSibling;\n+  }\n+  return list.lastChild;\n+}\n+\n+function moveFocus(list, currentFocus, traversalFunction) {\n+  let wrappedOnce = false;\n+  let nextFocus = traversalFunction(list, currentFocus);\n+\n+  while (nextFocus) {\n+    // Prevent infinite loop.\n+    if (nextFocus === list.firstChild) {\n+      if (wrappedOnce) {\n+        return;\n+      }\n+      wrappedOnce = true;\n+    }\n+\n+    // Same logic as useAutocomplete.js\n+    const nextFocusDisabled =\n+      nextFocus.disabled || nextFocus.getAttribute('aria-disabled') === 'true';\n+\n+    if (!nextFocus.hasAttribute('tabindex') || nextFocusDisabled) {\n+      // Move to the next element.\n+      nextFocus = traversalFunction(list, nextFocus);\n+    } else {\n+      nextFocus.focus();\n+      return;\n+    }\n+  }\n+}\n+\n const Tabs = React.forwardRef(function Tabs(inProps, ref) {\n   const props = useThemeProps({ props: inProps, name: 'MuiTabs' });\n   const theme = useTheme();\n@@ -588,16 +635,16 @@ const Tabs = React.forwardRef(function Tabs(inProps, ref) {\n   });\n \n   const handleKeyDown = (event) => {\n-    const { target } = event;\n+    const list = tabListRef.current;\n+    const { key } = event;\n     // Keyboard navigation assumes that [role=\"tab\"] are siblings\n     // though we might warn in the future about nested, interactive elements\n     // as a a11y violation\n-    const role = target.getAttribute('role');\n+    const role = event.target.getAttribute('role');\n     if (role !== 'tab') {\n       return;\n     }\n \n-    let newFocusTarget = null;\n     let previousItemKey = orientation === 'horizontal' ? 'ArrowLeft' : 'ArrowUp';\n     let nextItemKey = orientation === 'horizontal' ? 'ArrowRight' : 'ArrowDown';\n     if (orientation === 'horizontal' && isRtl) {\n@@ -606,27 +653,26 @@ const Tabs = React.forwardRef(function Tabs(inProps, ref) {\n       nextItemKey = 'ArrowLeft';\n     }\n \n-    switch (event.key) {\n+    switch (key) {\n       case previousItemKey:\n-        newFocusTarget = target.previousElementSibling || tabListRef.current.lastChild;\n+        event.preventDefault();\n+        moveFocus(list, event.target, previousItem);\n         break;\n       case nextItemKey:\n-        newFocusTarget = target.nextElementSibling || tabListRef.current.firstChild;\n+        event.preventDefault();\n+        moveFocus(list, event.target, nextItem);\n         break;\n       case 'Home':\n-        newFocusTarget = tabListRef.current.firstChild;\n+        event.preventDefault();\n+        moveFocus(list, null, nextItem);\n         break;\n       case 'End':\n-        newFocusTarget = tabListRef.current.lastChild;\n+        event.preventDefault();\n+        moveFocus(list, null, previousItem);\n         break;\n       default:\n         break;\n     }\n-\n-    if (newFocusTarget !== null) {\n-      newFocusTarget.focus();\n-      event.preventDefault();\n-    }\n   };\n \n   const conditionalElements = getConditionalElements();\n"}
{"instance_id": "mui__material-ui-26170", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui-lab/src/TabList/TabList.js b/packages/material-ui-lab/src/TabList/TabList.js\nindex 95a1783db7..8459b31cd7 100644\n--- a/packages/material-ui-lab/src/TabList/TabList.js\n+++ b/packages/material-ui-lab/src/TabList/TabList.js\n@@ -10,6 +10,9 @@ const TabList = React.forwardRef(function TabList(props, ref) {\n     throw new TypeError('No TabContext provided');\n   }\n   const children = React.Children.map(childrenProp, (child) => {\n+    if (!React.isValidElement(child)) {\n+      return null;\n+    }\n     return React.cloneElement(child, {\n       // SOMEDAY: `Tabs` will set those themselves\n       'aria-controls': getPanelId(context, child.props.value),\n"}
{"instance_id": "mui__material-ui-26098", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/styles/experimentalStyled.js b/packages/material-ui/src/styles/experimentalStyled.js\nindex a240d421b8..6dca21c5ab 100644\n--- a/packages/material-ui/src/styles/experimentalStyled.js\n+++ b/packages/material-ui/src/styles/experimentalStyled.js\n@@ -154,6 +154,13 @@ const experimentalStyled = (tag, options, muiOptions = {}) => {\n       // If the type is function, we need to define the default theme\n       transformedStyleArg = ({ theme: themeInput, ...other }) =>\n         styleArg({ theme: isEmpty(themeInput) ? defaultTheme : themeInput, ...other });\n+    } else if (styleArg == null && numOfCustomFnsApplied > 0) {\n+      // If styleArg is undefined or null and there are custom functions to apply,\n+      // we need to create a template array with placeholders for the overrides, variants and the sx styles.\n+      // This is needed for styled-components which requires a template array when using expressions.\n+      const placeholders = new Array(numOfCustomFnsApplied).fill('');\n+      transformedStyleArg = ['', ...placeholders];\n+      transformedStyleArg.raw = ['', ...placeholders];\n     }\n \n     const Component = defaultStyledResolver(transformedStyleArg, ...expressionsWithDefaultTheme);\n"}
{"instance_id": "mui__material-ui-26623", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/Slide/Slide.d.ts b/packages/material-ui/src/Slide/Slide.d.ts\nindex f9fcdfd2f4..58c00aeb1e 100644\n--- a/packages/material-ui/src/Slide/Slide.d.ts\n+++ b/packages/material-ui/src/Slide/Slide.d.ts\n@@ -12,6 +12,11 @@ export interface SlideProps extends TransitionProps {\n    * A single child content element.\n    */\n   children?: React.ReactElement<any, any>;\n+  /**\n+   * An HTML element, or a function that returns one.\n+   * It's used to set the container the Slide is transitioning from.\n+   */\n+  container?: Element | (() => Element | null) | null;\n   /**\n    * Direction the child node will enter from.\n    * @default 'down'\ndiff --git a/packages/material-ui/src/Slide/Slide.js b/packages/material-ui/src/Slide/Slide.js\nindex f5c3f266f1..325b470458 100644\n--- a/packages/material-ui/src/Slide/Slide.js\n+++ b/packages/material-ui/src/Slide/Slide.js\n@@ -1,7 +1,7 @@\n import * as React from 'react';\n import PropTypes from 'prop-types';\n import { Transition } from 'react-transition-group';\n-import { elementAcceptingRef } from '@material-ui/utils';\n+import { elementAcceptingRef, HTMLElementType } from '@material-ui/utils';\n import debounce from '../utils/debounce';\n import useForkRef from '../utils/useForkRef';\n import useTheme from '../styles/useTheme';\n@@ -9,11 +9,16 @@ import { duration, easing } from '../styles/createTransitions';\n import { reflow, getTransitionProps } from '../transitions/utils';\n import { ownerWindow } from '../utils';\n \n+function getContainer(container) {\n+  return typeof container === 'function' ? container() : container;\n+}\n+\n // Translate the node so it can't be seen on the screen.\n // Later, we're going to translate the node back to its original location with `none`.\n-function getTranslateValue(direction, node) {\n+function getTranslateValue(direction, node, containerProp) {\n   const rect = node.getBoundingClientRect();\n   const containerWindow = ownerWindow(node);\n+  const container = getContainer(containerProp);\n   let transform;\n \n   if (node.fakeTransform) {\n@@ -34,24 +39,36 @@ function getTranslateValue(direction, node) {\n     offsetY = parseInt(transformValues[5], 10);\n   }\n \n+  let containerRect;\n+  if (container && container.nodeType === 1) {\n+    containerRect = container.getBoundingClientRect();\n+  } else {\n+    containerRect = {\n+      top: 0,\n+      left: 0,\n+      right: containerWindow.innerWidth,\n+      bottom: containerWindow.innerHeight,\n+    };\n+  }\n+\n   if (direction === 'left') {\n-    return `translateX(${containerWindow.innerWidth}px) translateX(${offsetX - rect.left}px)`;\n+    return `translateX(${containerRect.right}px) translateX(${offsetX - rect.left}px)`;\n   }\n \n   if (direction === 'right') {\n-    return `translateX(-${rect.left + rect.width - offsetX}px)`;\n+    return `translateX(-${rect.left + rect.width - containerRect.left - offsetX}px)`;\n   }\n \n   if (direction === 'up') {\n-    return `translateY(${containerWindow.innerHeight}px) translateY(${offsetY - rect.top}px)`;\n+    return `translateY(${containerRect.bottom}px) translateY(${offsetY - rect.top}px)`;\n   }\n \n   // direction === 'down'\n-  return `translateY(-${rect.top + rect.height - offsetY}px)`;\n+  return `translateY(-${rect.top + rect.height - containerRect.top - offsetY}px)`;\n }\n \n-export function setTranslateValue(direction, node) {\n-  const transform = getTranslateValue(direction, node);\n+export function setTranslateValue(direction, node, containerProp) {\n+  const transform = getTranslateValue(direction, node, containerProp);\n \n   if (transform) {\n     node.style.webkitTransform = transform;\n@@ -77,6 +94,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n   const {\n     appear = true,\n     children,\n+    container: containerProp,\n     direction = 'down',\n     easing: easingProp = defaultEasing,\n     in: inProp,\n@@ -110,7 +128,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n   };\n \n   const handleEnter = normalizedTransitionCallback((node, isAppearing) => {\n-    setTranslateValue(direction, node);\n+    setTranslateValue(direction, node, containerProp);\n     reflow(node);\n \n     if (onEnter) {\n@@ -155,7 +173,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n     node.style.webkitTransition = theme.transitions.create('-webkit-transform', transitionProps);\n     node.style.transition = theme.transitions.create('transform', transitionProps);\n \n-    setTranslateValue(direction, node);\n+    setTranslateValue(direction, node, containerProp);\n \n     if (onExit) {\n       onExit(node);\n@@ -174,9 +192,9 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n \n   const updatePosition = React.useCallback(() => {\n     if (childrenRef.current) {\n-      setTranslateValue(direction, childrenRef.current);\n+      setTranslateValue(direction, childrenRef.current, containerProp);\n     }\n-  }, [direction]);\n+  }, [direction, containerProp]);\n \n   React.useEffect(() => {\n     // Skip configuration where the position is screen size invariant.\n@@ -186,7 +204,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n \n     const handleResize = debounce(() => {\n       if (childrenRef.current) {\n-        setTranslateValue(direction, childrenRef.current);\n+        setTranslateValue(direction, childrenRef.current, containerProp);\n       }\n     });\n \n@@ -196,7 +214,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n       handleResize.clear();\n       containerWindow.removeEventListener('resize', handleResize);\n     };\n-  }, [direction, inProp]);\n+  }, [direction, inProp, containerProp]);\n \n   React.useEffect(() => {\n     if (!inProp) {\n@@ -250,6 +268,14 @@ Slide.propTypes /* remove-proptypes */ = {\n    * A single child content element.\n    */\n   children: elementAcceptingRef,\n+  /**\n+   * An HTML element, or a function that returns one.\n+   * It's used to set the container the Slide is transitioning from.\n+   */\n+  container: PropTypes /* @typescript-to-proptypes-ignore */.oneOfType([\n+    HTMLElementType,\n+    PropTypes.func,\n+  ]),\n   /**\n    * Direction the child node will enter from.\n    * @default 'down'\n"}
{"instance_id": "mui__material-ui-26746", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/src/modules/components/AppContainer.js b/docs/src/modules/components/AppContainer.js\nindex be3765f05c..0250a57b3c 100644\n--- a/docs/src/modules/components/AppContainer.js\n+++ b/docs/src/modules/components/AppContainer.js\n@@ -9,7 +9,7 @@ const useStyles = makeStyles((theme) => ({\n     paddingTop: 80 + 16,\n     [theme.breakpoints.up('md')]: {\n       // We're mostly hosting text content so max-width by px does not make sense considering font-size is system-adjustable.\n-      // 120ch \u2248 960px (theme.breakpoints.values.md) using 16px Roboto\n+      // 120ch \u2248 960px using 16px Roboto\n       // TODO Does it make sense to create breakpoints based on `ch`?\n       maxWidth: '120ch',\n     },\ndiff --git a/docs/src/pages/customization/breakpoints/breakpoints-de.md b/docs/src/pages/customization/breakpoints/breakpoints-de.md\nindex fb4f45e604..5b4fdccfc0 100644\n--- a/docs/src/pages/customization/breakpoints/breakpoints-de.md\n+++ b/docs/src/pages/customization/breakpoints/breakpoints-de.md\n@@ -12,8 +12,8 @@ Jeder Haltepunkt (ein Schl\u00fcssel) stimmt mit einer *festen* Bildschirmbreite (ei\n \n - ** xs, ** extraklein: 0px\n - ** sm, ** klein: 600px\n-- ** md, ** mittel: 960px\n-- ** lg, ** gro\u00df: 1280px\n+- ** md, ** mittel: 1024px\n+- ** lg, ** gro\u00df: 1440px\n - ** xl ** extra gro\u00df: 1920px\n \n These values can be [customized](#custom-breakpoints).\n@@ -80,8 +80,8 @@ const theme = createTheme({\n     values: {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n   },\ndiff --git a/docs/src/pages/customization/breakpoints/breakpoints-es.md b/docs/src/pages/customization/breakpoints/breakpoints-es.md\nindex b9998bae52..fe310dcb17 100644\n--- a/docs/src/pages/customization/breakpoints/breakpoints-es.md\n+++ b/docs/src/pages/customization/breakpoints/breakpoints-es.md\n@@ -12,8 +12,8 @@ Cada separaci\u00f3n (una llave) coincide con el ancho de pantalla *fijo* (un valor)\n \n - **xs** extra-peque\u00f1o: 0px\n - **sm** peque\u00f1o: 600px\n-- **md,** mediano: 960px\n-- **lg,** grande: 1280px\n+- **md,** mediano: 1024px\n+- **lg,** grande: 1440px\n - **xl** extra-grande: 1920px\n \n These values can be [customized](#custom-breakpoints).\n@@ -80,8 +80,8 @@ const theme = createTheme({\n     values: {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n   },\ndiff --git a/docs/src/pages/customization/breakpoints/breakpoints-fr.md b/docs/src/pages/customization/breakpoints/breakpoints-fr.md\nindex 89d0d86ce2..bf52d24841 100644\n--- a/docs/src/pages/customization/breakpoints/breakpoints-fr.md\n+++ b/docs/src/pages/customization/breakpoints/breakpoints-fr.md\n@@ -12,8 +12,8 @@ Each breakpoint (a key) matches with a *fixed* screen width (a value):\n \n - **xs,** extra-small: 0px\n - **sm,** small: 600px\n-- **md,** medium: 960px\n-- **lg,** large: 1280px\n+- **md,** medium: 1024px\n+- **lg,** large: 1440px\n - **xl,** extra-large: 1920px\n \n These values can be [customized](#custom-breakpoints).\n@@ -80,8 +80,8 @@ const theme = createTheme({\n     values: {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n   },\ndiff --git a/docs/src/pages/customization/breakpoints/breakpoints-ja.md b/docs/src/pages/customization/breakpoints/breakpoints-ja.md\nindex 966ce8d073..ec954209d2 100644\n--- a/docs/src/pages/customization/breakpoints/breakpoints-ja.md\n+++ b/docs/src/pages/customization/breakpoints/breakpoints-ja.md\n@@ -12,8 +12,8 @@\n \n - **xs,** extra-small: 0px\n - **sm,** small: 600px\n-- **md,** medium: 960px\n-- **lg,** large: 1280px\n+- **md,** medium: 1024px\n+- **lg,** large: 1440px\n - **xl,** extra-large: 1920px\n \n These values can be [customized](#custom-breakpoints).\n@@ -80,8 +80,8 @@ const theme = createTheme({\n     values: {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n   },\ndiff --git a/docs/src/pages/customization/breakpoints/breakpoints-pt.md b/docs/src/pages/customization/breakpoints/breakpoints-pt.md\nindex c44fed4475..fb52dc0482 100644\n--- a/docs/src/pages/customization/breakpoints/breakpoints-pt.md\n+++ b/docs/src/pages/customization/breakpoints/breakpoints-pt.md\n@@ -12,8 +12,8 @@ Cada ponto de quebra (uma chave) corresponde a uma largura de tela *fixa* (um va\n \n - **xs,** extra-pequeno: 0px\n - **sm,** pequeno: 600px\n-- **md,** m\u00e9dio: 960px\n-- **lg,** grande: 1280px\n+- **md,** m\u00e9dio: 1024px\n+- **lg,** grande: 1440px\n - **xl,** extra-grande: 1920px\n \n Esses valores podem ser [customizados](#custom-breakpoints).\ndiff --git a/docs/src/pages/customization/breakpoints/breakpoints-ru.md b/docs/src/pages/customization/breakpoints/breakpoints-ru.md\nindex b68fad1851..7f07181e59 100644\n--- a/docs/src/pages/customization/breakpoints/breakpoints-ru.md\n+++ b/docs/src/pages/customization/breakpoints/breakpoints-ru.md\n@@ -12,8 +12,8 @@ The breakpoints are used internally in various components to make them responsiv\n \n - **xs,** extra-small: 0px\n - **sm,** small: 600px\n-- **md,** medium: 960px\n-- **lg,** large: 1280px\n+- **md,** medium: 1024px\n+- **lg,** large: 1440px\n - **xl,** extra-large: 1920px\n \n These values can be [customized](#custom-breakpoints).\n@@ -80,8 +80,8 @@ const theme = createTheme({\n     values: {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n   },\ndiff --git a/docs/src/pages/customization/breakpoints/breakpoints-zh.md b/docs/src/pages/customization/breakpoints/breakpoints-zh.md\nindex 941d24d056..25e2969149 100644\n--- a/docs/src/pages/customization/breakpoints/breakpoints-zh.md\n+++ b/docs/src/pages/customization/breakpoints/breakpoints-zh.md\n@@ -12,8 +12,8 @@\n \n - ** xs\uff0c ** \u8d85\u5c0f\uff1a0px\n - ** sm\uff0c **\u5c0f\uff1a600px\n-- ** md\uff0c **\u4e2d\u7b49\uff1a960px\n-- ** lg\uff0c **\u5927\uff1a1280px\n+- ** md\uff0c **\u4e2d\u7b49\uff1a1024px\n+- ** lg\uff0c **\u5927\uff1a1440px\n - ** xl\uff0c **\u8d85\u5927\uff1a1920px\n \n \u8fd9\u4e9b\u503c\u53ef\u4ee5\u662f [\u5b9a\u5236](#custom-breakpoints) \u7684\u3002\n@@ -90,8 +90,8 @@ const theme = createTheme({\n     values: {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n   },\ndiff --git a/docs/src/pages/customization/breakpoints/breakpoints.md b/docs/src/pages/customization/breakpoints/breakpoints.md\nindex 97fb959475..af7b1ee448 100644\n--- a/docs/src/pages/customization/breakpoints/breakpoints.md\n+++ b/docs/src/pages/customization/breakpoints/breakpoints.md\n@@ -15,8 +15,8 @@ Each breakpoint (a key) matches with a _fixed_ screen width (a value):\n \n - **xs,** extra-small: 0px\n - **sm,** small: 600px\n-- **md,** medium: 960px\n-- **lg,** large: 1280px\n+- **md,** medium: 1024px\n+- **lg,** large: 1440px\n - **xl,** extra-large: 1920px\n \n These values can be [customized](#custom-breakpoints).\n@@ -77,8 +77,8 @@ const theme = createTheme({\n     values: {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n   },\ndiff --git a/docs/src/pages/guides/migration-v4/migration-v4-de.md b/docs/src/pages/guides/migration-v4/migration-v4-de.md\nindex b23605cfdf..6410bc5e50 100644\n--- a/docs/src/pages/guides/migration-v4/migration-v4-de.md\n+++ b/docs/src/pages/guides/migration-v4/migration-v4-de.md\n@@ -114,13 +114,13 @@ export default function GlobalCssPriority() {\n - Breakpoints are now treated as values instead of ranges. The behavior of `down(key)` was changed to define media query less than the value defined with the corresponding breakpoint (exclusive). The `between(start, end)` was also updated to define media query for the values between the actual values of start (inclusive) and end (exclusive). When using the `down()` breakpoints utility you need to update the breakpoint key by one step up. When using the `between(start, end)` the end breakpoint should also be updated by one step up. The same should be done when using the `Hidden` component. Find examples of the changes required defined below:\n \n   ```diff\n-  -theme.breakpoints.down('sm') // '@media (max-width:959.95px)' - [0, sm + 1) => [0, md)\n-  +theme.breakpoints.down('md') // '@media (max-width:959.95px)' - [0, md)\n+  -theme.breakpoints.down('sm') // '@media (max-width:1023.95px)' - [0, sm + 1) => [0, md)\n+  +theme.breakpoints.down('md') // '@media (max-width:1023.95px)' - [0, md)\n   ```\n \n   ```diff\n-  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1279.95px)' - [sm, md + 1) => [0, lg)\n-  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1279.95px)' - [0, lg)\n+  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1439.95px)' - [sm, md + 1) => [0, lg)\n+  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1439.95px)' - [0, lg)\n   ```\n \n   ```diff\ndiff --git a/docs/src/pages/guides/migration-v4/migration-v4-es.md b/docs/src/pages/guides/migration-v4/migration-v4-es.md\nindex 8988a7f5a6..ddd8e030e7 100644\n--- a/docs/src/pages/guides/migration-v4/migration-v4-es.md\n+++ b/docs/src/pages/guides/migration-v4/migration-v4-es.md\n@@ -114,13 +114,13 @@ export default function GlobalCssPriority() {\n - Los puntos de interrupci\u00f3n ahora son tratados como valores en lugar de rangos. The behavior of `down(key)` was changed to define media query less than the value defined with the corresponding breakpoint (exclusive). The `between(start, end)` was also updated to define media query for the values between the actual values of start (inclusive) and end (exclusive). When using the `down()` breakpoints utility you need to update the breakpoint key by one step up. When using the `between(start, end)` the end breakpoint should also be updated by one step up. The same should be done when using the `Hidden` component. Find examples of the changes required defined below:\n \n   ```diff\n-  -theme.breakpoints.down('sm') // '@media (max-width:959.95px)' - [0, sm + 1) => [0, md)\n-  +theme.breakpoints.down('md') // '@media (max-width:959.95px)' - [0, md)\n+  -theme.breakpoints.down('sm') // '@media (max-width:1023.95px)' - [0, sm + 1) => [0, md)\n+  +theme.breakpoints.down('md') // '@media (max-width:1023.95px)' - [0, md)\n   ```\n \n   ```diff\n-  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1279.95px)' - [sm, md + 1) => [0, lg)\n-  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1279.95px)' - [0, lg)\n+  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1439.95px)' - [sm, md + 1) => [0, lg)\n+  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1439.95px)' - [0, lg)\n   ```\n \n   ```diff\ndiff --git a/docs/src/pages/guides/migration-v4/migration-v4-fr.md b/docs/src/pages/guides/migration-v4/migration-v4-fr.md\nindex 3c20a3b40b..d435987946 100644\n--- a/docs/src/pages/guides/migration-v4/migration-v4-fr.md\n+++ b/docs/src/pages/guides/migration-v4/migration-v4-fr.md\n@@ -114,13 +114,13 @@ export default function GlobalCssPriority() {\n - Breakpoints are now treated as values instead of ranges. The behavior of `down(key)` was changed to define media query less than the value defined with the corresponding breakpoint (exclusive). The `between(start, end)` was also updated to define media query for the values between the actual values of start (inclusive) and end (exclusive). When using the `down()` breakpoints utility you need to update the breakpoint key by one step up. When using the `between(start, end)` the end breakpoint should also be updated by one step up. The same should be done when using the `Hidden` component. Find examples of the changes required defined below:\n \n   ```diff\n-  -theme.breakpoints.down('sm') // '@media (max-width:959.95px)' - [0, sm + 1) => [0, md)\n-  +theme.breakpoints.down('md') // '@media (max-width:959.95px)' - [0, md)\n+  -theme.breakpoints.down('sm') // '@media (max-width:1023.95px)' - [0, sm + 1) => [0, md)\n+  +theme.breakpoints.down('md') // '@media (max-width:1023.95px)' - [0, md)\n   ```\n \n   ```diff\n-  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1279.95px)' - [sm, md + 1) => [0, lg)\n-  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1279.95px)' - [0, lg)\n+  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1439.95px)' - [sm, md + 1) => [0, lg)\n+  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1439.95px)' - [0, lg)\n   ```\n \n   ```diff\ndiff --git a/docs/src/pages/guides/migration-v4/migration-v4-ja.md b/docs/src/pages/guides/migration-v4/migration-v4-ja.md\nindex 39d522005a..c4aa916aba 100644\n--- a/docs/src/pages/guides/migration-v4/migration-v4-ja.md\n+++ b/docs/src/pages/guides/migration-v4/migration-v4-ja.md\n@@ -114,13 +114,13 @@ export default function GlobalCssPriority() {\n - Breakpoints are now treated as values instead of ranges. The behavior of `down(key)` was changed to define media query less than the value defined with the corresponding breakpoint (exclusive). The `between(start, end)` was also updated to define media query for the values between the actual values of start (inclusive) and end (exclusive). When using the `down()` breakpoints utility you need to update the breakpoint key by one step up. When using the `between(start, end)` the end breakpoint should also be updated by one step up. The same should be done when using the `Hidden` component. Find examples of the changes required defined below:\n \n   ```diff\n-  -theme.breakpoints.down('sm') // '@media (max-width:959.95px)' - [0, sm + 1) => [0, md)\n-  +theme.breakpoints.down('md') // '@media (max-width:959.95px)' - [0, md)\n+  -theme.breakpoints.down('sm') // '@media (max-width:1023.95px)' - [0, sm + 1) => [0, md)\n+  +theme.breakpoints.down('md') // '@media (max-width:1023.95px)' - [0, md)\n   ```\n \n   ```diff\n-  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1279.95px)' - [sm, md + 1) => [0, lg)\n-  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1279.95px)' - [0, lg)\n+  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1439.95px)' - [sm, md + 1) => [0, lg)\n+  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1439.95px)' - [0, lg)\n   ```\n \n   ```diff\ndiff --git a/docs/src/pages/guides/migration-v4/migration-v4-pt.md b/docs/src/pages/guides/migration-v4/migration-v4-pt.md\nindex 0b65265cab..1d4eee7669 100644\n--- a/docs/src/pages/guides/migration-v4/migration-v4-pt.md\n+++ b/docs/src/pages/guides/migration-v4/migration-v4-pt.md\n@@ -114,13 +114,13 @@ export default function GlobalCssPriority() {\n - Pontos de quebra agora s\u00e3o tratados como valores, em vez de intervalos. O comportamento de `down(key)` foi modificado para definir uma consulta de m\u00eddia menor do que o valor definido como ponto de quebra correspondente (de forma exclusiva). O `between(start, end)` tamb\u00e9m foi atualizado para definir uma consulta de m\u00eddia para os valores reais entre o in\u00edcio (de forma inclusiva) e fim (de forma exclusiva). Ao usar o utilit\u00e1rio de pontos de quebra `down()`, voc\u00ea precisa atualizar a chave de ponto de quebra em um passo. Ao usar o `between(start, end)`, o ponto de quebra de fim tamb\u00e9m deve ser atualizado em um passo. O mesmo deve ser feito ao usar o componente `Hidden`. Observe exemplos das defini\u00e7\u00f5es de mudan\u00e7as necess\u00e1rias abaixo:\n \n   ```diff\n-  -theme.breakpoints.down('sm') // '@media (max-width:959.95px)' - [0, sm + 1) => [0, md)\n-  +theme.breakpoints.down('md') // '@media (max-width:959.95px)' - [0, md)\n+  -theme.breakpoints.down('sm') // '@media (max-width:1023.95px)' - [0, sm + 1) => [0, md)\n+  +theme.breakpoints.down('md') // '@media (max-width:1023.95px)' - [0, md)\n   ```\n \n   ```diff\n-  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1279.95px)' - [sm, md + 1) => [0, lg)\n-  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1279.95px)' - [0, lg)\n+  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1439.95px)' - [sm, md + 1) => [0, lg)\n+  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1439.95px)' - [0, lg)\n   ```\n \n   ```diff\ndiff --git a/docs/src/pages/guides/migration-v4/migration-v4-ru.md b/docs/src/pages/guides/migration-v4/migration-v4-ru.md\nindex 16c33ac716..6e81d1e0b3 100644\n--- a/docs/src/pages/guides/migration-v4/migration-v4-ru.md\n+++ b/docs/src/pages/guides/migration-v4/migration-v4-ru.md\n@@ -114,13 +114,13 @@ export default function GlobalCssPriority() {\n - Breakpoints are now treated as values instead of ranges. The behavior of `down(key)` was changed to define media query less than the value defined with the corresponding breakpoint (exclusive). The `between(start, end)` was also updated to define media query for the values between the actual values of start (inclusive) and end (exclusive). When using the `down()` breakpoints utility you need to update the breakpoint key by one step up. When using the `between(start, end)` the end breakpoint should also be updated by one step up. The same should be done when using the `Hidden` component. Find examples of the changes required defined below:\n \n   ```diff\n-  -theme.breakpoints.down('sm') // '@media (max-width:959.95px)' - [0, sm + 1) => [0, md)\n-  +theme.breakpoints.down('md') // '@media (max-width:959.95px)' - [0, md)\n+  -theme.breakpoints.down('sm') // '@media (max-width:1023.95px)' - [0, sm + 1) => [0, md)\n+  +theme.breakpoints.down('md') // '@media (max-width:1023.95px)' - [0, md)\n   ```\n \n   ```diff\n-  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1279.95px)' - [sm, md + 1) => [0, lg)\n-  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1279.95px)' - [0, lg)\n+  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1439.95px)' - [sm, md + 1) => [0, lg)\n+  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1439.95px)' - [0, lg)\n   ```\n \n   ```diff\ndiff --git a/docs/src/pages/guides/migration-v4/migration-v4-zh.md b/docs/src/pages/guides/migration-v4/migration-v4-zh.md\nindex 7da5e45ce7..a77442ebe6 100644\n--- a/docs/src/pages/guides/migration-v4/migration-v4-zh.md\n+++ b/docs/src/pages/guides/migration-v4/migration-v4-zh.md\n@@ -108,13 +108,13 @@ export default function PlainCssPriority() {\n - \u65ad\u70b9\u73b0\u5728\u88ab\u5f53\u4f5c\u503c\u800c\u4e0d\u662f\u8303\u56f4\u6765\u5904\u7406\u3002 `down(key)` \u7684\u884c\u4e3a\u5df2\u66f4\u6539\u4e3a\u5b9a\u4e49\u7684\u5a92\u4f53\u67e5\u8be2\u5c0f\u4e8e\u4f7f\u7528\u76f8\u5e94\u65ad\u70b9\u5b9a\u4e49\u7684\u503c\uff08\u4e0d\u5305\u542b\u5f53\u524d\u503c\uff09\u3002 `between(start, end)` \u4e5f\u5df2\u66f4\u65b0\uff0c\u5b9a\u4e49\u4e86\u5a92\u4f53\u67e5\u8be2 start\uff08\u5305\u542b\uff09\u548c end\uff08\u4e0d\u5305\u542b\uff09\u5b9e\u9645\u503c\u4e4b\u95f4\u7684\u6570\u503c\u3002 \u5f53\u4f7f\u7528 `down()`\u65ad\u70b9\u5de5\u5177\u96c6\u65f6\uff0c\u4f60\u9700\u8981\u5411\u4e0a\u4e00\u6b65\u66f4\u65b0\u65ad\u70b9\u952e\u3002 \u5f53\u4f7f\u7528  `between(start, end)` \u65f6\uff0c\u7ed3\u675f\u65ad\u70b9\u4e5f\u5e94\u5411\u4e0a\u4e00\u6b65\u66f4\u65b0\u3002 \u4f7f\u7528 `Hidden` \u7ec4\u4ef6\u65f6\u4e5f\u5e94\u8be5\u8fd9\u6837\u505a\u3002 \u4e0b\u9762\u5217\u51fa\u4e86\u53d8\u52a8\u5f71\u54cd\u7684\u4f8b\u5b50\uff1a\n \n   ```diff\n-  -theme.breakpoints.down('sm') // '@media (max-width:959.95px)' - [0, sm + 1) => [0, md)\n-  +theme.breakpoints.down('md') // '@media (max-width:959.95px)' - [0, md)\n+  -theme.breakpoints.down('sm') // '@media (max-width:1023.95px)' - [0, sm + 1) => [0, md)\n+  +theme.breakpoints.down('md') // '@media (max-width:1023.95px)' - [0, md)\n   ```\n \n   ```diff\n-  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1279.95px)' - [sm, md + 1) => [0, lg)\n-  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1279.95px)' - [0, lg)\n+  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1439.95px)' - [sm, md + 1) => [0, lg)\n+  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1439.95px)' - [0, lg)\n   ```\n \n   ```diff\ndiff --git a/docs/src/pages/guides/migration-v4/migration-v4.md b/docs/src/pages/guides/migration-v4/migration-v4.md\nindex 23e6efbc64..13454486ae 100644\n--- a/docs/src/pages/guides/migration-v4/migration-v4.md\n+++ b/docs/src/pages/guides/migration-v4/migration-v4.md\n@@ -144,13 +144,13 @@ export default function PlainCssPriority() {\n   Here are some examples of the changes required:\n \n   ```diff\n-  -theme.breakpoints.down('sm') // '@media (max-width:959.95px)' - [0, sm + 1) => [0, md)\n-  +theme.breakpoints.down('md') // '@media (max-width:959.95px)' - [0, md)\n+  -theme.breakpoints.down('sm') // '@media (max-width:1023.95px)' - [0, sm + 1) => [0, md)\n+  +theme.breakpoints.down('md') // '@media (max-width:1023.95px)' - [0, md)\n   ```\n \n   ```diff\n-  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1279.95px)' - [sm, md + 1) => [0, lg)\n-  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1279.95px)' - [0, lg)\n+  -theme.breakpoints.between('sm', 'md') // '@media (min-width:600px) and (max-width:1439.95px)' - [sm, md + 1) => [0, lg)\n+  +theme.breakpoints.between('sm', 'lg') // '@media (min-width:600px) and (max-width:1439.95px)' - [0, lg)\n   ```\n \n   ```diff\ndiff --git a/packages/material-ui-system/src/breakpoints.js b/packages/material-ui-system/src/breakpoints.js\nindex 8dd221eeac..6eb2ae641d 100644\n--- a/packages/material-ui-system/src/breakpoints.js\n+++ b/packages/material-ui-system/src/breakpoints.js\n@@ -7,8 +7,8 @@ import merge from './merge';\n const values = {\n   xs: 0,\n   sm: 600,\n-  md: 960,\n-  lg: 1280,\n+  md: 1024,\n+  lg: 1440,\n   xl: 1920,\n };\n \ndiff --git a/packages/material-ui-system/src/createTheme/createBreakpoints.js b/packages/material-ui-system/src/createTheme/createBreakpoints.js\nindex 32c3f6e1f1..6c47c46ab8 100644\n--- a/packages/material-ui-system/src/createTheme/createBreakpoints.js\n+++ b/packages/material-ui-system/src/createTheme/createBreakpoints.js\n@@ -10,8 +10,8 @@ export default function createBreakpoints(breakpoints) {\n     values = {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n     unit = 'px',\ndiff --git a/packages/material-ui/src/styles/cssUtils.js b/packages/material-ui/src/styles/cssUtils.js\nindex 7d81edfaba..3a508f1d14 100644\n--- a/packages/material-ui/src/styles/cssUtils.js\n+++ b/packages/material-ui/src/styles/cssUtils.js\n@@ -102,7 +102,7 @@ export function responsiveProperty({\n   min,\n   max,\n   unit = 'rem',\n-  breakpoints = [600, 960, 1280],\n+  breakpoints = [600, 1024, 1440],\n   transform = null,\n }) {\n   const output = {\n"}
{"instance_id": "mui__material-ui-29023", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/mui-material/src/Tooltip/Tooltip.d.ts b/packages/mui-material/src/Tooltip/Tooltip.d.ts\nindex bad0ac0dd5..999e2eefd0 100644\n--- a/packages/mui-material/src/Tooltip/Tooltip.d.ts\n+++ b/packages/mui-material/src/Tooltip/Tooltip.d.ts\n@@ -37,7 +37,7 @@ export interface TooltipProps extends StandardProps<React.HTMLAttributes<HTMLDiv\n    * @default {}\n    */\n   componentsProps?: {\n-    popper?: PopperProps & TooltipComponentsPropsOverrides;\n+    popper?: Partial<PopperProps> & TooltipComponentsPropsOverrides;\n     transition?: TransitionProps & TooltipComponentsPropsOverrides;\n     tooltip?: React.HTMLProps<HTMLDivElement> &\n       MUIStyledCommonProps &\ndiff --git a/packages/mui-material/src/Tooltip/Tooltip.js b/packages/mui-material/src/Tooltip/Tooltip.js\nindex 920e22f237..c47269eb2d 100644\n--- a/packages/mui-material/src/Tooltip/Tooltip.js\n+++ b/packages/mui-material/src/Tooltip/Tooltip.js\n@@ -679,7 +679,7 @@ const Tooltip = React.forwardRef(function Tooltip(inProps, ref) {\n         transition\n         {...interactiveWrapperListeners}\n         {...popperProps}\n-        className={clsx(classes.popper, componentsProps.popper?.className)}\n+        className={clsx(classes.popper, PopperProps.className, componentsProps.popper?.className)}\n         popperOptions={popperOptions}\n       >\n         {({ TransitionProps: TransitionPropsInner }) => (\n"}
{"instance_id": "mui__material-ui-28813", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/mui-system/src/Box/Box.d.ts b/packages/mui-system/src/Box/Box.d.ts\nindex 7138586e2d..45bc14c5a6 100644\n--- a/packages/mui-system/src/Box/Box.d.ts\n+++ b/packages/mui-system/src/Box/Box.d.ts\n@@ -105,6 +105,12 @@ export const spacing: SimpleStyleFunction<\n   | 'marginLeft'\n   | 'marginX'\n   | 'marginY'\n+  | 'marginInline'\n+  | 'marginInlineStart'\n+  | 'marginInlineEnd'\n+  | 'marginBlock'\n+  | 'marginBlockStart'\n+  | 'marginBlockEnd'\n   | 'padding'\n   | 'paddingTop'\n   | 'paddingRight'\n@@ -112,6 +118,12 @@ export const spacing: SimpleStyleFunction<\n   | 'paddingLeft'\n   | 'paddingX'\n   | 'paddingY'\n+  | 'paddingInline'\n+  | 'paddingInlineStart'\n+  | 'paddingInlineEnd'\n+  | 'paddingBlock'\n+  | 'paddingBlockStart'\n+  | 'paddingBlockEnd'\n >;\n \n export const typography: SimpleStyleFunction<\ndiff --git a/packages/mui-system/src/spacing.d.ts b/packages/mui-system/src/spacing.d.ts\nindex 5c637db732..fe25376999 100644\n--- a/packages/mui-system/src/spacing.d.ts\n+++ b/packages/mui-system/src/spacing.d.ts\n@@ -25,6 +25,12 @@ export const margin: SimpleStyleFunction<\n   | 'marginLeft'\n   | 'marginX'\n   | 'marginY'\n+  | 'marginInline'\n+  | 'marginInlineStart'\n+  | 'marginInlineEnd'\n+  | 'marginBlock'\n+  | 'marginBlockStart'\n+  | 'marginBlockEnd'\n >;\n \n export type MarginProps = PropsFor<typeof margin>;\n@@ -44,6 +50,12 @@ export const padding: SimpleStyleFunction<\n   | 'paddingLeft'\n   | 'paddingX'\n   | 'paddingY'\n+  | 'paddingInline'\n+  | 'paddingInlineStart'\n+  | 'paddingInlineEnd'\n+  | 'paddingBlock'\n+  | 'paddingBlockStart'\n+  | 'paddingBlockEnd'\n >;\n \n export type PaddingProps = PropsFor<typeof padding>;\ndiff --git a/packages/mui-system/src/spacing.js b/packages/mui-system/src/spacing.js\nindex 2c8ccba9f2..455c50bea5 100644\n--- a/packages/mui-system/src/spacing.js\n+++ b/packages/mui-system/src/spacing.js\n@@ -59,6 +59,12 @@ const marginKeys = [\n   'marginLeft',\n   'marginX',\n   'marginY',\n+  'marginInline',\n+  'marginInlineStart',\n+  'marginInlineEnd',\n+  'marginBlock',\n+  'marginBlockStart',\n+  'marginBlockEnd',\n ];\n \n const paddingKeys = [\n@@ -76,6 +82,12 @@ const paddingKeys = [\n   'paddingLeft',\n   'paddingX',\n   'paddingY',\n+  'paddingInline',\n+  'paddingInlineStart',\n+  'paddingInlineEnd',\n+  'paddingBlock',\n+  'paddingBlockStart',\n+  'paddingBlockEnd',\n ];\n \n const spacingKeys = [...marginKeys, ...paddingKeys];\n"}
{"instance_id": "mui__material-ui-26807", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/translations/api-docs/step-label/step-label.json b/docs/translations/api-docs/step-label/step-label.json\nindex b2c54b7c39..b37a48d646 100644\n--- a/docs/translations/api-docs/step-label/step-label.json\n+++ b/docs/translations/api-docs/step-label/step-label.json\n@@ -8,7 +8,8 @@\n     \"optional\": \"The optional node to display.\",\n     \"StepIconComponent\": \"The component to render in place of the <a href=\\\"/api/step-icon/\\\"><code>StepIcon</code></a>.\",\n     \"StepIconProps\": \"Props applied to the <a href=\\\"/api/step-icon/\\\"><code>StepIcon</code></a> element.\",\n-    \"sx\": \"The system prop that allows defining system overrides as well as additional CSS styles. See the <a href=\\\"/system/basics/#the-sx-prop\\\">`sx` page</a> for more details.\"\n+    \"sx\": \"The system prop that allows defining system overrides as well as additional CSS styles. See the <a href=\\\"/system/basics/#the-sx-prop\\\">`sx` page</a> for more details.\",\n+    \"TypographyProps\": \"Props applied to the <a href=\\\"/api/typography/\\\"><code>Typography</code></a> element which wraps `children`.\"\n   },\n   \"classDescriptions\": {\n     \"root\": { \"description\": \"Styles applied to the root element.\" },\ndiff --git a/packages/material-ui/src/StepLabel/StepLabel.d.ts b/packages/material-ui/src/StepLabel/StepLabel.d.ts\nindex 521ffd3155..33982fa87b 100644\n--- a/packages/material-ui/src/StepLabel/StepLabel.d.ts\n+++ b/packages/material-ui/src/StepLabel/StepLabel.d.ts\n@@ -4,6 +4,7 @@ import { InternalStandardProps as StandardProps } from '..';\n import { StepIconProps } from '../StepIcon';\n import { Theme } from '../styles';\n import { StepLabelClasses } from './stepLabelClasses';\n+import { TypographyProps } from '../Typography';\n \n export interface StepLabelProps extends StandardProps<React.HTMLAttributes<HTMLDivElement>> {\n   /**\n@@ -39,6 +40,10 @@ export interface StepLabelProps extends StandardProps<React.HTMLAttributes<HTMLD\n    * The system prop that allows defining system overrides as well as additional CSS styles.\n    */\n   sx?: SxProps<Theme>;\n+  /**\n+   * Props applied to the [`Typography`](/api/typography/) element which wraps `children`.\n+   */\n+  TypographyProps?: Partial<TypographyProps>;\n }\n \n export type StepLabelClasskey = keyof NonNullable<StepLabelProps['classes']>;\ndiff --git a/packages/material-ui/src/StepLabel/StepLabel.js b/packages/material-ui/src/StepLabel/StepLabel.js\nindex e03382fbec..fe8d9bd4e5 100644\n--- a/packages/material-ui/src/StepLabel/StepLabel.js\n+++ b/packages/material-ui/src/StepLabel/StepLabel.js\n@@ -124,6 +124,7 @@ const StepLabel = React.forwardRef(function StepLabel(inProps, ref) {\n     optional,\n     StepIconComponent: StepIconComponentProp,\n     StepIconProps,\n+    TypographyProps,\n     ...other\n   } = props;\n \n@@ -173,7 +174,8 @@ const StepLabel = React.forwardRef(function StepLabel(inProps, ref) {\n             variant=\"body2\"\n             component=\"span\"\n             display=\"block\"\n-            className={classes.label}\n+            {...TypographyProps}\n+            className={clsx(classes.label, TypographyProps?.className)}\n             styleProps={styleProps}\n           >\n             {children}\n@@ -223,6 +225,10 @@ StepLabel.propTypes /* remove-proptypes */ = {\n    * Props applied to the [`StepIcon`](/api/step-icon/) element.\n    */\n   StepIconProps: PropTypes.object,\n+  /**\n+   * Props applied to the [`Typography`](/api/typography/) element which wraps `children`.\n+   */\n+  TypographyProps: PropTypes.object,\n   /**\n    * The system prop that allows defining system overrides as well as additional CSS styles.\n    */\n"}
{"instance_id": "mui__material-ui-34138", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/mui-material/src/Step/Step.d.ts b/packages/mui-material/src/Step/Step.d.ts\nindex ab2ba3a333..f76aa78f2a 100644\n--- a/packages/mui-material/src/Step/Step.d.ts\n+++ b/packages/mui-material/src/Step/Step.d.ts\n@@ -1,9 +1,10 @@\n import * as React from 'react';\n import { SxProps } from '@mui/system';\n-import { InternalStandardProps as StandardProps, Theme } from '..';\n+import { Theme } from '..';\n+import { OverridableComponent, OverrideProps } from '../OverridableComponent';\n import { StepClasses } from './stepClasses';\n \n-export interface StepProps extends StandardProps<React.HTMLAttributes<HTMLDivElement>> {\n+export interface StepOwnProps {\n   /**\n    * Sets the step as active. Is passed to child components.\n    */\n@@ -46,7 +47,10 @@ export interface StepProps extends StandardProps<React.HTMLAttributes<HTMLDivEle\n   sx?: SxProps<Theme>;\n }\n \n-export type StepClasskey = keyof NonNullable<StepProps['classes']>;\n+export interface StepTypeMap<AdditionalProps = {}, RootComponent extends React.ElementType = 'li'> {\n+  props: AdditionalProps & StepOwnProps;\n+  defaultComponent: RootComponent;\n+}\n \n /**\n  *\n@@ -58,4 +62,13 @@ export type StepClasskey = keyof NonNullable<StepProps['classes']>;\n  *\n  * - [Step API](https://mui.com/material-ui/api/step/)\n  */\n-export default function Step(props: StepProps): JSX.Element;\n+declare const Step: OverridableComponent<StepTypeMap>;\n+\n+export type StepProps<\n+  RootComponent extends React.ElementType = StepTypeMap['defaultComponent'],\n+  AdditionalProps = {},\n+> = OverrideProps<StepTypeMap<AdditionalProps, RootComponent>, RootComponent>;\n+\n+export type StepClasskey = keyof NonNullable<StepOwnProps['classes']>;\n+\n+export default Step;\ndiff --git a/packages/mui-material/src/Step/Step.js b/packages/mui-material/src/Step/Step.js\nindex df0c6ab669..fcaa9b9a0b 100644\n--- a/packages/mui-material/src/Step/Step.js\n+++ b/packages/mui-material/src/Step/Step.js\n@@ -19,7 +19,7 @@ const useUtilityClasses = (ownerState) => {\n   return composeClasses(slots, getStepUtilityClass, classes);\n };\n \n-const StepRoot = styled('div', {\n+const StepRoot = styled('li', {\n   name: 'MuiStep',\n   slot: 'Root',\n   overridesResolver: (props, styles) => {\n@@ -49,6 +49,7 @@ const Step = React.forwardRef(function Step(inProps, ref) {\n     active: activeProp,\n     children,\n     className,\n+    component = 'li',\n     completed: completedProp,\n     disabled: disabledProp,\n     expanded = false,\n@@ -87,12 +88,14 @@ const Step = React.forwardRef(function Step(inProps, ref) {\n     completed,\n     disabled,\n     expanded,\n+    component,\n   };\n \n   const classes = useUtilityClasses(ownerState);\n \n   const newChildren = (\n     <StepRoot\n+      as={component}\n       className={clsx(classes.root, className)}\n       ref={ref}\n       ownerState={ownerState}\n@@ -142,6 +145,12 @@ Step.propTypes /* remove-proptypes */ = {\n    * Mark the step as completed. Is passed to child components.\n    */\n   completed: PropTypes.bool,\n+  /**\n+   * The component used for the root node.\n+   * Either a string to use a HTML element or a component.\n+   * @default 'li'\n+   */\n+  component: PropTypes.elementType,\n   /**\n    * If `true`, the step is disabled, will also disable the button if\n    * `StepButton` is a child of `Step`. Is passed to child components.\ndiff --git a/packages/mui-material/src/Stepper/Stepper.d.ts b/packages/mui-material/src/Stepper/Stepper.d.ts\nindex 1efa284cf1..d8dce75076 100644\n--- a/packages/mui-material/src/Stepper/Stepper.d.ts\n+++ b/packages/mui-material/src/Stepper/Stepper.d.ts\n@@ -1,13 +1,12 @@\n import * as React from 'react';\n import { SxProps } from '@mui/system';\n import { Theme } from '../styles';\n-import { InternalStandardProps as StandardProps } from '..';\n-import { PaperProps } from '../Paper';\n+import { OverridableComponent, OverrideProps } from '../OverridableComponent';\n import { StepperClasses } from './stepperClasses';\n \n export type Orientation = 'horizontal' | 'vertical';\n \n-export interface StepperProps extends StandardProps<PaperProps> {\n+export interface StepperOwnProps {\n   /**\n    * Set the active step (zero based index).\n    * Set to -1 to disable all the steps.\n@@ -49,7 +48,13 @@ export interface StepperProps extends StandardProps<PaperProps> {\n   sx?: SxProps<Theme>;\n }\n \n-export type StepperClasskey = keyof NonNullable<StepperProps['classes']>;\n+export interface StepperTypeMap<\n+  AdditionalProps = {},\n+  RootComponent extends React.ElementType = 'ol',\n+> {\n+  props: AdditionalProps & StepperOwnProps;\n+  defaultComponent: RootComponent;\n+}\n \n /**\n  *\n@@ -61,4 +66,13 @@ export type StepperClasskey = keyof NonNullable<StepperProps['classes']>;\n  *\n  * - [Stepper API](https://mui.com/material-ui/api/stepper/)\n  */\n-export default function Stepper(props: StepperProps): JSX.Element;\n+declare const Stepper: OverridableComponent<StepperTypeMap>;\n+\n+export type StepperProps<\n+  RootComponent extends React.ElementType = StepperTypeMap['defaultComponent'],\n+  AdditionalProps = {},\n+> = OverrideProps<StepperTypeMap<AdditionalProps, RootComponent>, RootComponent>;\n+\n+export type StepperClasskey = keyof NonNullable<StepperOwnProps['classes']>;\n+\n+export default Stepper;\ndiff --git a/packages/mui-material/src/Stepper/Stepper.js b/packages/mui-material/src/Stepper/Stepper.js\nindex 8776ff6d3f..663d627cc7 100644\n--- a/packages/mui-material/src/Stepper/Stepper.js\n+++ b/packages/mui-material/src/Stepper/Stepper.js\n@@ -18,7 +18,7 @@ const useUtilityClasses = (ownerState) => {\n   return composeClasses(slots, getStepperUtilityClass, classes);\n };\n \n-const StepperRoot = styled('div', {\n+const StepperRoot = styled('ol', {\n   name: 'MuiStepper',\n   slot: 'Root',\n   overridesResolver: (props, styles) => {\n@@ -31,6 +31,9 @@ const StepperRoot = styled('div', {\n   },\n })(({ ownerState }) => ({\n   display: 'flex',\n+  listStyle: 'none',\n+  padding: 0,\n+  margin: 0,\n   ...(ownerState.orientation === 'horizontal' && {\n     flexDirection: 'row',\n     alignItems: 'center',\n@@ -52,6 +55,7 @@ const Stepper = React.forwardRef(function Stepper(inProps, ref) {\n     alternativeLabel = false,\n     children,\n     className,\n+    component = 'ol',\n     connector = defaultConnector,\n     nonLinear = false,\n     orientation = 'horizontal',\n@@ -62,6 +66,7 @@ const Stepper = React.forwardRef(function Stepper(inProps, ref) {\n     ...props,\n     alternativeLabel,\n     orientation,\n+    component,\n   };\n \n   const classes = useUtilityClasses(ownerState);\n@@ -82,6 +87,7 @@ const Stepper = React.forwardRef(function Stepper(inProps, ref) {\n   return (\n     <StepperContext.Provider value={contextValue}>\n       <StepperRoot\n+        as={component}\n         ownerState={ownerState}\n         className={clsx(classes.root, className)}\n         ref={ref}\n@@ -122,6 +128,12 @@ Stepper.propTypes /* remove-proptypes */ = {\n    * @ignore\n    */\n   className: PropTypes.string,\n+  /**\n+   * The component used for the root node.\n+   * Either a string to use a HTML element or a component.\n+   * @default 'ol'\n+   */\n+  component: PropTypes.elementType,\n   /**\n    * An element to be placed between each step.\n    * @default <StepConnector />\n"}
{"instance_id": "mui__material-ui-34610", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/mui-base/src/SliderUnstyled/SliderUnstyled.js b/packages/mui-base/src/SliderUnstyled/SliderUnstyled.js\nindex c5f73e2b24..a2e6e16509 100644\n--- a/packages/mui-base/src/SliderUnstyled/SliderUnstyled.js\n+++ b/packages/mui-base/src/SliderUnstyled/SliderUnstyled.js\n@@ -45,6 +45,7 @@ const Forward = ({ children }) => children;\n const SliderUnstyled = React.forwardRef(function SliderUnstyled(props, ref) {\n   const {\n     'aria-label': ariaLabel,\n+    'aria-labelledby': ariaLabelledby,\n     'aria-valuetext': ariaValuetext,\n     className,\n     component,\ndiff --git a/packages/mui-joy/src/Slider/Slider.tsx b/packages/mui-joy/src/Slider/Slider.tsx\nindex 6154087f2d..cbce128042 100644\n--- a/packages/mui-joy/src/Slider/Slider.tsx\n+++ b/packages/mui-joy/src/Slider/Slider.tsx\n@@ -368,6 +368,7 @@ const Slider = React.forwardRef(function Slider(inProps, ref) {\n \n   const {\n     'aria-label': ariaLabel,\n+    'aria-labelledby': ariaLabelledby,\n     'aria-valuetext': ariaValuetext,\n     component,\n     componentsProps = {},\n"}
{"instance_id": "mui__material-ui-27312", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/material-ui/src/useAutocomplete/useAutocomplete.d.ts b/packages/material-ui/src/useAutocomplete/useAutocomplete.d.ts\nindex c93d5990f0..df93a46c8b 100644\n--- a/packages/material-ui/src/useAutocomplete/useAutocomplete.d.ts\n+++ b/packages/material-ui/src/useAutocomplete/useAutocomplete.d.ts\n@@ -95,6 +95,11 @@ export interface UseAutocompleteProps<\n    * @default false\n    */\n   disableCloseOnSelect?: boolean;\n+  /**\n+   * If `true`, the component is disabled.\n+   * @default false\n+   */\n+  disabled?: boolean;\n   /**\n    * If `true`, will allow focus on disabled items.\n    * @default false\ndiff --git a/packages/material-ui/src/useAutocomplete/useAutocomplete.js b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\nindex 31f88be71e..e61a6a4ddc 100644\n--- a/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n@@ -73,6 +73,7 @@ export default function useAutocomplete(props) {\n     defaultValue = props.multiple ? [] : null,\n     disableClearable = false,\n     disableCloseOnSelect = false,\n+    disabled = false,\n     disabledItemsFocusable = false,\n     disableListWrap = false,\n     filterOptions = defaultFilterOptions,\n@@ -540,6 +541,12 @@ export default function useAutocomplete(props) {\n     }\n   };\n \n+  React.useEffect(() => {\n+    if (disabled && open) {\n+      handleClose(null, 'toggleInput');\n+    }\n+  }, [disabled]);\n+\n   const handleValue = (event, newValue, reason, details) => {\n     if (value === newValue) {\n       return;\n"}
{"instance_id": "mui__material-ui-28190", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/mui-core/src/AutocompleteUnstyled/useAutocomplete.js b/packages/mui-core/src/AutocompleteUnstyled/useAutocomplete.js\nindex 1d34b6b507..036db6e777 100644\n--- a/packages/mui-core/src/AutocompleteUnstyled/useAutocomplete.js\n+++ b/packages/mui-core/src/AutocompleteUnstyled/useAutocomplete.js\n@@ -181,12 +181,19 @@ export default function useAutocomplete(props) {\n     const valueChange = value !== prevValue.current;\n     prevValue.current = value;\n \n+    // Don't reset the input value when focused, unless the value changed\n     if (focused && !valueChange) {\n       return;\n     }\n \n+    // In freeSolo mode, don't reset the input value when losing focus\n+    // (clearOnBlur is false by default in freeSolo mode)\n+    if (!focused && !clearOnBlur && !valueChange) {\n+      return;\n+    }\n+\n     resetInputValue(null, value);\n-  }, [value, resetInputValue, focused, prevValue]);\n+  }, [value, resetInputValue, focused, prevValue, clearOnBlur]);\n \n   const [open, setOpenState] = useControlled({\n     controlled: openProp,\n"}
{"instance_id": "mui__material-ui-34158", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/data/base/components/select/UnstyledSelectControlled.js b/docs/data/base/components/select/UnstyledSelectControlled.js\nindex 7b8d91cc72..4e5a8d9cb7 100644\n--- a/docs/data/base/components/select/UnstyledSelectControlled.js\n+++ b/docs/data/base/components/select/UnstyledSelectControlled.js\n@@ -165,7 +165,7 @@ export default function UnstyledSelectsMultiple() {\n   const [value, setValue] = React.useState(10);\n   return (\n     <div>\n-      <CustomSelect value={value} onChange={setValue}>\n+      <CustomSelect value={value} onChange={(e, newValue) => setValue(newValue)}>\n         <StyledOption value={10}>Ten</StyledOption>\n         <StyledOption value={20}>Twenty</StyledOption>\n         <StyledOption value={30}>Thirty</StyledOption>\ndiff --git a/docs/data/base/components/select/UnstyledSelectControlled.tsx b/docs/data/base/components/select/UnstyledSelectControlled.tsx\nindex eed5cc325e..5fca0a1b6a 100644\n--- a/docs/data/base/components/select/UnstyledSelectControlled.tsx\n+++ b/docs/data/base/components/select/UnstyledSelectControlled.tsx\n@@ -154,7 +154,7 @@ export default function UnstyledSelectsMultiple() {\n   const [value, setValue] = React.useState<number | null>(10);\n   return (\n     <div>\n-      <CustomSelect value={value} onChange={setValue}>\n+      <CustomSelect value={value} onChange={(e, newValue) => setValue(newValue)}>\n         <StyledOption value={10}>Ten</StyledOption>\n         <StyledOption value={20}>Twenty</StyledOption>\n         <StyledOption value={30}>Thirty</StyledOption>\ndiff --git a/docs/data/base/components/select/UnstyledSelectObjectValues.js b/docs/data/base/components/select/UnstyledSelectObjectValues.js\nindex 3d00c3e7e1..74987c03b7 100644\n--- a/docs/data/base/components/select/UnstyledSelectObjectValues.js\n+++ b/docs/data/base/components/select/UnstyledSelectObjectValues.js\n@@ -187,7 +187,7 @@ export default function UnstyledSelectObjectValues() {\n   const [character, setCharacter] = React.useState(characters[0]);\n   return (\n     <div>\n-      <CustomSelect value={character} onChange={setCharacter}>\n+      <CustomSelect value={character} onChange={(e, newValue) => setCharacter(newValue)}>\n         {characters.map((c) => (\n           <StyledOption key={c.name} value={c}>\n             {c.name}\ndiff --git a/docs/data/base/components/select/UnstyledSelectObjectValues.tsx b/docs/data/base/components/select/UnstyledSelectObjectValues.tsx\nindex d50392f5bd..daeb14bfb4 100644\n--- a/docs/data/base/components/select/UnstyledSelectObjectValues.tsx\n+++ b/docs/data/base/components/select/UnstyledSelectObjectValues.tsx\n@@ -181,7 +181,7 @@ export default function UnstyledSelectObjectValues() {\n   const [character, setCharacter] = React.useState<Character | null>(characters[0]);\n   return (\n     <div>\n-      <CustomSelect value={character} onChange={setCharacter}>\n+      <CustomSelect value={character} onChange={(e, newValue) => setCharacter(newValue)}>\n         {characters.map((c) => (\n           <StyledOption key={c.name} value={c}>\n             {c.name}\ndiff --git a/docs/data/base/components/select/UnstyledSelectObjectValuesForm.js b/docs/data/base/components/select/UnstyledSelectObjectValuesForm.js\nindex e8c0b2cd24..9af2b70fd0 100644\n--- a/docs/data/base/components/select/UnstyledSelectObjectValuesForm.js\n+++ b/docs/data/base/components/select/UnstyledSelectObjectValuesForm.js\n@@ -204,7 +204,11 @@ export default function UnstyledSelectObjectValues() {\n     <div>\n       <Header>Default behavior</Header>\n       <form onSubmit={handleSubmit}>\n-        <CustomSelect value={character} onChange={setCharacter} name=\"character\">\n+        <CustomSelect\n+          value={character}\n+          onChange={(e, newValue) => setCharacter(newValue)}\n+          name=\"character\"\n+        >\n           {characters.map((c) => (\n             <StyledOption key={c.name} value={c}>\n               {c.name}\n@@ -219,7 +223,7 @@ export default function UnstyledSelectObjectValues() {\n       <form onSubmit={handleSubmit}>\n         <CustomSelect\n           value={character}\n-          onChange={setCharacter}\n+          onChange={(e, newValue) => setCharacter(newValue)}\n           getSerializedValue={getSerializedValue}\n           name=\"character\"\n         >\ndiff --git a/docs/data/base/components/select/UnstyledSelectObjectValuesForm.tsx b/docs/data/base/components/select/UnstyledSelectObjectValuesForm.tsx\nindex 7b063743d8..f75634bc65 100644\n--- a/docs/data/base/components/select/UnstyledSelectObjectValuesForm.tsx\n+++ b/docs/data/base/components/select/UnstyledSelectObjectValuesForm.tsx\n@@ -199,7 +199,11 @@ export default function UnstyledSelectObjectValues() {\n     <div>\n       <Header>Default behavior</Header>\n       <form onSubmit={handleSubmit}>\n-        <CustomSelect value={character} onChange={setCharacter} name=\"character\">\n+        <CustomSelect\n+          value={character}\n+          onChange={(e, newValue) => setCharacter(newValue)}\n+          name=\"character\"\n+        >\n           {characters.map((c) => (\n             <StyledOption key={c.name} value={c}>\n               {c.name}\n@@ -214,7 +218,7 @@ export default function UnstyledSelectObjectValues() {\n       <form onSubmit={handleSubmit}>\n         <CustomSelect\n           value={character}\n-          onChange={setCharacter}\n+          onChange={(e, newValue) => setCharacter(newValue)}\n           getSerializedValue={getSerializedValue}\n           name=\"character\"\n         >\ndiff --git a/packages/mui-base/src/ListboxUnstyled/useControllableReducer.ts b/packages/mui-base/src/ListboxUnstyled/useControllableReducer.ts\nindex 305c5d9f9a..f9ef5daf88 100644\n--- a/packages/mui-base/src/ListboxUnstyled/useControllableReducer.ts\n+++ b/packages/mui-base/src/ListboxUnstyled/useControllableReducer.ts\n@@ -1,5 +1,6 @@\n import * as React from 'react';\n import {\n+  ActionTypes,\n   ListboxAction,\n   ListboxReducer,\n   ListboxState,\n@@ -38,6 +39,19 @@ function areOptionsEqual<TOption>(\n   return optionComparer(option1, option2);\n }\n \n+function getActionEvent(action: ListboxAction<any>) {\n+  if (\n+    action.type === ActionTypes.keyDown ||\n+    action.type === ActionTypes.optionClick ||\n+    action.type === ActionTypes.blur ||\n+    action.type === ActionTypes.optionHover\n+  ) {\n+    return action.event;\n+  }\n+\n+  return null;\n+}\n+\n /**\n  * Triggers change event handlers when reducer returns changed state.\n  */\n@@ -45,37 +59,47 @@ function useStateChangeDetection<TOption>(\n   nextState: ListboxState<TOption>,\n   internalPreviousState: ListboxState<TOption>,\n   propsRef: React.RefObject<UseListboxPropsWithDefaults<TOption>>,\n-  hasDispatchedActionRef: React.MutableRefObject<boolean>,\n+  lastActionRef: React.MutableRefObject<ListboxAction<TOption> | null>,\n ) {\n   React.useEffect(() => {\n-    if (!propsRef.current || !hasDispatchedActionRef.current) {\n+    if (!propsRef.current || lastActionRef.current === null) {\n       // Detect changes only if an action has been dispatched.\n       return;\n     }\n \n-    hasDispatchedActionRef.current = false;\n-\n     const previousState = getControlledState(internalPreviousState, propsRef.current);\n     const { multiple, optionComparer } = propsRef.current;\n \n     if (multiple) {\n       const previousSelectedValues = (previousState?.selectedValue ?? []) as TOption[];\n       const nextSelectedValues = nextState.selectedValue as TOption[];\n-      const onChange = propsRef.current.onChange as ((value: TOption[]) => void) | undefined;\n+      const onChange = propsRef.current.onChange as\n+        | ((\n+            e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+            value: TOption[],\n+          ) => void)\n+        | undefined;\n \n       if (!areArraysEqual(nextSelectedValues, previousSelectedValues, optionComparer)) {\n-        onChange?.(nextSelectedValues);\n+        onChange?.(getActionEvent(lastActionRef.current), nextSelectedValues);\n       }\n     } else {\n       const previousSelectedValue = previousState?.selectedValue as TOption | null;\n       const nextSelectedValue = nextState.selectedValue as TOption | null;\n-      const onChange = propsRef.current.onChange as ((value: TOption | null) => void) | undefined;\n+      const onChange = propsRef.current.onChange as\n+        | ((\n+            e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+            value: TOption | null,\n+          ) => void)\n+        | undefined;\n \n       if (!areOptionsEqual(nextSelectedValue, previousSelectedValue, optionComparer)) {\n-        onChange?.(nextSelectedValue);\n+        onChange?.(getActionEvent(lastActionRef.current), nextSelectedValue);\n       }\n     }\n-  }, [nextState.selectedValue, internalPreviousState, propsRef, hasDispatchedActionRef]);\n+\n+    lastActionRef.current = null;\n+  }, [nextState.selectedValue, internalPreviousState, propsRef, lastActionRef]);\n \n   React.useEffect(() => {\n     if (!propsRef.current) {\n@@ -105,7 +129,7 @@ export default function useControllableReducer<TOption>(\n   const propsRef = React.useRef(props);\n   propsRef.current = props;\n \n-  const hasDispatchedActionRef = React.useRef(false);\n+  const lastActionRef = React.useRef<ListboxAction<TOption> | null>(null);\n \n   const initialSelectedValue =\n     (value === undefined ? defaultValue : value) ?? (props.multiple ? [] : null);\n@@ -117,7 +141,7 @@ export default function useControllableReducer<TOption>(\n \n   const combinedReducer = React.useCallback(\n     (state: ListboxState<TOption>, action: ListboxAction<TOption>) => {\n-      hasDispatchedActionRef.current = true;\n+      lastActionRef.current = action;\n \n       if (externalReducer) {\n         return externalReducer(getControlledState(state, propsRef.current), action);\n@@ -139,7 +163,7 @@ export default function useControllableReducer<TOption>(\n     nextState,\n     previousState.current,\n     propsRef,\n-    hasDispatchedActionRef,\n+    lastActionRef,\n   );\n   return [getControlledState(nextState, propsRef.current), dispatch];\n }\ndiff --git a/packages/mui-base/src/ListboxUnstyled/useListbox.types.ts b/packages/mui-base/src/ListboxUnstyled/useListbox.types.ts\nindex 8239f94810..9c48919b54 100644\n--- a/packages/mui-base/src/ListboxUnstyled/useListbox.types.ts\n+++ b/packages/mui-base/src/ListboxUnstyled/useListbox.types.ts\n@@ -178,7 +178,10 @@ interface UseSingleSelectListboxParameters<TOption> extends UseListboxCommonProp\n   /**\n    * Callback fired when the value changes.\n    */\n-  onChange?: (value: TOption) => void;\n+  onChange?: (\n+    e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+    value: TOption | null,\n+  ) => void;\n }\n \n interface UseMultiSelectListboxParameters<TOption> extends UseListboxCommonProps<TOption> {\n@@ -198,7 +201,10 @@ interface UseMultiSelectListboxParameters<TOption> extends UseListboxCommonProps\n   /**\n    * Callback fired when the value changes.\n    */\n-  onChange?: (value: TOption[]) => void;\n+  onChange?: (\n+    e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+    value: TOption[],\n+  ) => void;\n }\n \n export type UseListboxParameters<TOption> =\ndiff --git a/packages/mui-base/src/MultiSelectUnstyled/MultiSelectUnstyled.types.ts b/packages/mui-base/src/MultiSelectUnstyled/MultiSelectUnstyled.types.ts\nindex e03a97af79..d444fa3e7a 100644\n--- a/packages/mui-base/src/MultiSelectUnstyled/MultiSelectUnstyled.types.ts\n+++ b/packages/mui-base/src/MultiSelectUnstyled/MultiSelectUnstyled.types.ts\n@@ -59,7 +59,10 @@ export interface MultiSelectUnstyledOwnProps<TValue extends {}> extends SelectUn\n   /**\n    * Callback fired when an option is selected.\n    */\n-  onChange?: (value: TValue[]) => void;\n+  onChange?: (\n+    e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+    value: TValue[],\n+  ) => void;\n   /**\n    * A function used to convert the option label to a string.\n    * It's useful when labels are elements and need to be converted to plain text\ndiff --git a/packages/mui-base/src/SelectUnstyled/SelectUnstyled.types.ts b/packages/mui-base/src/SelectUnstyled/SelectUnstyled.types.ts\nindex 26833cf66c..dc00e6a658 100644\n--- a/packages/mui-base/src/SelectUnstyled/SelectUnstyled.types.ts\n+++ b/packages/mui-base/src/SelectUnstyled/SelectUnstyled.types.ts\n@@ -97,7 +97,10 @@ export interface SelectUnstyledOwnProps<TValue extends {}> extends SelectUnstyle\n   /**\n    * Callback fired when an option is selected.\n    */\n-  onChange?: (value: TValue | null) => void;\n+  onChange?: (\n+    e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+    value: TValue | null,\n+  ) => void;\n   /**\n    * A function used to convert the option label to a string.\n    * It's useful when labels are elements and need to be converted to plain text\ndiff --git a/packages/mui-base/src/SelectUnstyled/useSelect.ts b/packages/mui-base/src/SelectUnstyled/useSelect.ts\nindex a87c4977c9..9dbab1eac2 100644\n--- a/packages/mui-base/src/SelectUnstyled/useSelect.ts\n+++ b/packages/mui-base/src/SelectUnstyled/useSelect.ts\n@@ -214,10 +214,15 @@ function useSelect<TValue>(props: UseSelectParameters<TValue>) {\n       optionComparer: (o, v) => o?.value === v?.value,\n       listboxRef: handleListboxRef,\n       multiple: true,\n-      onChange: (newOptions) => {\n+      onChange: (e, newOptions) => {\n         const newValues = newOptions.map((o) => o.value);\n         setValue(newValues);\n-        (onChange as (value: TValue[]) => void)?.(newValues);\n+        (\n+          onChange as (\n+            e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+            value: TValue[],\n+          ) => void\n+        )?.(e, newValues);\n       },\n       options,\n       optionStringifier,\n@@ -230,9 +235,14 @@ function useSelect<TValue>(props: UseSelectParameters<TValue>) {\n       optionComparer: (o, v) => o?.value === v?.value,\n       listboxRef: handleListboxRef,\n       multiple: false,\n-      onChange: (option: SelectOption<TValue> | null) => {\n+      onChange: (e, option: SelectOption<TValue> | null) => {\n         setValue(option?.value ?? null);\n-        (onChange as (value: TValue | null) => void)?.(option?.value ?? null);\n+        (\n+          onChange as (\n+            e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+            value: TValue | null,\n+          ) => void\n+        )?.(e, option?.value ?? null);\n       },\n       options,\n       optionStringifier,\ndiff --git a/packages/mui-base/src/SelectUnstyled/useSelect.types.ts b/packages/mui-base/src/SelectUnstyled/useSelect.types.ts\nindex 93c1490cdf..f986878666 100644\n--- a/packages/mui-base/src/SelectUnstyled/useSelect.types.ts\n+++ b/packages/mui-base/src/SelectUnstyled/useSelect.types.ts\n@@ -41,14 +41,20 @@ interface UseSelectCommonProps<TValue> {\n export interface UseSelectSingleParameters<TValue> extends UseSelectCommonProps<TValue> {\n   defaultValue?: TValue | null;\n   multiple?: false;\n-  onChange?: (value: TValue | null) => void;\n+  onChange?: (\n+    e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+    value: TValue | null,\n+  ) => void;\n   value?: TValue | null;\n }\n \n export interface UseSelectMultiParameters<TValue> extends UseSelectCommonProps<TValue> {\n   defaultValue?: TValue[];\n   multiple: true;\n-  onChange?: (value: TValue[]) => void;\n+  onChange?: (\n+    e: React.MouseEvent | React.KeyboardEvent | React.FocusEvent | null,\n+    value: TValue[],\n+  ) => void;\n   value?: TValue[];\n }\n \n"}
{"instance_id": "mui__material-ui-28186", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/mui-material/src/useTouchRipple/useTouchRipple.ts b/packages/mui-material/src/useTouchRipple/useTouchRipple.ts\nindex 5f444d8e57..1714b25b0f 100644\n--- a/packages/mui-material/src/useTouchRipple/useTouchRipple.ts\n+++ b/packages/mui-material/src/useTouchRipple/useTouchRipple.ts\n@@ -38,6 +38,8 @@ const useTouchRipple = (props: UseTouchRippleProps) => {\n   React.useEffect(() => {\n     if (focusVisible && !disableFocusRipple && !disableRipple) {\n       rippleRef.current?.pulsate();\n+    } else {\n+      rippleRef.current?.stop();\n     }\n   }, [rippleRef, focusVisible, disableFocusRipple, disableRipple]);\n \n"}
{"instance_id": "mui__material-ui-36353", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/mui-material/src/DialogTitle/DialogTitle.js b/packages/mui-material/src/DialogTitle/DialogTitle.js\nindex 099b595797..e567305539 100644\n--- a/packages/mui-material/src/DialogTitle/DialogTitle.js\n+++ b/packages/mui-material/src/DialogTitle/DialogTitle.js\n@@ -37,7 +37,8 @@ const DialogTitle = React.forwardRef(function DialogTitle(inProps, ref) {\n   const ownerState = props;\n   const classes = useUtilityClasses(ownerState);\n \n-  const { titleId: id = idProp } = React.useContext(DialogContext);\n+  const { titleId } = React.useContext(DialogContext);\n+  const id = idProp ?? titleId;\n \n   return (\n     <DialogTitleRoot\n"}
{"instance_id": "mui__material-ui-36971", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/translations/api-docs/autocomplete/autocomplete-pt.json b/docs/translations/api-docs/autocomplete/autocomplete-pt.json\nindex 824e44e3b0..16e9c7096b 100644\n--- a/docs/translations/api-docs/autocomplete/autocomplete-pt.json\n+++ b/docs/translations/api-docs/autocomplete/autocomplete-pt.json\n@@ -56,7 +56,7 @@\n     \"readOnly\": \"If <code>true</code>, the component becomes readonly. It is also supported for multiple tags where the tag cannot be deleted.\",\n     \"renderGroup\": \"Render the group.<br><br><strong>Signature:</strong><br><code>function(option: any) =&gt; ReactNode</code><br><em>option:</em> The group to render.\",\n     \"renderInput\": \"Render the input.<br><br><strong>Signature:</strong><br><code>function(params: object) =&gt; ReactNode</code><br>\",\n-    \"renderOption\": \"Render the option, use <code>getOptionLabel</code> by default.<br><br><strong>Signature:</strong><br><code>function(props: object, option: T, state: object) =&gt; ReactNode</code><br><em>props:</em> The props to apply on the li element.<br><em>option:</em> The option to render.<br><em>state:</em> The state of the component.\",\n+    \"renderOption\": \"Render the option, use <code>getOptionLabel</code> by default.<br><br><strong>Signature:</strong><br><code>function(props: object, option: T, state: object, ownerState: object) =&gt; ReactNode</code><br><em>props:</em> The props to apply on the li element.<br><em>option:</em> The option to render.<br><em>state:</em> The state of the component.<br><em>ownerState:</em> The state of the Autocomplete component.\",\n     \"renderTags\": \"Render the selected value.<br><br><strong>Signature:</strong><br><code>function(value: Array&lt;T&gt;, getTagProps: function, ownerState: object) =&gt; ReactNode</code><br><em>value:</em> The <code>value</code> provided to the component.<br><em>getTagProps:</em> A tag props getter.<br><em>ownerState:</em> The state of the Autocomplete component.\",\n     \"selectOnFocus\": \"If <code>true</code>, the input&#39;s text is selected on focus. It helps the user clear the selected value.\",\n     \"size\": \"The size of the autocomplete.\",\ndiff --git a/docs/translations/api-docs/autocomplete/autocomplete-zh.json b/docs/translations/api-docs/autocomplete/autocomplete-zh.json\nindex 8766c05435..5a7028b5a3 100644\n--- a/docs/translations/api-docs/autocomplete/autocomplete-zh.json\n+++ b/docs/translations/api-docs/autocomplete/autocomplete-zh.json\n@@ -56,7 +56,7 @@\n     \"readOnly\": \"If <code>true</code>, the component becomes readonly. It is also supported for multiple tags where the tag cannot be deleted.\",\n     \"renderGroup\": \"Render the group.<br><br><strong>Signature:</strong><br><code>function(option: any) =&gt; ReactNode</code><br><em>option:</em> The group to render.\",\n     \"renderInput\": \"Render the input.<br><br><strong>Signature:</strong><br><code>function(params: object) =&gt; ReactNode</code><br>\",\n-    \"renderOption\": \"Render the option, use <code>getOptionLabel</code> by default.<br><br><strong>Signature:</strong><br><code>function(props: object, option: T, state: object) =&gt; ReactNode</code><br><em>props:</em> The props to apply on the li element.<br><em>option:</em> The option to render.<br><em>state:</em> The state of the component.\",\n+    \"renderOption\": \"Render the option, use <code>getOptionLabel</code> by default.<br><br><strong>Signature:</strong><br><code>function(props: object, option: T, state: object, ownerState: object) =&gt; ReactNode</code><br><em>props:</em> The props to apply on the li element.<br><em>option:</em> The option to render.<br><em>state:</em> The state of the component.<br><em>ownerState:</em> The state of the Autocomplete component.\",\n     \"renderTags\": \"Render the selected value.<br><br><strong>Signature:</strong><br><code>function(value: Array&lt;T&gt;, getTagProps: function, ownerState: object) =&gt; ReactNode</code><br><em>value:</em> The <code>value</code> provided to the component.<br><em>getTagProps:</em> A tag props getter.<br><em>ownerState:</em> The state of the Autocomplete component.\",\n     \"selectOnFocus\": \"If <code>true</code>, the input&#39;s text is selected on focus. It helps the user clear the selected value.\",\n     \"size\": \"The size of the autocomplete.\",\ndiff --git a/docs/translations/api-docs/autocomplete/autocomplete.json b/docs/translations/api-docs/autocomplete/autocomplete.json\nindex ab08b6316e..7f103aa052 100644\n--- a/docs/translations/api-docs/autocomplete/autocomplete.json\n+++ b/docs/translations/api-docs/autocomplete/autocomplete.json\n@@ -56,7 +56,7 @@\n     \"readOnly\": \"If <code>true</code>, the component becomes readonly. It is also supported for multiple tags where the tag cannot be deleted.\",\n     \"renderGroup\": \"Render the group.<br><br><strong>Signature:</strong><br><code>function(params: AutocompleteRenderGroupParams) =&gt; ReactNode</code><br><em>params:</em> The group to render.\",\n     \"renderInput\": \"Render the input.<br><br><strong>Signature:</strong><br><code>function(params: object) =&gt; ReactNode</code><br>\",\n-    \"renderOption\": \"Render the option, use <code>getOptionLabel</code> by default.<br><br><strong>Signature:</strong><br><code>function(props: object, option: T, state: object) =&gt; ReactNode</code><br><em>props:</em> The props to apply on the li element.<br><em>option:</em> The option to render.<br><em>state:</em> The state of the component.\",\n+    \"renderOption\": \"Render the option, use <code>getOptionLabel</code> by default.<br><br><strong>Signature:</strong><br><code>function(props: object, option: T, state: object, ownerState: object) =&gt; ReactNode</code><br><em>props:</em> The props to apply on the li element.<br><em>option:</em> The option to render.<br><em>state:</em> The state of the component.<br><em>ownerState:</em> The state of the Autocomplete component.\",\n     \"renderTags\": \"Render the selected value.<br><br><strong>Signature:</strong><br><code>function(value: Array&lt;T&gt;, getTagProps: function, ownerState: object) =&gt; ReactNode</code><br><em>value:</em> The <code>value</code> provided to the component.<br><em>getTagProps:</em> A tag props getter.<br><em>ownerState:</em> The state of the Autocomplete component.\",\n     \"selectOnFocus\": \"If <code>true</code>, the input&#39;s text is selected on focus. It helps the user clear the selected value.\",\n     \"size\": \"The size of the component.\",\ndiff --git a/packages/mui-material/src/Autocomplete/Autocomplete.d.ts b/packages/mui-material/src/Autocomplete/Autocomplete.d.ts\nindex a453c649cc..04175ea711 100644\n--- a/packages/mui-material/src/Autocomplete/Autocomplete.d.ts\n+++ b/packages/mui-material/src/Autocomplete/Autocomplete.d.ts\n@@ -238,12 +238,14 @@ export interface AutocompleteProps<\n    * @param {object} props The props to apply on the li element.\n    * @param {T} option The option to render.\n    * @param {object} state The state of the component.\n+   * @param {object} ownerState The state of the Autocomplete component.\n    * @returns {ReactNode}\n    */\n   renderOption?: (\n     props: React.HTMLAttributes<HTMLLIElement>,\n     option: T,\n     state: AutocompleteRenderOptionState,\n+    ownerState: AutocompleteOwnerState<T, Multiple, DisableClearable, FreeSolo, ChipComponent>,\n   ) => React.ReactNode;\n   /**\n    * Render the selected value.\ndiff --git a/packages/mui-material/src/Autocomplete/Autocomplete.js b/packages/mui-material/src/Autocomplete/Autocomplete.js\nindex 853f3be7e2..715df9ec88 100644\n--- a/packages/mui-material/src/Autocomplete/Autocomplete.js\n+++ b/packages/mui-material/src/Autocomplete/Autocomplete.js\n@@ -552,11 +552,16 @@ const Autocomplete = React.forwardRef(function Autocomplete(inProps, ref) {\n   const renderListOption = (option, index) => {\n     const optionProps = getOptionProps({ option, index });\n \n-    return renderOption({ ...optionProps, className: classes.option }, option, {\n-      selected: optionProps['aria-selected'],\n-      index,\n-      inputValue,\n-    });\n+    return renderOption(\n+      { ...optionProps, className: classes.option },\n+      option,\n+      {\n+        selected: optionProps['aria-selected'],\n+        index,\n+        inputValue,\n+      },\n+      ownerState,\n+    );\n   };\n \n   const clearIndicatorSlotProps = slotProps.clearIndicator ?? componentsProps.clearIndicator;\n@@ -1065,6 +1070,7 @@ Autocomplete.propTypes /* remove-proptypes */ = {\n    * @param {object} props The props to apply on the li element.\n    * @param {T} option The option to render.\n    * @param {object} state The state of the component.\n+   * @param {object} ownerState The state of the Autocomplete component.\n    * @returns {ReactNode}\n    */\n   renderOption: PropTypes.func,\n"}
{"instance_id": "mui__material-ui-38247", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/data/material/components/icons/TwoToneIcons.js b/docs/data/material/components/icons/TwoToneIcons.js\nindex 125785fdc2..179ee543aa 100644\n--- a/docs/data/material/components/icons/TwoToneIcons.js\n+++ b/docs/data/material/components/icons/TwoToneIcons.js\n@@ -1,6 +1,19 @@\n import * as React from 'react';\n+import { loadCSS } from 'fg-loadcss';\n import Icon from '@mui/material/Icon';\n \n export default function TwoToneIcons() {\n+  React.useEffect(() => {\n+    const node = loadCSS(\n+      'https://fonts.googleapis.com/css?family=Material+Icons+Two+Tone',\n+      // Inject before JSS\n+      document.querySelector('#material-icons-two-tone') || document.head.firstChild,\n+    );\n+\n+    return () => {\n+      node.parentNode.removeChild(node);\n+    };\n+  }, []);\n+\n   return <Icon baseClassName=\"material-icons-two-tone\">add_circle</Icon>;\n }\ndiff --git a/docs/data/material/components/icons/TwoToneIcons.tsx b/docs/data/material/components/icons/TwoToneIcons.tsx\nindex 125785fdc2..d323dc3b99 100644\n--- a/docs/data/material/components/icons/TwoToneIcons.tsx\n+++ b/docs/data/material/components/icons/TwoToneIcons.tsx\n@@ -1,6 +1,19 @@\n import * as React from 'react';\n+import { loadCSS } from 'fg-loadcss';\n import Icon from '@mui/material/Icon';\n \n export default function TwoToneIcons() {\n+  React.useEffect(() => {\n+    const node = loadCSS(\n+      'https://fonts.googleapis.com/css?family=Material+Icons+Two+Tone',\n+      // Inject before JSS\n+      document.querySelector('#material-icons-two-tone') || document.head.firstChild,\n+    );\n+\n+    return () => {\n+      node.parentNode!.removeChild(node);\n+    };\n+  }, []);\n+\n   return <Icon baseClassName=\"material-icons-two-tone\">add_circle</Icon>;\n }\n"}
{"instance_id": "prettier__prettier-12930", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/language-js/print/typescript.js b/src/language-js/print/typescript.js\nindex 32942f2d7..7aec42077 100644\n--- a/src/language-js/print/typescript.js\n+++ b/src/language-js/print/typescript.js\n@@ -414,7 +414,11 @@ function printTypescript(path, options, print) {\n \n       return parts;\n     case \"TSEnumMember\":\n-      parts.push(print(\"id\"));\n+      parts.push(\n+        node.computed ? \"[\" : \"\",\n+        print(\"id\"),\n+        node.computed ? \"]\" : \"\"\n+      );\n       if (node.initializer) {\n         parts.push(\" = \", print(\"initializer\"));\n       }\n"}
{"instance_id": "prettier__prettier-14400", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/language-html/utils/index.js b/src/language-html/utils/index.js\nindex 943ae6595..abe37f1ba 100644\n--- a/src/language-html/utils/index.js\n+++ b/src/language-html/utils/index.js\n@@ -109,6 +109,7 @@ function isScriptLikeTag(node) {\n     (node.fullName === \"script\" ||\n       node.fullName === \"style\" ||\n       node.fullName === \"svg:style\" ||\n+      node.fullName === \"svg:script\" ||\n       (isUnknownNamespace(node) &&\n         (node.name === \"script\" || node.name === \"style\")))\n   );\n"}
{"instance_id": "mui__material-ui-38544", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/packages/mui-material-next/src/Tabs/Tabs.js b/packages/mui-material-next/src/Tabs/Tabs.js\nindex bff171b48e..36ed273036 100644\n--- a/packages/mui-material-next/src/Tabs/Tabs.js\n+++ b/packages/mui-material-next/src/Tabs/Tabs.js\n@@ -432,6 +432,7 @@ const Tabs = React.forwardRef(function Tabs(inProps, ref) {\n       <TabsScrollbarSize\n         onChange={handleScrollbarSizeChange}\n         className={clsx(classes.scrollableX, classes.hideScrollbar)}\n+        ownerState={ownerState}\n       />\n     ) : null;\n \ndiff --git a/packages/mui-material/src/Tabs/Tabs.js b/packages/mui-material/src/Tabs/Tabs.js\nindex 12a9f9ba9f..530e568311 100644\n--- a/packages/mui-material/src/Tabs/Tabs.js\n+++ b/packages/mui-material/src/Tabs/Tabs.js\n@@ -504,6 +504,7 @@ const Tabs = React.forwardRef(function Tabs(inProps, ref) {\n       <TabsScrollbarSize\n         onChange={handleScrollbarSizeChange}\n         className={clsx(classes.scrollableX, classes.hideScrollbar)}\n+        ownerState={ownerState}\n       />\n     ) : null;\n \n"}
{"instance_id": "prettier__prettier-11000", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/cli/expand-patterns.js b/src/cli/expand-patterns.js\nindex 8e2e4d729..bbec7a78d 100644\n--- a/src/cli/expand-patterns.js\n+++ b/src/cli/expand-patterns.js\n@@ -4,6 +4,8 @@ const path = require(\"path\");\n const { promises: fs } = require(\"fs\");\n const fastGlob = require(\"fast-glob\");\n \n+const isWindows = path.sep === \"\\\\\";\n+\n /** @typedef {import('./context').Context} Context */\n \n /**\n@@ -76,10 +78,15 @@ async function* expandPatternsInternal(context) {\n           input: pattern,\n         });\n       } else if (stat.isDirectory()) {\n+        // Trailing slashes must be removed to avoid \"directory//\" in the glob.\n+        // On Windows, both forward and backward slashes are path separators.\n+        // On Linux/Mac, only forward slashes are path separators (backslash is valid in filenames).\n+        const trailingSlashPattern = isWindows ? /[/\\\\]+$/ : /\\/+$/;\n+        const directoryPattern = pattern.replace(trailingSlashPattern, \"\");\n         entries.push({\n           type: \"dir\",\n           glob:\n-            escapePathForGlob(fixWindowsSlashes(pattern)) +\n+            escapePathForGlob(fixWindowsSlashes(directoryPattern)) +\n             \"/\" +\n             getSupportedFilesGlob(),\n           input: pattern,\n@@ -198,8 +205,6 @@ function escapePathForGlob(path) {\n     .replace(/\\0/g, \"@(\\\\\\\\)\"); // Workaround for fast-glob#262 (part 2)\n }\n \n-const isWindows = path.sep === \"\\\\\";\n-\n /**\n  * Using backslashes in globs is probably not okay, but not accepting\n  * backslashes as path separators on Windows is even more not okay.\n"}
{"instance_id": "mui__material-ui-34207", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/translations/api-docs/form-control-label/form-control-label-pt.json b/docs/translations/api-docs/form-control-label/form-control-label-pt.json\nindex feff5b6afa..4102351394 100644\n--- a/docs/translations/api-docs/form-control-label/form-control-label-pt.json\n+++ b/docs/translations/api-docs/form-control-label/form-control-label-pt.json\n@@ -11,6 +11,7 @@\n     \"label\": \"The text to be used in an enclosing label element.\",\n     \"labelPlacement\": \"The position of the label.\",\n     \"onChange\": \"Callback fired when the state is changed.<br><br><strong>Signature:</strong><br><code>function(event: object) =&gt; void</code><br><em>event:</em> The event source of the callback. You can pull out the new checked state by accessing <code>event.target.checked</code> (boolean).\",\n+    \"required\": \"If <code>true</code>, the label will indicate that the <code>input</code> is required.\",\n     \"sx\": \"The system prop that allows defining system overrides as well as additional CSS styles. See the <a href=\\\"/system/getting-started/the-sx-prop/\\\">`sx` page</a> for more details.\",\n     \"value\": \"The value of the component.\"\n   },\n@@ -46,6 +47,15 @@\n       \"description\": \"State class applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n       \"conditions\": \"<code>error={true}</code>\"\n+    },\n+    \"required\": {\n+      \"description\": \"State class applied to {{nodeName}} if {{conditions}}.\",\n+      \"nodeName\": \"the root element\",\n+      \"conditions\": \"<code>required={true}</code>\"\n+    },\n+    \"asterisk\": {\n+      \"description\": \"Styles applied to {{nodeName}}.\",\n+      \"nodeName\": \"the asterisk element\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/form-control-label/form-control-label-zh.json b/docs/translations/api-docs/form-control-label/form-control-label-zh.json\nindex fb82af1179..088a282d7a 100644\n--- a/docs/translations/api-docs/form-control-label/form-control-label-zh.json\n+++ b/docs/translations/api-docs/form-control-label/form-control-label-zh.json\n@@ -11,6 +11,7 @@\n     \"label\": \"The text to be used in an enclosing label element.\",\n     \"labelPlacement\": \"The position of the label.\",\n     \"onChange\": \"Callback fired when the state is changed.<br><br><strong>Signature:</strong><br><code>function(event: object) =&gt; void</code><br><em>event:</em> The event source of the callback. You can pull out the new checked state by accessing <code>event.target.checked</code> (boolean).\",\n+    \"required\": \"If <code>true</code>, the label will indicate that the <code>input</code> is required.\",\n     \"sx\": \"The system prop that allows defining system overrides as well as additional CSS styles. See the <a href=\\\"/system/getting-started/the-sx-prop/\\\">`sx` page</a> for more details.\",\n     \"value\": \"The value of the component.\"\n   },\n@@ -46,6 +47,15 @@\n       \"description\": \"State class applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n       \"conditions\": \"<code>error={true}</code>\"\n+    },\n+    \"required\": {\n+      \"description\": \"State class applied to {{nodeName}} if {{conditions}}.\",\n+      \"nodeName\": \"the root element\",\n+      \"conditions\": \"<code>required={true}</code>\"\n+    },\n+    \"asterisk\": {\n+      \"description\": \"Styles applied to {{nodeName}}.\",\n+      \"nodeName\": \"the asterisk element\"\n     }\n   }\n }\ndiff --git a/docs/translations/api-docs/form-control-label/form-control-label.json b/docs/translations/api-docs/form-control-label/form-control-label.json\nindex 8c49084c06..dbc53fd933 100644\n--- a/docs/translations/api-docs/form-control-label/form-control-label.json\n+++ b/docs/translations/api-docs/form-control-label/form-control-label.json\n@@ -11,6 +11,7 @@\n     \"label\": \"A text or an element to be used in an enclosing label element.\",\n     \"labelPlacement\": \"The position of the label.\",\n     \"onChange\": \"Callback fired when the state is changed.<br><br><strong>Signature:</strong><br><code>function(event: React.SyntheticEvent) =&gt; void</code><br><em>event:</em> The event source of the callback. You can pull out the new checked state by accessing <code>event.target.checked</code> (boolean).\",\n+    \"required\": \"If <code>true</code>, the label will indicate that the <code>input</code> is required.\",\n     \"slotProps\": \"The props used for each slot inside.\",\n     \"sx\": \"The system prop that allows defining system overrides as well as additional CSS styles. See the <a href=\\\"/system/getting-started/the-sx-prop/\\\">`sx` page</a> for more details.\",\n     \"value\": \"The value of the component.\"\n@@ -45,6 +46,15 @@\n       \"description\": \"State class applied to {{nodeName}} if {{conditions}}.\",\n       \"nodeName\": \"the root element\",\n       \"conditions\": \"<code>error={true}</code>\"\n+    },\n+    \"required\": {\n+      \"description\": \"State class applied to {{nodeName}} if {{conditions}}.\",\n+      \"nodeName\": \"the root element\",\n+      \"conditions\": \"<code>required={true}</code>\"\n+    },\n+    \"asterisk\": {\n+      \"description\": \"Styles applied to {{nodeName}}.\",\n+      \"nodeName\": \"the asterisk element\"\n     }\n   }\n }\ndiff --git a/packages/mui-material/src/FormControlLabel/FormControlLabel.d.ts b/packages/mui-material/src/FormControlLabel/FormControlLabel.d.ts\nindex cf996bf876..3ba48a2d66 100644\n--- a/packages/mui-material/src/FormControlLabel/FormControlLabel.d.ts\n+++ b/packages/mui-material/src/FormControlLabel/FormControlLabel.d.ts\n@@ -59,6 +59,10 @@ export interface FormControlLabelProps\n    * You can pull out the new checked state by accessing `event.target.checked` (boolean).\n    */\n   onChange?: (event: React.SyntheticEvent, checked: boolean) => void;\n+  /**\n+   * If `true`, the label will indicate that the `input` is required.\n+   */\n+  required?: boolean;\n   /**\n    * The props used for each slot inside.\n    * @default {}\ndiff --git a/packages/mui-material/src/FormControlLabel/FormControlLabel.js b/packages/mui-material/src/FormControlLabel/FormControlLabel.js\nindex 2f4e89c2f3..63f4f02aeb 100644\n--- a/packages/mui-material/src/FormControlLabel/FormControlLabel.js\n+++ b/packages/mui-material/src/FormControlLabel/FormControlLabel.js\n@@ -14,15 +14,17 @@ import formControlLabelClasses, {\n import formControlState from '../FormControl/formControlState';\n \n const useUtilityClasses = (ownerState) => {\n-  const { classes, disabled, labelPlacement, error } = ownerState;\n+  const { classes, disabled, labelPlacement, error, required } = ownerState;\n   const slots = {\n     root: [\n       'root',\n       disabled && 'disabled',\n       `labelPlacement${capitalize(labelPlacement)}`,\n       error && 'error',\n+      required && 'required',\n     ],\n     label: ['label', disabled && 'disabled'],\n+    asterisk: ['asterisk', error && 'error'],\n   };\n \n   return composeClasses(slots, getFormControlLabelUtilityClasses, classes);\n@@ -72,6 +74,16 @@ export const FormControlLabelRoot = styled('label', {\n   },\n }));\n \n+const AsteriskComponent = styled('span', {\n+  name: 'MuiFormControlLabel',\n+  slot: 'Asterisk',\n+  overridesResolver: (props, styles) => styles.asterisk,\n+})(({ theme }) => ({\n+  [`&.${formControlLabelClasses.error}`]: {\n+    color: (theme.vars || theme).palette.error.main,\n+  },\n+}));\n+\n /**\n  * Drop-in replacement of the `Radio`, `Switch` and `Checkbox` component.\n  * Use this component if you want to display an extra label.\n@@ -90,6 +102,7 @@ const FormControlLabel = React.forwardRef(function FormControlLabel(inProps, ref\n     labelPlacement = 'end',\n     name,\n     onChange,\n+    required: requiredProp,\n     slotProps = {},\n     value,\n     ...other\n@@ -105,8 +118,17 @@ const FormControlLabel = React.forwardRef(function FormControlLabel(inProps, ref\n     disabled = muiFormControl.disabled;\n   }\n \n+  let required = requiredProp;\n+  if (typeof required === 'undefined' && typeof control.props.required !== 'undefined') {\n+    required = control.props.required;\n+  }\n+  if (typeof required === 'undefined' && muiFormControl) {\n+    required = muiFormControl.required;\n+  }\n+\n   const controlProps = {\n     disabled,\n+    required,\n   };\n \n   ['checked', 'name', 'onChange', 'value', 'inputRef'].forEach((key) => {\n@@ -125,6 +147,7 @@ const FormControlLabel = React.forwardRef(function FormControlLabel(inProps, ref\n     ...props,\n     disabled,\n     labelPlacement,\n+    required,\n     error: fcs.error,\n   };\n \n@@ -153,7 +176,16 @@ const FormControlLabel = React.forwardRef(function FormControlLabel(inProps, ref\n       {...other}\n     >\n       {React.cloneElement(control, controlProps)}\n-      {label}\n+      {required ? (\n+        <span>\n+          {label}\n+          <AsteriskComponent ownerState={ownerState} className={classes.asterisk}>\n+            &thinsp;{'*'}\n+          </AsteriskComponent>\n+        </span>\n+      ) : (\n+        label\n+      )}\n     </FormControlLabelRoot>\n   );\n });\n@@ -218,6 +250,10 @@ FormControlLabel.propTypes /* remove-proptypes */ = {\n    * You can pull out the new checked state by accessing `event.target.checked` (boolean).\n    */\n   onChange: PropTypes.func,\n+  /**\n+   * If `true`, the label will indicate that the `input` is required.\n+   */\n+  required: PropTypes.bool,\n   /**\n    * The props used for each slot inside.\n    * @default {}\ndiff --git a/packages/mui-material/src/FormControlLabel/formControlLabelClasses.ts b/packages/mui-material/src/FormControlLabel/formControlLabelClasses.ts\nindex 65b25aa6cc..b66860a7a3 100644\n--- a/packages/mui-material/src/FormControlLabel/formControlLabelClasses.ts\n+++ b/packages/mui-material/src/FormControlLabel/formControlLabelClasses.ts\n@@ -16,6 +16,10 @@ export interface FormControlLabelClasses {\n   label: string;\n   /** State class applied to the root element if `error={true}`. */\n   error: string;\n+  /** State class applied to the root element if `required={true}`. */\n+  required: string;\n+  /** Styles applied to the asterisk element. */\n+  asterisk: string;\n }\n \n export type FormControlLabelClassKey = keyof FormControlLabelClasses;\n@@ -34,6 +38,8 @@ const formControlLabelClasses: FormControlLabelClasses = generateUtilityClasses(\n     'disabled',\n     'label',\n     'error',\n+    'required',\n+    'asterisk',\n   ],\n );\n \n"}
{"instance_id": "prettier__prettier-11637", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/language-css/printer-postcss.js b/src/language-css/printer-postcss.js\nindex 0c326d6d2..c7a96c14c 100644\n--- a/src/language-css/printer-postcss.js\n+++ b/src/language-css/printer-postcss.js\n@@ -555,8 +555,10 @@ function genericPrint(path, options, print) {\n           insideAtRuleNode(path, \"forward\") &&\n           iNode.type === \"value-word\" &&\n           iNode.value &&\n+          iPrevNode &&\n           iPrevNode.type === \"value-word\" &&\n           iPrevNode.value === \"as\" &&\n+          iNextNode &&\n           iNextNode.type === \"value-operator\" &&\n           iNextNode.value === \"*\"\n         ) {\n@@ -769,6 +771,18 @@ function genericPrint(path, options, print) {\n           continue;\n         }\n \n+        // Add `space` before SCSS module `with` paren group (i.e. `@use \"...\" with ($var: 1)`)\n+        if (\n+          insideAtRuleNode(path, [\"use\", \"forward\"]) &&\n+          iNode.type === \"value-word\" &&\n+          iNode.value === \"with\" &&\n+          iNextNode.type === \"value-paren_group\"\n+        ) {\n+          parts.push(\" \");\n+\n+          continue;\n+        }\n+\n         // Formatting `grid` property\n         if (isGridValue) {\n           if (\n@@ -919,6 +933,18 @@ function genericPrint(path, options, print) {\n         }\n       );\n \n+      // Dedent for SCSS module `with` paren group to avoid double indentation\n+      // (one from value-comma_group and one from value-paren_group)\n+      const parentParentNode = path.getParentNode(1);\n+      if (\n+        insideAtRuleNode(path, [\"use\", \"forward\"]) &&\n+        parentNode.type === \"value-comma_group\" &&\n+        parentParentNode &&\n+        parentParentNode.type === \"value-value\"\n+      ) {\n+        return group(dedent(printed));\n+      }\n+\n       return isKey ? dedent(printed) : printed;\n     }\n     case \"value-func\": {\n"}
{"instance_id": "prettier__prettier-459", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/printer.js b/src/printer.js\nindex 28990dde8..8472aef4a 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -51,9 +51,13 @@ function genericPrint(path, options, printPath) {\n       // responsible for printing node.decorators.\n       !util.getParentExportDeclaration(path)\n   ) {\n+    const separator = node.type === \"ClassMethod\" ||\n+      node.type === \"ClassProperty\"\n+      ? \" \"\n+      : line;\n     path.each(\n       function(decoratorPath) {\n-        parts.push(printPath(decoratorPath), line);\n+        parts.push(printPath(decoratorPath), separator);\n       },\n       \"decorators\"\n     );\n"}
{"instance_id": "prettier__prettier-3723", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/language-css/printer-postcss.js b/src/language-css/printer-postcss.js\nindex 794ae8035..b8898c230 100644\n--- a/src/language-css/printer-postcss.js\n+++ b/src/language-css/printer-postcss.js\n@@ -30,7 +30,13 @@ function genericPrint(path, options, print) {\n \n   switch (n.type) {\n     case \"css-root\": {\n-      return concat([printNodeSequence(path, options, print), hardline]);\n+      const nodes = printNodeSequence(path, options, print);\n+\n+      if (n.nodes.length === 0) {\n+        return nodes;\n+      }\n+\n+      return concat([nodes, hardline]);\n     }\n     case \"css-comment\": {\n       if (n.raws.content) {\n"}
{"instance_id": "prettier__prettier-3436", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/fast-path.js b/src/fast-path.js\nindex 7e346df66..83ec429d0 100644\n--- a/src/fast-path.js\n+++ b/src/fast-path.js\n@@ -371,24 +371,8 @@ FastPath.prototype.needsParens = function(options) {\n       }\n \n     case \"TSParenthesizedType\": {\n-      const grandParent = this.getParentNode(1);\n-      if (\n-        (parent.type === \"TypeParameter\" ||\n-          parent.type === \"VariableDeclarator\" ||\n-          parent.type === \"TypeAnnotation\" ||\n-          parent.type === \"GenericTypeAnnotation\" ||\n-          parent.type === \"TSTypeReference\") &&\n-        (node.typeAnnotation.type === \"TypeAnnotation\" &&\n-          node.typeAnnotation.typeAnnotation.type !== \"TSFunctionType\" &&\n-          grandParent.type !== \"TSTypeOperator\")\n-      ) {\n-        return false;\n-      }\n-      // Delegate to inner TSParenthesizedType\n-      if (node.typeAnnotation.type === \"TSParenthesizedType\") {\n-        return false;\n-      }\n-      return true;\n+      // Parentheses are now handled directly in the printer\n+      return false;\n     }\n \n     case \"SequenceExpression\":\ndiff --git a/src/printer.js b/src/printer.js\nindex fe7b38c0b..b43b5285e 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -215,12 +215,25 @@ function genericPrint(path, options, printPath, args) {\n   parts.push(linesWithoutParens);\n \n   if (needsParens) {\n+    // For union and intersection types, add softline before closing paren\n+    // so that the closing paren is on its own line when the content breaks\n+    const isUnionOrIntersection =\n+      node.type === \"UnionTypeAnnotation\" ||\n+      node.type === \"TSUnionType\" ||\n+      node.type === \"IntersectionTypeAnnotation\" ||\n+      node.type === \"TSIntersectionType\";\n+    if (isUnionOrIntersection) {\n+      parts.push(softline);\n+    }\n     parts.push(\")\");\n   }\n \n   if (decorators.length > 0) {\n     return group(concat(decorators.concat(parts)));\n   }\n+  if (needsParens) {\n+    return group(concat(parts));\n+  }\n   return concat(parts);\n }\n \n@@ -2569,7 +2582,29 @@ function genericPrintNoParens(path, options, print, args) {\n     case \"TSTypeQuery\":\n       return concat([\"typeof \", path.call(print, \"exprName\")]);\n     case \"TSParenthesizedType\": {\n-      return path.call(print, \"typeAnnotation\");\n+      const parent = path.getParentNode();\n+      const grandParent = path.getParentNode(1);\n+      // Check if parentheses should be removed (same logic as original needsParens)\n+      if (\n+        (parent.type === \"TypeParameter\" ||\n+          parent.type === \"VariableDeclarator\" ||\n+          parent.type === \"TypeAnnotation\" ||\n+          parent.type === \"GenericTypeAnnotation\" ||\n+          parent.type === \"TSTypeReference\") &&\n+        (n.typeAnnotation.type === \"TypeAnnotation\" &&\n+          n.typeAnnotation.typeAnnotation.type !== \"TSFunctionType\" &&\n+          grandParent.type !== \"TSTypeOperator\")\n+      ) {\n+        return path.call(print, \"typeAnnotation\");\n+      }\n+      // Delegate to inner TSParenthesizedType\n+      if (n.typeAnnotation.type === \"TSParenthesizedType\") {\n+        return path.call(print, \"typeAnnotation\");\n+      }\n+      // Print parentheses with proper line breaks\n+      return group(\n+        concat([\"(\", path.call(print, \"typeAnnotation\"), softline, \")\"])\n+      );\n     }\n     case \"TSIndexSignature\": {\n       const parent = path.getParentNode();\n"}
{"instance_id": "prettier__prettier-3515", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/cli-logger.js b/src/cli-logger.js\nindex 5a390d23f..1ae8aa064 100644\n--- a/src/cli-logger.js\n+++ b/src/cli-logger.js\n@@ -40,9 +40,21 @@ function shouldLog(loggerName) {\n   }\n }\n \n+function isSilent() {\n+  return process.env[ENV_LOG_LEVEL] === \"silent\";\n+}\n+\n+function log(message) {\n+  if (!isSilent()) {\n+    console.log(message);\n+  }\n+}\n+\n module.exports = {\n   warn,\n   error,\n   debug,\n+  log,\n+  isSilent,\n   ENV_LOG_LEVEL\n };\ndiff --git a/src/cli-util.js b/src/cli-util.js\nindex 27c0494d2..7167cd425 100644\n--- a/src/cli-util.js\n+++ b/src/cli-util.js\n@@ -305,7 +305,9 @@ function eachFilename(argv, patterns, callback) {\n \n function formatFiles(argv) {\n   eachFilename(argv, argv.__filePatterns, (filename, options) => {\n-    if (argv[\"write\"] && process.stdout.isTTY) {\n+    const isTTY = process.stdout.isTTY && !logger.isSilent();\n+\n+    if (argv[\"write\"] && isTTY) {\n       // Don't use `console.log` here since we need to replace this line.\n       process.stdout.write(filename);\n     }\n@@ -315,7 +317,9 @@ function formatFiles(argv) {\n       input = fs.readFileSync(filename, \"utf8\");\n     } catch (error) {\n       // Add newline to split errors from filename line.\n-      process.stdout.write(\"\\n\");\n+      if (isTTY) {\n+        process.stdout.write(\"\\n\");\n+      }\n \n       logger.error(`Unable to read file: ${filename}\\n${error.message}`);\n       // Don't exit the process if one file failed\n@@ -339,14 +343,16 @@ function formatFiles(argv) {\n       output = result.formatted;\n     } catch (error) {\n       // Add newline to split errors from filename line.\n-      process.stdout.write(\"\\n\");\n+      if (isTTY) {\n+        process.stdout.write(\"\\n\");\n+      }\n \n       handleError(filename, error);\n       return;\n     }\n \n     if (argv[\"write\"]) {\n-      if (process.stdout.isTTY) {\n+      if (isTTY) {\n         // Remove previously printed filename to log it with duration.\n         readline.clearLine(process.stdout, 0);\n         readline.cursorTo(process.stdout, 0, null);\n@@ -356,13 +362,13 @@ function formatFiles(argv) {\n       // mtime based caches.\n       if (output === input) {\n         if (!argv[\"list-different\"]) {\n-          console.log(`${chalk.grey(filename)} ${Date.now() - start}ms`);\n+          logger.log(`${chalk.grey(filename)} ${Date.now() - start}ms`);\n         }\n       } else {\n         if (argv[\"list-different\"]) {\n-          console.log(filename);\n+          logger.log(filename);\n         } else {\n-          console.log(`${filename} ${Date.now() - start}ms`);\n+          logger.log(`${filename} ${Date.now() - start}ms`);\n         }\n \n         try {\ndiff --git a/tests_integration/__tests__/__snapshots__/debug-check.js.snap b/tests_integration/__tests__/__snapshots__/debug-check.js.snap\nindex 28cc9e705..b17deb479 100644\n--- a/tests_integration/__tests__/__snapshots__/debug-check.js.snap\n+++ b/tests_integration/__tests__/__snapshots__/debug-check.js.snap\n@@ -58,10 +58,6 @@ exports[`show diff for 2+ error files with --debug-check (stderr) 1`] = `\n \"\n `;\n \n-exports[`show diff for 2+ error files with --debug-check (stdout) 1`] = `\n-\"\n-\n-\"\n-`;\n+exports[`show diff for 2+ error files with --debug-check (stdout) 1`] = `\"\"`;\n \n exports[`show diff for 2+ error files with --debug-check (write) 1`] = `Array []`;\ndiff --git a/tests_integration/__tests__/__snapshots__/write.js.snap b/tests_integration/__tests__/__snapshots__/write.js.snap\nindex 39ef6f484..2251d45d2 100644\n--- a/tests_integration/__tests__/__snapshots__/write.js.snap\n+++ b/tests_integration/__tests__/__snapshots__/write.js.snap\n@@ -14,10 +14,7 @@ exports[`do not write file with --write + invalid file (stderr) 1`] = `\n \"\n `;\n \n-exports[`do not write file with --write + invalid file (stdout) 1`] = `\n-\"\n-\"\n-`;\n+exports[`do not write file with --write + invalid file (stdout) 1`] = `\"\"`;\n \n exports[`write file with --write + unformatted file (stderr) 1`] = `\"\"`;\n \n"}
{"instance_id": "prettier__prettier-361", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/printer.js b/src/printer.js\nindex 2468bbdba..5ae05622f 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -1841,24 +1841,53 @@ function printExportDeclaration(path, options, print) {\n       ) {\n         parts.push(\"*\");\n       } else {\n-        parts.push(\n-          decl.exportKind === \"type\" ? \"type \" : \"\",\n-          multilineGroup(\n-            concat([\n-              \"{\",\n-              indent(\n-                options.tabWidth,\n-                concat([\n-                  options.bracketSpacing ? line : softline,\n-                  join(concat([ \",\", line ]), path.map(print, \"specifiers\"))\n-                ])\n-              ),\n-              ifBreak(options.trailingComma ? \",\" : \"\"),\n-              options.bracketSpacing ? line : softline,\n-              \"}\"\n-            ])\n-          )\n+        var standalones = [];\n+        var grouped = [];\n+\n+        path.each(\n+          function(specifierPath) {\n+            var value = specifierPath.getValue();\n+            if (\n+              value.type === \"ExportDefaultSpecifier\" ||\n+                value.type === \"ExportNamespaceSpecifier\"\n+            ) {\n+              standalones.push(print(specifierPath));\n+            } else {\n+              grouped.push(print(specifierPath));\n+            }\n+          },\n+          \"specifiers\"\n         );\n+\n+        parts.push(decl.exportKind === \"type\" ? \"type \" : \"\");\n+\n+        if (standalones.length > 0) {\n+          parts.push(join(\", \", standalones));\n+        }\n+\n+        if (standalones.length > 0 && grouped.length > 0) {\n+          parts.push(\", \");\n+        }\n+\n+        if (grouped.length > 0) {\n+          parts.push(\n+            multilineGroup(\n+              concat([\n+                \"{\",\n+                indent(\n+                  options.tabWidth,\n+                  concat([\n+                    options.bracketSpacing ? line : softline,\n+                    join(concat([ \",\", line ]), grouped)\n+                  ])\n+                ),\n+                ifBreak(options.trailingComma ? \",\" : \"\"),\n+                options.bracketSpacing ? line : softline,\n+                \"}\"\n+              ])\n+            )\n+          );\n+        }\n       }\n     } else {\n       parts.push(\"{}\");\n"}
{"instance_id": "prettier__prettier-6604", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 9ee6b63bb..06626a69d 100644\n--- a/package.json\n+++ b/package.json\n@@ -2,9 +2,7 @@\n   \"name\": \"prettier\",\n   \"version\": \"1.18.2\",\n   \"description\": \"Prettier is an opinionated code formatter\",\n-  \"bin\": {\n-    \"prettier\": \"./bin/prettier.js\"\n-  },\n+  \"bin\": \"./bin/prettier.js\",\n   \"repository\": \"prettier/prettier\",\n   \"homepage\": \"https://prettier.io\",\n   \"author\": \"James Long\",\ndiff --git a/src/language-js/needs-parens.js b/src/language-js/needs-parens.js\nindex 014c16da6..61e5094dd 100644\n--- a/src/language-js/needs-parens.js\n+++ b/src/language-js/needs-parens.js\n@@ -408,13 +408,6 @@ function needsParens(path, options) {\n       ) {\n         return false;\n       }\n-      // Delegate to inner TSParenthesizedType\n-      if (\n-        node.typeAnnotation.type === \"TSParenthesizedType\" &&\n-        parent.type !== \"TSArrayType\"\n-      ) {\n-        return false;\n-      }\n       return true;\n     }\n \n"}
{"instance_id": "prettier__prettier-661", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/printer.js b/src/printer.js\nindex b99391c46..9d24934e8 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -1219,7 +1219,7 @@ function genericPrintNoParens(path, options, print) {\n                 path.map(attr => concat([line, print(attr)]), \"attributes\")\n               )\n             ),\n-            n.selfClosing ? line : softline\n+            n.selfClosing ? line : \"\"\n           ]),\n           n.selfClosing ? \"/>\" : \">\"\n         ])\n"}
{"instance_id": "prettier__prettier-4667", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/config/resolve-config.js b/src/config/resolve-config.js\nindex 229caf3d5..726c27577 100644\n--- a/src/config/resolve-config.js\n+++ b/src/config/resolve-config.js\n@@ -105,6 +105,24 @@ function mergeOverrides(configResult, filePath) {\n   }\n \n   delete options.overrides;\n+\n+  // Resolve relative paths for plugins and pluginSearchDirs relative to the config file\n+  if (configResult.filepath) {\n+    const configDir = path.dirname(configResult.filepath);\n+    if (options.plugins) {\n+      options.plugins = options.plugins.map(plugin =>\n+        typeof plugin === \"string\" && !path.isAbsolute(plugin)\n+          ? path.resolve(configDir, plugin)\n+          : plugin\n+      );\n+    }\n+    if (options.pluginSearchDirs) {\n+      options.pluginSearchDirs = options.pluginSearchDirs.map(dir =>\n+        !path.isAbsolute(dir) ? path.resolve(configDir, dir) : dir\n+      );\n+    }\n+  }\n+\n   return options;\n }\n \ndiff --git a/tests_integration/__tests__/config-resolution.js b/tests_integration/__tests__/config-resolution.js\nindex 25a610e53..6530d37c5 100644\n--- a/tests_integration/__tests__/config-resolution.js\n+++ b/tests_integration/__tests__/config-resolution.js\n@@ -226,3 +226,40 @@ test(\"API resolveConfig.sync removes $schema option\", () => {\n     tabWidth: 42\n   });\n });\n+\n+test(\"API resolveConfig resolves relative paths for plugins\", () => {\n+  const file = path.resolve(\n+    path.join(__dirname, \"../cli/config-plugins/file.js\")\n+  );\n+  const configDir = path.resolve(\n+    path.join(__dirname, \"../cli/config-plugins\")\n+  );\n+  return prettier.resolveConfig(file).then(result => {\n+    expect(result.plugins).toEqual([\n+      path.resolve(configDir, \"./my-plugin\"),\n+      path.resolve(configDir, \"../other-plugin\")\n+    ]);\n+    expect(result.pluginSearchDirs).toEqual([\n+      path.resolve(configDir, \"./search-dir\"),\n+      path.resolve(configDir, \"../other-search-dir\")\n+    ]);\n+  });\n+});\n+\n+test(\"API resolveConfig.sync resolves relative paths for plugins\", () => {\n+  const file = path.resolve(\n+    path.join(__dirname, \"../cli/config-plugins/file.js\")\n+  );\n+  const configDir = path.resolve(\n+    path.join(__dirname, \"../cli/config-plugins\")\n+  );\n+  const result = prettier.resolveConfig.sync(file);\n+  expect(result.plugins).toEqual([\n+    path.resolve(configDir, \"./my-plugin\"),\n+    path.resolve(configDir, \"../other-plugin\")\n+  ]);\n+  expect(result.pluginSearchDirs).toEqual([\n+    path.resolve(configDir, \"./search-dir\"),\n+    path.resolve(configDir, \"../other-search-dir\")\n+  ]);\n+});\ndiff --git a/tests_integration/cli/config-plugins/.prettierrc b/tests_integration/cli/config-plugins/.prettierrc\nnew file mode 100644\nindex 000000000..f674fafe8\n--- /dev/null\n+++ b/tests_integration/cli/config-plugins/.prettierrc\n@@ -0,0 +1,4 @@\n+{\n+  \"plugins\": [\"./my-plugin\", \"../other-plugin\"],\n+  \"pluginSearchDirs\": [\"./search-dir\", \"../other-search-dir\"]\n+}\ndiff --git a/tests_integration/cli/config-plugins/file.js b/tests_integration/cli/config-plugins/file.js\nnew file mode 100644\nindex 000000000..943c458c7\n--- /dev/null\n+++ b/tests_integration/cli/config-plugins/file.js\n@@ -0,0 +1 @@\n+const x = 1;\n"}
{"instance_id": "serverless__serverless-1910", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/event.json b/event.json\nnew file mode 100644\nindex 000000000..2ac50a459\n--- /dev/null\n+++ b/event.json\n@@ -0,0 +1,5 @@\n+{\n+  \"key3\": \"value3\",\n+  \"key2\": \"value2\",\n+  \"key1\": \"value1\"\n+}\ndiff --git a/handler.js b/handler.js\nnew file mode 100644\nindex 000000000..abf8c236a\n--- /dev/null\n+++ b/handler.js\n@@ -0,0 +1,8 @@\n+'use strict';\n+\n+// Your first function handler\n+module.exports.hello = (event, context, cb) => {\n+  cb(null, { message: 'Go Serverless v1.0! Your function executed successfully!', event });\n+};\n+\n+// You can add more handlers here, and reference them in serverless.yml\ndiff --git a/lib/plugins/create/create.js b/lib/plugins/create/create.js\nindex 4d77a7c3c..739ff73cc 100644\n--- a/lib/plugins/create/create.js\n+++ b/lib/plugins/create/create.js\n@@ -36,6 +36,10 @@ class Create {\n             usage: 'The path where the service should be created (e.g. --path my-service)',\n             shortcut: 'p',\n           },\n+          name: {\n+            usage: 'Name for the service. Overwrites the default name of the created service.',\n+            shortcut: 'n',\n+          },\n         },\n       },\n     };\n@@ -77,9 +81,9 @@ class Create {\n     this.serverless.utils.copyDirContentsSync(path.join(this.serverless.config.serverlessPath,\n       'plugins', 'create', 'templates', this.options.template), this.serverless.config.servicePath);\n \n-    // rename the service if the user has provided a path via options\n-    if (servicePath) {\n-      const serviceName = servicePath.split(path.sep).pop();\n+    // rename the service if the user has provided a path via options or a name\n+    const serviceName = this.options.name || (servicePath && servicePath.split(path.sep).pop());\n+    if (serviceName) {\n       const serverlessYmlFilePath = path\n         .join(this.serverless.config.servicePath, 'serverless.yml');\n \n@@ -96,7 +100,7 @@ class Create {\n     this.serverless.cli\n       .log(`Successfully created service with template: \"${this.options.template}\"`);\n \n-    if (!servicePath) {\n+    if (!serviceName) {\n       this.serverless.cli\n         .log('NOTE: Please update the \"service\" property in serverless.yml with your service name');\n     }\ndiff --git a/serverless.yml b/serverless.yml\nnew file mode 100644\nindex 000000000..d5269276d\n--- /dev/null\n+++ b/serverless.yml\n@@ -0,0 +1,70 @@\n+# Welcome to Serverless!\n+#\n+# This file is the main config file for your service.\n+# It's very minimal at this point and uses default values.\n+# You can always add more config options for more control.\n+# We've included some commented out config examples here.\n+# Just uncomment any of them to get that config option.\n+#\n+# For full config options, check the docs:\n+#    docs.serverless.com\n+#\n+# Happy Coding!\n+\n+service: aws-nodejs # NOTE: update this with your service name\n+\n+provider:\n+  name: aws\n+  runtime: nodejs4.3\n+\n+# you can overwrite defaults here\n+#  stage: dev\n+#  region: us-east-1\n+\n+# you can add statements to the Lambda function's IAM Role here\n+#  iamRoleStatements:\n+#    - Effect: \"Allow\"\n+#      Action:\n+#        - \"s3:ListBucket\"\n+#      Resource: { \"Fn::Join\" : [\"\", [\"arn:aws:s3:::\", { \"Ref\" : \"ServerlessDeploymentBucket\" } ] ]  }\n+#    - Effect: \"Allow\"\n+#      Action:\n+#        - \"s3:PutObject\"\n+#      Resource:\n+#        Fn::Join:\n+#          - \"\"\n+#          - - \"arn:aws:s3:::\"\n+#            - \"Ref\" : \"ServerlessDeploymentBucket\"\n+\n+# you can add packaging information here\n+#package:\n+#  include:\n+#    - include-me.js\n+#  exclude:\n+#    - exclude-me.js\n+#  artifact: my-service-code.zip\n+\n+functions:\n+  hello:\n+    handler: handler.hello\n+\n+#    you can add any of the following events\n+#    events:\n+#      - http:\n+#          path: users/create\n+#          method: get\n+#      - s3: ${env:BUCKET}\n+#      - schedule: rate(10 minutes)\n+#      - sns: greeter-topic\n+\n+# you can add CloudFormation resource templates here\n+#resources:\n+#  Resources:\n+#    NewResource:\n+#      Type: AWS::S3::Bucket\n+#      Properties:\n+#        BucketName: my-new-bucket\n+#  Outputs:\n+#     NewOutput:\n+#       Description: \"Description for the output\"\n+#       Value: \"Some output value\"\n"}
{"instance_id": "prettier__prettier-666", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/printer.js b/src/printer.js\nindex e78ec9718..93ccefa36 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -809,7 +809,18 @@ function genericPrintNoParens(path, options, print) {\n       if (n.prefix) parts.reverse();\n \n       return concat(parts);\n-    case \"ConditionalExpression\":\n+    case \"ConditionalExpression\": {\n+      // We need to check if the consequent or alternate has leading comments.\n+      // If they do, we need to print a hardline after ? or : so that the\n+      // comments remain on their own lines when re-parsed.\n+      const consequent = n.consequent;\n+      const alternate = n.alternate;\n+      \n+      const hasConsequentLeadingComments = consequent.comments &&\n+        consequent.comments.some(comment => comment.leading);\n+      const hasAlternateLeadingComments = alternate.comments &&\n+        alternate.comments.some(comment => comment.leading);\n+      \n       return group(\n         concat([\n           path.call(print, \"test\"),\n@@ -817,15 +828,20 @@ function genericPrintNoParens(path, options, print) {\n             options.tabWidth,\n             concat([\n               line,\n-              \"? \",\n-              indent(2, path.call(print, \"consequent\")),\n+              \"?\",\n+              hasConsequentLeadingComments\n+                ? concat([hardline, indent(2, path.call(print, \"consequent\"))])\n+                : concat([\" \", indent(2, path.call(print, \"consequent\"))]),\n               line,\n-              \": \",\n-              indent(2, path.call(print, \"alternate\"))\n+              \":\",\n+              hasAlternateLeadingComments\n+                ? concat([hardline, indent(2, path.call(print, \"alternate\"))])\n+                : concat([\" \", indent(2, path.call(print, \"alternate\"))])\n             ])\n           )\n         ])\n       );\n+    }\n     case \"NewExpression\":\n       parts.push(\"new \", path.call(print, \"callee\"));\n \n"}
{"instance_id": "serverless__serverless-2014", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/deploy/compile/events/apiGateway/lib/methods.js b/lib/plugins/aws/deploy/compile/events/apiGateway/lib/methods.js\nindex 8895c7f60..56986733b 100644\n--- a/lib/plugins/aws/deploy/compile/events/apiGateway/lib/methods.js\n+++ b/lib/plugins/aws/deploy/compile/events/apiGateway/lib/methods.js\n@@ -220,6 +220,19 @@ module.exports = {\n                 cors.headers = headers;\n               }\n \n+              if (cors.origins) {\n+                if (!Array.isArray(cors.origins)) {\n+                  const errorMessage = [\n+                    'CORS origin values must be provided as an array.',\n+                    ' Please check the docs for more info.',\n+                  ].join('');\n+                  throw new this.serverless.classes\n+                  .Error(errorMessage);\n+                }\n+              } else {\n+                cors.origins = ['*'];\n+              }\n+\n               if (!cors.methods.indexOf('OPTIONS') > -1) {\n                 cors.methods.push('OPTIONS');\n               }\n@@ -233,7 +246,9 @@ module.exports = {\n \n             if (corsConfig[path]) {\n               cors.methods = _.union(cors.methods, corsConfig[path].methods);\n-              corsConfig[path] = _.merge(corsConfig[path], cors);\n+              cors.headers = _.union(cors.headers, corsConfig[path].headers);\n+              cors.origins = _.union(cors.origins, corsConfig[path].origins);\n+              corsConfig[path] = cors;\n             } else {\n               corsConfig[path] = cors;\n             }\n"}
{"instance_id": "serverless__serverless-2576", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/lib/monitorStack.js b/lib/plugins/aws/lib/monitorStack.js\nindex 3c3e49e8c..48c5448a8 100644\n--- a/lib/plugins/aws/lib/monitorStack.js\n+++ b/lib/plugins/aws/lib/monitorStack.js\n@@ -77,7 +77,7 @@ module.exports = {\n                 });\n                 // Handle stack create/update/delete failures\n                 if ((stackLatestError && !this.options.verbose)\n-                || (stackStatus.endsWith('ROLLBACK_COMPLETE') && this.options.verbose)) {\n+                || (stackStatus && stackStatus.endsWith('ROLLBACK_COMPLETE') && this.options.verbose)) {\n                   this.serverless.cli.log('Deployment failed!');\n                   let errorMessage = 'An error occurred while provisioning your stack: ';\n                   errorMessage += `${stackLatestError.LogicalResourceId} - `;\n"}
{"instance_id": "prettier__prettier-8046", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/language-js/postprocess.js b/src/language-js/postprocess.js\nindex 5b1cff5bb..0e689c2b7 100644\n--- a/src/language-js/postprocess.js\n+++ b/src/language-js/postprocess.js\n@@ -4,6 +4,7 @@ const {\n   getLast,\n   getNextNonSpaceNonCommentCharacter,\n } = require(\"../common/util\");\n+const createError = require(\"../common/parser-create-error\");\n const { composeLoc, locEnd } = require(\"./loc\");\n const { isTypeCastComment } = require(\"./comments\");\n \n@@ -50,6 +51,15 @@ function postprocess(ast, options) {\n         }\n         break;\n       }\n+      // babel-ts produces this node type when parsing invalid TypeScript like `(a:b)`\n+      // We need to throw a proper error for this case\n+      case \"TSTypeCastExpression\":\n+        throw createError(\"Did not expect a type annotation here.\", {\n+          start: {\n+            line: node.typeAnnotation.loc.start.line,\n+            column: node.typeAnnotation.loc.start.column + 1,\n+          },\n+        });\n       // fix unexpected locEnd caused by --no-semi style\n       case \"VariableDeclaration\": {\n         const lastDeclaration = getLast(node.declarations);\n"}
{"instance_id": "prettier__prettier-5025", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/language-markdown/printer-markdown.js b/src/language-markdown/printer-markdown.js\nindex b6e66b2f8..53714ac57 100644\n--- a/src/language-markdown/printer-markdown.js\n+++ b/src/language-markdown/printer-markdown.js\n@@ -345,23 +345,40 @@ function genericPrint(path, options, print) {\n       return concat([\"[^\", node.identifier, \"]\"]);\n     case \"footnoteDefinition\": {\n       const nextNode = path.getParentNode().children[path.getName() + 1];\n+      const firstChild = node.children[0];\n+      // Check if the first child starts on the same line as the footnote definition\n+      // and is a single-line element (like a paragraph that fits on one line)\n+      const shouldInlineFirstChild =\n+        node.children.length > 0 &&\n+        node.position.start.line === firstChild.position.start.line &&\n+        firstChild.position.start.line === firstChild.position.end.line;\n       return concat([\n         \"[^\",\n         node.identifier,\n         \"]: \",\n         group(\n-          concat([\n-            align(\n-              \" \".repeat(options.tabWidth),\n-              printChildren(path, options, print, {\n-                processor: (childPath, index) =>\n-                  index === 0\n-                    ? group(concat([softline, softline, childPath.call(print)]))\n-                    : childPath.call(print)\n-              })\n-            ),\n-            nextNode && nextNode.type === \"footnoteDefinition\" ? softline : \"\"\n-          ])\n+          shouldInlineFirstChild\n+            ? concat([\n+                align(\n+                  \" \".repeat(options.tabWidth),\n+                  printChildren(path, options, print)\n+                ),\n+                nextNode && nextNode.type === \"footnoteDefinition\" ? softline : \"\"\n+              ])\n+            : concat([\n+                align(\n+                  \" \".repeat(options.tabWidth),\n+                  printChildren(path, options, print, {\n+                    processor: (childPath, index) =>\n+                      index === 0\n+                        ? group(\n+                            concat([softline, softline, childPath.call(print)])\n+                          )\n+                        : childPath.call(print)\n+                  })\n+                ),\n+                nextNode && nextNode.type === \"footnoteDefinition\" ? softline : \"\"\n+              ])\n         )\n       ]);\n     }\n"}
{"instance_id": "serverless__serverless-2945", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/deploy/lib/mergeIamTemplates.js b/lib/plugins/aws/deploy/lib/mergeIamTemplates.js\nindex a85c8518b..9767e19f9 100644\n--- a/lib/plugins/aws/deploy/lib/mergeIamTemplates.js\n+++ b/lib/plugins/aws/deploy/lib/mergeIamTemplates.js\n@@ -120,17 +120,25 @@ module.exports = {\n       }\n \n       // add custom iam role statements\n-      if (this.serverless.service.provider.iamRoleStatements &&\n-        this.serverless.service.provider.iamRoleStatements instanceof Array) {\n-        this.serverless.service.provider.compiledCloudFormationTemplate\n-          .Resources[this.provider.naming.getPolicyLogicalId()]\n-          .Properties\n-          .PolicyDocument\n-          .Statement = this.serverless.service.provider.compiledCloudFormationTemplate\n-          .Resources[this.provider.naming.getPolicyLogicalId()]\n-          .Properties\n-          .PolicyDocument\n-          .Statement.concat(this.serverless.service.provider.iamRoleStatements);\n+      if (this.serverless.service.provider.iamRoleStatements) {\n+        if (this.serverless.service.provider.iamRoleStatements instanceof Array) {\n+          this.serverless.service.provider.compiledCloudFormationTemplate\n+            .Resources[this.provider.naming.getPolicyLogicalId()]\n+            .Properties\n+            .PolicyDocument\n+            .Statement = this.serverless.service.provider.compiledCloudFormationTemplate\n+            .Resources[this.provider.naming.getPolicyLogicalId()]\n+            .Properties\n+            .PolicyDocument\n+            .Statement.concat(this.serverless.service.provider.iamRoleStatements);\n+        } else {\n+          const errorMessage = [\n+            'iamRoleStatements should be an array of objects,',\n+            ' where each object has Effect, Action, Resource fields.',\n+            ' Please check the docs for more info.',\n+          ].join('');\n+          this.serverless.cli.log(errorMessage);\n+        }\n       }\n     }\n \n"}
{"instance_id": "serverless__serverless-2842", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/deploy/lib/mergeCustomProviderResources.js b/lib/plugins/aws/deploy/lib/mergeCustomProviderResources.js\nindex 414b098f4..a0645c6e9 100644\n--- a/lib/plugins/aws/deploy/lib/mergeCustomProviderResources.js\n+++ b/lib/plugins/aws/deploy/lib/mergeCustomProviderResources.js\n@@ -5,11 +5,30 @@ const BbPromise = require('bluebird');\n \n module.exports = {\n   mergeCustomProviderResources() {\n-    if (this.serverless.service.resources && !this.serverless.service.resources.Resources) {\n-      this.serverless.service.resources.Resources = {};\n-    }\n-    if (this.serverless.service.resources && !this.serverless.service.resources.Outputs) {\n-      this.serverless.service.resources.Outputs = {};\n+    if (this.serverless.service.resources) {\n+      // Check if Resources is an array and merge all objects in the array\n+      if (Array.isArray(this.serverless.service.resources.Resources)) {\n+        this.serverless.service.resources.Resources = this.serverless.service.resources.Resources\n+          .reduce((accumulator, resource) => (\n+            _.merge(accumulator, resource)\n+          ), {});\n+      }\n+\n+      if (!this.serverless.service.resources.Resources) {\n+        this.serverless.service.resources.Resources = {};\n+      }\n+\n+      // Check if Outputs is an array and merge all objects in the array\n+      if (Array.isArray(this.serverless.service.resources.Outputs)) {\n+        this.serverless.service.resources.Outputs = this.serverless.service.resources.Outputs\n+          .reduce((accumulator, output) => (\n+            _.merge(accumulator, output)\n+          ), {});\n+      }\n+\n+      if (!this.serverless.service.resources.Outputs) {\n+        this.serverless.service.resources.Outputs = {};\n+      }\n     }\n \n     _.merge(\n"}
{"instance_id": "serverless__serverless-3095", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/deploy/compile/events/iot/index.js b/lib/plugins/aws/deploy/compile/events/iot/index.js\nindex 0d6b01f07..f9c33779c 100644\n--- a/lib/plugins/aws/deploy/compile/events/iot/index.js\n+++ b/lib/plugins/aws/deploy/compile/events/iot/index.js\n@@ -28,14 +28,22 @@ class AwsCompileIoTEvents {\n             let Sql;\n \n             if (typeof event.iot === 'object') {\n-              RuleName = event.iot.name;\n-              AwsIotSqlVersion = event.iot.sqlVersion;\n-              Description = event.iot.description;\n+              if (event.iot.name) {\n+                RuleName = event.iot.name.replace(/\\n/g, '');\n+              }\n+              if (event.iot.sqlVersion) {\n+                AwsIotSqlVersion = event.iot.sqlVersion.replace(/\\n/g, '');\n+              }\n+              if (event.iot.description) {\n+                Description = event.iot.description.replace(/\\n/g, '');\n+              }\n               RuleDisabled = false;\n               if (event.iot.enabled === false) {\n                 RuleDisabled = true;\n               }\n-              Sql = event.iot.sql;\n+              if (event.iot.sql) {\n+                Sql = event.iot.sql.replace(/\\n/g, '');\n+              }\n             } else {\n               const errorMessage = [\n                 `IoT event of function \"${functionName}\" is not an object`,\n"}
{"instance_id": "serverless__serverless-2952", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/artifact.zip b/artifact.zip\nnew file mode 100644\nindex 000000000..f6ea04951\n--- /dev/null\n+++ b/artifact.zip\n@@ -0,0 +1 @@\n+foobar\n\\ No newline at end of file\ndiff --git a/lib/plugins/aws/deploy/compile/events/stream/index.js b/lib/plugins/aws/deploy/compile/events/stream/index.js\nindex 41dab7cc4..992352c48 100644\n--- a/lib/plugins/aws/deploy/compile/events/stream/index.js\n+++ b/lib/plugins/aws/deploy/compile/events/stream/index.js\n@@ -91,32 +91,6 @@ class AwsCompileStreamEvents {\n               }\n             `;\n \n-            // create type specific PolicyDocument statements\n-            let streamStatement = {};\n-            if (streamType === 'dynamodb') {\n-              streamStatement = {\n-                Effect: 'Allow',\n-                Action: [\n-                  'dynamodb:GetRecords',\n-                  'dynamodb:GetShardIterator',\n-                  'dynamodb:DescribeStream',\n-                  'dynamodb:ListStreams',\n-                ],\n-                Resource: EventSourceArn,\n-              };\n-            } else {\n-              streamStatement = {\n-                Effect: 'Allow',\n-                Action: [\n-                  'kinesis:GetRecords',\n-                  'kinesis:GetShardIterator',\n-                  'kinesis:DescribeStream',\n-                  'kinesis:ListStreams',\n-                ],\n-                Resource: EventSourceArn,\n-              };\n-            }\n-\n             // update the PolicyDocument statements (if default policy is used)\n             if (this.serverless.service.provider.compiledCloudFormationTemplate\n               .Resources.IamPolicyLambdaExecution) {\n@@ -127,12 +101,45 @@ class AwsCompileStreamEvents {\n                 .PolicyDocument\n                 .Statement;\n \n-              this.serverless.service.provider.compiledCloudFormationTemplate\n-                .Resources\n-                .IamPolicyLambdaExecution\n-                .Properties\n-                .PolicyDocument\n-                .Statement = statement.concat([streamStatement]);\n+              // create type specific PolicyDocument statements\n+              // and look for an existing statement with the same actions\n+              if (streamType === 'dynamodb') {\n+                const dynamodbStreamStatement = statement.find((elem) =>\n+                  elem.Action[0] === 'dynamodb:GetRecords');\n+                if (dynamodbStreamStatement) {\n+                  dynamodbStreamStatement.Resource.push(EventSourceArn);\n+                } else {\n+                  const newStatement = {\n+                    Effect: 'Allow',\n+                    Action: [\n+                      'dynamodb:GetRecords',\n+                      'dynamodb:GetShardIterator',\n+                      'dynamodb:DescribeStream',\n+                      'dynamodb:ListStreams',\n+                    ],\n+                    Resource: [EventSourceArn],\n+                  };\n+                  statement.push(newStatement);\n+                }\n+              } else {\n+                const kinesisStreamStatement = statement.find((elem) =>\n+                  elem.Action[0] === 'kinesis:GetRecords');\n+                if (kinesisStreamStatement) {\n+                  kinesisStreamStatement.Resource.push(EventSourceArn);\n+                } else {\n+                  const newStatement = {\n+                    Effect: 'Allow',\n+                    Action: [\n+                      'kinesis:GetRecords',\n+                      'kinesis:GetShardIterator',\n+                      'kinesis:DescribeStream',\n+                      'kinesis:ListStreams',\n+                    ],\n+                    Resource: [EventSourceArn],\n+                  };\n+                  statement.push(newStatement);\n+                }\n+              }\n             }\n \n             const newStreamObject = {\ndiff --git a/test.zip b/test.zip\nnew file mode 100644\nindex 000000000..4b498a6dd\n--- /dev/null\n+++ b/test.zip\n@@ -0,0 +1 @@\n+barbaz\n\\ No newline at end of file\n"}
{"instance_id": "prettier__prettier-8777", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/main/ast-to-doc.js b/src/main/ast-to-doc.js\nindex 7d861c258..1c26fa94b 100644\n--- a/src/main/ast-to-doc.js\n+++ b/src/main/ast-to-doc.js\n@@ -10,6 +10,39 @@ const docBuilders = doc.builders;\n const { concat, hardline, addAlignmentToDoc } = docBuilders;\n const docUtils = doc.utils;\n \n+/**\n+ * Mark all comments in the given node and its descendants as printed.\n+ * This is used when a node is ignored via prettier-ignore.\n+ */\n+function printIgnoredNodeComments(node) {\n+  if (!node || typeof node !== \"object\") {\n+    return;\n+  }\n+\n+  if (Array.isArray(node.comments)) {\n+    node.comments.forEach((comment) => {\n+      comment.printed = true;\n+    });\n+  }\n+\n+  for (const key of Object.keys(node)) {\n+    if (\n+      key === \"comments\" ||\n+      key === \"enclosingNode\" ||\n+      key === \"precedingNode\" ||\n+      key === \"followingNode\"\n+    ) {\n+      continue;\n+    }\n+    const value = node[key];\n+    if (Array.isArray(value)) {\n+      value.forEach(printIgnoredNodeComments);\n+    } else if (value && typeof value === \"object\") {\n+      printIgnoredNodeComments(value);\n+    }\n+  }\n+}\n+\n /**\n  * Takes an abstract syntax tree (AST) and recursively converts it to a\n  * document (series of printing primitives).\n@@ -97,6 +130,7 @@ function callPluginPrintFunction(path, options, printPath, args) {\n \n   // Escape hatch\n   if (printer.hasPrettierIgnore && printer.hasPrettierIgnore(path)) {\n+    printIgnoredNodeComments(node);\n     return options.originalText.slice(\n       options.locStart(node),\n       options.locEnd(node)\ndiff --git a/src/main/core.js b/src/main/core.js\nindex 3faeefc2a..d33e568c3 100644\n--- a/src/main/core.js\n+++ b/src/main/core.js\n@@ -6,7 +6,7 @@ const {\n   printer: { printDocToString },\n   debug: { printDocToDebug },\n } = require(\"../document\");\n-const { isNodeIgnoreComment, getAlignmentSize } = require(\"../common/util\");\n+const { getAlignmentSize } = require(\"../common/util\");\n const {\n   guessEndOfLine,\n   convertEndOfLineToChars,\n@@ -32,14 +32,6 @@ function ensureAllCommentsPrinted(astComments) {\n     return;\n   }\n \n-  for (let i = 0; i < astComments.length; ++i) {\n-    if (isNodeIgnoreComment(astComments[i])) {\n-      // If there's a prettier-ignore, we're not printing that sub-tree so we\n-      // don't know if the comments was printed or not.\n-      return;\n-    }\n-  }\n-\n   astComments.forEach((comment) => {\n     if (!comment.printed) {\n       throw new Error(\n"}
{"instance_id": "serverless__serverless-2434", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/classes/Service.js b/lib/classes/Service.js\nindex 9cff995f2..ef3cd2e4f 100644\n--- a/lib/classes/Service.js\n+++ b/lib/classes/Service.js\n@@ -152,7 +152,14 @@ class Service {\n           if (!functionObj.events) {\n             that.functions[functionName].events = [];\n           }\n-          if (!_.isArray(functionObj.events)) {\n+\n+          // check if the events value is a variable reference\n+          // if so, skip validation as the variable will be resolved later\n+          const variableSyntaxPattern = RegExp(that.defaults.variableSyntax, 'g');\n+          const isEventsVariableRef = typeof functionObj.events === 'string' &&\n+            functionObj.events.match(variableSyntaxPattern);\n+\n+          if (!isEventsVariableRef && !_.isArray(functionObj.events)) {\n             throw new SError(`Events for \"${functionName}\" must be an array,` +\n                              ` not an ${typeof functionObj.events}`);\n           }\n"}
{"instance_id": "prettier__prettier-9850", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/language-js/print/block.js b/src/language-js/print/block.js\nindex aacffab1e..339999ad0 100644\n--- a/src/language-js/print/block.js\n+++ b/src/language-js/print/block.js\n@@ -5,7 +5,7 @@ const { isNextLineEmpty } = require(\"../../common/util\");\n const {\n   builders: { concat, hardline, indent },\n } = require(\"../../document\");\n-const { hasComment, CommentCheckFlags } = require(\"../utils\");\n+const { hasComment, CommentCheckFlags, hasPrettierIgnore } = require(\"../utils\");\n const { locEnd } = require(\"../loc\");\n \n const { printStatementSequence } = require(\"./statement\");\n@@ -56,7 +56,17 @@ function printBlock(path, options, print) {\n   // Babel 6\n   if (hasDirectives) {\n     path.each((childPath) => {\n-      parts.push(indent(concat([hardline, print(childPath), semi])));\n+      parts.push(\n+        indent(\n+          concat([\n+            hardline,\n+            print(childPath),\n+            // Only add semicolon if the directive is not being ignored\n+            // (ignored directives already include the semicolon in the original text)\n+            hasPrettierIgnore(childPath) ? \"\" : semi,\n+          ])\n+        )\n+      );\n       if (isNextLineEmpty(options.originalText, childPath.getValue(), locEnd)) {\n         parts.push(hardline);\n       }\ndiff --git a/src/language-js/printer-estree.js b/src/language-js/printer-estree.js\nindex e02dd375e..e98303afe 100644\n--- a/src/language-js/printer-estree.js\n+++ b/src/language-js/printer-estree.js\n@@ -267,7 +267,13 @@ function printPathNoParens(path, options, print, args) {\n       if (n.directives) {\n         const directivesCount = n.directives.length;\n         path.each((childPath, index) => {\n-          parts.push(print(childPath), semi, hardline);\n+          parts.push(print(childPath));\n+          // Only add semicolon if the directive is not being ignored\n+          // (ignored directives already include the semicolon in the original text)\n+          if (!hasPrettierIgnore(childPath)) {\n+            parts.push(semi);\n+          }\n+          parts.push(hardline);\n           if (\n             (index < directivesCount - 1 || hasContents) &&\n             isNextLineEmpty(options.originalText, childPath.getValue(), locEnd)\n"}
{"instance_id": "serverless__serverless-3187", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/deploy/compile/events/apiGateway/lib/method/index.js b/lib/plugins/aws/deploy/compile/events/apiGateway/lib/method/index.js\nindex aa5cbe4bd..a96f0a0e0 100644\n--- a/lib/plugins/aws/deploy/compile/events/apiGateway/lib/method/index.js\n+++ b/lib/plugins/aws/deploy/compile/events/apiGateway/lib/method/index.js\n@@ -47,7 +47,7 @@ module.exports = {\n         const claims = event.http.authorizer.claims || [];\n         extraCognitoPoolClaims = _.map(claims, claim =>\n             `\"${claim}\": \"$context.authorizer.claims.${claim}\",`\n-        );\n+        ).join('\\n       ');\n       }\n       const requestTemplates = template.Properties.Integration.RequestTemplates;\n       _.forEach(requestTemplates, (value, key) => {\n"}
{"instance_id": "serverless__serverless-3457", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/stream/index.js b/lib/plugins/aws/package/compile/events/stream/index.js\nindex a0bb4ab36..7bc0e6bdd 100644\n--- a/lib/plugins/aws/package/compile/events/stream/index.js\n+++ b/lib/plugins/aws/package/compile/events/stream/index.js\n@@ -136,6 +136,9 @@ class AwsCompileStreamEvents {\n                 funcRole['Fn::GetAtt'][1] === 'Arn'\n               ) {\n                 dependsOn = `\"${funcRole['Fn::GetAtt'][0]}\"`;\n+              } else if (typeof funcRole === 'string') {\n+                // role is a Logical Role Name\n+                dependsOn = `\"${funcRole}\"`;\n               }\n             }\n             const streamTemplate = `\n"}
{"instance_id": "serverless__serverless-5571", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/classes/Variables.js b/lib/classes/Variables.js\nindex 6411f043f..e11e2edb5 100644\n--- a/lib/classes/Variables.js\n+++ b/lib/classes/Variables.js\n@@ -265,10 +265,34 @@ class Variables {\n    * @returns {string} The cleaned variable match\n    */\n   cleanVariable(match) {\n-    return match.replace(\n+    const cleaned = match.replace(\n       this.variableSyntax,\n       (context, contents) => contents.trim()\n-    ).replace(/\\s/g, '');\n+    );\n+    // remove only whitespace that is NOT inside single or double quotes\n+    // by finding quoted strings and preserving them while removing whitespace elsewhere\n+    let result = '';\n+    let inQuote = false;\n+    let quoteChar = '';\n+    for (let i = 0; i < cleaned.length; i += 1) {\n+      const char = cleaned[i];\n+      if (!inQuote && (char === '\"' || char === \"'\")) {\n+        inQuote = true;\n+        quoteChar = char;\n+        result += char;\n+      } else if (inQuote && char === quoteChar) {\n+        inQuote = false;\n+        quoteChar = '';\n+        result += char;\n+      } else if (inQuote) {\n+        // preserve all characters inside quotes, including whitespace\n+        result += char;\n+      } else if (!/\\s/.test(char)) {\n+        // outside quotes, only add non-whitespace characters\n+        result += char;\n+      }\n+    }\n+    return result;\n   }\n   /**\n    * @typedef {Object} MatchResult\n"}
{"instance_id": "serverless__serverless-5775", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/classes/Variables.js b/lib/classes/Variables.js\nindex b5f6f406f..c29635a9f 100644\n--- a/lib/classes/Variables.js\n+++ b/lib/classes/Variables.js\n@@ -294,7 +294,7 @@ class Variables {\n       this.variableSyntax,\n       (context, contents) => contents.trim()\n     );\n-    if (!cleaned.match(/\".*\"/)) {\n+    if (!cleaned.match(/('|\").*\\1/)) {\n       cleaned = cleaned.replace(/\\s/g, '');\n     }\n     return cleaned;\n"}
{"instance_id": "serverless__serverless-5640", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/classes/Service.js b/lib/classes/Service.js\nindex f508aa038..7bd1a2ed9 100644\n--- a/lib/classes/Service.js\n+++ b/lib/classes/Service.js\n@@ -21,7 +21,7 @@ class Service {\n     this.provider = {\n       stage: 'dev',\n       region: 'us-east-1',\n-      variableSyntax: '\\\\${([ ~:a-zA-Z0-9._@\\'\",\\\\-\\\\/\\\\(\\\\)]+?)}',\n+      variableSyntax: '\\\\${([ ~:a-zA-Z0-9._@\\'\",\\\\-\\\\/\\\\(\\\\)*]+?)}',\n     };\n     this.custom = {};\n     this.plugins = [];\ndiff --git a/lib/plugins/print/print.js b/lib/plugins/print/print.js\nindex 65b137927..aea70be26 100644\n--- a/lib/plugins/print/print.js\n+++ b/lib/plugins/print/print.js\n@@ -56,7 +56,7 @@ class Print {\n     service.provider = _.merge({\n       stage: 'dev',\n       region: 'us-east-1',\n-      variableSyntax: '\\\\${([ ~:a-zA-Z0-9._@\\'\",\\\\-\\\\/\\\\(\\\\)]+?)}',\n+      variableSyntax: '\\\\${([ ~:a-zA-Z0-9._@\\'\",\\\\-\\\\/\\\\(\\\\)*]+?)}',\n     }, service.provider);\n   }\n   strip(svc) {\n"}
{"instance_id": "serverless__serverless-3804", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/providers/aws/guide/serverless.yml.md b/docs/providers/aws/guide/serverless.yml.md\nindex 547eadea1..d0413ced8 100644\n--- a/docs/providers/aws/guide/serverless.yml.md\n+++ b/docs/providers/aws/guide/serverless.yml.md\n@@ -31,7 +31,10 @@ provider:\n   profile: production # The default profile to use with this service\n   memorySize: 512 # Overwrite the default memory size. Default is 1024\n   timeout: 10 # The default is 6\n-  deploymentBucket: com.serverless.${self:provider.region}.deploys # Deployment bucket name. Default is generated by the framework\n+  deploymentBucket:\n+    name: com.serverless.${self:provider.region}.deploys # Deployment bucket name. Default is generated by the framework\n+    serverSideEncryption: AES256 # when using server-side encryption\n+    # sseKMSKeyId: arn:aws:kms:us-east-1:xxxxxxxxxxxx:key/aaaaaaaa-aaaa-aaaa-aaaa-aaaaaaaaaaaa # when using server-side encryption with custom KMS key\n   role: arn:aws:iam::XXXXXX:role/role # Overwrite the default IAM role which is used for all functions\n   cfnRole: arn:aws:iam::XXXXXX:role/role # ARN of an IAM role for CloudFormation service. If specified, CloudFormation uses the role's credentials\n   versionFunctions: false # Optional function versioning\ndiff --git a/docs/providers/aws/guide/services.md b/docs/providers/aws/guide/services.md\nindex c5c67356f..ee776f9e2 100644\n--- a/docs/providers/aws/guide/services.md\n+++ b/docs/providers/aws/guide/services.md\n@@ -94,7 +94,9 @@ provider:\n   region: us-east-1 # Overwrite the default region used. Default is us-east-1\n   profile: production # The default profile to use with this service\n   memorySize: 512 # Overwrite the default memory size. Default is 1024\n-  deploymentBucket: com.serverless.${self:provider.region}.deploys # Overwrite the default deployment bucket\n+  deploymentBucket:\n+    name: com.serverless.${self:provider.region}.deploys # Overwrite the default deployment bucket\n+    serverSideEncryption: AES256 # when using server-side encryption\n   versionFunctions: false # Optional function versioning\n   stackTags: # Optional CF stack tags\n    key: value\ndiff --git a/lib/plugins/aws/deploy/lib/uploadArtifacts.js b/lib/plugins/aws/deploy/lib/uploadArtifacts.js\nindex 6c7ad61d2..cff1852a9 100644\n--- a/lib/plugins/aws/deploy/lib/uploadArtifacts.js\n+++ b/lib/plugins/aws/deploy/lib/uploadArtifacts.js\n@@ -6,6 +6,18 @@ const filesize = require('filesize');\n const path = require('path');\n \n module.exports = {\n+  getSSEParams() {\n+    const deploymentBucketObject = this.serverless.service.provider.deploymentBucketObject;\n+    const params = {};\n+    if (deploymentBucketObject && deploymentBucketObject.serverSideEncryption) {\n+      params.ServerSideEncryption = deploymentBucketObject.serverSideEncryption;\n+    }\n+    if (deploymentBucketObject && deploymentBucketObject.sseKMSKeyId) {\n+      params.SSEKMSKeyId = deploymentBucketObject.sseKMSKeyId;\n+    }\n+    return params;\n+  },\n+\n   uploadCloudFormationFile() {\n     this.serverless.cli.log('Uploading CloudFormation file to S3...');\n \n@@ -19,6 +31,9 @@ module.exports = {\n       ContentType: 'application/json',\n     };\n \n+    const sseParams = this.getSSEParams();\n+    Object.assign(params, sseParams);\n+\n     return this.provider.request('S3',\n       'putObject',\n       params,\n@@ -36,6 +51,9 @@ module.exports = {\n       ContentType: 'application/zip',\n     };\n \n+    const sseParams = this.getSSEParams();\n+    Object.assign(params, sseParams);\n+\n     return this.provider.request('S3',\n       'putObject',\n       params,\ndiff --git a/lib/plugins/aws/package/lib/generateCoreTemplate.js b/lib/plugins/aws/package/lib/generateCoreTemplate.js\nindex ef15492be..8f9e7097a 100644\n--- a/lib/plugins/aws/package/lib/generateCoreTemplate.js\n+++ b/lib/plugins/aws/package/lib/generateCoreTemplate.js\n@@ -23,7 +23,15 @@ module.exports = {\n         'core-cloudformation-template.json')\n     );\n \n-    const bucketName = this.serverless.service.provider.deploymentBucket;\n+    const deploymentBucket = this.serverless.service.provider.deploymentBucket;\n+    const bucketName = deploymentBucket && deploymentBucket.name\n+      ? deploymentBucket.name\n+      : deploymentBucket;\n+\n+    // Store the SSE configuration for later use in uploads\n+    if (deploymentBucket && typeof deploymentBucket === 'object') {\n+      this.serverless.service.provider.deploymentBucketObject = deploymentBucket;\n+    }\n \n     if (bucketName) {\n       return BbPromise.bind(this)\ndiff --git a/lib/plugins/aws/provider/awsProvider.js b/lib/plugins/aws/provider/awsProvider.js\nindex 3d0f48cef..a6baf9e87 100644\n--- a/lib/plugins/aws/provider/awsProvider.js\n+++ b/lib/plugins/aws/provider/awsProvider.js\n@@ -208,7 +208,10 @@ class AwsProvider {\n \n   getServerlessDeploymentBucketName() {\n     if (this.serverless.service.provider.deploymentBucket) {\n-      return BbPromise.resolve(this.serverless.service.provider.deploymentBucket);\n+      const deploymentBucket = this.serverless.service.provider.deploymentBucket;\n+      return BbPromise.resolve(\n+        deploymentBucket.name ? deploymentBucket.name : deploymentBucket\n+      );\n     }\n     return this.request('CloudFormation',\n       'describeStackResource',\n"}
{"instance_id": "serverless__serverless-5842", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/providers/aws/guide/variables.md b/docs/providers/aws/guide/variables.md\nindex 677e6c681..59e50a190 100644\n--- a/docs/providers/aws/guide/variables.md\n+++ b/docs/providers/aws/guide/variables.md\n@@ -274,6 +274,39 @@ custom:\n \n In this example, the serverless variable will contain the decrypted value of the secret.\n \n+### Secrets Manager JSON Secrets\n+\n+If your secret is stored as a JSON object in Secrets Manager, you can access individual keys by adding the `~split` option. This will parse the JSON and return an object, allowing you to access specific properties using standard variable syntax.\n+\n+For example, if you have a secret stored as:\n+```json\n+{\n+  \"username\": \"admin\",\n+  \"password\": \"secret123\",\n+  \"host\": \"db.example.com\"\n+}\n+```\n+\n+You can reference individual keys like this:\n+\n+```yml\n+service: new-service\n+provider: aws\n+functions:\n+  hello:\n+    name: hello\n+    handler: handler.hello\n+custom:\n+  # Get the entire secret as an object\n+  dbSecrets: ${ssm:/aws/reference/secretsmanager/my_db_secret~true~split}\n+  # Access individual properties\n+  dbUsername: ${ssm:/aws/reference/secretsmanager/my_db_secret~true~split.username}\n+  dbPassword: ${ssm:/aws/reference/secretsmanager/my_db_secret~true~split.password}\n+  dbHost: ${ssm:/aws/reference/secretsmanager/my_db_secret~true~split.host}\n+```\n+\n+This is particularly useful when you have many secrets stored in a single Secrets Manager secret, as it's more cost-effective than storing each secret value separately.\n+\n ## Reference Variables in Other Files\n You can reference variables in other YAML or JSON files.  To reference variables in other YAML files use the `${file(./myFile.yml):someProperty}` syntax in your `serverless.yml` configuration file. To reference variables in other JSON files use the `${file(./myFile.json):someProperty}` syntax. It is important that the file you are referencing has the correct suffix, or file extension, for its file type (`.yml` for YAML or `.json` for JSON) in order for it to be interpreted correctly. Here's an example:\n \ndiff --git a/lib/classes/Variables.js b/lib/classes/Variables.js\nindex ef1b4f829..dc158ac4d 100644\n--- a/lib/classes/Variables.js\n+++ b/lib/classes/Variables.js\n@@ -53,7 +53,7 @@ class Variables {\n     this.stringRefSyntax = RegExp(/(?:('|\").*?\\1)/g);\n     this.cfRefSyntax = RegExp(/^(?:\\${)?cf(\\.[a-zA-Z0-9-]+)?:/g);\n     this.s3RefSyntax = RegExp(/^(?:\\${)?s3:(.+?)\\/(.+)$/);\n-    this.ssmRefSyntax = RegExp(/^(?:\\${)?ssm:([a-zA-Z0-9_.\\-/]+)[~]?(true|false)?/);\n+    this.ssmRefSyntax = RegExp(/^(?:\\${)?ssm:([a-zA-Z0-9_.\\-/]+)[~]?(true|false)?[~]?(split)?/);\n   }\n \n   loadVariableSyntax() {\n@@ -736,6 +736,7 @@ class Variables {\n     const groups = variableString.match(this.ssmRefSyntax);\n     const param = groups[1];\n     const decrypt = (groups[2] === 'true');\n+    const split = (groups[3] === 'split');\n     return this.serverless.getProvider('aws').request(\n       'SSM',\n       'getParameter',\n@@ -744,7 +745,19 @@ class Variables {\n         WithDecryption: decrypt,\n       },\n       { useCache: true }) // Use request cache\n-      .then(response => BbPromise.resolve(response.Parameter.Value))\n+      .then((response) => {\n+        const value = response.Parameter.Value;\n+        if (split) {\n+          // Attempt to parse the value as JSON\n+          try {\n+            return BbPromise.resolve(JSON.parse(value));\n+          } catch (e) {\n+            // If parsing fails, return the original value\n+            return BbPromise.resolve(value);\n+          }\n+        }\n+        return BbPromise.resolve(value);\n+      })\n       .catch((err) => {\n         if (err.statusCode !== 400) {\n           return BbPromise.reject(new this.serverless.classes.Error(err.message));\n"}
{"instance_id": "serverless__serverless-3534", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\nindex e8e040b2b..44b8ac299 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\n@@ -30,11 +30,20 @@ module.exports = {\n \n       const methodLogicalId = this.provider.naming\n         .getMethodLogicalId(resourceName, event.http.method);\n-      const lambdaLogicalId = this.provider.naming\n-        .getLambdaLogicalId(event.functionName);\n \n-      const singlePermissionMapping = { resourceName, lambdaLogicalId, event };\n-      this.permissionMapping.push(singlePermissionMapping);\n+      // Check if this is a Lambda integration (AWS or AWS_PROXY)\n+      // Default integration type is AWS_PROXY if not specified\n+      const integrationType = event.http.integration || 'AWS_PROXY';\n+      const isLambdaIntegration = integrationType === 'AWS' || integrationType === 'AWS_PROXY';\n+\n+      let lambdaLogicalId;\n+      if (isLambdaIntegration) {\n+        lambdaLogicalId = this.provider.naming\n+          .getLambdaLogicalId(event.functionName);\n+\n+        const singlePermissionMapping = { resourceName, lambdaLogicalId, event };\n+        this.permissionMapping.push(singlePermissionMapping);\n+      }\n \n       _.merge(template,\n         this.getMethodAuthorization(event.http),\n@@ -42,28 +51,31 @@ module.exports = {\n         this.getMethodResponses(event.http)\n       );\n \n-      let extraCognitoPoolClaims;\n-      if (event.http.authorizer) {\n-        const claims = event.http.authorizer.claims || [];\n-        extraCognitoPoolClaims = _.map(claims, (claim) => {\n-          if (typeof claim === 'string') {\n-            const colonIndex = claim.indexOf(':');\n-            if (colonIndex !== -1) {\n-              const subClaim = claim.substring(colonIndex + 1);\n-              return `\"${subClaim}\": \"$context.authorizer.claims['${claim}']\"`;\n+      // Only process Cognito pool claims for Lambda integrations\n+      if (isLambdaIntegration) {\n+        let extraCognitoPoolClaims;\n+        if (event.http.authorizer) {\n+          const claims = event.http.authorizer.claims || [];\n+          extraCognitoPoolClaims = _.map(claims, (claim) => {\n+            if (typeof claim === 'string') {\n+              const colonIndex = claim.indexOf(':');\n+              if (colonIndex !== -1) {\n+                const subClaim = claim.substring(colonIndex + 1);\n+                return `\"${subClaim}\": \"$context.authorizer.claims['${claim}']\"`;\n+              }\n             }\n+            return `\"${claim}\": \"$context.authorizer.claims.${claim}\"`;\n+          });\n+        }\n+        const requestTemplates = template.Properties.Integration.RequestTemplates;\n+        _.forEach(requestTemplates, (value, key) => {\n+          let claimsString = '';\n+          if (extraCognitoPoolClaims && extraCognitoPoolClaims.length > 0) {\n+            claimsString = extraCognitoPoolClaims.join(',').concat(',');\n           }\n-          return `\"${claim}\": \"$context.authorizer.claims.${claim}\"`;\n+          requestTemplates[key] = value.replace('extraCognitoPoolClaims', claimsString);\n         });\n       }\n-      const requestTemplates = template.Properties.Integration.RequestTemplates;\n-      _.forEach(requestTemplates, (value, key) => {\n-        let claimsString = '';\n-        if (extraCognitoPoolClaims && extraCognitoPoolClaims.length > 0) {\n-          claimsString = extraCognitoPoolClaims.join(',').concat(',');\n-        }\n-        requestTemplates[key] = value.replace('extraCognitoPoolClaims', claimsString);\n-      });\n \n       this.apiGatewayMethodLogicalIds.push(methodLogicalId);\n \ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\nindex 765e3ee65..38fffb7eb 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n@@ -45,26 +45,44 @@ const DEFAULT_COMMON_TEMPLATE = `\n \n module.exports = {\n   getMethodIntegration(http, lambdaLogicalId) {\n+    // Default integration type is AWS_PROXY if not specified\n+    const type = http.integration || 'AWS_PROXY';\n     const integration = {\n       IntegrationHttpMethod: 'POST',\n-      Type: http.integration,\n-      Uri: {\n-        'Fn::Join': ['',\n-          [\n-            'arn:aws:apigateway:',\n-            { Ref: 'AWS::Region' },\n-            ':lambda:path/2015-03-31/functions/',\n-            { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] },\n-            '/invocations',\n-          ],\n-        ],\n-      },\n+      Type: type,\n     };\n \n-    if (http.integration === 'AWS') {\n+    // Lambda integrations\n+    if (type === 'AWS' || type === 'AWS_PROXY') {\n+      _.assign(integration, {\n+        Uri: {\n+          'Fn::Join': ['',\n+            [\n+              'arn:aws:apigateway:',\n+              { Ref: 'AWS::Region' },\n+              ':lambda:path/2015-03-31/functions/',\n+              { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] },\n+              '/invocations',\n+            ],\n+          ],\n+        },\n+      });\n+    }\n+\n+    // HTTP integrations\n+    if (type === 'HTTP' || type === 'HTTP_PROXY') {\n+      _.assign(integration, {\n+        Uri: http.request.uri,\n+        IntegrationHttpMethod: http.request.method\n+          ? http.request.method.toUpperCase()\n+          : http.method.toUpperCase(),\n+      });\n+    }\n+\n+    if (type === 'AWS' || type === 'HTTP') {\n       _.assign(integration, {\n         PassthroughBehavior: http.request && http.request.passThrough,\n-        RequestTemplates: this.getIntegrationRequestTemplates(http),\n+        RequestTemplates: this.getIntegrationRequestTemplates(http, type),\n         IntegrationResponses: this.getIntegrationResponses(http),\n       });\n     }\n@@ -129,12 +147,16 @@ module.exports = {\n     return integrationResponses;\n   },\n \n-  getIntegrationRequestTemplates(http) {\n-    // default request templates\n-    const integrationRequestTemplates = {\n-      'application/json': this.DEFAULT_JSON_REQUEST_TEMPLATE,\n-      'application/x-www-form-urlencoded': this.DEFAULT_FORM_URL_ENCODED_REQUEST_TEMPLATE,\n-    };\n+  getIntegrationRequestTemplates(http, type) {\n+    // default request templates for Lambda (AWS) integration\n+    const integrationRequestTemplates = {};\n+\n+    if (type === 'AWS') {\n+      _.assign(integrationRequestTemplates, {\n+        'application/json': this.DEFAULT_JSON_REQUEST_TEMPLATE,\n+        'application/x-www-form-urlencoded': this.DEFAULT_FORM_URL_ENCODED_REQUEST_TEMPLATE,\n+      });\n+    }\n \n     // set custom request templates if provided\n     if (http.request && typeof http.request.template === 'object') {\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/responses.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/responses.js\nindex 776306a01..263cd78d1 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/responses.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/responses.js\n@@ -7,7 +7,7 @@ module.exports = {\n   getMethodResponses(http) {\n     const methodResponses = [];\n \n-    if (http.integration === 'AWS') {\n+    if (http.integration === 'AWS' || http.integration === 'HTTP') {\n       if (http.response) {\n         const methodResponseHeaders = [];\n \ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\nindex 60c3f1eb8..2513de54b 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\n@@ -65,6 +65,14 @@ module.exports = {\n \n           http.integration = this.getIntegration(http, functionName);\n \n+          if ((http.integration === 'HTTP' || http.integration === 'HTTP_PROXY')\n+            && (!http.request || !http.request.uri)) {\n+            const errorMessage = [\n+              'You need to set the request uri when using the http-proxy or http integration.',\n+            ].join('');\n+            throw new this.serverless.classes.Error(errorMessage);\n+          }\n+\n           if (http.integration === 'AWS') {\n             if (http.request) {\n               http.request = this.getRequest(http);\n@@ -106,6 +114,46 @@ module.exports = {\n               delete http.request;\n               delete http.response;\n             }\n+          } else if (http.integration === 'HTTP_PROXY') {\n+            // show a warning when response config is used with HTTP_PROXY\n+            if (http.response) {\n+              const warningMessage = [\n+                'Warning! You\\'re using the HTTP-PROXY in combination with response',\n+                ` configuration in your function \"${functionName}\".`,\n+                ' Serverless will remove this configuration automatically before deployment.',\n+              ].join('');\n+              this.serverless.cli.log(warningMessage);\n+\n+              delete http.response;\n+            }\n+          } else if (http.integration === 'HTTP') {\n+            if (http.request) {\n+              http.request = this.getRequest(http);\n+\n+              if (http.request.parameters) {\n+                http.request.parameters = this.getRequestParameters(http.request);\n+              }\n+            } else {\n+              http.request = {};\n+            }\n+\n+            http.request.passThrough = this.getRequestPassThrough(http);\n+\n+            if (http.response) {\n+              http.response = this.getResponse(http);\n+            } else {\n+              http.response = {};\n+            }\n+\n+            if (http.response.statusCodes) {\n+              http.response.statusCodes = _.assign({}, http.response.statusCodes);\n+\n+              if (!_.some(http.response.statusCodes, code => code.pattern === '')) {\n+                http.response.statusCodes['200'] = DEFAULT_STATUS_CODES['200'];\n+              }\n+            } else {\n+              http.response.statusCodes = DEFAULT_STATUS_CODES;\n+            }\n           }\n \n           events.push({\n@@ -299,7 +347,7 @@ module.exports = {\n   getIntegration(http, functionName) {\n     if (http.integration) {\n       const allowedIntegrations = [\n-        'LAMBDA-PROXY', 'LAMBDA',\n+        'LAMBDA-PROXY', 'LAMBDA', 'HTTP-PROXY', 'HTTP',\n       ];\n       // normalize the integration for further processing\n       const normalizedIntegration = http.integration.toUpperCase();\n@@ -308,12 +356,16 @@ module.exports = {\n         const errorMessage = [\n           `Invalid APIG integration \"${http.integration}\"`,\n           ` in function \"${functionName}\".`,\n-          ' Supported integrations are: lambda, lambda-proxy.',\n+          ' Supported integrations are: lambda, lambda-proxy, http, http-proxy.',\n         ].join('');\n         throw new this.serverless.classes.Error(errorMessage);\n       }\n       if (normalizedIntegration === 'LAMBDA') {\n         return 'AWS';\n+      } else if (normalizedIntegration === 'HTTP') {\n+        return 'HTTP';\n+      } else if (normalizedIntegration === 'HTTP-PROXY') {\n+        return 'HTTP_PROXY';\n       }\n     }\n     return 'AWS_PROXY';\n"}
{"instance_id": "serverless__serverless-4192", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/deploy/index.js b/lib/plugins/aws/deploy/index.js\nindex bd54900ae..955459b55 100644\n--- a/lib/plugins/aws/deploy/index.js\n+++ b/lib/plugins/aws/deploy/index.js\n@@ -72,8 +72,16 @@ class AwsDeploy {\n \n     this.hooks = {\n       'before:deploy:deploy': () => BbPromise.bind(this)\n-        .then(() => this.serverless.pluginManager.spawn('aws:common:validate'))\n         .then(() => {\n+          if (this.serverless.service.provider.shouldNotDeploy) {\n+            return BbPromise.resolve();\n+          }\n+          return this.serverless.pluginManager.spawn('aws:common:validate');\n+        })\n+        .then(() => {\n+          if (this.serverless.service.provider.shouldNotDeploy) {\n+            return BbPromise.resolve();\n+          }\n           if (!this.options.package && !this.serverless.service.package.path) {\n             return this.extendedValidate();\n           }\n@@ -85,13 +93,19 @@ class AwsDeploy {\n       // Deploy outer lifecycle\n       'deploy:deploy': () => BbPromise.bind(this)\n         .then(() => {\n-          if (this.options.noDeploy) {\n+          if (this.options.noDeploy || this.serverless.service.provider.shouldNotDeploy) {\n             return BbPromise.resolve();\n           }\n           return this.serverless.pluginManager.spawn('aws:deploy:deploy');\n         }),\n \n-      'deploy:finalize': () => this.serverless.pluginManager.spawn('aws:deploy:finalize'),\n+      'deploy:finalize': () => BbPromise.bind(this)\n+        .then(() => {\n+          if (this.serverless.service.provider.shouldNotDeploy) {\n+            return BbPromise.resolve();\n+          }\n+          return this.serverless.pluginManager.spawn('aws:deploy:finalize');\n+        }),\n \n       // Deploy deploy inner lifecycle\n       'aws:deploy:deploy:createStack': () => BbPromise.bind(this)\ndiff --git a/lib/plugins/aws/info/index.js b/lib/plugins/aws/info/index.js\nindex ebad3db23..33be8714b 100644\n--- a/lib/plugins/aws/info/index.js\n+++ b/lib/plugins/aws/info/index.js\n@@ -43,7 +43,7 @@ class AwsInfo {\n \n       'deploy:deploy': () => BbPromise.bind(this)\n         .then(() => {\n-          if (this.options.noDeploy) {\n+          if (this.options.noDeploy || this.serverless.service.provider.shouldNotDeploy) {\n             return BbPromise.resolve();\n           }\n           return this.serverless.pluginManager.spawn('aws:info');\ndiff --git a/lib/plugins/deploy/deploy.js b/lib/plugins/deploy/deploy.js\nindex 5290b3247..04aec4f93 100644\n--- a/lib/plugins/deploy/deploy.js\n+++ b/lib/plugins/deploy/deploy.js\n@@ -47,6 +47,10 @@ class Deploy {\n           force: {\n             usage: 'Forces a deployment to take place',\n           },\n+          function: {\n+            usage: 'Function name. Deploys a single function (see \\'deploy function\\')',\n+            shortcut: 'f',\n+          },\n         },\n         commands: {\n           function: {\n@@ -97,6 +101,17 @@ class Deploy {\n       'before:deploy:deploy': () => BbPromise.bind(this)\n         .then(this.validate)\n         .then(() => {\n+          if (this.options.function) {\n+            // If the user specified a function option, spawn the deploy:function lifecycle\n+            // and set shouldNotDeploy to skip the rest of the deploy lifecycle\n+            this.serverless.cli.log(\n+              'Deploying function...'\n+            );\n+            return this.serverless.pluginManager.spawn('deploy:function')\n+              .then(() => {\n+                this.serverless.service.provider.shouldNotDeploy = true;\n+              });\n+          }\n           if (!this.options.package && !this.serverless.service.package.path) {\n             return this.serverless.pluginManager.spawn('package');\n           }\n"}
{"instance_id": "serverless__serverless-6261", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/classes/PluginManager.js b/lib/classes/PluginManager.js\nindex 1e6c063b1..6b05eac1f 100644\n--- a/lib/classes/PluginManager.js\n+++ b/lib/classes/PluginManager.js\n@@ -100,7 +100,12 @@ class PluginManager {\n   loadPlugins(plugins) {\n     plugins.forEach((plugin) => {\n       try {\n-        const Plugin = require(plugin); // eslint-disable-line global-require\n+        let pluginPath = plugin;\n+        // Resolve relative paths to the service path\n+        if (pluginPath.startsWith('./') || pluginPath.startsWith('../')) {\n+          pluginPath = path.resolve(this.serverless.config.servicePath, pluginPath);\n+        }\n+        const Plugin = require(pluginPath); // eslint-disable-line global-require\n \n         this.addPlugin(Plugin);\n       } catch (error) {\n"}
{"instance_id": "serverless__serverless-6366", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/sns/index.js b/lib/plugins/aws/package/compile/events/sns/index.js\nindex 4d065c677..d455d35fc 100644\n--- a/lib/plugins/aws/package/compile/events/sns/index.js\n+++ b/lib/plugins/aws/package/compile/events/sns/index.js\n@@ -49,6 +49,7 @@ class AwsCompileSNSEvents {\n           if (event.sns) {\n             let topicArn;\n             let topicName;\n+            let region;\n             let displayName = '';\n \n             if (typeof event.sns === 'object') {\n@@ -64,6 +65,7 @@ class AwsCompileSNSEvents {\n                   if (topicArn.indexOf('arn:') === 0) {\n                     const splitArn = topicArn.split(':');\n                     topicName = splitArn[splitArn.length - 1];\n+                    region = splitArn[3];\n                   } else {\n                     throw new this.serverless.classes.Error(\n                       this.invalidPropertyErrorMessage(functionName, 'arn')\n@@ -97,6 +99,7 @@ class AwsCompileSNSEvents {\n                 topicArn = event.sns;\n                 const splitArn = topicArn.split(':');\n                 topicName = splitArn[splitArn.length - 1];\n+                region = splitArn[3];\n               } else {\n                 topicName = event.sns;\n               }\n@@ -124,16 +127,23 @@ class AwsCompileSNSEvents {\n             );\n \n             if (topicArn) {\n-              _.merge(template.Resources, {\n-                [subscriptionLogicalId]: {\n-                  Type: 'AWS::SNS::Subscription',\n-                  Properties: {\n-                    TopicArn: topicArn,\n-                    Protocol: 'lambda',\n-                    Endpoint: endpoint,\n-                    FilterPolicy: event.sns.filterPolicy,\n-                  },\n+              const subscriptionResource = {\n+                Type: 'AWS::SNS::Subscription',\n+                Properties: {\n+                  TopicArn: topicArn,\n+                  Protocol: 'lambda',\n+                  Endpoint: endpoint,\n+                  FilterPolicy: event.sns.filterPolicy,\n                 },\n+              };\n+\n+              // Only add the region property if the topic is in a different region than the stack\n+              if (region && region !== this.provider.getRegion()) {\n+                subscriptionResource.Properties.Region = region;\n+              }\n+\n+              _.merge(template.Resources, {\n+                [subscriptionLogicalId]: subscriptionResource,\n               });\n             } else {\n               topicArn = {\n"}
{"instance_id": "serverless__serverless-5860", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/providers/aws/guide/functions.md b/docs/providers/aws/guide/functions.md\nindex 9a3ae2266..b31e581f1 100644\n--- a/docs/providers/aws/guide/functions.md\n+++ b/docs/providers/aws/guide/functions.md\n@@ -430,3 +430,38 @@ functions:\n ### Secrets using environment variables and KMS\n \n When storing secrets in environment variables, AWS [strongly suggests](http://docs.aws.amazon.com/lambda/latest/dg/env_variables.html#env-storing-sensitive-data) encrypting sensitive information. AWS provides a [tutorial](http://docs.aws.amazon.com/lambda/latest/dg/tutorial-env_console.html) on using KMS for this purpose.\n+\n+## AWS X-Ray Tracing\n+\n+You can enable [AWS X-Ray Tracing](https://aws.amazon.com/xray/) for your Lambda functions to gain insights into the performance of your serverless applications.\n+\n+```yml\n+service: myService\n+\n+provider:\n+  name: aws\n+  runtime: nodejs6.10\n+  tracing:\n+    lambda: true # optional, enables tracing for all functions (can be true (true equals 'Active') 'Active' or 'PassThrough')\n+\n+functions:\n+  hello:\n+    handler: handler.hello\n+    tracing: Active # optional overwrite, can be 'Active' or 'PassThrough'\n+```\n+\n+You can also set the tracing configuration on a per-function basis. This will override any provider-level settings.\n+\n+```yml\n+functions:\n+  hello:\n+    handler: handler.hello\n+    tracing: Active\n+  goodbye:\n+    handler: handler.goodbye\n+    tracing: PassThrough\n+```\n+\n+**X-Ray IAM permissions**\n+\n+The Lambda function execution role must have permissions to write to X-Ray. When tracing configuration is provided the default AWS `AWSXrayWriteOnlyAccess` managed policy will be associated with your Lambda execution role. In case custom roles are provided, be sure to include the proper permissions to write to X-Ray.\ndiff --git a/lib/plugins/aws/package/compile/functions/index.js b/lib/plugins/aws/package/compile/functions/index.js\nindex 8a130d1c9..ba3a14124 100644\n--- a/lib/plugins/aws/package/compile/functions/index.js\n+++ b/lib/plugins/aws/package/compile/functions/index.js\n@@ -325,6 +325,19 @@ class AwsCompileFunctions {\n       */\n     }\n \n+    if (functionObject.tracing) {\n+      const tracing = functionObject.tracing;\n+      newFunction.Properties.TracingConfig = {\n+        Mode: tracing === true ? 'Active' : tracing,\n+      };\n+    } else if (this.serverless.service.provider.tracing &&\n+               this.serverless.service.provider.tracing.lambda) {\n+      const tracing = this.serverless.service.provider.tracing.lambda;\n+      newFunction.Properties.TracingConfig = {\n+        Mode: tracing === true ? 'Active' : tracing,\n+      };\n+    }\n+\n     const functionLogicalId = this.provider.naming\n       .getLambdaLogicalId(functionName);\n     const newFunctionObject = {\ndiff --git a/lib/plugins/aws/package/lib/mergeIamTemplates.js b/lib/plugins/aws/package/lib/mergeIamTemplates.js\nindex cb74e820d..8871ca2e9 100644\n--- a/lib/plugins/aws/package/lib/mergeIamTemplates.js\n+++ b/lib/plugins/aws/package/lib/mergeIamTemplates.js\n@@ -156,6 +156,30 @@ module.exports = {\n       }]);\n     }\n \n+    // check if one of the functions contains tracing configuration\n+    const tracingConfigProvided = [];\n+    this.serverless.service.getAllFunctions().forEach((functionName) => {\n+      const functionObject = this.serverless.service.getFunction(functionName);\n+      if (functionObject.tracing) {\n+        tracingConfigProvided.push(true);\n+      }\n+    });\n+\n+    if (_.includes(tracingConfigProvided, true) ||\n+        (this.serverless.service.provider.tracing &&\n+         this.serverless.service.provider.tracing.lambda)) {\n+      // add managed iam policy to allow X-Ray tracing\n+      this.mergeManagedPolicies([{\n+        'Fn::Join': ['',\n+          [\n+            'arn:',\n+            { Ref: 'AWS::Partition' },\n+            ':iam::aws:policy/AWSXrayWriteOnlyAccess',\n+          ],\n+        ],\n+      }]);\n+    }\n+\n     return BbPromise.resolve();\n   },\n \n"}
{"instance_id": "serverless__serverless-6827", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/cloudWatchLog/index.js b/lib/plugins/aws/package/compile/events/cloudWatchLog/index.js\nindex 58024492c..d6e5c60ea 100644\n--- a/lib/plugins/aws/package/compile/events/cloudWatchLog/index.js\n+++ b/lib/plugins/aws/package/compile/events/cloudWatchLog/index.js\n@@ -159,7 +159,7 @@ class AwsCompileCloudWatchLogEvents {\n       }\n       return last;\n     }, first);\n-    return longestCommon + (longestCommon === first ? '' : '*');\n+    return longestCommon + (logGroupNames.length === 1 ? '' : '*');\n   }\n }\n \n"}
{"instance_id": "serverless__serverless-3799", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/cognitoUserPool/index.js b/lib/plugins/aws/package/compile/events/cognitoUserPool/index.js\nindex d94063701..3d87ef0c5 100644\n--- a/lib/plugins/aws/package/compile/events/cognitoUserPool/index.js\n+++ b/lib/plugins/aws/package/compile/events/cognitoUserPool/index.js\n@@ -80,6 +80,47 @@ class AwsCompileCognitoUserPoolEvents {\n       }\n     });\n \n+    // Generate CloudFormation templates for IAM permissions to allow Cognito to trigger Lambda\n+    // These must be created before the User Pool resources to avoid circular dependencies\n+    cognitoUserPoolTriggerFunctions.forEach((cognitoUserPoolTriggerFunction) => {\n+      const lambdaLogicalId = this.provider.naming\n+        .getLambdaLogicalId(cognitoUserPoolTriggerFunction.functionName);\n+\n+      const permissionTemplate = {\n+        Type: 'AWS::Lambda::Permission',\n+        Properties: {\n+          FunctionName: {\n+            'Fn::GetAtt': [\n+              lambdaLogicalId,\n+              'Arn',\n+            ],\n+          },\n+          Action: 'lambda:InvokeFunction',\n+          Principal: 'cognito-idp.amazonaws.com',\n+          SourceArn: {\n+            'Fn::Join': [\n+              '',\n+              [\n+                'arn:aws:cognito-idp:',\n+                { Ref: 'AWS::Region' },\n+                ':',\n+                { Ref: 'AWS::AccountId' },\n+                ':userpool/*',\n+              ],\n+            ],\n+          },\n+        },\n+      };\n+      const lambdaPermissionLogicalId = this.provider.naming\n+        .getLambdaCognitoUserPoolPermissionLogicalId(cognitoUserPoolTriggerFunction.functionName,\n+          cognitoUserPoolTriggerFunction.poolName, cognitoUserPoolTriggerFunction.triggerSource);\n+      const permissionCFResource = {\n+        [lambdaPermissionLogicalId]: permissionTemplate,\n+      };\n+      _.merge(this.serverless.service.provider.compiledCloudFormationTemplate.Resources,\n+        permissionCFResource);\n+    });\n+\n     // Generate CloudFormation templates for Cognito User Pool changes\n     _.forEach(userPools, (poolName) => {\n       // Create a `LambdaConfig` object for the CloudFormation template\n@@ -103,8 +144,10 @@ class AwsCompileCognitoUserPoolEvents {\n \n       const userPoolLogicalId = this.provider.naming.getCognitoUserPoolLogicalId(poolName);\n \n+      // DependsOn the Lambda Permission resources to ensure they are created first\n       const DependsOn = _.map(currentPoolTriggerFunctions, (value) => this\n-        .provider.naming.getLambdaLogicalId(value.functionName));\n+        .provider.naming.getLambdaCognitoUserPoolPermissionLogicalId(\n+          value.functionName, poolName, value.triggerSource));\n \n       const userPoolTemplate = {\n         Type: 'AWS::Cognito::UserPool',\n@@ -122,42 +165,6 @@ class AwsCompileCognitoUserPoolEvents {\n       _.merge(this.serverless.service.provider.compiledCloudFormationTemplate.Resources,\n         userPoolCFResource);\n     });\n-\n-    // Generate CloudFormation templates for IAM permissions to allow Cognito to trigger Lambda\n-    cognitoUserPoolTriggerFunctions.forEach((cognitoUserPoolTriggerFunction) => {\n-      const userPoolLogicalId = this.provider.naming\n-        .getCognitoUserPoolLogicalId(cognitoUserPoolTriggerFunction.poolName);\n-      const lambdaLogicalId = this.provider.naming\n-        .getLambdaLogicalId(cognitoUserPoolTriggerFunction.functionName);\n-\n-      const permissionTemplate = {\n-        Type: 'AWS::Lambda::Permission',\n-        Properties: {\n-          FunctionName: {\n-            'Fn::GetAtt': [\n-              lambdaLogicalId,\n-              'Arn',\n-            ],\n-          },\n-          Action: 'lambda:InvokeFunction',\n-          Principal: 'cognito-idp.amazonaws.com',\n-          SourceArn: {\n-            'Fn::GetAtt': [\n-              userPoolLogicalId,\n-              'Arn',\n-            ],\n-          },\n-        },\n-      };\n-      const lambdaPermissionLogicalId = this.provider.naming\n-        .getLambdaCognitoUserPoolPermissionLogicalId(cognitoUserPoolTriggerFunction.functionName,\n-          cognitoUserPoolTriggerFunction.poolName, cognitoUserPoolTriggerFunction.triggerSource);\n-      const permissionCFResource = {\n-        [lambdaPermissionLogicalId]: permissionTemplate,\n-      };\n-      _.merge(this.serverless.service.provider.compiledCloudFormationTemplate.Resources,\n-        permissionCFResource);\n-    });\n   }\n }\n \n"}
{"instance_id": "serverless__serverless-6842", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/lib/mergeIamTemplates.js b/lib/plugins/aws/package/lib/mergeIamTemplates.js\nindex 2d97671ad..ca1e49d16 100644\n--- a/lib/plugins/aws/package/lib/mergeIamTemplates.js\n+++ b/lib/plugins/aws/package/lib/mergeIamTemplates.js\n@@ -183,7 +183,7 @@ module.exports = {\n \n   validateStatements(statements) {\n     // Verify that iamRoleStatements (if present) is an array of { Effect: ...,\n-    // Action: ..., Resource: ... } objects.\n+    // Action/NotAction: ..., Resource/NotResource: ... } objects.\n     if (!statements) {\n       return;\n     }\n@@ -192,9 +192,16 @@ module.exports = {\n       violationsFound = 'it is not an array';\n     } else {\n       const descriptions = statements.map((statement, i) => {\n-        const missing = ['Effect', 'Action', 'Resource'].filter(\n-          prop => statement[prop] === undefined\n-        );\n+        const missing = [];\n+        if (statement.Effect === undefined) {\n+          missing.push('Effect');\n+        }\n+        if (statement.Action === undefined && statement.NotAction === undefined) {\n+          missing.push('Action / NotAction');\n+        }\n+        if (statement.Resource === undefined && statement.NotResource === undefined) {\n+          missing.push('Resource / NotResource');\n+        }\n         return missing.length === 0\n           ? null\n           : `statement ${i} is missing the following properties: ${missing.join(', ')}`;\n@@ -208,7 +215,7 @@ module.exports = {\n     if (violationsFound) {\n       const errorMessage = [\n         'iamRoleStatements should be an array of objects,',\n-        ' where each object has Effect, Action, Resource fields.',\n+        ' where each object has Effect, Action / NotAction, Resource / NotResource fields.',\n         ` Specifically, ${violationsFound}`,\n       ].join('');\n       throw new this.serverless.classes.Error(errorMessage);\n"}
{"instance_id": "serverless__serverless-6534", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/lib/mergeIamTemplates.js b/lib/plugins/aws/package/lib/mergeIamTemplates.js\nindex 945312b69..fb467d443 100644\n--- a/lib/plugins/aws/package/lib/mergeIamTemplates.js\n+++ b/lib/plugins/aws/package/lib/mergeIamTemplates.js\n@@ -90,18 +90,29 @@ module.exports = {\n       .Resources[this.provider.naming.getRoleLogicalId()].Properties.Policies[0].PolicyDocument\n       .Statement;\n \n-    // Ensure general polices for functions with default name resolution\n-    policyDocumentStatements[0].Resource.push({\n-      'Fn::Sub':\n-        'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}' +\n-        `:log-group:${logGroupsPrefix}*:*`,\n+    // Ensure general policies for functions with default name resolution\n+    // but only if there are functions that use the default naming scheme\n+    let shouldAddDefaultLogGroupPolicy = false;\n+    this.serverless.service.getAllFunctions().forEach(functionName => {\n+      const { name: resolvedFunctionName } = this.serverless.service.getFunction(functionName);\n+      if (!resolvedFunctionName || resolvedFunctionName.startsWith(canonicalFunctionNamePrefix)) {\n+        shouldAddDefaultLogGroupPolicy = true;\n+      }\n     });\n \n-    policyDocumentStatements[1].Resource.push({\n-      'Fn::Sub':\n-        'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}' +\n-        `:log-group:${logGroupsPrefix}*:*:*`,\n-    });\n+    if (shouldAddDefaultLogGroupPolicy) {\n+      policyDocumentStatements[0].Resource.push({\n+        'Fn::Sub':\n+          'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}' +\n+          `:log-group:${logGroupsPrefix}*:*`,\n+      });\n+\n+      policyDocumentStatements[1].Resource.push({\n+        'Fn::Sub':\n+          'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}' +\n+          `:log-group:${logGroupsPrefix}*:*:*`,\n+      });\n+    }\n \n     // Ensure policies for functions with custom name resolution\n     this.serverless.service.getAllFunctions().forEach(functionName => {\n"}
{"instance_id": "serverless__serverless-6447", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/lib/validate.js b/lib/plugins/aws/lib/validate.js\nindex a4be8a5f0..b2d0563a1 100644\n--- a/lib/plugins/aws/lib/validate.js\n+++ b/lib/plugins/aws/lib/validate.js\n@@ -15,6 +15,14 @@ module.exports = {\n \n     this.options.stage = this.provider.getStage();\n     this.options.region = this.provider.getRegion();\n+\n+    // Skip credentials validation for commands that don't need them\n+    const command =\n+      this.serverless.processedInput && this.serverless.processedInput.commands[0];\n+    if (command === 'package') {\n+      return BbPromise.resolve();\n+    }\n+\n     const creds = Object.assign({}, this.provider.getCredentials());\n     delete creds.region;\n     delete creds.signatureVersion;\n"}
{"instance_id": "serverless__serverless-6869", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/hack/updateStage.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/hack/updateStage.js\nindex a4c5da743..31d91b37c 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/hack/updateStage.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/hack/updateStage.js\n@@ -5,6 +5,16 @@ const BbPromise = require('bluebird');\n const ServerlessError = require('../../../../../../../../classes/Error').ServerlessError;\n \n const isRestApiId = RegExp.prototype.test.bind(/^[a-z0-9]{3,}$/);\n+\n+// Some configuration parameters can be passed as strings (e.g. from SSM parameters)\n+// This function ensures that string representations of booleans are converted to actual booleans\n+function toBoolean(value) {\n+  if (typeof value === 'string') {\n+    return value !== 'false';\n+  }\n+  return Boolean(value);\n+}\n+\n const defaultApiGatewayLogFormat = [\n   'requestId: $context.requestId',\n   'ip: $context.identity.sourceIp',\n@@ -212,7 +222,7 @@ function handleLogs() {\n       logFormat = logs.format;\n     }\n \n-    const executionLogging = logs.executionLogging == null ? true : logs.executionLogging;\n+    const executionLogging = logs.executionLogging == null ? true : toBoolean(logs.executionLogging);\n \n     let level = defaultApiGatewayLogLevel;\n     if (!executionLogging) {\n@@ -228,7 +238,7 @@ function handleLogs() {\n       }\n     }\n \n-    const accessLogging = logs.accessLogging == null ? true : logs.accessLogging;\n+    const accessLogging = logs.accessLogging == null ? true : toBoolean(logs.accessLogging);\n \n     if (accessLogging) {\n       let resourceArn;\n@@ -257,7 +267,7 @@ function handleLogs() {\n       });\n     }\n \n-    const fullExecutionData = logs.fullExecutionData == null ? true : logs.fullExecutionData;\n+    const fullExecutionData = logs.fullExecutionData == null ? true : toBoolean(logs.fullExecutionData);\n     operations.push({\n       op: 'replace',\n       path: '/*/*/logging/dataTrace',\n@@ -342,7 +352,8 @@ function removeAccessLoggingLogGroup() {\n   let accessLogging = provider.logs && provider.logs.restApi;\n \n   if (accessLogging) {\n-    accessLogging = accessLogging.accessLogging == null ? true : accessLogging.accessLogging;\n+    accessLogging =\n+      accessLogging.accessLogging == null ? true : toBoolean(accessLogging.accessLogging);\n   }\n \n   // if there are no logs setup (or the user has disabled them) we need to\n"}
{"instance_id": "serverless__serverless-7587", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/info/getResourceCount.js b/lib/plugins/aws/info/getResourceCount.js\nindex abe00ac4c..6071dd686 100644\n--- a/lib/plugins/aws/info/getResourceCount.js\n+++ b/lib/plugins/aws/info/getResourceCount.js\n@@ -1,19 +1,12 @@\n 'use strict';\n \n const BbPromise = require('bluebird');\n-const _ = require('lodash');\n \n module.exports = {\n   getResourceCount() {\n-    const stackName = this.provider.naming.getStackName();\n-\n-    return this.provider\n-      .request('CloudFormation', 'listStackResources', { StackName: stackName })\n-      .then(result => {\n-        if (!_.isEmpty(result)) {\n-          this.gatheredData.info.resourceCount = result.StackResourceSummaries.length;\n-        }\n-        return BbPromise.resolve();\n-      });\n+    return this.provider.getStackResources().then(resources => {\n+      this.gatheredData.info.resourceCount = resources.length;\n+      return BbPromise.resolve();\n+    });\n   },\n };\n"}
{"instance_id": "serverless__serverless-7277", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/providers/aws/events/sns.md b/docs/providers/aws/events/sns.md\nindex 556153b77..c567674be 100644\n--- a/docs/providers/aws/events/sns.md\n+++ b/docs/providers/aws/events/sns.md\n@@ -149,7 +149,9 @@ functions:\n \n ## Setting a redrive policy\n \n-This event definition creates an SNS topic that sends messages to a Dead Letter Queue (defined by its ARN) when the associated lambda is not available. In this example, messages that aren't delivered to the `dispatcher` Lambda (because the lambda service is down or irresponsive) will end in `myDLQ`\n+This event definition creates an SNS topic that sends messages to a Dead Letter Queue when the associated lambda is not available. In this example, messages that aren't delivered to the `dispatcher` Lambda (because the lambda service is down or irresponsive) will end in `myDLQ`.\n+\n+You can use `deadLetterTargetRef` to reference an SQS queue defined in the same template by its logical ID. This is the recommended approach as it properly handles both the ARN (for the subscription) and URL (for the queue policy):\n \n ```yml\n functions:\n@@ -159,7 +161,7 @@ functions:\n       - sns:\n           topicName: dispatcher\n           redrivePolicy:\n-            deadLetterTargetArn: !Ref myDLQ\n+            deadLetterTargetRef: myDLQ\n \n resources:\n   Resources:\n@@ -168,3 +170,16 @@ resources:\n       Properties:\n         QueueName: myDLQ\n ```\n+\n+Alternatively, you can use `deadLetterTargetArn` to specify the ARN directly (useful for cross-stack references):\n+\n+```yml\n+functions:\n+  dispatcher:\n+    handler: dispatcher.handler\n+    events:\n+      - sns:\n+          topicName: dispatcher\n+          redrivePolicy:\n+            deadLetterTargetArn: arn:aws:sqs:us-east-1:11111111111:myDLQ\n+```\ndiff --git a/docs/providers/aws/guide/serverless.yml.md b/docs/providers/aws/guide/serverless.yml.md\nindex 907003d83..4d71e6317 100644\n--- a/docs/providers/aws/guide/serverless.yml.md\n+++ b/docs/providers/aws/guide/serverless.yml.md\n@@ -261,7 +261,7 @@ functions:\n               - dog\n               - cat\n           redrivePolicy:\n-            deadLetterTargetArn: arn:aws:sqs:region:XXXXXX:myDLQ\n+            deadLetterTargetRef: myDLQ # Reference to SQS queue logical ID (recommended)\n       - sqs:\n           arn: arn:aws:sqs:region:XXXXXX:myQueue\n           batchSize: 10\ndiff --git a/lib/plugins/aws/package/compile/events/sns/index.js b/lib/plugins/aws/package/compile/events/sns/index.js\nindex 3b62dc379..788951029 100644\n--- a/lib/plugins/aws/package/compile/events/sns/index.js\n+++ b/lib/plugins/aws/package/compile/events/sns/index.js\n@@ -133,6 +133,16 @@ class AwsCompileSNSEvents {\n               topicName\n             );\n \n+            // Transform redrivePolicy if deadLetterTargetRef is used\n+            let redrivePolicy = event.sns.redrivePolicy;\n+            if (redrivePolicy && redrivePolicy.deadLetterTargetRef) {\n+              redrivePolicy = {\n+                deadLetterTargetArn: {\n+                  'Fn::GetAtt': [redrivePolicy.deadLetterTargetRef, 'Arn'],\n+                },\n+              };\n+            }\n+\n             if (topicArn) {\n               _.merge(template.Resources, {\n                 [subscriptionLogicalId]: {\n@@ -142,7 +152,7 @@ class AwsCompileSNSEvents {\n                     Protocol: 'lambda',\n                     Endpoint: endpoint,\n                     FilterPolicy: event.sns.filterPolicy,\n-                    RedrivePolicy: event.sns.redrivePolicy,\n+                    RedrivePolicy: redrivePolicy,\n                     Region: region,\n                   },\n                 },\n@@ -183,10 +193,7 @@ class AwsCompileSNSEvents {\n                 });\n               }\n \n-              if (\n-                event.sns.filterPolicy ||\n-                (event.sns.redrivePolicy && event.sns.redrivePolicy.deadLetterTargetArn)\n-              ) {\n+              if (event.sns.filterPolicy || redrivePolicy) {\n                 _.merge(template.Resources, {\n                   [subscriptionLogicalId]: {\n                     Type: 'AWS::SNS::Subscription',\n@@ -195,7 +202,7 @@ class AwsCompileSNSEvents {\n                         Ref: topicLogicalId,\n                       },\n                       FilterPolicy: event.sns.filterPolicy,\n-                      RedrivePolicy: event.sns.redrivePolicy,\n+                      RedrivePolicy: redrivePolicy,\n                     }),\n                   },\n                 });\n@@ -224,38 +231,51 @@ class AwsCompileSNSEvents {\n               },\n             });\n \n-            if (event.sns.redrivePolicy && event.sns.redrivePolicy.deadLetterTargetArn) {\n-              const queuePolicyLogicalId = this.provider.naming.getQueueLogicalId(\n-                functionName,\n-                `${topicName}DLQ`\n-              );\n-              Object.assign(template.Resources, {\n-                [queuePolicyLogicalId]: {\n-                  Type: 'AWS::SQS::QueuePolicy',\n-                  Properties: {\n-                    PolicyDocument: {\n-                      Version: '2012-10-17',\n-                      Id: queuePolicyLogicalId,\n-                      Statement: [\n-                        {\n-                          Effect: 'Allow',\n-                          Principal: {\n-                            Service: 'sns.amazonaws.com',\n-                          },\n-                          Action: 'sqs:SendMessage',\n-                          Resource: event.sns.redrivePolicy.deadLetterTargetArn,\n-                          Condition: {\n-                            ArnEquals: {\n-                              'aws:SourceArn': topicArn,\n+            if (event.sns.redrivePolicy) {\n+              let dlqArn;\n+              let dlqUrl;\n+              if (event.sns.redrivePolicy.deadLetterTargetRef) {\n+                const deadLetterTargetRef = event.sns.redrivePolicy.deadLetterTargetRef;\n+                dlqArn = { 'Fn::GetAtt': [deadLetterTargetRef, 'Arn'] };\n+                dlqUrl = { Ref: deadLetterTargetRef };\n+              } else if (event.sns.redrivePolicy.deadLetterTargetArn) {\n+                dlqArn = event.sns.redrivePolicy.deadLetterTargetArn;\n+                dlqUrl = event.sns.redrivePolicy.deadLetterTargetArn;\n+              }\n+\n+              if (dlqArn) {\n+                const queuePolicyLogicalId = this.provider.naming.getQueueLogicalId(\n+                  functionName,\n+                  `${topicName}DLQ`\n+                );\n+                Object.assign(template.Resources, {\n+                  [queuePolicyLogicalId]: {\n+                    Type: 'AWS::SQS::QueuePolicy',\n+                    Properties: {\n+                      PolicyDocument: {\n+                        Version: '2012-10-17',\n+                        Id: queuePolicyLogicalId,\n+                        Statement: [\n+                          {\n+                            Effect: 'Allow',\n+                            Principal: {\n+                              Service: 'sns.amazonaws.com',\n+                            },\n+                            Action: 'sqs:SendMessage',\n+                            Resource: dlqArn,\n+                            Condition: {\n+                              ArnEquals: {\n+                                'aws:SourceArn': topicArn,\n+                              },\n                             },\n                           },\n-                        },\n-                      ],\n+                        ],\n+                      },\n+                      Queues: [dlqUrl],\n                     },\n-                    Queues: [event.sns.redrivePolicy.deadLetterTargetArn],\n                   },\n-                },\n-              });\n+                });\n+              }\n             }\n           }\n         });\n"}
{"instance_id": "serverless__serverless-7617", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/providers/aws/events/apigateway.md b/docs/providers/aws/events/apigateway.md\nindex 27922e7c8..9fc446bb8 100644\n--- a/docs/providers/aws/events/apigateway.md\n+++ b/docs/providers/aws/events/apigateway.md\n@@ -203,6 +203,21 @@ functions:\n           method: post\n ```\n \n+#### Customizing the Operation Name\n+\n+You can set the `operationId` to customize the `OperationName` of the API Gateway Method. This is useful when exporting your API to Swagger/OpenAPI, as the `operationId` maps to the Swagger `operationId` field, which is used by code generation tools to generate function names.\n+\n+```yml\n+functions:\n+  create:\n+    handler: posts.create\n+    events:\n+      - http:\n+          path: posts/create\n+          method: post\n+          operationId: createPost\n+```\n+\n ### Enabling CORS\n \n To set CORS configurations for your HTTP endpoints, simply modify your event configurations as follows:\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\nindex 11d1027f3..e70f871b3 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\n@@ -28,6 +28,10 @@ module.exports = {\n         template.Properties.ApiKeyRequired = false;\n       }\n \n+      if (event.http.operationId) {\n+        template.Properties.OperationName = event.http.operationId;\n+      }\n+\n       const methodLogicalId = this.provider.naming.getMethodLogicalId(\n         resourceName,\n         event.http.method\n"}
{"instance_id": "serverless__serverless-6987", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\nindex decf7ff49..f6c71fb46 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\n@@ -40,6 +40,50 @@ module.exports = {\n         },\n       });\n \n+      // Add a more specific permission for lambda (non-proxy) integration\n+      // This is needed when using binaryMediaTypes with lambda integration\n+      if (singlePermissionMapping.event.http.integration === 'AWS') {\n+        const http = singlePermissionMapping.event.http;\n+        const path = http.path === '/' ? '' : `/${http.path}`;\n+        const method = http.method.toUpperCase();\n+\n+        const lambdaPermissionLogicalIdApigEvent = this.provider.naming.getMethodLogicalId(\n+          singlePermissionMapping.resourceName,\n+          http.method\n+        );\n+\n+        _.merge(this.serverless.service.provider.compiledCloudFormationTemplate.Resources, {\n+          [`${lambdaPermissionLogicalIdApigEvent}PermissionApigEvent`]: {\n+            Type: 'AWS::Lambda::Permission',\n+            Properties: {\n+              FunctionName: {\n+                'Fn::GetAtt': [singlePermissionMapping.lambdaLogicalId, 'Arn'],\n+              },\n+              Action: 'lambda:InvokeFunction',\n+              Principal: 'apigateway.amazonaws.com',\n+              SourceArn: {\n+                'Fn::Join': [\n+                  '',\n+                  [\n+                    'arn:',\n+                    { Ref: 'AWS::Partition' },\n+                    ':execute-api:',\n+                    { Ref: 'AWS::Region' },\n+                    ':',\n+                    { Ref: 'AWS::AccountId' },\n+                    ':',\n+                    this.provider.getApiGatewayRestApiId(),\n+                    '/*/',\n+                    method,\n+                    path,\n+                  ],\n+                ],\n+              },\n+            },\n+          },\n+        });\n+      }\n+\n       if (\n         singlePermissionMapping.event.http.authorizer &&\n         singlePermissionMapping.event.http.authorizer.arn\n"}
{"instance_id": "serverless__serverless-8159", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/providers/aws/events/apigateway.md b/docs/providers/aws/events/apigateway.md\nindex 77c99fa11..9893e136e 100644\n--- a/docs/providers/aws/events/apigateway.md\n+++ b/docs/providers/aws/events/apigateway.md\n@@ -970,6 +970,22 @@ functions:\n               application/json: '{ \"httpMethod\" : \"$context.httpMethod\" }'\n ```\n \n+You can also remove one of the default request templates by setting its value to `null`. For example, if you only want to support `application/json` and want to remove the default `application/x-www-form-urlencoded` template:\n+\n+```yml\n+functions:\n+  create:\n+    handler: posts.create\n+    events:\n+      - http:\n+          method: get\n+          path: whatever\n+          integration: lambda\n+          request:\n+            template:\n+              application/x-www-form-urlencoded: null\n+```\n+\n **Note:** The templates are defined as plain text here. However you can also reference an external file with the help of the `${file(templatefile)}` syntax.\n \n **Note 2:** In .yml, strings containing `:`, `{`, `}`, `[`, `]`, `,`, `&`, `*`, `#`, `?`, `|`, `-`, `<`, `>`, `=`, `!`, `%`, `@`, `` ` `` must be quoted.\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\nindex 3be224959..9dd99233c 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n@@ -212,6 +212,13 @@ module.exports = {\n       Object.assign(integrationRequestTemplates, http.request.template);\n     }\n \n+    // filter out templates with null values to allow for removal of default templates\n+    Object.keys(integrationRequestTemplates).forEach(contentType => {\n+      if (integrationRequestTemplates[contentType] === null) {\n+        delete integrationRequestTemplates[contentType];\n+      }\n+    });\n+\n     return Object.keys(integrationRequestTemplates).length\n       ? integrationRequestTemplates\n       : undefined;\n"}
{"instance_id": "serverless__serverless-7374", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/utils/fs/dirExists.js b/lib/utils/fs/dirExists.js\nindex ab52ae6ad..b34cd5bb1 100644\n--- a/lib/utils/fs/dirExists.js\n+++ b/lib/utils/fs/dirExists.js\n@@ -3,7 +3,7 @@\n const fse = require('./fse');\n \n function dirExists(path) {\n-  return fse.lstatAsync(path).then(\n+  return fse.statAsync(path).then(\n     stats => stats.isDirectory(),\n     error => {\n       if (error.code === 'ENOENT') {\ndiff --git a/lib/utils/fs/fileExists.js b/lib/utils/fs/fileExists.js\nindex 81a829ad5..94de78ae9 100644\n--- a/lib/utils/fs/fileExists.js\n+++ b/lib/utils/fs/fileExists.js\n@@ -4,7 +4,7 @@ const fse = require('./fse');\n \n function fileExists(filePath) {\n   return fse\n-    .lstatAsync(filePath)\n+    .statAsync(filePath)\n     .then(stats => stats.isFile())\n     .catch(() => false);\n }\ndiff --git a/lib/utils/fs/fileExistsSync.js b/lib/utils/fs/fileExistsSync.js\nindex 147300e7b..e11066ef2 100644\n--- a/lib/utils/fs/fileExistsSync.js\n+++ b/lib/utils/fs/fileExistsSync.js\n@@ -4,7 +4,7 @@ const fse = require('./fse');\n \n function fileExistsSync(filePath) {\n   try {\n-    const stats = fse.lstatSync(filePath);\n+    const stats = fse.statSync(filePath);\n     return stats.isFile();\n   } catch (e) {\n     return false;\n"}
{"instance_id": "sveltejs__svelte-1095", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/validate/html/a11y.ts b/src/validate/html/a11y.ts\nindex 4dbf249ff..30be66dc8 100644\n--- a/src/validate/html/a11y.ts\n+++ b/src/validate/html/a11y.ts\n@@ -160,6 +160,17 @@ export default function a11y(\n \t\tvalidator.warn(`A11y: Avoid <${node.name}> elements`, node.start);\n \t}\n \n+\t// svg-viewbox-lowercase\n+\tif (node.name === 'svg') {\n+\t\tconst viewBox = attributeMap.get('viewBox');\n+\t\tif (!viewBox) {\n+\t\t\tconst viewbox = node.attributes.find(a => a.name === 'viewbox');\n+\t\t\tif (viewbox) {\n+\t\t\t\tvalidator.warn(`A11y: <svg> element should have a viewBox attribute (case-sensitive)`, viewbox.start);\n+\t\t\t}\n+\t\t}\n+\t}\n+\n \tif (node.name === 'figcaption') {\n \t\tconst parent = elementStack[elementStack.length - 1];\n \t\tif (parent) {\n"}
{"instance_id": "sveltejs__svelte-1049", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/nodes/Element.ts b/src/generators/nodes/Element.ts\nindex f3d87ab2b..6c07d7f21 100644\n--- a/src/generators/nodes/Element.ts\n+++ b/src/generators/nodes/Element.ts\n@@ -291,6 +291,12 @@ export default class Element extends Node {\n \t\t\t\tconst indexName = block.indexNames.get(name);\n \t\t\t\tconst contextName = block.contexts.get(name);\n \n+\t\t\t\t// for await blocks, the context is passed directly as a parameter\n+\t\t\t\t// rather than being stored in a list/index structure\n+\t\t\t\tif (!listName) {\n+\t\t\t\t\treturn `var ${contextName} = ${ctx}._svelte.${contextName};`;\n+\t\t\t\t}\n+\n \t\t\t\treturn `var ${listName} = ${ctx}._svelte.${listName}, ${indexName} = ${ctx}._svelte.${indexName}, ${contextName} = ${listName}[${indexName}];`;\n \t\t\t});\n \n@@ -376,12 +382,24 @@ export default class Element extends Node {\n \t\t\t\tconst listName = block.listNames.get(contextName);\n \t\t\t\tconst indexName = block.indexNames.get(contextName);\n \n-\t\t\t\tinitialProps.push(\n-\t\t\t\t\t`${listName}: ${listName},\\n${indexName}: ${indexName}`\n-\t\t\t\t);\n-\t\t\t\tupdates.push(\n-\t\t\t\t\t`${name}._svelte.${listName} = ${listName};\\n${name}._svelte.${indexName} = ${indexName};`\n-\t\t\t\t);\n+\t\t\t\t// for await blocks, the context is passed directly as a parameter\n+\t\t\t\t// rather than being stored in a list/index structure\n+\t\t\t\tif (!listName) {\n+\t\t\t\t\tconst contextVariable = block.contexts.get(contextName);\n+\t\t\t\t\tinitialProps.push(\n+\t\t\t\t\t\t`${contextVariable}: ${contextVariable}`\n+\t\t\t\t\t);\n+\t\t\t\t\tupdates.push(\n+\t\t\t\t\t\t`${name}._svelte.${contextVariable} = ${contextVariable};`\n+\t\t\t\t\t);\n+\t\t\t\t} else {\n+\t\t\t\t\tinitialProps.push(\n+\t\t\t\t\t\t`${listName}: ${listName},\\n${indexName}: ${indexName}`\n+\t\t\t\t\t);\n+\t\t\t\t\tupdates.push(\n+\t\t\t\t\t\t`${name}._svelte.${listName} = ${listName};\\n${name}._svelte.${indexName} = ${indexName};`\n+\t\t\t\t\t);\n+\t\t\t\t}\n \t\t\t});\n \n \t\t\tif (initialProps.length) {\n"}
{"instance_id": "sveltejs__svelte-1116", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/server-side-rendering/index.ts b/src/generators/server-side-rendering/index.ts\nindex 37bf859da..9ee99123c 100644\n--- a/src/generators/server-side-rendering/index.ts\n+++ b/src/generators/server-side-rendering/index.ts\n@@ -132,6 +132,8 @@ export default function ssr(\n \t\t${name}._render = function(__result, state, options) {\n \t\t\t__result.addComponent(${name});\n \n+\t\t\t${templateProperties.store && `options = Object.assign({ store: %store() }, options);`}\n+\n \t\t\tstate = Object.assign(${initialState.join(', ')});\n \n \t\t\t${computations.map(\ndiff --git a/src/generators/server-side-rendering/visitors/Component.ts b/src/generators/server-side-rendering/visitors/Component.ts\nindex 4843010fc..4f4ca13b2 100644\n--- a/src/generators/server-side-rendering/visitors/Component.ts\n+++ b/src/generators/server-side-rendering/visitors/Component.ts\n@@ -87,7 +87,7 @@ export default function visitComponent(\n \tlet open = `\\${${expression}._render(__result, {${props}}`;\n \n \tconst options = [];\n-\tif (generator.options.store) {\n+\tif (generator.options.store || generator.templateProperties.store) {\n \t\toptions.push(`store: options.store`);\n \t}\n \n"}
{"instance_id": "serverless__serverless-7102", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/lib/plugins/aws/lib/naming.js b/lib/plugins/aws/lib/naming.js\nindex 2c1f5dfdc..bb0d3f738 100644\n--- a/lib/plugins/aws/lib/naming.js\n+++ b/lib/plugins/aws/lib/naming.js\n@@ -166,6 +166,12 @@ module.exports = {\n   getLambdaOnlyVersionLogicalId(functionName) {\n     return `${this.getNormalizedFunctionName(functionName)}LambdaVersion`;\n   },\n+  getLambdaProvisionedConcurrencyAliasLogicalId(functionName) {\n+    return `${this.getNormalizedFunctionName(functionName)}ProvConcLambdaAlias`;\n+  },\n+  getLambdaProvisionedConcurrencyAliasName() {\n+    return 'provisioned';\n+  },\n   getLambdaVersionOutputLogicalId(functionName) {\n     return `${this.getLambdaLogicalId(functionName)}QualifiedArn`;\n   },\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\nindex d83ad2ba8..16eb840a4 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\n@@ -38,13 +38,33 @@ module.exports = {\n       );\n       const lambdaLogicalId = this.provider.naming.getLambdaLogicalId(event.functionName);\n \n-      const singlePermissionMapping = { resourceName, lambdaLogicalId, event };\n+      // Check if the function has provisioned concurrency configured\n+      // If so, we need to use the alias ARN instead of the function ARN\n+      let lambdaAliasName;\n+      let lambdaAliasLogicalId;\n+      if (event.functionName in this.serverless.service.functions) {\n+        const functionObject = this.serverless.service.getFunction(event.functionName);\n+        if (functionObject.provisionedConcurrency) {\n+          lambdaAliasName = 'provisioned';\n+          lambdaAliasLogicalId = this.provider.naming.getLambdaProvisionedConcurrencyAliasLogicalId(\n+            event.functionName\n+          );\n+        }\n+      }\n+\n+      const singlePermissionMapping = {\n+        resourceName,\n+        lambdaLogicalId,\n+        lambdaAliasName,\n+        lambdaAliasLogicalId,\n+        event,\n+      };\n       this.permissionMapping.push(singlePermissionMapping);\n \n       _.merge(\n         template,\n         this.getMethodAuthorization(event.http),\n-        this.getMethodIntegration(event.http, lambdaLogicalId, methodLogicalId),\n+        this.getMethodIntegration(event.http, lambdaLogicalId, methodLogicalId, lambdaAliasLogicalId),\n         this.getMethodResponses(event.http)\n       );\n \ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\nindex f3f0639b2..e9186495e 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n@@ -49,7 +49,7 @@ const DEFAULT_COMMON_TEMPLATE = `\n `;\n \n module.exports = {\n-  getMethodIntegration(http, lambdaLogicalId) {\n+  getMethodIntegration(http, lambdaLogicalId, methodLogicalId, lambdaAliasLogicalId) {\n     const type = http.integration || 'AWS_PROXY';\n     const integration = {\n       IntegrationHttpMethod: 'POST',\n@@ -63,6 +63,12 @@ module.exports = {\n     // * `HTTP_PROXY` for integrating with the HTTP proxy integration, or\n     // * `AWS_PROXY` for integrating with the Lambda proxy integration type (the default)\n     if (type === 'AWS' || type === 'AWS_PROXY') {\n+      // Use the Lambda alias ARN if provisioned concurrency is configured,\n+      // otherwise use the function ARN\n+      const lambdaArn = lambdaAliasLogicalId\n+        ? { Ref: lambdaAliasLogicalId }\n+        : { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] };\n+\n       _.assign(integration, {\n         Uri: {\n           'Fn::Join': [\n@@ -73,7 +79,7 @@ module.exports = {\n               ':apigateway:',\n               { Ref: 'AWS::Region' },\n               ':lambda:path/2015-03-31/functions/',\n-              { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] },\n+              lambdaArn,\n               '/invocations',\n             ],\n           ],\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\nindex decf7ff49..1d7229ab7 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\n@@ -11,13 +11,17 @@ module.exports = {\n         singlePermissionMapping.event.functionName\n       );\n \n+      // Use the Lambda alias ARN if provisioned concurrency is configured,\n+      // otherwise use the function ARN\n+      const lambdaArn = singlePermissionMapping.lambdaAliasLogicalId\n+        ? { Ref: singlePermissionMapping.lambdaAliasLogicalId }\n+        : { 'Fn::GetAtt': [singlePermissionMapping.lambdaLogicalId, 'Arn'] };\n+\n       _.merge(this.serverless.service.provider.compiledCloudFormationTemplate.Resources, {\n         [lambdaPermissionLogicalId]: {\n           Type: 'AWS::Lambda::Permission',\n           Properties: {\n-            FunctionName: {\n-              'Fn::GetAtt': [singlePermissionMapping.lambdaLogicalId, 'Arn'],\n-            },\n+            FunctionName: lambdaArn,\n             Action: 'lambda:InvokeFunction',\n             Principal: 'apigateway.amazonaws.com',\n             SourceArn: {\ndiff --git a/lib/plugins/aws/package/compile/functions/index.js b/lib/plugins/aws/package/compile/functions/index.js\nindex a9b582e7e..01405a85b 100644\n--- a/lib/plugins/aws/package/compile/functions/index.js\n+++ b/lib/plugins/aws/package/compile/functions/index.js\n@@ -447,7 +447,7 @@ class AwsCompileFunctions {\n       if (functionObject.provisionedConcurrency) {\n         if (versionFunction) {\n           const errorMessage = [\n-            'Sorry, at this point,provisioned conncurrency for ' +\n+            'Sorry, at this point, provisioned concurrency for ' +\n               `${newFunction.Properties.FunctionName}\\n`,\n             'cannot be setup together with lambda versioning enabled.\\n\\n',\n             'If you want to take advantage of provisioned concurrency, please turn off lambda versioning.\\n\\n',\n@@ -465,16 +465,36 @@ class AwsCompileFunctions {\n           );\n         }\n \n+        const versionLogicalId = this.provider.naming.getLambdaOnlyVersionLogicalId(functionName);\n+        const aliasLogicalId = this.provider.naming.getLambdaProvisionedConcurrencyAliasLogicalId(\n+          functionName\n+        );\n+        const aliasName = this.provider.naming.getLambdaProvisionedConcurrencyAliasName();\n+\n+        // Create a Lambda version\n         this.serverless.service.provider.compiledCloudFormationTemplate.Resources[\n-          this.provider.naming.getLambdaOnlyVersionLogicalId(functionName)\n+          versionLogicalId\n         ] = {\n           Type: 'AWS::Lambda::Version',\n           Properties: {\n             FunctionName: { Ref: functionLogicalId },\n+          },\n+        };\n+\n+        // Create a Lambda alias with provisioned concurrency that points to the version\n+        this.serverless.service.provider.compiledCloudFormationTemplate.Resources[\n+          aliasLogicalId\n+        ] = {\n+          Type: 'AWS::Lambda::Alias',\n+          Properties: {\n+            FunctionName: { Ref: functionLogicalId },\n+            FunctionVersion: { 'Fn::GetAtt': [versionLogicalId, 'Version'] },\n+            Name: aliasName,\n             ProvisionedConcurrencyConfig: {\n               ProvisionedConcurrentExecutions: provisionedConcurrency,\n             },\n           },\n+          DependsOn: functionLogicalId,\n         };\n       }\n \n"}
{"instance_id": "sveltejs__svelte-1310", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/css/Selector.ts b/src/css/Selector.ts\nindex fba0386f1..9017ffe8c 100644\n--- a/src/css/Selector.ts\n+++ b/src/css/Selector.ts\n@@ -223,6 +223,9 @@ const operators = {\n };\n \n function attributeMatches(node: Node, name: string, expectedValue: string, operator: string, caseInsensitive: boolean) {\n+\tconst spread = node.attributes.find((attr: Node) => attr.type === 'Spread');\n+\tif (spread) return true;\n+\n \tconst attr = node.attributes.find((attr: Node) => attr.name === name);\n \tif (!attr) return false;\n \tif (attr.value === true) return operator === null;\n"}
{"instance_id": "sveltejs__svelte-1227", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/nodes/Element.ts b/src/generators/nodes/Element.ts\nindex 69997e077..00800f841 100644\n--- a/src/generators/nodes/Element.ts\n+++ b/src/generators/nodes/Element.ts\n@@ -735,8 +735,7 @@ function stringifyAttributeValue(value: Node | true) {\n \tif (value === true) return '';\n \tif (value.length === 0) return `=\"\"`;\n \n-\tconst data = value[0].data;\n-\treturn `=${JSON.stringify(data)}`;\n+\treturn `=\"${value.map((chunk: Node) => chunk.data.replace(/\"/g, '&quot;')).join('')}\"`;\n }\n \n const events = [\n"}
{"instance_id": "sveltejs__svelte-1376", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compile/nodes/EventHandler.ts b/src/compile/nodes/EventHandler.ts\nindex a733b6554..e0145b65b 100644\n--- a/src/compile/nodes/EventHandler.ts\n+++ b/src/compile/nodes/EventHandler.ts\n@@ -19,6 +19,9 @@ export default class EventHandler extends Node {\n \targs: Expression[];\n \tsnippet: string;\n \n+\tusesThis: boolean;\n+\tthisReference: { start: number, end: number };\n+\n \tconstructor(compiler, parent, scope, info) {\n \t\tsuper(compiler, parent, scope, info);\n \n@@ -40,6 +43,20 @@ export default class EventHandler extends Node {\n \t\t\t});\n \n \t\t\tthis.snippet = `[\u2702${info.expression.start}-${info.expression.end}\u2702];`;\n+\n+\t\t\t// Check if the callee uses `this` (e.g., this.blur())\n+\t\t\tthis.usesThis = false;\n+\t\t\tif (this.callee && this.callee.name === 'this') {\n+\t\t\t\t// Find the ThisExpression node in the callee\n+\t\t\t\tlet node = info.expression.callee;\n+\t\t\t\twhile (node.type === 'MemberExpression') {\n+\t\t\t\t\tnode = node.object;\n+\t\t\t\t}\n+\t\t\t\tif (node.type === 'ThisExpression') {\n+\t\t\t\t\tthis.usesThis = true;\n+\t\t\t\t\tthis.thisReference = { start: node.start, end: node.end };\n+\t\t\t\t}\n+\t\t\t}\n \t\t} else {\n \t\t\tthis.callee = null;\n \t\t\tthis.insertionPoint = null;\n@@ -77,8 +94,22 @@ export default class EventHandler extends Node {\n \t\t\t}\n \t\t}\n \n-\t\tthis.args.forEach(arg => {\n-\t\t\targ.overwriteThis(this.parent.var);\n-\t\t});\n+\t\t// Rewrite `this` in the callee to the element variable (e.g., this.blur() -> input.blur())\n+\t\t// For Window, use 'window' as the replacement\n+\t\tconst thisReplacement = this.parent.var || (this.parent.type === 'Window' ? 'window' : null);\n+\t\tif (this.usesThis && thisReplacement) {\n+\t\t\tcompiler.code.overwrite(\n+\t\t\t\tthis.thisReference.start,\n+\t\t\t\tthis.thisReference.end,\n+\t\t\t\tthisReplacement,\n+\t\t\t\t{ storeName: true }\n+\t\t\t);\n+\t\t}\n+\n+\t\tif (thisReplacement) {\n+\t\t\tthis.args.forEach(arg => {\n+\t\t\t\targ.overwriteThis(thisReplacement);\n+\t\t\t});\n+\t\t}\n \t}\n }\n\\ No newline at end of file\n"}
{"instance_id": "sveltejs__svelte-1923", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compile/render-dom/wrappers/Element/index.ts b/src/compile/render-dom/wrappers/Element/index.ts\nindex 5f6f94f38..9b51799cd 100644\n--- a/src/compile/render-dom/wrappers/Element/index.ts\n+++ b/src/compile/render-dom/wrappers/Element/index.ts\n@@ -410,7 +410,7 @@ export default class ElementWrapper extends Wrapper {\n \t\t\t.filter(group => group.bindings.length);\n \n \t\tgroups.forEach(group => {\n-\t\t\tconst handler = block.getUniqueName(`${this.var}_${group.events.join('_')}_handler`);\n+\t\t\tconst handler = renderer.component.getUniqueName(`${this.var}_${group.events.join('_')}_handler`);\n \t\t\trenderer.component.declarations.push(handler);\n \t\t\trenderer.component.template_references.add(handler);\n \n"}
{"instance_id": "sveltejs__svelte-1231", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/dom/index.ts b/src/generators/dom/index.ts\nindex f02b013d0..8b947beac 100644\n--- a/src/generators/dom/index.ts\n+++ b/src/generators/dom/index.ts\n@@ -264,7 +264,7 @@ export default function dom(\n \t\t\tif (options.target) {\n \t\t\t\t${generator.hydratable\n \t\t\t\t\t? deindent`\n-\t\t\t\t\t\tvar nodes = @children(options.target);\n+\t\t\t\t\t\tvar nodes = @getChildren(options.target);\n \t\t\t\t\t\toptions.hydrate ? this._fragment.l(nodes) : this._fragment.c();\n \t\t\t\t\t\tnodes.forEach(@detachNode);\n \t\t\t\t\t` :\ndiff --git a/src/generators/nodes/Element.ts b/src/generators/nodes/Element.ts\nindex 42db165f9..5bebfd8f5 100644\n--- a/src/generators/nodes/Element.ts\n+++ b/src/generators/nodes/Element.ts\n@@ -185,7 +185,7 @@ export default class Element extends Node {\n \t\t\tif (parentNodes) {\n \t\t\t\tblock.builders.claim.addBlock(deindent`\n \t\t\t\t\t${name} = ${getClaimStatement(generator, this.namespace, parentNodes, this)};\n-\t\t\t\t\tvar ${childState.parentNodes} = @children(${name});\n+\t\t\t\t\tvar ${childState.parentNodes} = @getChildren(${name});\n \t\t\t\t`);\n \t\t\t} else {\n \t\t\t\tblock.builders.claim.addLine(\ndiff --git a/src/shared/dom.js b/src/shared/dom.js\nindex 9003faee3..667c16e1f 100644\n--- a/src/shared/dom.js\n+++ b/src/shared/dom.js\n@@ -109,7 +109,7 @@ export function timeRangesToArray(ranges) {\n \treturn array;\n }\n \n-export function children (element) {\n+export function getChildren (element) {\n \treturn Array.from(element.childNodes);\n }\n \n"}
{"instance_id": "sveltejs__svelte-2185", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compile/Component.ts b/src/compile/Component.ts\nindex c4695abce..b84cd95be 100644\n--- a/src/compile/Component.ts\n+++ b/src/compile/Component.ts\n@@ -677,11 +677,13 @@ export default class Component {\n \t\t\t\tif (node.type === 'AssignmentExpression') {\n \t\t\t\t\tdeep = node.left.type === 'MemberExpression';\n \n+\t\t\t\t\tconst left_object = getObject(node.left);\n \t\t\t\t\tnames = deep\n-\t\t\t\t\t\t? [getObject(node.left).name]\n+\t\t\t\t\t\t? (left_object.type === 'Identifier' ? [left_object.name] : [])\n \t\t\t\t\t\t: extractNames(node.left);\n \t\t\t\t} else if (node.type === 'UpdateExpression') {\n-\t\t\t\t\tnames = [getObject(node.argument).name];\n+\t\t\t\t\tconst object = getObject(node.argument);\n+\t\t\t\t\tnames = object.type === 'Identifier' ? [object.name] : [];\n \t\t\t\t}\n \n \t\t\t\tif (names) {\n@@ -1049,13 +1051,17 @@ export default class Component {\n \t\t\t\t\t\t}\n \n \t\t\t\t\t\tif (node.type === 'AssignmentExpression') {\n-\t\t\t\t\t\t\tconst { name } = getObject(node.left)\n-\t\t\t\t\t\t\tassignees.add(name);\n-\t\t\t\t\t\t\tdependencies.delete(name);\n+\t\t\t\t\t\t\tconst left_object = getObject(node.left);\n+\t\t\t\t\t\t\tif (left_object.type === 'Identifier') {\n+\t\t\t\t\t\t\t\tassignees.add(left_object.name);\n+\t\t\t\t\t\t\t\tdependencies.delete(left_object.name);\n+\t\t\t\t\t\t\t}\n \t\t\t\t\t\t} else if (node.type === 'UpdateExpression') {\n-\t\t\t\t\t\t\tconst { name } = getObject(node.argument);\n-\t\t\t\t\t\t\tassignees.add(name);\n-\t\t\t\t\t\t\tdependencies.delete(name);\n+\t\t\t\t\t\t\tconst object = getObject(node.argument);\n+\t\t\t\t\t\t\tif (object.type === 'Identifier') {\n+\t\t\t\t\t\t\t\tassignees.add(object.name);\n+\t\t\t\t\t\t\t\tdependencies.delete(object.name);\n+\t\t\t\t\t\t\t}\n \t\t\t\t\t\t} else if (isReference(node, parent)) {\n \t\t\t\t\t\t\tconst { name } = getObject(node);\n \t\t\t\t\t\t\tconst owner = scope.findOwner(name);\ndiff --git a/src/compile/nodes/shared/Expression.ts b/src/compile/nodes/shared/Expression.ts\nindex 22a32fa3d..9ba81a3e3 100644\n--- a/src/compile/nodes/shared/Expression.ts\n+++ b/src/compile/nodes/shared/Expression.ts\n@@ -163,12 +163,13 @@ export default class Expression {\n \t\t\t\tif (function_expression) {\n \t\t\t\t\tif (node.type === 'AssignmentExpression') {\n \t\t\t\t\t\tdeep = node.left.type === 'MemberExpression';\n+\t\t\t\t\t\tconst left_object = getObject(node.left);\n \t\t\t\t\t\tnames = deep\n-\t\t\t\t\t\t\t? [getObject(node.left).name]\n+\t\t\t\t\t\t\t? (left_object.type === 'Identifier' ? [left_object.name] : [])\n \t\t\t\t\t\t\t: extractNames(node.left);\n \t\t\t\t\t} else if (node.type === 'UpdateExpression') {\n-\t\t\t\t\t\tconst { name } = getObject(node.argument);\n-\t\t\t\t\t\tnames = [name];\n+\t\t\t\t\t\tconst object = getObject(node.argument);\n+\t\t\t\t\t\tnames = object.type === 'Identifier' ? [object.name] : [];\n \t\t\t\t\t}\n \t\t\t\t}\n \n@@ -287,8 +288,10 @@ export default class Expression {\n \n \t\t\t\tif (function_expression) {\n \t\t\t\t\tif (node.type === 'AssignmentExpression') {\n+\t\t\t\t\t\tconst left_object = getObject(node.left);\n+\t\t\t\t\t\tconst left_name = left_object.type === 'Identifier' ? left_object.name : null;\n \t\t\t\t\t\tconst names = node.left.type === 'MemberExpression'\n-\t\t\t\t\t\t\t? [getObject(node.left).name]\n+\t\t\t\t\t\t\t? (left_name ? [left_name] : [])\n \t\t\t\t\t\t\t: extractNames(node.left);\n \n \t\t\t\t\t\tif (node.operator === '=' && nodes_match(node.left, node.right)) {\n@@ -310,7 +313,10 @@ export default class Expression {\n \t\t\t\t\t\t\t});\n \t\t\t\t\t\t}\n \t\t\t\t\t} else if (node.type === 'UpdateExpression') {\n-\t\t\t\t\t\tconst { name } = getObject(node.argument);\n+\t\t\t\t\t\tconst object = getObject(node.argument);\n+\t\t\t\t\t\tif (object.type !== 'Identifier') return;\n+\n+\t\t\t\t\t\tconst { name } = object;\n \n \t\t\t\t\t\tif (scope.declarations.has(name)) return;\n \ndiff --git a/src/compile/render-dom/index.ts b/src/compile/render-dom/index.ts\nindex 067288c0f..854b56eb0 100644\n--- a/src/compile/render-dom/index.ts\n+++ b/src/compile/render-dom/index.ts\n@@ -165,8 +165,10 @@ export default function dom(\n \t\t\t\t}\n \n \t\t\t\tif (node.type === 'AssignmentExpression') {\n+\t\t\t\t\tconst left_object = getObject(node.left);\n+\t\t\t\t\tconst left_name = left_object.type === 'Identifier' ? left_object.name : null;\n \t\t\t\t\tconst names = node.left.type === 'MemberExpression'\n-\t\t\t\t\t\t? [getObject(node.left).name]\n+\t\t\t\t\t\t? (left_name ? [left_name] : [])\n \t\t\t\t\t\t: extractNames(node.left);\n \n \t\t\t\t\tif (node.operator === '=' && nodes_match(node.left, node.right)) {\n@@ -192,7 +194,10 @@ export default function dom(\n \t\t\t\t}\n \n \t\t\t\telse if (node.type === 'UpdateExpression') {\n-\t\t\t\t\tconst { name } = getObject(node.argument);\n+\t\t\t\t\tconst object = getObject(node.argument);\n+\t\t\t\t\tif (object.type !== 'Identifier') return;\n+\n+\t\t\t\t\tconst { name } = object;\n \n \t\t\t\t\tif (scope.findOwner(name) !== component.instance_scope) return;\n \n"}
{"instance_id": "sveltejs__svelte-3305", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/Element/index.ts b/src/compiler/compile/render_dom/wrappers/Element/index.ts\nindex 9d3f60ac7..7c0fd6289 100644\n--- a/src/compiler/compile/render_dom/wrappers/Element/index.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Element/index.ts\n@@ -26,7 +26,7 @@ const events = [\n \t\tevent_names: ['input'],\n \t\tfilter: (node: Element, _name: string) =>\n \t\t\tnode.name === 'textarea' ||\n-\t\t\tnode.name === 'input' && !/radio|checkbox|range/.test(node.get_static_attribute_value('type') as string)\n+\t\t\tnode.name === 'input' && !/radio|checkbox|range|file/.test(node.get_static_attribute_value('type') as string)\n \t},\n \t{\n \t\tevent_names: ['input'],\n@@ -38,7 +38,7 @@ const events = [\n \t\tevent_names: ['change'],\n \t\tfilter: (node: Element, _name: string) =>\n \t\t\tnode.name === 'select' ||\n-\t\t\tnode.name === 'input' && /radio|checkbox/.test(node.get_static_attribute_value('type') as string)\n+\t\t\tnode.name === 'input' && /radio|checkbox|file/.test(node.get_static_attribute_value('type') as string)\n \t},\n \t{\n \t\tevent_names: ['change', 'input'],\n"}
{"instance_id": "sveltejs__svelte-1137", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/dom/index.ts b/src/generators/dom/index.ts\nindex c124f05bb..de96fd9ce 100644\n--- a/src/generators/dom/index.ts\n+++ b/src/generators/dom/index.ts\n@@ -280,7 +280,7 @@ export default function dom(\n \n \t\t\t\t${(generator.hasComponents || generator.hasComplexBindings || templateProperties.oncreate || generator.hasIntroTransitions) && deindent`\n \t\t\t\t\t${generator.hasComponents && `this._lock = true;`}\n-\t\t\t\t\t${(generator.hasComponents || generator.hasComplexBindings) && `@callAll(this._beforecreate);`}\n+\t\t\t\t\t${(generator.hasComponents || generator.hasComplexBindings) && `@flush(this._beforecreate);`}\n \t\t\t\t\t${(generator.hasComponents || templateProperties.oncreate) && `@callAll(this._oncreate);`}\n \t\t\t\t\t${(generator.hasComponents || generator.hasIntroTransitions) && `@callAll(this._aftercreate);`}\n \t\t\t\t\t${generator.hasComponents && `this._lock = false;`}\ndiff --git a/src/shared/index.js b/src/shared/index.js\nindex 3adae010c..f9c2963af 100644\n--- a/src/shared/index.js\n+++ b/src/shared/index.js\n@@ -138,7 +138,7 @@ export function set(newState) {\n \tthis._set(assign({}, newState));\n \tif (this.root._lock) return;\n \tthis.root._lock = true;\n-\tcallAll(this.root._beforecreate);\n+\tflush(this.root._beforecreate);\n \tcallAll(this.root._oncreate);\n \tcallAll(this.root._aftercreate);\n \tthis.root._lock = false;\n@@ -177,6 +177,10 @@ export function setDev(newState) {\n }\n \n export function callAll(fns) {\n+\twhile (fns && fns.length) fns.shift()();\n+}\n+\n+export function flush(fns) {\n \twhile (fns && fns.length) fns.pop()();\n }\n \n"}
{"instance_id": "sveltejs__svelte-3151", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/nodes/shared/Expression.ts b/src/compiler/compile/nodes/shared/Expression.ts\nindex e85c1de5e..08ec73308 100644\n--- a/src/compiler/compile/nodes/shared/Expression.ts\n+++ b/src/compiler/compile/nodes/shared/Expression.ts\n@@ -399,10 +399,47 @@ export default class Expression {\n \t\t\t\t\t\tfunction ${name}(${args.join(', ')}) ${body}\n \t\t\t\t\t`;\n \n+\t\t\t\t\t// handle shorthand method syntax in object literals\n+\t\t\t\t\t// This includes regular methods, getters, and setters\n+\t\t\t\t\tconst is_method_or_accessor = parent && parent.type === 'Property' && (parent.method || parent.kind === 'get' || parent.kind === 'set');\n+\t\t\t\t\tconst replacement_start = is_method_or_accessor ? parent.start : node.start;\n+\t\t\t\t\tconst replacement_end = is_method_or_accessor ? parent.end : node.end;\n+\n+\t\t\t\t\t// For methods/accessors, we need to generate the property key\n+\t\t\t\t\t// For computed properties like [expr](), we need to preserve the brackets\n+\t\t\t\t\tconst get_key_prefix = (fn_name: string) => {\n+\t\t\t\t\t\tif (!is_method_or_accessor) return '';\n+\t\t\t\t\t\tlet key_str;\n+\t\t\t\t\t\tif (parent.computed) {\n+\t\t\t\t\t\t\tkey_str = `[${code.slice(parent.key.start, parent.key.end)}]`;\n+\t\t\t\t\t\t} else if (parent.key.type === 'Identifier') {\n+\t\t\t\t\t\t\tkey_str = parent.key.name;\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t// Literal key (e.g., \"get-name\" or 123)\n+\t\t\t\t\t\t\tkey_str = code.slice(parent.key.start, parent.key.end);\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\tif (parent.kind === 'get') {\n+\t\t\t\t\t\t\treturn `get ${key_str}() { return ${fn_name}(); }`;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\tif (parent.kind === 'set') {\n+\t\t\t\t\t\t\t// For setters, we need to preserve the parameter\n+\t\t\t\t\t\t\tconst params = node.params.length > 0\n+\t\t\t\t\t\t\t\t? code.slice(node.params[0].start, node.params[node.params.length - 1].end)\n+\t\t\t\t\t\t\t\t: '';\n+\t\t\t\t\t\t\treturn `set ${key_str}(${params}) { ${fn_name}(${params}); }`;\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\treturn `${key_str}: ${fn_name}`;\n+\t\t\t\t\t};\n+\n \t\t\t\t\tif (dependencies.size === 0 && contextual_dependencies.size === 0) {\n \t\t\t\t\t\t// we can hoist this out of the component completely\n \t\t\t\t\t\tcomponent.fully_hoisted.push(fn);\n-\t\t\t\t\t\tcode.overwrite(node.start, node.end, name);\n+\n+\t\t\t\t\t\tif (is_method_or_accessor) {\n+\t\t\t\t\t\t\tcode.overwrite(replacement_start, replacement_end, get_key_prefix(name));\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tcode.overwrite(replacement_start, replacement_end, name);\n+\t\t\t\t\t\t}\n \n \t\t\t\t\t\tcomponent.add_var({\n \t\t\t\t\t\t\tname,\n@@ -415,7 +452,12 @@ export default class Expression {\n \t\t\t\t\telse if (contextual_dependencies.size === 0) {\n \t\t\t\t\t\t// function can be hoisted inside the component init\n \t\t\t\t\t\tcomponent.partly_hoisted.push(fn);\n-\t\t\t\t\t\tcode.overwrite(node.start, node.end, `ctx.${name}`);\n+\n+\t\t\t\t\t\tif (is_method_or_accessor) {\n+\t\t\t\t\t\t\tcode.overwrite(replacement_start, replacement_end, get_key_prefix(`ctx.${name}`));\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tcode.overwrite(replacement_start, replacement_end, `ctx.${name}`);\n+\t\t\t\t\t\t}\n \n \t\t\t\t\t\tcomponent.add_var({\n \t\t\t\t\t\t\tname,\n@@ -427,7 +469,12 @@ export default class Expression {\n \t\t\t\t\telse {\n \t\t\t\t\t\t// we need a combo block/init recipe\n \t\t\t\t\t\tcomponent.partly_hoisted.push(fn);\n-\t\t\t\t\t\tcode.overwrite(node.start, node.end, name);\n+\n+\t\t\t\t\t\tif (is_method_or_accessor) {\n+\t\t\t\t\t\t\tcode.overwrite(replacement_start, replacement_end, get_key_prefix(name));\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\tcode.overwrite(replacement_start, replacement_end, name);\n+\t\t\t\t\t\t}\n \n \t\t\t\t\t\tcomponent.add_var({\n \t\t\t\t\t\t\tname,\n"}
{"instance_id": "sveltejs__svelte-3314", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_ssr/handlers/InlineComponent.ts b/src/compiler/compile/render_ssr/handlers/InlineComponent.ts\nindex 320bf5e6a..d25a096da 100644\n--- a/src/compiler/compile/render_ssr/handlers/InlineComponent.ts\n+++ b/src/compiler/compile/render_ssr/handlers/InlineComponent.ts\n@@ -43,8 +43,8 @@ export default function(node: InlineComponent, renderer: Renderer, options: Rend\n \t\t// TODO this probably won't work for contextual bindings\n \t\tconst snippet = snip(binding.expression);\n \n-\t\tbinding_props.push(`${binding.name}: ${snippet}`);\n-\t\tbinding_fns.push(`${binding.name}: $$value => { ${snippet} = $$value; $$settled = false }`);\n+\t\tbinding_props.push(`${quote_name_if_necessary(binding.name)}: ${snippet}`);\n+\t\tbinding_fns.push(`${quote_name_if_necessary(binding.name)}: $$value => { ${snippet} = $$value; $$settled = false }`);\n \t});\n \n \tconst uses_spread = node.attributes.find(attr => attr.is_spread);\n@@ -58,7 +58,7 @@ export default function(node: InlineComponent, renderer: Renderer, options: Rend\n \t\t\t\t\tif (attribute.is_spread) {\n \t\t\t\t\t\treturn snip(attribute.expression);\n \t\t\t\t\t} else {\n-\t\t\t\t\t\treturn `{ ${attribute.name}: ${get_attribute_value(attribute)} }`;\n+\t\t\t\t\t\treturn `{ ${quote_name_if_necessary(attribute.name)}: ${get_attribute_value(attribute)} }`;\n \t\t\t\t\t}\n \t\t\t\t})\n \t\t\t\t.concat(binding_props.map(p => `{ ${p} }`))\n@@ -67,7 +67,7 @@ export default function(node: InlineComponent, renderer: Renderer, options: Rend\n \t} else {\n \t\tprops = stringify_props(\n \t\t\tnode.attributes\n-\t\t\t\t.map(attribute => `${attribute.name}: ${get_attribute_value(attribute)}`)\n+\t\t\t\t.map(attribute => `${quote_name_if_necessary(attribute.name)}: ${get_attribute_value(attribute)}`)\n \t\t\t\t.concat(binding_props)\n \t\t);\n \t}\ndiff --git a/src/compiler/compile/utils/get_slot_data.ts b/src/compiler/compile/utils/get_slot_data.ts\nindex ee64d8f1a..17240c770 100644\n--- a/src/compiler/compile/utils/get_slot_data.ts\n+++ b/src/compiler/compile/utils/get_slot_data.ts\n@@ -1,5 +1,6 @@\n import { snip } from './snip';\n import { stringify_attribute } from './stringify_attribute';\n+import { quote_name_if_necessary } from '../../utils/names';\n import Attribute from '../nodes/Attribute';\n \n export default function get_slot_data(values: Map<string, Attribute>, is_ssr: boolean) {\n@@ -14,6 +15,6 @@ export default function get_slot_data(values: Map<string, Attribute>, is_ssr: bo\n \t\t\t\t\t\t? snip(attribute.chunks[0])\n \t\t\t\t\t\t: '`' + stringify_attribute(attribute, is_ssr) + '`';\n \n-\t\t\treturn `${attribute.name}: ${value}`;\n+\t\t\treturn `${quote_name_if_necessary(attribute.name)}: ${value}`;\n \t\t});\n }\n\\ No newline at end of file\n"}
{"instance_id": "sveltejs__svelte-3435", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/Element/StyleAttribute.ts b/src/compiler/compile/render_dom/wrappers/Element/StyleAttribute.ts\nindex 7f9dd2ee9..36489b2c7 100644\n--- a/src/compiler/compile/render_dom/wrappers/Element/StyleAttribute.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Element/StyleAttribute.ts\n@@ -10,6 +10,7 @@ import Text from '../../../nodes/Text';\n export interface StyleProp {\n \tkey: string;\n \tvalue: Array<Text|Expression>;\n+\timportant: boolean;\n }\n \n export default class StyleAttributeWrapper extends AttributeWrapper {\n@@ -51,7 +52,7 @@ export default class StyleAttributeWrapper extends AttributeWrapper {\n \n \t\t\t\t\tblock.builders.update.add_conditional(\n \t\t\t\t\t\tcondition,\n-\t\t\t\t\t\t`@set_style(${this.parent.var}, \"${prop.key}\", ${value});`\n+\t\t\t\t\t\t`@set_style(${this.parent.var}, \"${prop.key}\", ${value}${prop.important ? ', 1' : ''});`\n \t\t\t\t\t);\n \t\t\t\t}\n \t\t\t} else {\n@@ -59,7 +60,7 @@ export default class StyleAttributeWrapper extends AttributeWrapper {\n \t\t\t}\n \n \t\t\tblock.builders.hydrate.add_line(\n-\t\t\t\t`@set_style(${this.parent.var}, \"${prop.key}\", ${value});`\n+\t\t\t\t`@set_style(${this.parent.var}, \"${prop.key}\", ${value}${prop.important ? ', 1' : ''});`\n \t\t\t);\n \t\t});\n \t}\n@@ -97,13 +98,15 @@ function optimize_style(value: Array<Text|Expression>) {\n \n \t\tconst result = get_style_value(chunks);\n \n-\t\tprops.push({ key, value: result.value });\n+\t\tprops.push({ key, value: result.value, important: result.important });\n \t\tchunks = result.chunks;\n \t}\n \n \treturn props;\n }\n \n+const IMPORTANT_REGEX = /\\s*!important\\s*$/;\n+\n function get_style_value(chunks: Array<Text | Expression>) {\n \tconst value: Array<Text|Expression> = [];\n \n@@ -169,9 +172,22 @@ function get_style_value(chunks: Array<Text | Expression>) {\n \t\t}\n \t}\n \n+\tlet important = false;\n+\n+\t// Check if the last chunk is a Text node ending with !important\n+\tconst last_chunk = value[value.length - 1];\n+\tif (last_chunk && last_chunk.type === 'Text' && IMPORTANT_REGEX.test((last_chunk as Text).data)) {\n+\t\timportant = true;\n+\t\t(last_chunk as Text).data = (last_chunk as Text).data.replace(IMPORTANT_REGEX, '');\n+\t\tif (!(last_chunk as Text).data) {\n+\t\t\tvalue.pop();\n+\t\t}\n+\t}\n+\n \treturn {\n \t\tchunks,\n-\t\tvalue\n+\t\tvalue,\n+\t\timportant\n \t};\n }\n \ndiff --git a/src/runtime/internal/dom.ts b/src/runtime/internal/dom.ts\nindex 8b28a1f77..d8ebffa2b 100644\n--- a/src/runtime/internal/dom.ts\n+++ b/src/runtime/internal/dom.ts\n@@ -183,8 +183,8 @@ export function set_input_type(input, type) {\n \t}\n }\n \n-export function set_style(node, key, value) {\n-\tnode.style.setProperty(key, value);\n+export function set_style(node, key, value, important) {\n+\tnode.style.setProperty(key, value, important ? 'important' : '');\n }\n \n export function select_option(select, value) {\n"}
{"instance_id": "sveltejs__svelte-3403", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/nodes/Element.ts b/src/compiler/compile/nodes/Element.ts\nindex 62bc62059..e08e1f963 100644\n--- a/src/compiler/compile/nodes/Element.ts\n+++ b/src/compiler/compile/nodes/Element.ts\n@@ -84,7 +84,7 @@ function get_namespace(parent: Element, element: Element, explicit_namespace: st\n \t\t\t: null);\n \t}\n \n-\tif (element.name.toLowerCase() === 'svg') return namespaces.svg;\n+\tif (svg.test(element.name.toLowerCase())) return namespaces.svg;\n \tif (parent_element.name.toLowerCase() === 'foreignobject') return null;\n \n \treturn parent_element.namespace;\n"}
{"instance_id": "sveltejs__svelte-3702", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/DebugTag.ts b/src/compiler/compile/render_dom/wrappers/DebugTag.ts\nindex 6705b51cc..3a74da3b2 100644\n--- a/src/compiler/compile/render_dom/wrappers/DebugTag.ts\n+++ b/src/compiler/compile/render_dom/wrappers/DebugTag.ts\n@@ -59,13 +59,15 @@ export default class DebugTagWrapper extends Wrapper {\n \t\t\t\t.join(', ');\n \t\t\tconst logged_identifiers = this.node.expressions.map(e => e.node.name).join(', ');\n \n-\t\t\tblock.builders.update.add_block(deindent`\n-\t\t\t\tif (${condition}) {\n-\t\t\t\t\tconst { ${ctx_identifiers} } = ctx;\n-\t\t\t\t\t@_console.${log}({ ${logged_identifiers} });\n-\t\t\t\t\tdebugger;\n-\t\t\t\t}\n-\t\t\t`);\n+\t\t\tif (condition) {\n+\t\t\t\tblock.builders.update.add_block(deindent`\n+\t\t\t\t\tif (${condition}) {\n+\t\t\t\t\t\tconst { ${ctx_identifiers} } = ctx;\n+\t\t\t\t\t\t@_console.${log}({ ${logged_identifiers} });\n+\t\t\t\t\t\tdebugger;\n+\t\t\t\t\t}\n+\t\t\t\t`);\n+\t\t\t}\n \n \t\t\tblock.builders.create.add_block(deindent`\n \t\t\t\t{\n"}
{"instance_id": "sveltejs__svelte-3749", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/IfBlock.ts b/src/compiler/compile/render_dom/wrappers/IfBlock.ts\nindex c54994a36..769f3db0d 100644\n--- a/src/compiler/compile/render_dom/wrappers/IfBlock.ts\n+++ b/src/compiler/compile/render_dom/wrappers/IfBlock.ts\n@@ -388,7 +388,11 @@ export default class IfBlockWrapper extends Wrapper {\n \t\t\t\t\tfunction ${select_block_type}(#changed, #ctx) {\n \t\t\t\t\t\t${this.branches.map(({ dependencies, condition, snippet }, i) => condition\n \t\t\t\t\t\t? b`\n-\t\t\t\t\t\t${snippet && b`if ((${condition} == null) || ${changed(dependencies)}) ${condition} = !!(${snippet})`}\n+\t\t\t\t\t\t${snippet && (\n+\t\t\t\t\t\t\tdependencies.length > 0\n+\t\t\t\t\t\t\t\t? b`if ((${condition} == null) || ${changed(dependencies)}) ${condition} = !!(${snippet})`\n+\t\t\t\t\t\t\t\t: b`if (${condition} == null) ${condition} = !!(${snippet})`\n+\t\t\t\t\t\t)}\n \t\t\t\t\t\tif (${condition}) return ${i};`\n \t\t\t\t\t\t: b`return ${i};`)}\n \t\t\t\t\t\t${!has_else && b`return -1;`}\n"}
{"instance_id": "sveltejs__svelte-3949", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/runtime/internal/dom.ts b/src/runtime/internal/dom.ts\nindex e4db8c1e1..e25692ac3 100644\n--- a/src/runtime/internal/dom.ts\n+++ b/src/runtime/internal/dom.ts\n@@ -237,6 +237,7 @@ export function add_resize_listener(element, fn) {\n \n \tconst object = document.createElement('object');\n \tobject.setAttribute('style', 'display: block; position: absolute; top: 0; left: 0; height: 100%; width: 100%; overflow: hidden; pointer-events: none; z-index: -1;');\n+\tobject.setAttribute('aria-hidden', 'true');\n \tobject.type = 'text/html';\n \tobject.tabIndex = -1;\n \n"}
{"instance_id": "sveltejs__svelte-1932", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compile/Component.ts b/src/compile/Component.ts\nindex 647068fdf..3a334fd70 100644\n--- a/src/compile/Component.ts\n+++ b/src/compile/Component.ts\n@@ -673,7 +673,17 @@ export default class Component {\n \t\t\t});\n \n \t\t\tif (combining) {\n-\t\t\t\tcode.prependRight(c, ' } = $$props');\n+\t\t\t\t// If the next character is a semicolon, use prependRight so that\n+\t\t\t\t// the insertion comes after any other insertions at the same position\n+\t\t\t\t// (e.g., the arrow function body transformation).\n+\t\t\t\t// Otherwise, use appendLeft so that the insertion is included in\n+\t\t\t\t// the snip range even when there's no semicolon.\n+\t\t\t\tconst next_char = this.source[c];\n+\t\t\t\tif (next_char === ';') {\n+\t\t\t\t\tcode.prependRight(c, ' } = $$props');\n+\t\t\t\t} else {\n+\t\t\t\t\tcode.appendLeft(c, ' } = $$props');\n+\t\t\t\t}\n \t\t\t}\n \t\t});\n \t}\n"}
{"instance_id": "sveltejs__svelte-3451", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/Component.ts b/src/compiler/compile/Component.ts\nindex 355ad0c42..2a70d7187 100644\n--- a/src/compiler/compile/Component.ts\n+++ b/src/compiler/compile/Component.ts\n@@ -1158,10 +1158,12 @@ export default class Component {\n \t\t\t\t\t\t\t\tconst owner = scope.find_owner(name);\n \t\t\t\t\t\t\t\tconst variable = component.var_lookup.get(name);\n \t\t\t\t\t\t\t\tif (variable) variable.is_reactive_dependency = true;\n+\t\t\t\t\t\t\t\tconst declaration = component.node_for_declaration.get(name);\n+\t\t\t\t\t\t\t\tconst is_function = declaration && declaration.type === 'FunctionDeclaration';\n \t\t\t\t\t\t\t\tconst is_writable_or_mutated = variable && (variable.writable || variable.mutated);\n \t\t\t\t\t\t\t\tif (\n \t\t\t\t\t\t\t\t\t(!owner || owner === component.instance_scope) &&\n-\t\t\t\t\t\t\t\t\t(name[0] === '$' || is_writable_or_mutated)\n+\t\t\t\t\t\t\t\t\t(name[0] === '$' || is_writable_or_mutated || is_function)\n \t\t\t\t\t\t\t\t) {\n \t\t\t\t\t\t\t\t\tdependencies.add(name);\n \t\t\t\t\t\t\t\t}\ndiff --git a/src/compiler/compile/render_dom/index.ts b/src/compiler/compile/render_dom/index.ts\nindex 52006e4d8..d1b02b339 100644\n--- a/src/compiler/compile/render_dom/index.ts\n+++ b/src/compiler/compile/render_dom/index.ts\n@@ -365,7 +365,9 @@ export default function dom(\n \t\t\t\tconst condition = !uses_props && dependencies\n \t\t\t\t\t.filter(n => {\n \t\t\t\t\t\tconst variable = component.var_lookup.get(n);\n-\t\t\t\t\t\treturn variable && (variable.writable || variable.mutated);\n+\t\t\t\t\t\tconst declaration = component.node_for_declaration.get(n);\n+\t\t\t\t\t\tconst is_function = declaration && declaration.type === 'FunctionDeclaration';\n+\t\t\t\t\t\treturn variable && (variable.writable || variable.mutated || is_function);\n \t\t\t\t\t})\n \t\t\t\t\t.map(n => `$$dirty.${n}`).join(' || ');\n \n"}
{"instance_id": "sveltejs__svelte-4288", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/runtime/internal/dom.ts b/src/runtime/internal/dom.ts\nindex f9e89f41b..c39cf93b6 100644\n--- a/src/runtime/internal/dom.ts\n+++ b/src/runtime/internal/dom.ts\n@@ -152,7 +152,7 @@ export function claim_element(nodes, name, attributes, svg) {\n \tfor (let i = 0; i < nodes.length; i += 1) {\n \t\tconst node = nodes[i];\n \t\tif (node.nodeName === name) {\n-\t\t\tfor (let j = 0; j < node.attributes.length; j += 1) {\n+\t\t\tfor (let j = node.attributes.length - 1; j >= 0; j -= 1) {\n \t\t\t\tconst attribute = node.attributes[j];\n \t\t\t\tif (!attributes[attribute.name]) node.removeAttribute(attribute.name);\n \t\t\t}\n"}
{"instance_id": "sveltejs__svelte-477", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/dom/index.js b/src/generators/dom/index.js\nindex 385690d71..3e994e0b3 100644\n--- a/src/generators/dom/index.js\n+++ b/src/generators/dom/index.js\n@@ -218,7 +218,7 @@ export default function dom ( parsed, source, options ) {\n \tif ( options.dev ) {\n \t\tgenerator.expectedProperties.forEach( prop => {\n \t\t\tconstructorBlock.addLine(\n-\t\t\t\t`if ( !( '${prop}' in this._state ) ) throw new Error( \"Component was created without expected data property '${prop}'\" );`\n+\t\t\t\t`if ( !( '${prop}' in this._state ) ) console.warn( \"Component was created without expected data property '${prop}'\" );`\n \t\t\t);\n \t\t});\n \n"}
{"instance_id": "sveltejs__svelte-4146", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/css/Selector.ts b/src/compiler/compile/css/Selector.ts\nindex d99af7a11..52621e0be 100644\n--- a/src/compiler/compile/css/Selector.ts\n+++ b/src/compiler/compile/css/Selector.ts\n@@ -63,8 +63,10 @@ export default class Selector {\n \t\t});\n \t}\n \n-\ttransform(code: MagicString, attr: string) {\n-\t\tfunction encapsulate_block(block: Block) {\n+\ttransform(code: MagicString, attr: string, max_amount_class_specificity_increased: number) {\n+\t\tconst amount_class_specificity_to_increase = max_amount_class_specificity_increased - this.blocks.filter(block => block.should_encapsulate).length;\n+\n+\t\tfunction encapsulate_block(block: Block, attr: string) {\n \t\t\tlet i = block.selectors.length;\n \t\t\twhile (i--) {\n \t\t\t\tconst selector = block.selectors[i];\n@@ -85,7 +87,7 @@ export default class Selector {\n \t\t\t}\n \t\t}\n \n-\t\tthis.blocks.forEach((block) => {\n+\t\tthis.blocks.forEach((block, index) => {\n \t\t\tif (block.global) {\n \t\t\t\tconst selector = block.selectors[0];\n \t\t\t\tconst first = selector.children[0];\n@@ -93,7 +95,7 @@ export default class Selector {\n \t\t\t\tcode.remove(selector.start, first.start).remove(last.end, selector.end);\n \t\t\t}\n \n-\t\t\tif (block.should_encapsulate) encapsulate_block(block);\n+\t\t\tif (block.should_encapsulate) encapsulate_block(block, index === this.blocks.length - 1 ? attr.repeat(amount_class_specificity_to_increase + 1) : attr);\n \t\t});\n \t}\n \ndiff --git a/src/compiler/compile/css/Stylesheet.ts b/src/compiler/compile/css/Stylesheet.ts\nindex 8342c3fa2..5354d7ac7 100644\n--- a/src/compiler/compile/css/Stylesheet.ts\n+++ b/src/compiler/compile/css/Stylesheet.ts\n@@ -95,12 +95,12 @@ class Rule {\n \t\tcode.remove(c, this.node.block.end - 1);\n \t}\n \n-\ttransform(code: MagicString, id: string, keyframes: Map<string, string>) {\n+\ttransform(code: MagicString, id: string, keyframes: Map<string, string>, max_amount_class_specificity_increased: number) {\n \t\tif (this.parent && this.parent.node.type === 'Atrule' && is_keyframes_node(this.parent.node)) return true;\n \n \t\tconst attr = `.${id}`;\n \n-\t\tthis.selectors.forEach(selector => selector.transform(code, attr));\n+\t\tthis.selectors.forEach(selector => selector.transform(code, attr, max_amount_class_specificity_increased));\n \t\tthis.declarations.forEach(declaration => declaration.transform(code, keyframes));\n \t}\n \n@@ -239,7 +239,7 @@ class Atrule {\n \t\t}\n \t}\n \n-\ttransform(code: MagicString, id: string, keyframes: Map<string, string>) {\n+\ttransform(code: MagicString, id: string, keyframes: Map<string, string>, max_amount_class_specificity_increased: number) {\n \t\tif (is_keyframes_node(this.node)) {\n \t\t\tthis.node.expression.children.forEach(({ type, name, start, end }: CssNode) => {\n \t\t\t\tif (type === 'Identifier') {\n@@ -258,7 +258,7 @@ class Atrule {\n \t\t}\n \n \t\tthis.children.forEach(child => {\n-\t\t\tchild.transform(code, id, keyframes);\n+\t\t\tchild.transform(code, id, keyframes, max_amount_class_specificity_increased);\n \t\t});\n \t}\n \n@@ -277,6 +277,20 @@ class Atrule {\n \t}\n }\n \n+function get_max_amount_class_specificity_increased(children: Array<Rule|Atrule>): number {\n+\tlet dominated_selectors_max = 0;\n+\tchildren.forEach((child: (Atrule|Rule)) => {\n+\t\tif (child instanceof Rule) {\n+\t\t\tchild.selectors.forEach(selector => {\n+\t\t\t\tdominated_selectors_max = Math.max(dominated_selectors_max, selector.blocks.filter(block => block.should_encapsulate).length);\n+\t\t\t});\n+\t\t} else if (child instanceof Atrule) {\n+\t\t\tdominated_selectors_max = Math.max(dominated_selectors_max, get_max_amount_class_specificity_increased(child.children));\n+\t\t}\n+\t});\n+\treturn dominated_selectors_max;\n+}\n+\n export default class Stylesheet {\n \tsource: string;\n \tast: Ast;\n@@ -397,8 +411,9 @@ export default class Stylesheet {\n \t\t});\n \n \t\tif (should_transform_selectors) {\n+\t\t\tconst max = get_max_amount_class_specificity_increased(this.children);\n \t\t\tthis.children.forEach((child: (Atrule|Rule)) => {\n-\t\t\t\tchild.transform(code, this.id, this.keyframes);\n+\t\t\t\tchild.transform(code, this.id, this.keyframes, max);\n \t\t\t});\n \t\t}\n \n"}
{"instance_id": "sveltejs__svelte-510", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/dom/visitors/EachBlock.js b/src/generators/dom/visitors/EachBlock.js\nindex dbb1d2c08..5a1a71d16 100644\n--- a/src/generators/dom/visitors/EachBlock.js\n+++ b/src/generators/dom/visitors/EachBlock.js\n@@ -66,12 +66,16 @@ export default function visitEachBlock ( generator, block, state, node ) {\n \t\t\t\t\t${each_block_else}.mount( ${anchor}.parentNode, ${anchor} );\n \t\t\t\t} else if ( ${each_block_else} ) {\n \t\t\t\t\t${each_block_else}.destroy( true );\n+\t\t\t\t\t${each_block_else} = null;\n \t\t\t\t}\n \t\t\t` );\n \t\t} else {\n \t\t\tblock.builders.update.addBlock( deindent`\n \t\t\t\tif ( ${each_block_value}.length ) {\n-\t\t\t\t\tif ( ${each_block_else} ) ${each_block_else}.destroy( true );\n+\t\t\t\t\tif ( ${each_block_else} ) {\n+\t\t\t\t\t\t${each_block_else}.destroy( true );\n+\t\t\t\t\t\t${each_block_else} = null;\n+\t\t\t\t\t}\n \t\t\t\t} else if ( !${each_block_else} ) {\n \t\t\t\t\t${each_block_else} = ${node.else._block.name}( ${params}, ${block.component} );\n \t\t\t\t\t${each_block_else}.mount( ${anchor}.parentNode, ${anchor} );\n"}
{"instance_id": "sveltejs__svelte-464", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/dom/visitors/Component/Component.js b/src/generators/dom/visitors/Component/Component.js\nindex 5446d5427..f702d1d09 100644\n--- a/src/generators/dom/visitors/Component/Component.js\n+++ b/src/generators/dom/visitors/Component/Component.js\n@@ -38,7 +38,9 @@ const visitors = {\n \n export default function visitComponent ( generator, block, state, node ) {\n \tconst hasChildren = node.children.length > 0;\n-\tconst name = block.getUniqueName( capDown( node.name === ':Self' ? generator.name : node.name ) );\n+\tconst name = node.name === ':Self' ?\n+\t\tblock.getUniqueName( `${capDown( generator.name )}_self` ) :\n+\t\tblock.getUniqueName( capDown( node.name ) );\n \n \tconst childState = Object.assign( {}, state, {\n \t\tparentNode: null\n"}
{"instance_id": "sveltejs__svelte-4558", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/EachBlock.ts b/src/compiler/compile/render_dom/wrappers/EachBlock.ts\nindex f0dfa5fbc..488f31dae 100644\n--- a/src/compiler/compile/render_dom/wrappers/EachBlock.ts\n+++ b/src/compiler/compile/render_dom/wrappers/EachBlock.ts\n@@ -423,7 +423,7 @@ export default class EachBlockWrapper extends Wrapper {\n \t\tif (all_dependencies.size) {\n \t\t\tblock.chunks.update.push(b`\n \t\t\t\tif (${block.renderer.dirty(Array.from(all_dependencies))}) {\n-\t\t\t\t\tconst ${this.vars.each_block_value} = ${snippet};\n+\t\t\t\t\t${this.vars.each_block_value} = ${snippet};\n \t\t\t\t\t${this.renderer.options.dev && b`@validate_each_argument(${this.vars.each_block_value});`}\n \n \t\t\t\t\t${this.block.has_outros && b`@group_outros();`}\n"}
{"instance_id": "sveltejs__svelte-1190", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/css/Stylesheet.ts b/src/css/Stylesheet.ts\nindex d16af0929..3b37ca526 100644\n--- a/src/css/Stylesheet.ts\n+++ b/src/css/Stylesheet.ts\n@@ -69,7 +69,7 @@ class Rule {\n \ttransform(code: MagicString, id: string, keyframes: Map<string, string>, cascade: boolean) {\n \t\tif (this.parent && this.parent.node.type === 'Atrule' && this.parent.node.name === 'keyframes') return true;\n \n-\t\tconst attr = `[${id}]`;\n+\t\tconst attr = `.${id}`;\n \n \t\tif (cascade) {\n \t\t\tthis.selectors.forEach(selector => {\ndiff --git a/src/generators/dom/index.ts b/src/generators/dom/index.ts\nindex ada015269..fb1277c69 100644\n--- a/src/generators/dom/index.ts\n+++ b/src/generators/dom/index.ts\n@@ -138,7 +138,7 @@ export default function dom(\n \tif (generator.needsEncapsulateHelper) {\n \t\tbuilder.addBlock(deindent`\n \t\t\tfunction @encapsulateStyles(node) {\n-\t\t\t\t@setAttribute(node, \"${generator.stylesheet.id}\", \"\");\n+\t\t\t\tnode.className = \"${generator.stylesheet.id}\";\n \t\t\t}\n \t\t`);\n \t}\ndiff --git a/src/generators/nodes/Attribute.ts b/src/generators/nodes/Attribute.ts\nindex 08075efee..0ccb26b23 100644\n--- a/src/generators/nodes/Attribute.ts\n+++ b/src/generators/nodes/Attribute.ts\n@@ -86,6 +86,11 @@ export default class Attribute {\n \t\t\treturn m[1].toUpperCase();\n \t\t}) : name;\n \n+\t\t// Check if we need to add the scoping class\n+\t\tconst classId = (name === 'class' && node._needsCssAttribute && !this.generator.customElement)\n+\t\t\t? this.generator.stylesheet.id\n+\t\t\t: null;\n+\n \t\tif (isDynamic) {\n \t\t\tlet value;\n \n@@ -188,10 +193,19 @@ export default class Attribute {\n \n \t\t\t\tblock.builders.update.addLine(`${last} = ${value};`);\n \t\t\t} else if (propertyName) {\n-\t\t\t\tblock.builders.hydrate.addLine(\n-\t\t\t\t\t`${node.var}.${propertyName} = ${init};`\n-\t\t\t\t);\n-\t\t\t\tupdater = `${node.var}.${propertyName} = ${shouldCache || isSelectValueAttribute ? last : value};`;\n+\t\t\t\tif (classId) {\n+\t\t\t\t\t// Need to wrap init in parentheses if it contains an assignment\n+\t\t\t\t\tconst initExpr = shouldCache ? `(${init})` : init;\n+\t\t\t\t\tblock.builders.hydrate.addLine(\n+\t\t\t\t\t\t`${node.var}.${propertyName} = \"${classId} \" + ${initExpr};`\n+\t\t\t\t\t);\n+\t\t\t\t\tupdater = `${node.var}.${propertyName} = \"${classId} \" + ${shouldCache || isSelectValueAttribute ? last : value};`;\n+\t\t\t\t} else {\n+\t\t\t\t\tblock.builders.hydrate.addLine(\n+\t\t\t\t\t\t`${node.var}.${propertyName} = ${init};`\n+\t\t\t\t\t);\n+\t\t\t\t\tupdater = `${node.var}.${propertyName} = ${shouldCache || isSelectValueAttribute ? last : value};`;\n+\t\t\t\t}\n \t\t\t} else if (isDataSet) {\n \t\t\t\tblock.builders.hydrate.addLine(\n \t\t\t\t\t`${node.var}.dataset.${camelCaseName} = ${init};`\n@@ -231,6 +245,7 @@ export default class Attribute {\n \n \t\t\tconst statement = (\n \t\t\t\tisLegacyInputType ? `@setInputType(${node.var}, ${value});` :\n+\t\t\t\tpropertyName && classId ? `${node.var}.${propertyName} = \"${classId} \" + ${value};` :\n \t\t\t\tpropertyName ? `${node.var}.${propertyName} = ${value};` :\n \t\t\t\t\tisDataSet ? `${node.var}.dataset.${camelCaseName} = ${value};` :\n \t\t\t\t`${method}(${node.var}, \"${name}\", ${value});`\ndiff --git a/src/generators/nodes/Element.ts b/src/generators/nodes/Element.ts\nindex 2a75f1fc3..d364bda16 100644\n--- a/src/generators/nodes/Element.ts\n+++ b/src/generators/nodes/Element.ts\n@@ -214,10 +214,15 @@ export default class Element extends Node {\n \n \t\t// add CSS encapsulation attribute\n \t\tif (this._needsCssAttribute && !this.generator.customElement) {\n-\t\t\tthis.generator.needsEncapsulateHelper = true;\n-\t\t\tblock.builders.hydrate.addLine(\n-\t\t\t\t`@encapsulateStyles(${name});`\n-\t\t\t);\n+\t\t\tconst classAttribute = this.attributes.find((a: Attribute) => a.type === 'Attribute' && a.name === 'class');\n+\t\t\tif (classAttribute) {\n+\t\t\t\t// class attribute will include the scoping class\n+\t\t\t} else {\n+\t\t\t\tthis.generator.needsEncapsulateHelper = true;\n+\t\t\t\tblock.builders.hydrate.addLine(\n+\t\t\t\t\t`@encapsulateStyles(${name});`\n+\t\t\t\t);\n+\t\t\t}\n \n \t\t\tif (this._cssRefAttribute) {\n \t\t\t\tblock.builders.hydrate.addLine(\n@@ -429,18 +434,22 @@ export default class Element extends Node {\n \n \t\t\tlet open = `<${node.name}`;\n \n-\t\t\tif (node._needsCssAttribute) {\n-\t\t\t\topen += ` ${generator.stylesheet.id}`;\n-\t\t\t}\n-\n \t\t\tif (node._cssRefAttribute) {\n \t\t\t\topen += ` svelte-ref-${node._cssRefAttribute}`;\n \t\t\t}\n \n \t\t\tnode.attributes.forEach((attr: Node) => {\n-\t\t\t\topen += ` ${fixAttributeCasing(attr.name)}${stringifyAttributeValue(attr.value)}`\n+\t\t\t\tif (attr.name === 'class' && node._needsCssAttribute) {\n+\t\t\t\t\topen += ` ${fixAttributeCasing(attr.name)}=\"${generator.stylesheet.id}${stringifyAttributeValue(attr.value).slice(1)}`;\n+\t\t\t\t} else {\n+\t\t\t\t\topen += ` ${fixAttributeCasing(attr.name)}${stringifyAttributeValue(attr.value)}`;\n+\t\t\t\t}\n \t\t\t});\n \n+\t\t\tif (node._needsCssAttribute && !node.attributes.find((a: Node) => a.name === 'class')) {\n+\t\t\t\topen += ` class=\"${generator.stylesheet.id}\"`;\n+\t\t\t}\n+\n \t\t\tif (isVoidElementName(node.name)) return open + '>';\n \n \t\t\treturn `${open}>${node.children.map(toHTML).join('')}</${node.name}>`;\ndiff --git a/src/generators/server-side-rendering/visitors/Element.ts b/src/generators/server-side-rendering/visitors/Element.ts\nindex 21ec923e3..cf94092ef 100644\n--- a/src/generators/server-side-rendering/visitors/Element.ts\n+++ b/src/generators/server-side-rendering/visitors/Element.ts\n@@ -34,6 +34,8 @@ export default function visitElement(\n \t\tappendTarget.slots[slotName] = '';\n \t}\n \n+\tlet classAttributeHandled = false;\n+\n \tnode.attributes.forEach((attribute: Node) => {\n \t\tif (attribute.type !== 'Attribute') return;\n \n@@ -49,13 +51,18 @@ export default function visitElement(\n \t\t\t// a boolean attribute with one non-Text chunk\n \t\t\tblock.contextualise(attribute.value[0].expression);\n \t\t\topeningTag += '${' + attribute.value[0].metadata.snippet + ' ? \" ' + attribute.name + '\" : \"\" }';\n+\t\t} else if (attribute.name === 'class' && node._needsCssAttribute) {\n+\t\t\tclassAttributeHandled = true;\n+\t\t\topeningTag += ` ${attribute.name}=\"${generator.stylesheet.id} ${stringifyAttributeValue(block, attribute.value)}\"`;\n \t\t} else {\n \t\t\topeningTag += ` ${attribute.name}=\"${stringifyAttributeValue(block, attribute.value)}\"`;\n \t\t}\n \t});\n \n \tif (node._needsCssAttribute) {\n-\t\topeningTag += ` ${generator.stylesheet.id}`;\n+\t\tif (!classAttributeHandled) {\n+\t\t\topeningTag += ` class=\"${generator.stylesheet.id}\"`;\n+\t\t}\n \n \t\tif (node._cssRefAttribute) {\n \t\t\topeningTag += ` svelte-ref-${node._cssRefAttribute}`;\n"}
{"instance_id": "sveltejs__svelte-4454", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/index.ts b/src/compiler/compile/render_dom/index.ts\nindex 17e5eaf75..77b8167f6 100644\n--- a/src/compiler/compile/render_dom/index.ts\n+++ b/src/compiler/compile/render_dom/index.ts\n@@ -379,9 +379,9 @@ export default function dom(\n \t\t});\n \n \t\tlet unknown_props_check;\n-\t\tif (component.compile_options.dev && !component.var_lookup.has('$$props') && writable_props.length) {\n+\t\tif (component.compile_options.dev && !component.var_lookup.has('$$props') && props.length) {\n \t\t\tunknown_props_check = b`\n-\t\t\t\tconst writable_props = [${writable_props.map(prop => x`'${prop.export_name}'`)}];\n+\t\t\t\tconst writable_props = [${props.map(prop => x`'${prop.export_name}'`)}];\n \t\t\t\t@_Object.keys($$props).forEach(key => {\n \t\t\t\t\tif (!~writable_props.indexOf(key) && key.slice(0, 2) !== '$$') @_console.warn(\\`<${component.tag}> was created with unknown prop '\\${key}'\\`);\n \t\t\t\t});\n"}
{"instance_id": "sveltejs__svelte-5875", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/parse/state/tag.ts b/src/compiler/parse/state/tag.ts\nindex efeb9433b..696a47b64 100644\n--- a/src/compiler/parse/state/tag.ts\n+++ b/src/compiler/parse/state/tag.ts\n@@ -376,7 +376,7 @@ function read_attribute(parser: Parser, unique_names: Set<string>) {\n \n \t\tif (type === 'Binding' && directive_name !== 'this') {\n \t\t\tcheck_unique(directive_name);\n-\t\t} else if (type !== 'EventHandler') {\n+\t\t} else if (type !== 'EventHandler' && type !== 'Action') {\n \t\t\tcheck_unique(name);\n \t\t}\n \n"}
{"instance_id": "sveltejs__svelte-4332", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/css/Selector.ts b/src/compiler/compile/css/Selector.ts\nindex 39bbc2e8d..f04f2ee06 100644\n--- a/src/compiler/compile/css/Selector.ts\n+++ b/src/compiler/compile/css/Selector.ts\n@@ -185,13 +185,24 @@ function apply_selector(blocks: Block[], node: Element, stack: Element[], to_enc\n \t\t\t}\n \n \t\t\tif (blocks.every(block => block.global)) {\n-\t\t\t\tto_encapsulate.push({ node, block });\n+\t\t\t\t// Check if the match is only due to a dynamic class that doesn't\n+\t\t\t\t// actually match the selector's class name. In that case, we should\n+\t\t\t\t// not encapsulate the block because the selector is intended to\n+\t\t\t\t// match elements in child components.\n+\t\t\t\tif (!block_is_dynamic_match_only(block, node)) {\n+\t\t\t\t\tto_encapsulate.push({ node, block });\n+\t\t\t\t}\n \t\t\t\treturn true;\n \t\t\t}\n \n \t\t\treturn false;\n \t\t} else if (block.combinator.name === '>') {\n \t\t\tif (apply_selector(blocks, stack.pop(), stack, to_encapsulate)) {\n+\t\t\t\t// Check if the match is only due to a dynamic class when all\n+\t\t\t\t// ancestor blocks are global\n+\t\t\t\tif (blocks.every(block => block.global) && block_is_dynamic_match_only(block, node)) {\n+\t\t\t\t\treturn true;\n+\t\t\t\t}\n \t\t\t\tto_encapsulate.push({ node, block });\n \t\t\t\treturn true;\n \t\t\t}\n@@ -249,6 +260,56 @@ function block_might_apply_to_node(block, node): BlockAppliesToNode {\n \treturn BlockAppliesToNode.Possible;\n }\n \n+function block_is_dynamic_match_only(block: Block, node: Element): boolean {\n+\t// Check if the block's match with the node is only due to dynamic/unknown values\n+\t// (like class={variable}) rather than a definite static match.\n+\t// This is used to determine if we should encapsulate the block when all\n+\t// ancestor blocks are global.\n+\t\n+\tfor (const selector of block.selectors) {\n+\t\tif (selector.type === 'ClassSelector') {\n+\t\t\tconst name = selector.name.replace(/\\\\(.)/g, '$1');\n+\t\t\t// If there's a class directive with the matching name, it's a definite match\n+\t\t\tif (node.classes.some(c => c.name === name)) {\n+\t\t\t\treturn false;\n+\t\t\t}\n+\t\t\t// Check if the class attribute has a static match\n+\t\t\tconst attr = node.attributes.find((attr: CssNode) => attr.name === 'class');\n+\t\t\tif (attr && !attr.is_true) {\n+\t\t\t\tfor (const chunk of attr.chunks) {\n+\t\t\t\t\tif (chunk.type === 'Text') {\n+\t\t\t\t\t\tconst static_classes = chunk.data.split(/\\s+/);\n+\t\t\t\t\t\tif (static_classes.includes(name)) {\n+\t\t\t\t\t\t\treturn false; // Static match found\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\t\n+\t\tif (selector.type === 'IdSelector') {\n+\t\t\tconst name = selector.name.replace(/\\\\(.)/g, '$1');\n+\t\t\tconst attr = node.attributes.find((attr: CssNode) => attr.name === 'id');\n+\t\t\tif (attr && !attr.is_true && attr.chunks.length === 1) {\n+\t\t\t\tconst value = attr.chunks[0];\n+\t\t\t\tif (value && value.type === 'Text' && value.data === name) {\n+\t\t\t\t\treturn false; // Static match found\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\t\t\n+\t\tif (selector.type === 'TypeSelector') {\n+\t\t\tconst name = selector.name.replace(/\\\\(.)/g, '$1');\n+\t\t\tif (node.name.toLowerCase() === name.toLowerCase() || name === '*') {\n+\t\t\t\treturn false; // Type selector always matches statically\n+\t\t\t}\n+\t\t}\n+\t}\n+\t\n+\t// If we get here, the match is only due to dynamic values\n+\treturn true;\n+}\n+\n function test_attribute(operator, expected_value, case_insensitive, value) {\n \tif (case_insensitive) {\n \t\texpected_value = expected_value.toLowerCase();\n"}
{"instance_id": "sveltejs__svelte-6458", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/runtime/internal/ssr.ts b/src/runtime/internal/ssr.ts\nindex c64d88fa7..99519293b 100644\n--- a/src/runtime/internal/ssr.ts\n+++ b/src/runtime/internal/ssr.ts\n@@ -140,7 +140,7 @@ export function create_ssr_component(fn) {\n }\n \n export function add_attribute(name, value, boolean) {\n-\tif (value == null || (boolean && !value)) return '';\n+\tif (value == null || (boolean && value === false)) return '';\n \treturn ` ${name}${value === true ? '' : `=${typeof value === 'string' ? JSON.stringify(escape(value)) : `\"${value}\"`}`}`;\n }\n \n"}
{"instance_id": "sveltejs__svelte-630", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/dom/visitors/Element/Binding.ts b/src/generators/dom/visitors/Element/Binding.ts\nindex fb7f72a7c..f7577d507 100644\n--- a/src/generators/dom/visitors/Element/Binding.ts\n+++ b/src/generators/dom/visitors/Element/Binding.ts\n@@ -198,11 +198,9 @@ export default function visitBinding(\n \n function getBindingEventName(node: Node, attribute: Node) {\n \tif (node.name === 'input') {\n-\t\tconst typeAttribute = node.attributes.find(\n-\t\t\t(attr: Node) => attr.type === 'Attribute' && attr.name === 'type'\n-\t\t);\n-\t\tconst type = typeAttribute ? typeAttribute.value[0].data : 'text'; // TODO in validation, should throw if type attribute is not static\n+\t\tconst type = getStaticAttributeValue(node, 'type');\n \n+\t\t// if type is dynamic, use 'input' as the default event\n \t\treturn type === 'checkbox' || type === 'radio' ? 'change' : 'input';\n \t}\n \ndiff --git a/src/generators/dom/visitors/Element/getStaticAttributeValue.ts b/src/generators/dom/visitors/Element/getStaticAttributeValue.ts\nindex 490a24351..608c9d580 100644\n--- a/src/generators/dom/visitors/Element/getStaticAttributeValue.ts\n+++ b/src/generators/dom/visitors/Element/getStaticAttributeValue.ts\n@@ -6,9 +6,9 @@ export default function getStaticAttributeValue(node: Node, name: string) {\n \t);\n \tif (!attribute) return null;\n \n+\tif (attribute.value === true) return null;\n \tif (attribute.value.length !== 1 || attribute.value[0].type !== 'Text') {\n-\t\t// TODO catch this in validation phase, give a more useful error (with location etc)\n-\t\tthrow new Error(`'${name}' must be a static attribute`);\n+\t\treturn null;\n \t}\n \n \treturn attribute.value[0].data;\n"}
{"instance_id": "sveltejs__svelte-6941", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/Element/Attribute.ts b/src/compiler/compile/render_dom/wrappers/Element/Attribute.ts\nindex 3f57d004b..fb081e295 100644\n--- a/src/compiler/compile/render_dom/wrappers/Element/Attribute.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Element/Attribute.ts\n@@ -204,7 +204,7 @@ export default class AttributeWrapper extends BaseAttributeWrapper {\n \t\tif (this.is_input_value) {\n \t\t\tconst type = element.node.get_static_attribute_value('type');\n \n-\t\t\tif (type === null || type === '' || type === 'text' || type === 'email' || type === 'password') {\n+\t\t\tif (type === null || type === '' || type === 'text' || type === 'email' || type === 'password' || type === 'search') {\n \t\t\t\tcondition = x`${condition} && ${element.var}.${property_name} !== ${should_cache ? last : value}`;\n \t\t\t}\n \t\t}\ndiff --git a/src/compiler/compile/render_dom/wrappers/Element/Binding.ts b/src/compiler/compile/render_dom/wrappers/Element/Binding.ts\nindex 7c8a339d0..1bf43006a 100644\n--- a/src/compiler/compile/render_dom/wrappers/Element/Binding.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Element/Binding.ts\n@@ -96,7 +96,8 @@ export default class BindingWrapper {\n \t\t\t\ttype === '' ||\n \t\t\t\ttype === 'text' ||\n \t\t\t\ttype === 'email' ||\n-\t\t\t\ttype === 'password'\n+\t\t\t\ttype === 'password' ||\n+\t\t\t\ttype === 'search'\n \t\t\t) {\n \t\t\t\tupdate_conditions.push(\n \t\t\t\t\tx`${parent.var}.${this.node.name} !== ${this.snippet}`\ndiff --git a/src/compiler/compile/render_dom/wrappers/Element/index.ts b/src/compiler/compile/render_dom/wrappers/Element/index.ts\nindex 9ec36b12d..afcb5b14e 100644\n--- a/src/compiler/compile/render_dom/wrappers/Element/index.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Element/index.ts\n@@ -678,7 +678,7 @@ export default class ElementWrapper extends Wrapper {\n \t\t\t`);\n \t\t} else if (this.node.name === 'input' && this.attributes.find(attr => attr.node.name === 'value')) {\n \t\t\tconst type = this.node.get_static_attribute_value('type');\n-\t\t\tif (type === null || type === '' || type === 'text' || type === 'email' || type === 'password') {\n+\t\t\tif (type === null || type === '' || type === 'text' || type === 'email' || type === 'password' || type === 'search') {\n \t\t\t\tblock.chunks.mount.push(b`\n \t\t\t\t\t${this.var}.value = ${data}.value;\n \t\t\t\t`);\n"}
{"instance_id": "sveltejs__svelte-5616", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/nodes/Slot.ts b/src/compiler/compile/nodes/Slot.ts\nindex 87b6c1ea9..8a65abf21 100644\n--- a/src/compiler/compile/nodes/Slot.ts\n+++ b/src/compiler/compile/nodes/Slot.ts\n@@ -10,18 +10,24 @@ export default class Slot extends Element {\n \tchildren: INode[];\n \tslot_name: string;\n \tvalues: Map<string, Attribute> = new Map();\n+\tspread_attributes: Attribute[] = [];\n \n \tconstructor(component: Component, parent: INode, scope: TemplateScope, info: any) {\n \t\tsuper(component, parent, scope, info);\n \n \t\tinfo.attributes.forEach(attr => {\n-\t\t\tif (attr.type !== 'Attribute') {\n+\t\t\tif (attr.type !== 'Attribute' && attr.type !== 'Spread') {\n \t\t\t\tcomponent.error(attr, {\n \t\t\t\t\tcode: 'invalid-slot-directive',\n \t\t\t\t\tmessage: '<slot> cannot have directives'\n \t\t\t\t});\n \t\t\t}\n \n+\t\t\tif (attr.type === 'Spread') {\n+\t\t\t\tthis.spread_attributes.push(new Attribute(component, this, scope, attr));\n+\t\t\t\treturn;\n+\t\t\t}\n+\n \t\t\tif (attr.name === 'name') {\n \t\t\t\tif (attr.value.length !== 1 || attr.value[0].type !== 'Text') {\n \t\t\t\t\tcomponent.error(attr, {\ndiff --git a/src/compiler/compile/render_dom/wrappers/Slot.ts b/src/compiler/compile/render_dom/wrappers/Slot.ts\nindex 0746de323..c0bc3bb1a 100644\n--- a/src/compiler/compile/render_dom/wrappers/Slot.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Slot.ts\n@@ -61,6 +61,10 @@ export default class SlotWrapper extends Wrapper {\n \t\t\tadd_to_set(this.dependencies, attribute.dependencies);\n \t\t});\n \n+\t\tthis.node.spread_attributes.forEach(attribute => {\n+\t\t\tadd_to_set(this.dependencies, attribute.dependencies);\n+\t\t});\n+\n \t\tblock.add_dependencies(this.dependencies);\n \n \t\t// we have to do this, just in case\n@@ -84,7 +88,9 @@ export default class SlotWrapper extends Wrapper {\n \t\tlet get_slot_changes_fn;\n \t\tlet get_slot_context_fn;\n \n-\t\tif (this.node.values.size > 0) {\n+\t\tconst has_spreads = this.node.spread_attributes.length > 0;\n+\n+\t\tif (this.node.values.size > 0 || has_spreads) {\n \t\t\tget_slot_changes_fn = renderer.component.get_unique_name(`get_${sanitize(slot_name)}_slot_changes`);\n \t\t\tget_slot_context_fn = renderer.component.get_unique_name(`get_${sanitize(slot_name)}_slot_context`);\n \n@@ -112,10 +118,47 @@ export default class SlotWrapper extends Wrapper {\n \t\t\t\t}\n \t\t\t});\n \n-\t\t\trenderer.blocks.push(b`\n-\t\t\t\tconst ${get_slot_changes_fn} = #dirty => ${changes};\n-\t\t\t\tconst ${get_slot_context_fn} = #ctx => ${get_slot_data(this.node.values, block)};\n-\t\t\t`);\n+\t\t\t// Handle spread attributes - they contribute to dependencies and we need to mark\n+\t\t\t// that all properties could have changed when a spread changes\n+\t\t\tthis.node.spread_attributes.forEach(attribute => {\n+\t\t\t\tif (attribute.expression) {\n+\t\t\t\t\tadd_to_set(dependencies, attribute.expression.contextual_dependencies);\n+\t\t\t\t\tattribute.expression.dependencies.forEach(name => {\n+\t\t\t\t\t\tconst variable = renderer.component.var_lookup.get(name);\n+\t\t\t\t\t\tif (variable && !variable.hoistable) dependencies.add(name);\n+\t\t\t\t\t});\n+\t\t\t\t}\n+\t\t\t});\n+\n+\n+\t\t\tconst slot_data_expression = get_slot_data(this.node.values, block, this.node.spread_attributes);\n+\n+\t\t\t// For spreads, we need to return the slot data in the changes function\n+\t\t\t// so that the slot definition can calculate which properties have changed\n+\t\t\tif (has_spreads) {\n+\t\t\t\tconst spread_dynamic_dependencies = this.node.spread_attributes\n+\t\t\t\t\t.map(attr => Array.from(attr.dependencies).filter((name) => this.is_dependency_dynamic(name)))\n+\t\t\t\t\t.reduce((acc, deps) => [...acc, ...deps], []);\n+\n+\t\t\t\tif (spread_dynamic_dependencies.length > 0) {\n+\t\t\t\t\t// When spreads change, return the slot context so the slot can determine which props changed\n+\t\t\t\t\t// The slot_ctx parameter is passed by the runtime's update_slot function\n+\t\t\t\t\trenderer.blocks.push(b`\n+\t\t\t\t\t\tconst ${get_slot_changes_fn} = (#dirty, #slot_ctx) => ${renderer.dirty(spread_dynamic_dependencies)} ? #slot_ctx : ${changes};\n+\t\t\t\t\t\tconst ${get_slot_context_fn} = #ctx => ${slot_data_expression};\n+\t\t\t\t\t`);\n+\t\t\t\t} else {\n+\t\t\t\t\trenderer.blocks.push(b`\n+\t\t\t\t\t\tconst ${get_slot_changes_fn} = #dirty => ${changes};\n+\t\t\t\t\t\tconst ${get_slot_context_fn} = #ctx => ${slot_data_expression};\n+\t\t\t\t\t`);\n+\t\t\t\t}\n+\t\t\t} else {\n+\t\t\t\trenderer.blocks.push(b`\n+\t\t\t\t\tconst ${get_slot_changes_fn} = #dirty => ${changes};\n+\t\t\t\t\tconst ${get_slot_context_fn} = #ctx => ${slot_data_expression};\n+\t\t\t\t`);\n+\t\t\t}\n \t\t} else {\n \t\t\tget_slot_changes_fn = 'null';\n \t\t\tget_slot_context_fn = 'null';\ndiff --git a/src/compiler/compile/render_ssr/handlers/Slot.ts b/src/compiler/compile/render_ssr/handlers/Slot.ts\nindex f89b619c4..6bb23e01e 100644\n--- a/src/compiler/compile/render_ssr/handlers/Slot.ts\n+++ b/src/compiler/compile/render_ssr/handlers/Slot.ts\n@@ -7,7 +7,7 @@ import { get_slot_scope } from './shared/get_slot_scope';\n export default function(node: Slot, renderer: Renderer, options: RenderOptions & {\n \tslot_scopes: Map<any, any>;\n }) {\n-\tconst slot_data = get_slot_data(node.values);\n+\tconst slot_data = get_slot_data(node.values, null, node.spread_attributes);\n \tconst slot = node.get_static_attribute_value('slot');\n \tconst nearest_inline_component = node.find_nearest(/InlineComponent/);\n \ndiff --git a/src/compiler/compile/utils/get_slot_data.ts b/src/compiler/compile/utils/get_slot_data.ts\nindex c7f70aa48..ad8d538e3 100644\n--- a/src/compiler/compile/utils/get_slot_data.ts\n+++ b/src/compiler/compile/utils/get_slot_data.ts\n@@ -3,16 +3,40 @@ import { p, x } from 'code-red';\n import { string_literal } from './stringify';\n import Block from '../render_dom/Block';\n \n-export default function get_slot_data(values: Map<string, Attribute>, block: Block = null) {\n-\treturn {\n+export default function get_slot_data(values: Map<string, Attribute>, block: Block = null, spread_attributes: Attribute[] = []) {\n+\tconst properties = Array.from(values.values())\n+\t\t.filter(attribute => attribute.name !== 'name')\n+\t\t.map(attribute => {\n+\t\t\tconst value = get_value(block, attribute);\n+\t\t\treturn p`${attribute.name}: ${value}`;\n+\t\t});\n+\n+\tif (spread_attributes.length === 0) {\n+\t\treturn {\n+\t\t\ttype: 'ObjectExpression',\n+\t\t\tproperties\n+\t\t};\n+\t}\n+\n+\t// If there are spread attributes, we need to use Object.assign or spread syntax\n+\tconst object_expression = {\n \t\ttype: 'ObjectExpression',\n-\t\tproperties: Array.from(values.values())\n-\t\t\t.filter(attribute => attribute.name !== 'name')\n-\t\t\t.map(attribute => {\n-\t\t\t\tconst value = get_value(block, attribute);\n-\t\t\t\treturn p`${attribute.name}: ${value}`;\n-\t\t\t})\n+\t\tproperties\n \t};\n+\n+\t// Build up the assign chain: assign(assign(assign({}, spread1), spread2), { ...regular_props })\n+\tlet result = x`{}`;\n+\tfor (const attr of spread_attributes) {\n+\t\tconst snippet = block ? attr.expression.manipulate(block) : attr.expression.node;\n+\t\tresult = x`@assign(${result}, ${snippet})`;\n+\t}\n+\t\n+\t// Add the regular properties at the end so they take precedence\n+\tif (properties.length > 0) {\n+\t\tresult = x`@assign(${result}, ${object_expression})`;\n+\t}\n+\n+\treturn result;\n }\n \n function get_value(block: Block, attribute: Attribute) {\ndiff --git a/src/runtime/internal/utils.ts b/src/runtime/internal/utils.ts\nindex 3b8815cb1..95aa235a5 100644\n--- a/src/runtime/internal/utils.ts\n+++ b/src/runtime/internal/utils.ts\n@@ -85,9 +85,9 @@ export function get_slot_context(definition, ctx, $$scope, fn) {\n \t\t: $$scope.ctx;\n }\n \n-export function get_slot_changes(definition, $$scope, dirty, fn) {\n+export function get_slot_changes(definition, $$scope, dirty, fn, slot_ctx = null) {\n \tif (definition[2] && fn) {\n-\t\tconst lets = definition[2](fn(dirty));\n+\t\tconst lets = definition[2](fn(dirty, slot_ctx));\n \n \t\tif ($$scope.dirty === undefined) {\n \t\t\treturn lets;\n@@ -110,7 +110,8 @@ export function get_slot_changes(definition, $$scope, dirty, fn) {\n }\n \n export function update_slot(slot, slot_definition, ctx, $$scope, dirty, get_slot_changes_fn, get_slot_context_fn) {\n-\tconst slot_changes = get_slot_changes(slot_definition, $$scope, dirty, get_slot_changes_fn);\n+\tconst slot_ctx = get_slot_context_fn ? get_slot_context_fn(ctx) : null;\n+\tconst slot_changes = get_slot_changes(slot_definition, $$scope, dirty, get_slot_changes_fn, slot_ctx);\n \tif (slot_changes) {\n \t\tconst slot_context = get_slot_context(slot_definition, ctx, $$scope, get_slot_context_fn);\n \t\tslot.p(slot_context, slot_changes);\n"}
{"instance_id": "sveltejs__svelte-5850", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/runtime/internal/await_block.ts b/src/runtime/internal/await_block.ts\nindex 4b7ca6fd2..b93f216b3 100644\n--- a/src/runtime/internal/await_block.ts\n+++ b/src/runtime/internal/await_block.ts\n@@ -28,7 +28,9 @@ export function handle_promise(promise, info) {\n \t\t\t\t\tif (i !== index && block) {\n \t\t\t\t\t\tgroup_outros();\n \t\t\t\t\t\ttransition_out(block, 1, 1, () => {\n-\t\t\t\t\t\t\tinfo.blocks[i] = null;\n+\t\t\t\t\t\t\tif (info.blocks[i] === block) {\n+\t\t\t\t\t\t\t\tinfo.blocks[i] = null;\n+\t\t\t\t\t\t\t}\n \t\t\t\t\t\t});\n \t\t\t\t\t\tcheck_outros();\n \t\t\t\t\t}\n"}
{"instance_id": "sveltejs__svelte-6564", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/parse/state/mustache.ts b/src/compiler/parse/state/mustache.ts\nindex cc3c24349..738fd0df0 100644\n--- a/src/compiler/parse/state/mustache.ts\n+++ b/src/compiler/parse/state/mustache.ts\n@@ -290,16 +290,20 @@ export default function mustache(parser: Parser) {\n \n \t\tconst await_block_shorthand = type === 'AwaitBlock' && parser.eat('then');\n \t\tif (await_block_shorthand) {\n-\t\t\tparser.require_whitespace();\n-\t\t\tblock.value = read_context(parser);\n \t\t\tparser.allow_whitespace();\n+\t\t\tif (!parser.match('}')) {\n+\t\t\t\tblock.value = read_context(parser);\n+\t\t\t\tparser.allow_whitespace();\n+\t\t\t}\n \t\t}\n \n \t\tconst await_block_catch_shorthand = !await_block_shorthand && type === 'AwaitBlock' && parser.eat('catch');\n \t\tif (await_block_catch_shorthand) {\n-\t\t\tparser.require_whitespace();\n-\t\t\tblock.error = read_context(parser);\n \t\t\tparser.allow_whitespace();\n+\t\t\tif (!parser.match('}')) {\n+\t\t\t\tblock.error = read_context(parser);\n+\t\t\t\tparser.allow_whitespace();\n+\t\t\t}\n \t\t}\n \n \t\tparser.eat('}', true);\n"}
{"instance_id": "sveltejs__svelte-6759", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/runtime/internal/Component.ts b/src/runtime/internal/Component.ts\nindex e706928af..93ba42e37 100644\n--- a/src/runtime/internal/Component.ts\n+++ b/src/runtime/internal/Component.ts\n@@ -124,7 +124,7 @@ export function init(component, options, instance, create_fragment, not_equal, p\n \t\ton_disconnect: [],\n \t\tbefore_update: [],\n \t\tafter_update: [],\n-\t\tcontext: new Map(parent_component ? parent_component.$$.context : options.context || []),\n+\t\tcontext: new Map(options.context || (parent_component ? parent_component.$$.context : [])),\n \n \t\t// everything else\n \t\tcallbacks: blank_object(),\n"}
{"instance_id": "sveltejs__svelte-906", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/css/Selector.ts b/src/css/Selector.ts\nindex 85922c017..b002fb57f 100644\n--- a/src/css/Selector.ts\n+++ b/src/css/Selector.ts\n@@ -223,6 +223,7 @@ function attributeMatches(node: Node, name: string, expectedValue: string, opera\n \tconst attr = node.attributes.find((attr: Node) => attr.name === name);\n \tif (!attr) return false;\n \tif (attr.value === true) return operator === null;\n+\tif (!operator) return true;\n \tif (attr.value.length > 1) return true;\n \n \tconst pattern = operators[operator](expectedValue, caseInsensitive ? 'i' : '');\n"}
{"instance_id": "sveltejs__svelte-6525", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/Block.ts b/src/compiler/compile/render_dom/Block.ts\nindex 63195b610..2f4b43086 100644\n--- a/src/compiler/compile/render_dom/Block.ts\n+++ b/src/compiler/compile/render_dom/Block.ts\n@@ -177,10 +177,18 @@ export default class Block {\n \t\t}\n \n \t\tif (parent_node) {\n-\t\t\tthis.chunks.mount.push(b`@append(${parent_node}, ${id});`);\n+\t\t\tif (this.renderer.options.hydratable) {\n+\t\t\t\tthis.chunks.mount.push(b`@append_hydration(${parent_node}, ${id});`);\n+\t\t\t} else {\n+\t\t\t\tthis.chunks.mount.push(b`@append(${parent_node}, ${id});`);\n+\t\t\t}\n \t\t\tif (is_head(parent_node) && !no_detach) this.chunks.destroy.push(b`@detach(${id});`);\n \t\t} else {\n-\t\t\tthis.chunks.mount.push(b`@insert(#target, ${id}, #anchor);`);\n+\t\t\tif (this.renderer.options.hydratable) {\n+\t\t\t\tthis.chunks.mount.push(b`@insert_hydration(#target, ${id}, #anchor);`);\n+\t\t\t} else {\n+\t\t\t\tthis.chunks.mount.push(b`@insert(#target, ${id}, #anchor);`);\n+\t\t\t}\n \t\t\tif (!no_detach) this.chunks.destroy.push(b`if (detaching) @detach(${id});`);\n \t\t}\n \t}\ndiff --git a/src/compiler/compile/render_dom/wrappers/Element/index.ts b/src/compiler/compile/render_dom/wrappers/Element/index.ts\nindex 20dfed891..7e2dd88ba 100644\n--- a/src/compiler/compile/render_dom/wrappers/Element/index.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Element/index.ts\n@@ -263,7 +263,9 @@ export default class ElementWrapper extends Wrapper {\n \t\t}\n \n \t\tif (parent_node) {\n-\t\t\tconst append = b`@append(${parent_node}, ${node});`;\n+\t\t\tconst append = renderer.options.hydratable\n+\t\t\t\t? b`@append_hydration(${parent_node}, ${node});`\n+\t\t\t\t: b`@append(${parent_node}, ${node});`;\n \t\t\t((append[0] as ExpressionStatement).expression as CallExpression).callee.loc = {\n \t\t\t\tstart: this.renderer.locate(this.node.start),\n \t\t\t\tend: this.renderer.locate(this.node.end)\n@@ -274,7 +276,9 @@ export default class ElementWrapper extends Wrapper {\n \t\t\t\tblock.chunks.destroy.push(b`@detach(${node});`);\n \t\t\t}\n \t\t} else {\n-\t\t\tconst insert = b`@insert(#target, ${node}, #anchor);`;\n+\t\t\tconst insert = renderer.options.hydratable\n+\t\t\t\t? b`@insert_hydration(#target, ${node}, #anchor);`\n+\t\t\t\t: b`@insert(#target, ${node}, #anchor);`;\n \t\t\t((insert[0] as ExpressionStatement).expression as CallExpression).callee.loc = {\n \t\t\t\tstart: this.renderer.locate(this.node.start),\n \t\t\t\tend: this.renderer.locate(this.node.end)\ndiff --git a/src/compiler/compile/render_dom/wrappers/InlineComponent/index.ts b/src/compiler/compile/render_dom/wrappers/InlineComponent/index.ts\nindex e6eab33fb..b3499c008 100644\n--- a/src/compiler/compile/render_dom/wrappers/InlineComponent/index.ts\n+++ b/src/compiler/compile/render_dom/wrappers/InlineComponent/index.ts\n@@ -542,12 +542,20 @@ export default class InlineComponentWrapper extends Wrapper {\n \n \t\t\tif (has_css_custom_properties) {\n \t\t\t\tif (parent_node) {\n-\t\t\t\t\tblock.chunks.mount.push(b`@append(${parent_node}, ${css_custom_properties_wrapper})`);\n+\t\t\t\t\tif (this.renderer.options.hydratable) {\n+\t\t\t\t\t\tblock.chunks.mount.push(b`@append_hydration(${parent_node}, ${css_custom_properties_wrapper})`);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tblock.chunks.mount.push(b`@append(${parent_node}, ${css_custom_properties_wrapper})`);\n+\t\t\t\t\t}\n \t\t\t\t\tif (is_head(parent_node)) {\n \t\t\t\t\t\tblock.chunks.destroy.push(b`@detach(${css_custom_properties_wrapper});`);\n \t\t\t\t\t}\n \t\t\t\t} else {\n-\t\t\t\t\tblock.chunks.mount.push(b`@insert(#target, ${css_custom_properties_wrapper}, #anchor);`);\n+\t\t\t\t\tif (this.renderer.options.hydratable) {\n+\t\t\t\t\t\tblock.chunks.mount.push(b`@insert_hydration(#target, ${css_custom_properties_wrapper}, #anchor);`);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tblock.chunks.mount.push(b`@insert(#target, ${css_custom_properties_wrapper}, #anchor);`);\n+\t\t\t\t\t}\n \t\t\t\t\t// TODO we eventually need to consider what happens to elements\n \t\t\t\t\t// that belong to the same outgroup as an outroing element...\n \t\t\t\t\tblock.chunks.destroy.push(b`if (detaching) @detach(${css_custom_properties_wrapper});`);\ndiff --git a/src/compiler/compile/render_dom/wrappers/RawMustacheTag.ts b/src/compiler/compile/render_dom/wrappers/RawMustacheTag.ts\nindex 1315f1e14..a9bade0d5 100644\n--- a/src/compiler/compile/render_dom/wrappers/RawMustacheTag.ts\n+++ b/src/compiler/compile/render_dom/wrappers/RawMustacheTag.ts\n@@ -51,9 +51,11 @@ export default class RawMustacheTagWrapper extends Tag {\n \n \t\t\tconst update_anchor = needs_anchor ? html_anchor : this.next ? this.next.var : 'null';\n \n-\t\t\tblock.chunks.create.push(b`${html_tag} = new @HtmlTag();`);\n \t\t\tif (this.renderer.options.hydratable) {\n+\t\t\t\tblock.chunks.create.push(b`${html_tag} = new @HtmlTagHydration();`);\n \t\t\t\tblock.chunks.claim.push(b`${html_tag} = @claim_html_tag(${_parent_nodes});`);\n+\t\t\t} else {\n+\t\t\t\tblock.chunks.create.push(b`${html_tag} = new @HtmlTag();`);\n \t\t\t}\n \t\t\tblock.chunks.hydrate.push(b`${html_tag}.a = ${update_anchor};`);\n \t\t\tblock.chunks.mount.push(b`${html_tag}.m(${init}, ${parent_node || '#target'}, ${parent_node ? null : '#anchor'});`);\ndiff --git a/src/runtime/internal/dom.ts b/src/runtime/internal/dom.ts\nindex 7af269178..a1e24579d 100644\n--- a/src/runtime/internal/dom.ts\n+++ b/src/runtime/internal/dom.ts\n@@ -161,7 +161,11 @@ function append_stylesheet(node: ShadowRoot | Document, style: HTMLStyleElement)\n \tappend((node as Document).head || node, style);\n }\n \n-export function append(target: NodeEx, node: NodeEx) {\n+export function append(target: Node, node: Node) {\n+\ttarget.appendChild(node);\n+}\n+\n+export function append_hydration(target: NodeEx, node: NodeEx) {\n \tif (is_hydrating) {\n \t\tinit_hydrate(target);\n \n@@ -187,9 +191,13 @@ export function append(target: NodeEx, node: NodeEx) {\n \t}\n }\n \n-export function insert(target: NodeEx, node: NodeEx, anchor?: NodeEx) {\n+export function insert(target: Node, node: Node, anchor?: Node) {\n+\ttarget.insertBefore(node, anchor || null);\n+}\n+\n+export function insert_hydration(target: NodeEx, node: NodeEx, anchor?: NodeEx) {\n \tif (is_hydrating && !anchor) {\n-\t\tappend(target, node);\n+\t\tappend_hydration(target, node);\n \t} else if (node.parentNode !== target || node.nextSibling != anchor) {\n \t\ttarget.insertBefore(node, anchor || null);\n \t}\n@@ -482,7 +490,7 @@ export function claim_html_tag(nodes) {\n \tconst start_index = find_comment(nodes, 'HTML_TAG_START', 0);\n \tconst end_index = find_comment(nodes, 'HTML_TAG_END', start_index);\n \tif (start_index === end_index) {\n-\t\treturn new HtmlTag();\n+\t\treturn new HtmlTagHydration(undefined);\n \t}\n \n \tinit_claim_info(nodes);\n@@ -494,7 +502,7 @@ export function claim_html_tag(nodes) {\n \t\tn.claim_order = nodes.claim_info.total_claimed;\n \t\tnodes.claim_info.total_claimed += 1;\n \t}\n-\treturn new HtmlTag(claimed_nodes);\n+\treturn new HtmlTagHydration(claimed_nodes);\n }\n \n export function set_data(text, data) {\n@@ -628,27 +636,24 @@ export class HtmlTag {\n \te: HTMLElement;\n \t// html tag nodes\n \tn: ChildNode[];\n-\t// hydration claimed nodes\n-\tl: ChildNode[] | void;\n \t// target\n \tt: HTMLElement;\n \t// anchor\n \ta: HTMLElement;\n \n-\tconstructor(claimed_nodes?: ChildNode[]) {\n+\tconstructor() {\n \t\tthis.e = this.n = null;\n-\t\tthis.l = claimed_nodes;\n+\t}\n+\n+\tc(html: string) {\n+\t\tthis.h(html);\n \t}\n \n \tm(html: string, target: HTMLElement, anchor: HTMLElement = null) {\n \t\tif (!this.e) {\n \t\t\tthis.e = element(target.nodeName as keyof HTMLElementTagNameMap);\n \t\t\tthis.t = target;\n-\t\t\tif (this.l) {\n-\t\t\t\tthis.n = this.l;\n-\t\t\t} else {\n-\t\t\t\tthis.h(html);\n-\t\t\t}\n+\t\t\tthis.c(html);\n \t\t}\n \n \t\tthis.i(anchor);\n@@ -676,6 +681,31 @@ export class HtmlTag {\n \t}\n }\n \n+export class HtmlTagHydration extends HtmlTag {\n+\t// hydration claimed nodes\n+\tl: ChildNode[] | void;\n+\n+\tconstructor(claimed_nodes?: ChildNode[]) {\n+\t\tsuper();\n+\t\tthis.e = this.n = null;\n+\t\tthis.l = claimed_nodes;\n+\t}\n+\n+\tc(html: string) {\n+\t\tif (this.l) {\n+\t\t\tthis.n = this.l;\n+\t\t} else {\n+\t\t\tsuper.c(html);\n+\t\t}\n+\t}\n+\n+\ti(anchor) {\n+\t\tfor (let i = 0; i < this.n.length; i += 1) {\n+\t\t\tinsert_hydration(this.t, this.n[i], anchor);\n+\t\t}\n+\t}\n+}\n+\n export function attribute_to_object(attributes: NamedNodeMap) {\n \tconst result = {};\n \tfor (const attribute of attributes) {\n"}
{"instance_id": "tailwindlabs__tailwindcss-550", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/flexbox.js b/src/generators/flexbox.js\nindex 10e26c30..23320855 100644\n--- a/src/generators/flexbox.js\n+++ b/src/generators/flexbox.js\n@@ -90,7 +90,7 @@ export default function() {\n       'align-content': 'space-around',\n     },\n     'flex-1': {\n-      flex: '1',\n+      flex: '1 1 0%',\n     },\n     'flex-auto': {\n       flex: 'auto',\n"}
{"instance_id": "tailwindlabs__tailwindcss-853", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/util/configurePlugins.js b/src/util/configurePlugins.js\nindex 64654c5f..66048f3d 100644\n--- a/src/util/configurePlugins.js\n+++ b/src/util/configurePlugins.js\n@@ -1,7 +1,17 @@\n+import isArray from 'lodash/isArray'\n+\n export default function(pluginConfig, plugins) {\n   return Object.keys(plugins)\n     .filter(pluginName => {\n-      return pluginConfig !== false && pluginConfig[pluginName] !== false\n+      if (pluginConfig === false) {\n+        return false\n+      }\n+\n+      if (isArray(pluginConfig)) {\n+        return pluginConfig.includes(pluginName)\n+      }\n+\n+      return pluginConfig[pluginName] !== false\n     })\n     .map(pluginName => {\n       return plugins[pluginName]()\n"}
{"instance_id": "tailwindlabs__tailwindcss-116", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/borderStylesReset.js b/src/generators/borderStylesReset.js\ndeleted file mode 100644\nindex 230dfc88..00000000\n--- a/src/generators/borderStylesReset.js\n+++ /dev/null\n@@ -1,12 +0,0 @@\n-import defineClasses from '../util/defineClasses'\n-\n-export default function() {\n-  return defineClasses({\n-    'border-dashed': {\n-      'border-width': '0',\n-    },\n-    'border-dotted': {\n-      'border-width': '0',\n-    },\n-  })\n-}\ndiff --git a/src/lib/generateUtilities.js b/src/lib/generateUtilities.js\nindex 75dd4e7d..39f637b7 100644\n--- a/src/lib/generateUtilities.js\n+++ b/src/lib/generateUtilities.js\n@@ -3,7 +3,6 @@ import backgroundColors from '../generators/backgroundColors'\n import backgroundPositions from '../generators/backgroundPositions'\n import backgroundSize from '../generators/backgroundSize'\n import borderColors from '../generators/borderColors'\n-import borderStylesReset from '../generators/borderStylesReset'\n import borderStyles from '../generators/borderStyles'\n import borderWidths from '../generators/borderWidths'\n import container from '../generators/container'\n@@ -59,7 +58,6 @@ export default function(config) {\n           backgroundColors(options),\n           backgroundPositions(options),\n           backgroundSize(options),\n-          borderStylesReset(options),\n           borderWidths(options),\n           borderColors(options),\n           borderStyles(options),\n"}
{"instance_id": "sveltejs__svelte-907", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/generators/Generator.ts b/src/generators/Generator.ts\nindex 5b7ec8f07..4898d1e05 100644\n--- a/src/generators/Generator.ts\n+++ b/src/generators/Generator.ts\n@@ -509,19 +509,21 @@ export default class Generator {\n \t\t\t\t});\n \n \t\t\t\tconst addArrowFunctionExpression = (name: string, node: Node) => {\n-\t\t\t\t\tconst { body, params } = node;\n+\t\t\t\t\tconst { body, params, async } = node;\n \n \t\t\t\t\tconst paramString = params.length ?\n \t\t\t\t\t\t`[\u2702${params[0].start}-${params[params.length - 1].end}\u2702]` :\n \t\t\t\t\t\t``;\n \n+\t\t\t\t\tconst functionKeyword = async ? 'async function' : 'function';\n+\n \t\t\t\t\tif (body.type === 'BlockStatement') {\n \t\t\t\t\t\tcomponentDefinition.addBlock(deindent`\n-\t\t\t\t\t\t\tfunction ${name}(${paramString}) [\u2702${body.start}-${body.end}\u2702]\n+\t\t\t\t\t\t\t${functionKeyword} ${name}(${paramString}) [\u2702${body.start}-${body.end}\u2702]\n \t\t\t\t\t\t`);\n \t\t\t\t\t} else {\n \t\t\t\t\t\tcomponentDefinition.addBlock(deindent`\n-\t\t\t\t\t\t\tfunction ${name}(${paramString}) {\n+\t\t\t\t\t\t\t${functionKeyword} ${name}(${paramString}) {\n \t\t\t\t\t\t\t\treturn [\u2702${body.start}-${body.end}\u2702];\n \t\t\t\t\t\t\t}\n \t\t\t\t\t\t`);\n@@ -531,8 +533,9 @@ export default class Generator {\n \t\t\t\tconst addFunctionExpression = (name: string, node: Node) => {\n \t\t\t\t\tlet c = node.start;\n \t\t\t\t\twhile (this.source[c] !== '(') c += 1;\n+\t\t\t\t\tconst functionKeyword = node.async ? 'async function' : 'function';\n \t\t\t\t\tcomponentDefinition.addBlock(deindent`\n-\t\t\t\t\t\tfunction ${name}[\u2702${c}-${node.end}\u2702];\n+\t\t\t\t\t\t${functionKeyword} ${name}[\u2702${c}-${node.end}\u2702];\n \t\t\t\t\t`);\n \t\t\t\t};\n \n"}
{"instance_id": "trinodb__trino-1512", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/HashGenerationOptimizer.java b/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/HashGenerationOptimizer.java\nindex 9b77a314183..7729639baae 100644\n--- a/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/HashGenerationOptimizer.java\n+++ b/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/HashGenerationOptimizer.java\n@@ -803,12 +803,12 @@ public class HashGenerationOptimizer\n \n         public HashComputationSet translate(Function<Symbol, Optional<Symbol>> translator)\n         {\n-            ImmutableMap.Builder<HashComputation, HashComputation> builder = ImmutableMap.builder();\n+            Map<HashComputation, HashComputation> newHashes = new HashMap<>();\n             for (HashComputation hashComputation : hashes.keySet()) {\n                 hashComputation.translate(translator)\n-                        .ifPresent(hash -> builder.put(hash, hashComputation));\n+                        .ifPresent(hash -> newHashes.putIfAbsent(hash, hashComputation));\n             }\n-            return new HashComputationSet(builder.build());\n+            return new HashComputationSet(ImmutableMap.copyOf(newHashes));\n         }\n \n         public HashComputation lookup(HashComputation hashComputation)\n"}
{"instance_id": "sveltejs__svelte-738", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/css/Selector.ts b/src/css/Selector.ts\nindex 07a0fb978..6b5840f3f 100644\n--- a/src/css/Selector.ts\n+++ b/src/css/Selector.ts\n@@ -56,7 +56,15 @@ export default class Selector {\n \t\t\tlet i = block.selectors.length;\n \t\t\twhile (i--) {\n \t\t\t\tconst selector = block.selectors[i];\n-\t\t\t\tif (selector.type === 'PseudoElementSelector' || selector.type === 'PseudoClassSelector') continue;\n+\t\t\t\tif (selector.type === 'PseudoElementSelector') continue;\n+\t\t\t\tif (selector.type === 'PseudoClassSelector') {\n+\t\t\t\t\tif (selector.name === 'ref') {\n+\t\t\t\t\t\t// remove :ref(...) and replace with scoping attribute\n+\t\t\t\t\t\tcode.overwrite(selector.start, selector.end, attr);\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n+\t\t\t\t\tcontinue;\n+\t\t\t\t}\n \n \t\t\t\tif (selector.type === 'TypeSelector' && selector.name === '*') {\n \t\t\t\t\tcode.overwrite(selector.start, selector.end, attr);\n@@ -134,6 +142,16 @@ function selectorAppliesTo(blocks: Block[], node: Node, stack: Node[]): boolean\n \t\t\treturn false;\n \t\t}\n \n+\t\tif (selector.type === 'PseudoClassSelector' && selector.name === 'ref') {\n+\t\t\tconst ref = node.attributes.find((attr: Node) => attr.type === 'Ref');\n+\t\t\tif (!ref) return false;\n+\t\t\tif (selector.children && selector.children.length > 0) {\n+\t\t\t\tconst refName = selector.children[0].value;\n+\t\t\t\tif (ref.name !== refName) return false;\n+\t\t\t}\n+\t\t\tcontinue;\n+\t\t}\n+\n \t\tif (selector.type === 'PseudoClassSelector' || selector.type === 'PseudoElementSelector') {\n \t\t\tcontinue;\n \t\t}\ndiff --git a/src/css/Stylesheet.ts b/src/css/Stylesheet.ts\nindex d0fcd10b7..7ce386e4c 100644\n--- a/src/css/Stylesheet.ts\n+++ b/src/css/Stylesheet.ts\n@@ -72,7 +72,10 @@ class Rule {\n \t\t\t\tconst { start, end, children } = selector.node;\n \n \t\t\t\tconst css = code.original;\n-\t\t\t\tconst selectorString = css.slice(start, end);\n+\t\t\t\tlet selectorString = css.slice(start, end);\n+\n+\t\t\t\t// Remove :ref(...) from the selector string as it's not valid CSS\n+\t\t\t\tselectorString = selectorString.replace(/:ref\\([^)]*\\)/g, '');\n \n \t\t\t\tconst firstToken = children[0];\n \n@@ -81,9 +84,14 @@ class Rule {\n \t\t\t\tif (firstToken.type === 'TypeSelector') {\n \t\t\t\t\tconst insert = firstToken.end;\n \t\t\t\t\tconst head = firstToken.name === '*' ? '' : css.slice(start, insert);\n-\t\t\t\t\tconst tail = css.slice(insert, end);\n+\t\t\t\t\tlet tail = css.slice(insert, end);\n+\t\t\t\t\t// Remove :ref(...) from tail as well\n+\t\t\t\t\ttail = tail.replace(/:ref\\([^)]*\\)/g, '');\n \n \t\t\t\t\ttransformed = `${head}${attr}${tail},${attr} ${selectorString}`;\n+\t\t\t\t} else if (firstToken.type === 'PseudoClassSelector' && firstToken.name === 'ref') {\n+\t\t\t\t\t// If the first token is :ref(...), just use the scoping attribute\n+\t\t\t\t\ttransformed = `${attr}${selectorString},${attr} ${selectorString}`;\n \t\t\t\t} else {\n \t\t\t\t\ttransformed = `${attr}${selectorString},${attr} ${selectorString}`;\n \t\t\t\t}\n"}
{"instance_id": "sveltejs__svelte-7422", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/KeyBlock.ts b/src/compiler/compile/render_dom/wrappers/KeyBlock.ts\nindex cbd021ff6..074eec51d 100644\n--- a/src/compiler/compile/render_dom/wrappers/KeyBlock.ts\n+++ b/src/compiler/compile/render_dom/wrappers/KeyBlock.ts\n@@ -48,6 +48,10 @@ export default class KeyBlockWrapper extends Wrapper {\n \t\t\tstrip_whitespace,\n \t\t\tnext_sibling\n \t\t);\n+\n+\t\tif (this.dependencies.length) {\n+\t\t\tblock.add_dependencies(new Set(this.dependencies));\n+\t\t}\n \t}\n \n \trender(block: Block, parent_node: Identifier, parent_nodes: Identifier) {\n"}
{"instance_id": "trinodb__trino-2768", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/Session.java b/presto-main/src/main/java/io/prestosql/Session.java\nindex f7a73e50da1..f605f581eff 100644\n--- a/presto-main/src/main/java/io/prestosql/Session.java\n+++ b/presto-main/src/main/java/io/prestosql/Session.java\n@@ -20,6 +20,7 @@ import com.google.common.collect.Maps;\n import io.airlift.units.DataSize;\n import io.airlift.units.Duration;\n import io.prestosql.connector.CatalogName;\n+import io.prestosql.metadata.CatalogMetadata;\n import io.prestosql.metadata.SessionPropertyManager;\n import io.prestosql.security.AccessControl;\n import io.prestosql.security.SecurityContext;\n@@ -328,9 +329,12 @@ public final class Session\n         for (Entry<String, SelectedRole> entry : identity.getRoles().entrySet()) {\n             String catalogName = entry.getKey();\n             SelectedRole role = entry.getValue();\n-            CatalogName catalog = transactionManager.getOptionalCatalogMetadata(transactionId, catalogName)\n-                    .orElseThrow(() -> new PrestoException(NOT_FOUND, \"Catalog does not exist: \" + catalogName))\n-                    .getCatalogName();\n+            Optional<CatalogMetadata> catalogMetadata = transactionManager.getOptionalCatalogMetadata(transactionId, catalogName);\n+            if (catalogMetadata.isEmpty()) {\n+                // Skip roles for catalogs that do not exist\n+                continue;\n+            }\n+            CatalogName catalog = catalogMetadata.get().getCatalogName();\n             if (role.getType() == SelectedRole.Type.ROLE) {\n                 accessControl.checkCanSetRole(new SecurityContext(transactionId, identity), role.getRole().get(), catalogName);\n             }\n"}
{"instance_id": "trinodb__trino-2707", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/BingTileFunctions.java b/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/BingTileFunctions.java\nindex 659caccb507..f85c1a3905e 100644\n--- a/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/BingTileFunctions.java\n+++ b/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/BingTileFunctions.java\n@@ -82,7 +82,7 @@ public final class BingTileFunctions\n \n     private BingTileFunctions() {}\n \n-    @Description(\"Creates a Bing tile from XY coordinates and zoom level\")\n+    @Description(\"Creates a Bing tile from XY coordinates and zoom level.\")\n     @ScalarFunction(\"bing_tile\")\n     @SqlType(BingTileType.NAME)\n     public static long toBingTile(@SqlType(StandardTypes.INTEGER) long tileX, @SqlType(StandardTypes.INTEGER) long tileY, @SqlType(StandardTypes.INTEGER) long zoomLevel)\n@@ -94,7 +94,7 @@ public final class BingTileFunctions\n         return BingTile.fromCoordinates(toIntExact(tileX), toIntExact(tileY), toIntExact(zoomLevel)).encode();\n     }\n \n-    @Description(\"Given a Bing tile, returns its QuadKey\")\n+    @Description(\"Given a Bing tile, returns its QuadKey.\")\n     @ScalarFunction(\"bing_tile_quadkey\")\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice toQuadKey(@SqlType(BingTileType.NAME) long input)\n@@ -102,7 +102,7 @@ public final class BingTileFunctions\n         return utf8Slice(BingTile.decode(input).toQuadKey());\n     }\n \n-    @Description(\"Given a Bing tile, returns XY coordinates of the tile\")\n+    @Description(\"Given a Bing tile, returns XY coordinates of the tile.\")\n     @ScalarFunction(\"bing_tile_coordinates\")\n     public static final class BingTileCoordinatesFunction\n     {\n@@ -133,7 +133,7 @@ public final class BingTileFunctions\n         }\n     }\n \n-    @Description(\"Given a Bing tile, returns zoom level of the tile\")\n+    @Description(\"Given a Bing tile, returns zoom level of the tile.\")\n     @ScalarFunction(\"bing_tile_zoom_level\")\n     @SqlType(StandardTypes.TINYINT)\n     public static long bingTileZoomLevel(@SqlType(BingTileType.NAME) long input)\n@@ -141,7 +141,7 @@ public final class BingTileFunctions\n         return BingTile.decode(input).getZoomLevel();\n     }\n \n-    @Description(\"Creates a Bing tile from a QuadKey\")\n+    @Description(\"Creates a Bing tile from a QuadKey.\")\n     @ScalarFunction(\"bing_tile\")\n     @SqlType(BingTileType.NAME)\n     public static long toBingTile(@SqlType(StandardTypes.VARCHAR) Slice quadKey)\n@@ -150,7 +150,7 @@ public final class BingTileFunctions\n         return BingTile.fromQuadKey(quadKey.toStringUtf8()).encode();\n     }\n \n-    @Description(\"Given a (latitude, longitude) point, returns the containing Bing tile at the specified zoom level\")\n+    @Description(\"Given a (latitude, longitude) point, returns the containing Bing tile at the specified zoom level.\")\n     @ScalarFunction(\"bing_tile_at\")\n     @SqlType(BingTileType.NAME)\n     public static long bingTileAt(\n@@ -165,7 +165,7 @@ public final class BingTileFunctions\n         return latitudeLongitudeToTile(latitude, longitude, toIntExact(zoomLevel)).encode();\n     }\n \n-    @Description(\"Given a (longitude, latitude) point, returns the surrounding Bing tiles at the specified zoom level\")\n+    @Description(\"Given a (longitude, latitude) point, returns the surrounding Bing tiles at the specified zoom level.\")\n     @ScalarFunction(\"bing_tiles_around\")\n     @SqlType(\"array(\" + BingTileType.NAME + \")\")\n     public static Block bingTilesAround(\n@@ -333,7 +333,7 @@ public final class BingTileFunctions\n         return blockBuilder.build();\n     }\n \n-    @Description(\"Given a Bing tile, returns the polygon representation of the tile\")\n+    @Description(\"Given a Bing tile, returns the polygon representation of the tile.\")\n     @ScalarFunction(\"bing_tile_polygon\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice bingTilePolygon(@SqlType(BingTileType.NAME) long input)\n@@ -343,7 +343,7 @@ public final class BingTileFunctions\n         return serialize(tileToEnvelope(tile));\n     }\n \n-    @Description(\"Given a geometry and a zoom level, returns the minimum set of Bing tiles that fully covers that geometry\")\n+    @Description(\"Given a geometry and a zoom level, returns the minimum set of Bing tiles that fully covers that geometry.\")\n     @ScalarFunction(\"geometry_to_bing_tiles\")\n     @SqlType(\"array(\" + BingTileType.NAME + \")\")\n     public static Block geometryToBingTiles(@SqlType(GEOMETRY_TYPE_NAME) Slice input, @SqlType(StandardTypes.INTEGER) long zoomLevelInput)\ndiff --git a/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/EncodedPolylineFunctions.java b/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/EncodedPolylineFunctions.java\nindex 97319911da3..aed7bd1ee7a 100644\n--- a/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/EncodedPolylineFunctions.java\n+++ b/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/EncodedPolylineFunctions.java\n@@ -50,7 +50,7 @@ public final class EncodedPolylineFunctions\n {\n     private EncodedPolylineFunctions() {}\n \n-    @Description(\"Decodes a polyline to a linestring\")\n+    @Description(\"Decodes a polyline to a linestring.\")\n     @ScalarFunction(\"from_encoded_polyline\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice fromEncodedPolyline(@SqlType(StandardTypes.VARCHAR) Slice input)\n@@ -99,7 +99,7 @@ public final class EncodedPolylineFunctions\n         return new OGCLineString(multipath, 0, null);\n     }\n \n-    @Description(\"Encodes a linestring or multipoint geometry to a polyline\")\n+    @Description(\"Encodes a linestring or multipoint geometry to a polyline.\")\n     @ScalarFunction(\"to_encoded_polyline\")\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice toEncodedPolyline(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\ndiff --git a/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/GeoFunctions.java b/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/GeoFunctions.java\nindex b9a7914e462..c3cb163290e 100644\n--- a/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/GeoFunctions.java\n+++ b/presto-geospatial/src/main/java/io/prestosql/plugin/geospatial/GeoFunctions.java\n@@ -170,7 +170,7 @@ public final class GeoFunctions\n \n     private GeoFunctions() {}\n \n-    @Description(\"Returns a Geometry type LineString object from Well-Known Text representation (WKT)\")\n+    @Description(\"Returns a Geometry type LineString object from Well-Known Text representation (WKT).\")\n     @ScalarFunction(\"ST_LineFromText\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice parseLine(@SqlType(VARCHAR) Slice input)\n@@ -180,7 +180,7 @@ public final class GeoFunctions\n         return serialize(geometry);\n     }\n \n-    @Description(\"Returns a LineString from an array of points\")\n+    @Description(\"Returns a LineString from an array of points.\")\n     @ScalarFunction(\"ST_LineString\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stLineString(@SqlType(\"array(\" + GEOMETRY_TYPE_NAME + \")\") Block input)\n@@ -220,7 +220,7 @@ public final class GeoFunctions\n         return serialize(linestring);\n     }\n \n-    @Description(\"Returns a Geometry type Point object with the given coordinate values\")\n+    @Description(\"Returns a Geometry type Point object with the given coordinate values.\")\n     @ScalarFunction(\"ST_Point\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stPoint(@SqlType(DOUBLE) double x, @SqlType(DOUBLE) double y)\n@@ -230,7 +230,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns a multi-point geometry formed from input points\")\n+    @Description(\"Returns a multi-point geometry formed from input points.\")\n     @ScalarFunction(\"ST_MultiPoint\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stMultiPoint(@SqlType(\"array(\" + GEOMETRY_TYPE_NAME + \")\") Block input)\n@@ -259,7 +259,7 @@ public final class GeoFunctions\n         return serialize(createFromEsriGeometry(multipoint, null, true));\n     }\n \n-    @Description(\"Returns a Geometry type Polygon object from Well-Known Text representation (WKT)\")\n+    @Description(\"Returns a Geometry type Polygon object from Well-Known Text representation (WKT).\")\n     @ScalarFunction(\"ST_Polygon\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stPolygon(@SqlType(VARCHAR) Slice input)\n@@ -269,7 +269,7 @@ public final class GeoFunctions\n         return serialize(geometry);\n     }\n \n-    @Description(\"Returns the 2D Euclidean area of a geometry\")\n+    @Description(\"Returns the 2D Euclidean area of a geometry.\")\n     @ScalarFunction(\"ST_Area\")\n     @SqlType(DOUBLE)\n     public static double stArea(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -294,7 +294,7 @@ public final class GeoFunctions\n         return geometry.getEsriGeometry().calculateArea2D();\n     }\n \n-    @Description(\"Returns a Geometry type object from Well-Known Text representation (WKT)\")\n+    @Description(\"Returns a Geometry type object from Well-Known Text representation (WKT).\")\n     @ScalarFunction(\"ST_GeometryFromText\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stGeometryFromText(@SqlType(VARCHAR) Slice input)\n@@ -302,7 +302,7 @@ public final class GeoFunctions\n         return serialize(geometryFromText(input));\n     }\n \n-    @Description(\"Returns a Geometry type object from Well-Known Binary representation (WKB)\")\n+    @Description(\"Returns a Geometry type object from Well-Known Binary representation (WKB).\")\n     @ScalarFunction(\"ST_GeomFromBinary\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stGeomFromBinary(@SqlType(VARBINARY) Slice input)\n@@ -310,7 +310,7 @@ public final class GeoFunctions\n         return serialize(geomFromBinary(input));\n     }\n \n-    @Description(\"Returns a Geometry type object from Spatial Framework for Hadoop representation\")\n+    @Description(\"Returns a Geometry type object from Spatial Framework for Hadoop representation.\")\n     @ScalarFunction(\"geometry_from_hadoop_shape\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice geometryFromHadoopShape(@SqlType(VARBINARY) Slice input)\n@@ -327,7 +327,7 @@ public final class GeoFunctions\n         }\n     }\n \n-    @Description(\"Converts a Geometry object to a SphericalGeography object\")\n+    @Description(\"Converts a Geometry object to a SphericalGeography object.\")\n     @ScalarFunction(\"to_spherical_geography\")\n     @SqlType(SPHERICAL_GEOGRAPHY_TYPE_NAME)\n     public static Slice toSphericalGeography(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -369,7 +369,7 @@ public final class GeoFunctions\n         return input;\n     }\n \n-    @Description(\"Returns the Well-Known Text (WKT) representation of the geometry\")\n+    @Description(\"Returns the Well-Known Text (WKT) representation of the geometry.\")\n     @ScalarFunction(\"ST_AsText\")\n     @SqlType(VARCHAR)\n     public static Slice stAsText(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -377,7 +377,7 @@ public final class GeoFunctions\n         return utf8Slice(deserialize(input).asText());\n     }\n \n-    @Description(\"Returns the Well-Known Binary (WKB) representation of the geometry\")\n+    @Description(\"Returns the Well-Known Binary (WKB) representation of the geometry.\")\n     @ScalarFunction(\"ST_AsBinary\")\n     @SqlType(VARBINARY)\n     public static Slice stAsBinary(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -386,7 +386,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the geometry that represents all points whose distance from the specified geometry is less than or equal to the specified distance\")\n+    @Description(\"Returns the geometry that represents all points whose distance from the specified geometry is less than or equal to the specified distance.\")\n     @ScalarFunction(\"ST_Buffer\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stBuffer(@SqlType(GEOMETRY_TYPE_NAME) Slice input, @SqlType(DOUBLE) double distance)\n@@ -410,7 +410,7 @@ public final class GeoFunctions\n         return serialize(geometry.buffer(distance));\n     }\n \n-    @Description(\"Returns the Point value that is the mathematical centroid of a Geometry\")\n+    @Description(\"Returns the Point value that is the mathematical centroid of a Geometry.\")\n     @ScalarFunction(\"ST_Centroid\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stCentroid(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -448,7 +448,7 @@ public final class GeoFunctions\n         return serialize(createFromEsriGeometry(centroid, geometry.getEsriSpatialReference()));\n     }\n \n-    @Description(\"Returns the minimum convex geometry that encloses all input geometries\")\n+    @Description(\"Returns the minimum convex geometry that encloses all input geometries.\")\n     @ScalarFunction(\"ST_ConvexHull\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stConvexHull(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -463,7 +463,7 @@ public final class GeoFunctions\n         return serialize(geometry.convexHull());\n     }\n \n-    @Description(\"Return the coordinate dimension of the Geometry\")\n+    @Description(\"Return the coordinate dimension of the Geometry.\")\n     @ScalarFunction(\"ST_CoordDim\")\n     @SqlType(TINYINT)\n     public static long stCoordinateDimension(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -471,7 +471,7 @@ public final class GeoFunctions\n         return deserialize(input).coordinateDimension();\n     }\n \n-    @Description(\"Returns the inherent dimension of this Geometry object, which must be less than or equal to the coordinate dimension\")\n+    @Description(\"Returns the inherent dimension of this Geometry object, which must be less than or equal to the coordinate dimension.\")\n     @ScalarFunction(\"ST_Dimension\")\n     @SqlType(TINYINT)\n     public static long stDimension(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -480,7 +480,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if the LineString or Multi-LineString's start and end points are coincident\")\n+    @Description(\"Returns TRUE if the LineString or Multi-LineString's start and end points are coincident.\")\n     @ScalarFunction(\"ST_IsClosed\")\n     @SqlType(BOOLEAN)\n     public static Boolean stIsClosed(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -500,7 +500,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if this Geometry is an empty geometrycollection, polygon, point etc\")\n+    @Description(\"Returns TRUE if this Geometry is an empty geometrycollection, polygon, point etc.\")\n     @ScalarFunction(\"ST_IsEmpty\")\n     @SqlType(BOOLEAN)\n     public static Boolean stIsEmpty(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -508,7 +508,7 @@ public final class GeoFunctions\n         return deserializeEnvelope(input).isEmpty();\n     }\n \n-    @Description(\"Returns TRUE if this Geometry has no anomalous geometric points, such as self intersection or self tangency\")\n+    @Description(\"Returns TRUE if this Geometry has no anomalous geometric points, such as self intersection or self tangency.\")\n     @ScalarFunction(\"ST_IsSimple\")\n     @SqlType(BOOLEAN)\n     public static boolean stIsSimple(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -517,7 +517,7 @@ public final class GeoFunctions\n         return geometry.isEmpty() || geometry.isSimple();\n     }\n \n-    @Description(\"Returns true if the input geometry is well formed\")\n+    @Description(\"Returns true if the input geometry is well formed.\")\n     @ScalarFunction(\"ST_IsValid\")\n     @SqlType(BOOLEAN)\n     public static boolean stIsValid(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -573,7 +573,7 @@ public final class GeoFunctions\n         }\n     }\n \n-    @Description(\"Returns the length of a LineString or Multi-LineString using Euclidean measurement on a 2D plane (based on spatial ref) in projected units\")\n+    @Description(\"Returns the length of a LineString or Multi-LineString using Euclidean measurement on a 2D plane (based on spatial ref) in projected units.\")\n     @ScalarFunction(\"ST_Length\")\n     @SqlType(DOUBLE)\n     public static double stLength(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -584,7 +584,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the great-circle length in meters of a linestring or multi-linestring on Earth's surface\")\n+    @Description(\"Returns the great-circle length in meters of a linestring or multi-linestring on Earth's surface.\")\n     @ScalarFunction(\"ST_Length\")\n     @SqlType(DOUBLE)\n     public static Double stSphericalLength(@SqlType(SPHERICAL_GEOGRAPHY_TYPE_NAME) Slice input)\n@@ -731,7 +731,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns X maxima of a bounding box of a Geometry\")\n+    @Description(\"Returns X maxima of a bounding box of a Geometry.\")\n     @ScalarFunction(\"ST_XMax\")\n     @SqlType(DOUBLE)\n     public static Double stXMax(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -744,7 +744,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns Y maxima of a bounding box of a Geometry\")\n+    @Description(\"Returns Y maxima of a bounding box of a Geometry.\")\n     @ScalarFunction(\"ST_YMax\")\n     @SqlType(DOUBLE)\n     public static Double stYMax(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -757,7 +757,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns X minima of a bounding box of a Geometry\")\n+    @Description(\"Returns X minima of a bounding box of a Geometry.\")\n     @ScalarFunction(\"ST_XMin\")\n     @SqlType(DOUBLE)\n     public static Double stXMin(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -770,7 +770,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns Y minima of a bounding box of a Geometry\")\n+    @Description(\"Returns Y minima of a bounding box of a Geometry.\")\n     @ScalarFunction(\"ST_YMin\")\n     @SqlType(DOUBLE)\n     public static Double stYMin(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -783,7 +783,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the cardinality of the collection of interior rings of a polygon\")\n+    @Description(\"Returns the cardinality of the collection of interior rings of a polygon.\")\n     @ScalarFunction(\"ST_NumInteriorRing\")\n     @SqlType(BIGINT)\n     public static Long stNumInteriorRings(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -797,7 +797,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns an array of interior rings of a polygon\")\n+    @Description(\"Returns an array of interior rings of a polygon.\")\n     @ScalarFunction(\"ST_InteriorRings\")\n     @SqlType(\"array(\" + GEOMETRY_TYPE_NAME + \")\")\n     public static Block stInteriorRings(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -816,7 +816,7 @@ public final class GeoFunctions\n         return blockBuilder.build();\n     }\n \n-    @Description(\"Returns the cardinality of the geometry collection\")\n+    @Description(\"Returns the cardinality of the geometry collection.\")\n     @ScalarFunction(\"ST_NumGeometries\")\n     @SqlType(INTEGER)\n     public static long stNumGeometries(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -895,7 +895,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the geometry element at the specified index (indices started with 1)\")\n+    @Description(\"Returns the geometry element at the specified index (indices started with 1).\")\n     @ScalarFunction(\"ST_GeometryN\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stGeometryN(@SqlType(GEOMETRY_TYPE_NAME) Slice input, @SqlType(INTEGER) long index)\n@@ -920,7 +920,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the vertex of a linestring at the specified index (indices started with 1) \")\n+    @Description(\"Returns the vertex of a linestring at the specified index (indices started with 1) .\")\n     @ScalarFunction(\"ST_PointN\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stPointN(@SqlType(GEOMETRY_TYPE_NAME) Slice input, @SqlType(INTEGER) long index)\n@@ -936,7 +936,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns an array of geometries in the specified collection\")\n+    @Description(\"Returns an array of geometries in the specified collection.\")\n     @ScalarFunction(\"ST_Geometries\")\n     @SqlType(\"array(\" + GEOMETRY_TYPE_NAME + \")\")\n     public static Block stGeometries(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -962,7 +962,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the interior ring element at the specified index (indices start at 1)\")\n+    @Description(\"Returns the interior ring element at the specified index (indices start at 1).\")\n     @ScalarFunction(\"ST_InteriorRingN\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stInteriorRingN(@SqlType(GEOMETRY_TYPE_NAME) Slice input, @SqlType(INTEGER) long index)\n@@ -977,7 +977,7 @@ public final class GeoFunctions\n         return serialize(interiorRing);\n     }\n \n-    @Description(\"Returns the number of points in a Geometry\")\n+    @Description(\"Returns the number of points in a Geometry.\")\n     @ScalarFunction(\"ST_NumPoints\")\n     @SqlType(BIGINT)\n     public static long stNumPoints(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -986,7 +986,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if and only if the line is closed and simple\")\n+    @Description(\"Returns TRUE if and only if the line is closed and simple.\")\n     @ScalarFunction(\"ST_IsRing\")\n     @SqlType(BOOLEAN)\n     public static Boolean stIsRing(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -998,7 +998,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the first point of a LINESTRING geometry as a Point\")\n+    @Description(\"Returns the first point of a LINESTRING geometry as a Point.\")\n     @ScalarFunction(\"ST_StartPoint\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stStartPoint(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1013,7 +1013,7 @@ public final class GeoFunctions\n         return serialize(createFromEsriGeometry(lines.getPoint(0), reference));\n     }\n \n-    @Description(\"Returns a \\\"simplified\\\" version of the given geometry\")\n+    @Description(\"Returns a \\\"simplified\\\" version of the given geometry.\")\n     @ScalarFunction(\"simplify_geometry\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice simplifyGeometry(@SqlType(GEOMETRY_TYPE_NAME) Slice input, @SqlType(DOUBLE) double distanceTolerance)\n@@ -1034,7 +1034,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the last point of a LINESTRING geometry as a Point\")\n+    @Description(\"Returns the last point of a LINESTRING geometry as a Point.\")\n     @ScalarFunction(\"ST_EndPoint\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stEndPoint(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1050,7 +1050,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns an array of points in a geometry\")\n+    @Description(\"Returns an array of points in a geometry.\")\n     @ScalarFunction(\"ST_Points\")\n     @SqlType(\"array(\" + GEOMETRY_TYPE_NAME + \")\")\n     public static Block stPoints(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1091,7 +1091,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Return the X coordinate of the point\")\n+    @Description(\"Return the X coordinate of the point.\")\n     @ScalarFunction(\"ST_X\")\n     @SqlType(DOUBLE)\n     public static Double stX(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1105,7 +1105,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Return the Y coordinate of the point\")\n+    @Description(\"Return the Y coordinate of the point.\")\n     @ScalarFunction(\"ST_Y\")\n     @SqlType(DOUBLE)\n     public static Double stY(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1118,7 +1118,7 @@ public final class GeoFunctions\n         return ((OGCPoint) geometry).Y();\n     }\n \n-    @Description(\"Returns the closure of the combinatorial boundary of this Geometry\")\n+    @Description(\"Returns the closure of the combinatorial boundary of this Geometry.\")\n     @ScalarFunction(\"ST_Boundary\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stBoundary(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1131,7 +1131,7 @@ public final class GeoFunctions\n         return serialize(geometry.boundary());\n     }\n \n-    @Description(\"Returns the bounding rectangular polygon of a Geometry\")\n+    @Description(\"Returns the bounding rectangular polygon of a Geometry.\")\n     @ScalarFunction(\"ST_Envelope\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stEnvelope(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1144,7 +1144,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the lower left and upper right corners of bounding rectangular polygon of a Geometry\")\n+    @Description(\"Returns the lower left and upper right corners of bounding rectangular polygon of a Geometry.\")\n     @ScalarFunction(\"ST_EnvelopeAsPts\")\n     @SqlType(\"array(\" + GEOMETRY_TYPE_NAME + \")\")\n     public static Block stEnvelopeAsPts(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1161,7 +1161,7 @@ public final class GeoFunctions\n         return blockBuilder.build();\n     }\n \n-    @Description(\"Returns the Geometry value that represents the point set difference of two geometries\")\n+    @Description(\"Returns the Geometry value that represents the point set difference of two geometries.\")\n     @ScalarFunction(\"ST_Difference\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stDifference(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1173,7 +1173,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the 2-dimensional cartesian minimum distance (based on spatial ref) between two geometries in projected units\")\n+    @Description(\"Returns the 2-dimensional cartesian minimum distance (based on spatial ref) between two geometries in projected units.\")\n     @ScalarFunction(\"ST_Distance\")\n     @SqlType(DOUBLE)\n     public static Double stDistance(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1185,7 +1185,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns a line string representing the exterior ring of the POLYGON\")\n+    @Description(\"Returns a line string representing the exterior ring of the POLYGON.\")\n     @ScalarFunction(\"ST_ExteriorRing\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stExteriorRing(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1198,7 +1198,7 @@ public final class GeoFunctions\n         return serialize(((OGCPolygon) geometry).exteriorRing());\n     }\n \n-    @Description(\"Returns the Geometry value that represents the point set intersection of two Geometries\")\n+    @Description(\"Returns the Geometry value that represents the point set intersection of two Geometries.\")\n     @ScalarFunction(\"ST_Intersection\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stIntersection(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1233,7 +1233,7 @@ public final class GeoFunctions\n         return serialize(leftGeometry.intersection(rightGeometry));\n     }\n \n-    @Description(\"Returns the Geometry value that represents the point set symmetric difference of two Geometries\")\n+    @Description(\"Returns the Geometry value that represents the point set symmetric difference of two Geometries.\")\n     @ScalarFunction(\"ST_SymDifference\")\n     @SqlType(GEOMETRY_TYPE_NAME)\n     public static Slice stSymmetricDifference(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1245,7 +1245,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if and only if no points of right lie in the exterior of left, and at least one point of the interior of left lies in the interior of right\")\n+    @Description(\"Returns TRUE if and only if no points of right lie in the exterior of left, and at least one point of the interior of left lies in the interior of right.\")\n     @ScalarFunction(\"ST_Contains\")\n     @SqlType(BOOLEAN)\n     public static Boolean stContains(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1260,7 +1260,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if the supplied geometries have some, but not all, interior points in common\")\n+    @Description(\"Returns TRUE if the supplied geometries have some, but not all, interior points in common.\")\n     @ScalarFunction(\"ST_Crosses\")\n     @SqlType(BOOLEAN)\n     public static Boolean stCrosses(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1275,7 +1275,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if the Geometries do not spatially intersect - if they do not share any space together\")\n+    @Description(\"Returns TRUE if the Geometries do not spatially intersect - if they do not share any space together.\")\n     @ScalarFunction(\"ST_Disjoint\")\n     @SqlType(BOOLEAN)\n     public static Boolean stDisjoint(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1290,7 +1290,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if the given geometries represent the same geometry\")\n+    @Description(\"Returns TRUE if the given geometries represent the same geometry.\")\n     @ScalarFunction(\"ST_Equals\")\n     @SqlType(BOOLEAN)\n     public static Boolean stEquals(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1302,7 +1302,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if the Geometries spatially intersect in 2D - (share any portion of space) and FALSE if they don't (they are Disjoint)\")\n+    @Description(\"Returns TRUE if the Geometries spatially intersect in 2D - (share any portion of space) and FALSE if they don't (they are Disjoint).\")\n     @ScalarFunction(\"ST_Intersects\")\n     @SqlType(BOOLEAN)\n     public static Boolean stIntersects(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1317,7 +1317,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if the Geometries share space, are of the same dimension, but are not completely contained by each other\")\n+    @Description(\"Returns TRUE if the Geometries share space, are of the same dimension, but are not completely contained by each other.\")\n     @ScalarFunction(\"ST_Overlaps\")\n     @SqlType(BOOLEAN)\n     public static Boolean stOverlaps(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1332,7 +1332,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if this Geometry is spatially related to another Geometry\")\n+    @Description(\"Returns TRUE if this Geometry is spatially related to another Geometry.\")\n     @ScalarFunction(\"ST_Relate\")\n     @SqlType(BOOLEAN)\n     public static Boolean stRelate(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right, @SqlType(VARCHAR) Slice relation)\n@@ -1344,7 +1344,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if the geometries have at least one point in common, but their interiors do not intersect\")\n+    @Description(\"Returns TRUE if the geometries have at least one point in common, but their interiors do not intersect.\")\n     @ScalarFunction(\"ST_Touches\")\n     @SqlType(BOOLEAN)\n     public static Boolean stTouches(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1359,7 +1359,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns TRUE if the geometry A is completely inside geometry B\")\n+    @Description(\"Returns TRUE if the geometry A is completely inside geometry B.\")\n     @ScalarFunction(\"ST_Within\")\n     @SqlType(BOOLEAN)\n     public static Boolean stWithin(@SqlType(GEOMETRY_TYPE_NAME) Slice left, @SqlType(GEOMETRY_TYPE_NAME) Slice right)\n@@ -1373,7 +1373,7 @@ public final class GeoFunctions\n         return leftGeometry.within(rightGeometry);\n     }\n \n-    @Description(\"Returns the type of the geometry\")\n+    @Description(\"Returns the type of the geometry.\")\n     @ScalarFunction(\"ST_GeometryType\")\n     @SqlType(VARCHAR)\n     public static Slice stGeometryType(@SqlType(GEOMETRY_TYPE_NAME) Slice input)\n@@ -1383,7 +1383,7 @@ public final class GeoFunctions\n \n     @ScalarFunction\n     @SqlNullable\n-    @Description(\"Returns an array of spatial partition IDs for a given geometry\")\n+    @Description(\"Returns an array of spatial partition IDs for a given geometry.\")\n     @SqlType(\"array(integer)\")\n     public static Block spatialPartitions(@SqlType(KdbTreeType.NAME) Object kdbTree, @SqlType(GEOMETRY_TYPE_NAME) Slice geometry)\n     {\n@@ -1398,7 +1398,7 @@ public final class GeoFunctions\n \n     @ScalarFunction\n     @SqlNullable\n-    @Description(\"Returns an array of spatial partition IDs for a geometry representing a set of points within specified distance from the input geometry\")\n+    @Description(\"Returns an array of spatial partition IDs for a geometry representing a set of points within specified distance from the input geometry.\")\n     @SqlType(\"array(integer)\")\n     public static Block spatialPartitions(@SqlType(KdbTreeType.NAME) Object kdbTree, @SqlType(GEOMETRY_TYPE_NAME) Slice geometry, @SqlType(DOUBLE) double distance)\n     {\n@@ -1455,7 +1455,7 @@ public final class GeoFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"Calculates the great-circle distance between two points on the Earth's surface in kilometers\")\n+    @Description(\"Calculates the great-circle distance between two points on the Earth's surface in kilometers.\")\n     @SqlType(DOUBLE)\n     public static double greatCircleDistance(\n             @SqlType(DOUBLE) double latitude1,\n@@ -1724,7 +1724,7 @@ public final class GeoFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"Returns the area of a geometry on the Earth's surface using spherical model\")\n+    @Description(\"Returns the area of a geometry on the Earth's surface using spherical model.\")\n     @ScalarFunction(\"ST_Area\")\n     @SqlType(DOUBLE)\n     public static Double stSphericalArea(@SqlType(SPHERICAL_GEOGRAPHY_TYPE_NAME) Slice input)\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/aggregation/CentralMomentsAggregation.java b/presto-main/src/main/java/io/prestosql/operator/aggregation/CentralMomentsAggregation.java\nindex 91605e8cf00..a694e491ff0 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/aggregation/CentralMomentsAggregation.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/aggregation/CentralMomentsAggregation.java\n@@ -29,7 +29,7 @@ import static io.prestosql.operator.aggregation.AggregationUtils.updateCentralMo\n import static io.prestosql.spi.type.DoubleType.DOUBLE;\n \n @AggregationFunction\n-@Description(\"Returns the central moments of the argument as an array\")\n+@Description(\"Returns the central moments of the argument as an array.\")\n public final class CentralMomentsAggregation\n {\n     private CentralMomentsAggregation() {}\n@@ -53,7 +53,7 @@ public final class CentralMomentsAggregation\n     }\n \n     @AggregationFunction(\"skewness\")\n-    @Description(\"Returns the skewness of the argument\")\n+    @Description(\"Returns the skewness of the argument.\")\n     @OutputFunction(StandardTypes.DOUBLE)\n     public static void skewness(@AggregationState CentralMomentsState state, BlockBuilder out)\n     {\n@@ -69,7 +69,7 @@ public final class CentralMomentsAggregation\n     }\n \n     @AggregationFunction(\"kurtosis\")\n-    @Description(\"Returns the (excess) kurtosis of the argument\")\n+    @Description(\"Returns the (excess) kurtosis of the argument.\")\n     @OutputFunction(StandardTypes.DOUBLE)\n     public static void kurtosis(@AggregationState CentralMomentsState state, BlockBuilder out)\n     {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/aggregation/VarianceAggregation.java b/presto-main/src/main/java/io/prestosql/operator/aggregation/VarianceAggregation.java\nindex 78684613c79..247bfa950a2 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/aggregation/VarianceAggregation.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/aggregation/VarianceAggregation.java\n@@ -52,7 +52,7 @@ public final class VarianceAggregation\n     }\n \n     @AggregationFunction(value = \"variance\", alias = \"var_samp\")\n-    @Description(\"Returns the sample variance of the argument\")\n+    @Description(\"Returns the sample variance of the argument.\")\n     @OutputFunction(StandardTypes.DOUBLE)\n     public static void variance(@AggregationState VarianceState state, BlockBuilder out)\n     {\n@@ -68,7 +68,7 @@ public final class VarianceAggregation\n     }\n \n     @AggregationFunction(\"var_pop\")\n-    @Description(\"Returns the population variance of the argument\")\n+    @Description(\"Returns the population variance of the argument.\")\n     @OutputFunction(StandardTypes.DOUBLE)\n     public static void variancePop(@AggregationState VarianceState state, BlockBuilder out)\n     {\n@@ -84,7 +84,7 @@ public final class VarianceAggregation\n     }\n \n     @AggregationFunction(value = \"stddev\", alias = \"stddev_samp\")\n-    @Description(\"Returns the sample standard deviation of the argument\")\n+    @Description(\"Returns the sample standard deviation of the argument.\")\n     @OutputFunction(StandardTypes.DOUBLE)\n     public static void stddev(@AggregationState VarianceState state, BlockBuilder out)\n     {\n@@ -101,7 +101,7 @@ public final class VarianceAggregation\n     }\n \n     @AggregationFunction(\"stddev_pop\")\n-    @Description(\"Returns the population standard deviation of the argument\")\n+    @Description(\"Returns the population standard deviation of the argument.\")\n     @OutputFunction(StandardTypes.DOUBLE)\n     public static void stddevPop(@AggregationState VarianceState state, BlockBuilder out)\n     {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayAllMatchFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayAllMatchFunction.java\nindex 825351bfa3f..6ed93cadf13 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayAllMatchFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayAllMatchFunction.java\n@@ -26,7 +26,7 @@ import io.prestosql.spi.type.Type;\n \n import static java.lang.Boolean.FALSE;\n \n-@Description(\"Returns true if all elements of the array match the given predicate\")\n+@Description(\"Returns true if all elements of the array match the given predicate.\")\n @ScalarFunction(\"all_match\")\n public final class ArrayAllMatchFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayAnyMatchFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayAnyMatchFunction.java\nindex e3fa673ebf5..dfba60662ad 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayAnyMatchFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayAnyMatchFunction.java\n@@ -26,7 +26,7 @@ import io.prestosql.spi.type.Type;\n \n import static java.lang.Boolean.TRUE;\n \n-@Description(\"Returns true if the array contains one or more elements that match the given predicate\")\n+@Description(\"Returns true if the array contains one or more elements that match the given predicate.\")\n @ScalarFunction(\"any_match\")\n public final class ArrayAnyMatchFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayCardinalityFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayCardinalityFunction.java\nindex 818e691bf64..277e8c124a1 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayCardinalityFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayCardinalityFunction.java\n@@ -20,7 +20,7 @@ import io.prestosql.spi.function.SqlType;\n import io.prestosql.spi.function.TypeParameter;\n import io.prestosql.spi.type.StandardTypes;\n \n-@Description(\"Returns the cardinality (length) of the array\")\n+@Description(\"Returns the cardinality (length) of the array.\")\n @ScalarFunction(\"cardinality\")\n public final class ArrayCardinalityFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayCombinationsFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayCombinationsFunction.java\nindex f5fd59f3521..648cbbd28a9 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayCombinationsFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayCombinationsFunction.java\n@@ -39,7 +39,7 @@ import static java.lang.System.arraycopy;\n import static java.util.Arrays.setAll;\n \n @ScalarFunction(\"combinations\")\n-@Description(\"Return n-element subsets from array\")\n+@Description(\"Return n-element subsets from array.\")\n public final class ArrayCombinationsFunction\n {\n     private ArrayCombinationsFunction() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayContains.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayContains.java\nindex 3349dd47f8e..105891a2208 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayContains.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayContains.java\n@@ -31,7 +31,7 @@ import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n import static io.prestosql.spi.function.OperatorType.EQUAL;\n import static io.prestosql.util.Failures.internalError;\n \n-@Description(\"Determines whether given value exists in the array\")\n+@Description(\"Determines whether given value exists in the array.\")\n @ScalarFunction(\"contains\")\n public final class ArrayContains\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayDistinctFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayDistinctFunction.java\nindex b198306abbf..879d86acbe3 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayDistinctFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayDistinctFunction.java\n@@ -36,7 +36,7 @@ import static io.prestosql.spi.type.TypeUtils.readNativeValue;\n import static io.prestosql.util.Failures.internalError;\n \n @ScalarFunction(\"array_distinct\")\n-@Description(\"Remove duplicate values from the given array\")\n+@Description(\"Remove duplicate values from the given array.\")\n public final class ArrayDistinctFunction\n {\n     private final PageBuilder pageBuilder;\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayElementAtFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayElementAtFunction.java\nindex 0280af808b0..c01d7b1a6bf 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayElementAtFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayElementAtFunction.java\n@@ -27,7 +27,7 @@ import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n import static java.lang.Math.toIntExact;\n \n @ScalarFunction(\"element_at\")\n-@Description(\"Get element of array at given index\")\n+@Description(\"Get element of array at given index.\")\n public final class ArrayElementAtFunction\n {\n     private ArrayElementAtFunction() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayFilterFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayFilterFunction.java\nindex 535b6c6b023..0f7139128c6 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayFilterFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayFilterFunction.java\n@@ -25,7 +25,7 @@ import io.prestosql.spi.type.Type;\n \n import static java.lang.Boolean.TRUE;\n \n-@Description(\"return array containing elements that match the given predicate\")\n+@Description(\"Return array containing elements that match the given predicate.\")\n @ScalarFunction(value = \"filter\", deterministic = false)\n public final class ArrayFilterFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayIntersectFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayIntersectFunction.java\nindex f358859c75f..c4b3d36b149 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayIntersectFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayIntersectFunction.java\n@@ -31,7 +31,7 @@ import java.util.Optional;\n import static io.prestosql.spi.function.OperatorType.IS_DISTINCT_FROM;\n \n @ScalarFunction(\"array_intersect\")\n-@Description(\"Intersects elements of the two given arrays\")\n+@Description(\"Intersects elements of the two given arrays.\")\n public final class ArrayIntersectFunction\n {\n     private final PageBuilder pageBuilder;\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayMaxFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayMaxFunction.java\nindex a29175ee9fe..9b6854e0144 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayMaxFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayMaxFunction.java\n@@ -33,7 +33,7 @@ import static io.prestosql.spi.function.OperatorType.GREATER_THAN;\n import static io.prestosql.util.Failures.internalError;\n \n @ScalarFunction(\"array_max\")\n-@Description(\"Get maximum value of array\")\n+@Description(\"Get maximum value of array.\")\n public final class ArrayMaxFunction\n {\n     private ArrayMaxFunction() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayMinFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayMinFunction.java\nindex d19112f7516..4822886dbc3 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayMinFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayMinFunction.java\n@@ -33,7 +33,7 @@ import static io.prestosql.spi.function.OperatorType.LESS_THAN;\n import static io.prestosql.util.Failures.internalError;\n \n @ScalarFunction(\"array_min\")\n-@Description(\"Get minimum value of array\")\n+@Description(\"Get minimum value of array.\")\n public final class ArrayMinFunction\n {\n     private ArrayMinFunction() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayNgramsFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayNgramsFunction.java\nindex a52af30227b..e989664d7b2 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayNgramsFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayNgramsFunction.java\n@@ -29,7 +29,7 @@ import static java.lang.Math.min;\n import static java.lang.StrictMath.toIntExact;\n \n @ScalarFunction(\"ngrams\")\n-@Description(\"Return N-grams for the input\")\n+@Description(\"Return N-grams for the input.\")\n public final class ArrayNgramsFunction\n {\n     private ArrayNgramsFunction() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayNoneMatchFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayNoneMatchFunction.java\nindex 30e2e9b17b2..ca9ec6820f4 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayNoneMatchFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayNoneMatchFunction.java\n@@ -24,7 +24,7 @@ import io.prestosql.spi.function.TypeParameterSpecialization;\n import io.prestosql.spi.type.StandardTypes;\n import io.prestosql.spi.type.Type;\n \n-@Description(\"Returns true if all elements of the array don't match the given predicate\")\n+@Description(\"Returns true if all elements of the array don't match the given predicate.\")\n @ScalarFunction(\"none_match\")\n public final class ArrayNoneMatchFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayPositionFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayPositionFunction.java\nindex b8e6d962c1e..c3befb48296 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayPositionFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayPositionFunction.java\n@@ -30,7 +30,7 @@ import static io.prestosql.spi.StandardErrorCode.NOT_SUPPORTED;\n import static io.prestosql.spi.function.OperatorType.EQUAL;\n import static io.prestosql.util.Failures.internalError;\n \n-@Description(\"Returns the position of the first occurrence of the given value in array (or 0 if not found)\")\n+@Description(\"Returns the position of the first occurrence of the given value in array (or 0 if not found).\")\n @ScalarFunction(\"array_position\")\n public final class ArrayPositionFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayRemoveFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayRemoveFunction.java\nindex 37bf240ecc9..1ca3fc5ae35 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayRemoveFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayRemoveFunction.java\n@@ -35,7 +35,7 @@ import static io.prestosql.spi.type.TypeUtils.readNativeValue;\n import static io.prestosql.util.Failures.internalError;\n \n @ScalarFunction(\"array_remove\")\n-@Description(\"Remove specified values from the given array\")\n+@Description(\"Remove specified values from the given array.\")\n public final class ArrayRemoveFunction\n {\n     private final PageBuilder pageBuilder;\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArraySliceFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArraySliceFunction.java\nindex d90928162a1..eb63a2b3757 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArraySliceFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArraySliceFunction.java\n@@ -25,7 +25,7 @@ import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n import static io.prestosql.util.Failures.checkCondition;\n \n @ScalarFunction(\"slice\")\n-@Description(\"Subsets an array given an offset (1-indexed) and length\")\n+@Description(\"Subsets an array given an offset (1-indexed) and length.\")\n public final class ArraySliceFunction\n {\n     private ArraySliceFunction() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayUnionFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayUnionFunction.java\nindex ddffeb01360..6c3ca7825ed 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayUnionFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArrayUnionFunction.java\n@@ -29,7 +29,7 @@ import java.util.concurrent.atomic.AtomicBoolean;\n import static io.prestosql.spi.type.BigintType.BIGINT;\n \n @ScalarFunction(\"array_union\")\n-@Description(\"Union elements of the two given arrays\")\n+@Description(\"Union elements of the two given arrays.\")\n public final class ArrayUnionFunction\n {\n     private ArrayUnionFunction() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/ArraysOverlapFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/ArraysOverlapFunction.java\nindex 648e7819cf3..8d002de7dd5 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/ArraysOverlapFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/ArraysOverlapFunction.java\n@@ -35,7 +35,7 @@ import static io.prestosql.spi.type.BigintType.BIGINT;\n import static io.prestosql.spi.type.IntegerType.INTEGER;\n \n @ScalarFunction(\"arrays_overlap\")\n-@Description(\"Returns true if arrays have common elements\")\n+@Description(\"Returns true if arrays have common elements.\")\n public final class ArraysOverlapFunction\n {\n     private int[] leftPositions;\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/BitwiseFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/BitwiseFunctions.java\nindex 03c16b19c8b..f4371aa5f26 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/BitwiseFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/BitwiseFunctions.java\n@@ -25,7 +25,7 @@ public final class BitwiseFunctions\n {\n     private BitwiseFunctions() {}\n \n-    @Description(\"count number of set bits in 2's complement representation\")\n+    @Description(\"Count number of set bits in 2's complement representation.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long bitCount(@SqlType(StandardTypes.BIGINT) long num, @SqlType(StandardTypes.BIGINT) long bits)\n@@ -44,7 +44,7 @@ public final class BitwiseFunctions\n         return Long.bitCount(num & mask);\n     }\n \n-    @Description(\"bitwise NOT in 2's complement arithmetic\")\n+    @Description(\"Bitwise NOT in 2's complement arithmetic.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long bitwiseNot(@SqlType(StandardTypes.BIGINT) long num)\n@@ -52,7 +52,7 @@ public final class BitwiseFunctions\n         return ~num;\n     }\n \n-    @Description(\"bitwise AND in 2's complement arithmetic\")\n+    @Description(\"Bitwise AND in 2's complement arithmetic.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long bitwiseAnd(@SqlType(StandardTypes.BIGINT) long left, @SqlType(StandardTypes.BIGINT) long right)\n@@ -60,7 +60,7 @@ public final class BitwiseFunctions\n         return left & right;\n     }\n \n-    @Description(\"bitwise OR in 2's complement arithmetic\")\n+    @Description(\"Bitwise OR in 2's complement arithmetic.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long bitwiseOr(@SqlType(StandardTypes.BIGINT) long left, @SqlType(StandardTypes.BIGINT) long right)\n@@ -68,7 +68,7 @@ public final class BitwiseFunctions\n         return left | right;\n     }\n \n-    @Description(\"bitwise XOR in 2's complement arithmetic\")\n+    @Description(\"Bitwise XOR in 2's complement arithmetic.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long bitwiseXor(@SqlType(StandardTypes.BIGINT) long left, @SqlType(StandardTypes.BIGINT) long right)\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/DataSizeFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/DataSizeFunctions.java\nindex 6fdabadc81c..27e7f0d7dae 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/DataSizeFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/DataSizeFunctions.java\n@@ -33,7 +33,7 @@ public final class DataSizeFunctions\n {\n     private DataSizeFunctions() {}\n \n-    @Description(\"converts data size string to bytes\")\n+    @Description(\"Converts data size string to bytes.\")\n     @ScalarFunction(\"parse_presto_data_size\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"decimal(38,0)\")\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/DateTimeFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/DateTimeFunctions.java\nindex 7f358e1cac6..428be1a9d80 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/DateTimeFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/DateTimeFunctions.java\n@@ -87,7 +87,7 @@ public final class DateTimeFunctions\n \n     private DateTimeFunctions() {}\n \n-    @Description(\"current date\")\n+    @Description(\"Current date.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DATE)\n     public static long currentDate(ConnectorSession session)\n@@ -100,7 +100,7 @@ public final class DateTimeFunctions\n         return Days.daysBetween(new LocalDate(1970, 1, 1), currentDate).getDays();\n     }\n \n-    @Description(\"current time with time zone\")\n+    @Description(\"Current time with time zone.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.TIME_WITH_TIME_ZONE)\n     public static long currentTime(ConnectorSession session)\n@@ -119,7 +119,7 @@ public final class DateTimeFunctions\n         return packDateTimeWithZone(millis, session.getTimeZoneKey());\n     }\n \n-    @Description(\"current time without time zone\")\n+    @Description(\"Current time without time zone.\")\n     @ScalarFunction(\"localtime\")\n     @SqlType(StandardTypes.TIME)\n     public static long localTime(ConnectorSession session)\n@@ -131,7 +131,7 @@ public final class DateTimeFunctions\n         return localChronology.millisOfDay().get(session.getStartTime());\n     }\n \n-    @Description(\"current time zone\")\n+    @Description(\"Current time zone.\")\n     @ScalarFunction(\"current_timezone\")\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice currentTimeZone(ConnectorSession session)\n@@ -139,7 +139,7 @@ public final class DateTimeFunctions\n         return utf8Slice(session.getTimeZoneKey().getId());\n     }\n \n-    @Description(\"current timestamp with time zone\")\n+    @Description(\"Current timestamp with time zone.\")\n     @ScalarFunction(value = \"current_timestamp\", alias = \"now\")\n     @SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE)\n     public static long currentTimestamp(ConnectorSession session)\n@@ -147,7 +147,7 @@ public final class DateTimeFunctions\n         return packDateTimeWithZone(session.getStartTime(), session.getTimeZoneKey());\n     }\n \n-    @Description(\"current timestamp without time zone\")\n+    @Description(\"Current timestamp without time zone.\")\n     @ScalarFunction(\"localtimestamp\")\n     @SqlType(StandardTypes.TIMESTAMP)\n     public static long localTimestamp(ConnectorSession session)\n@@ -313,7 +313,7 @@ public final class DateTimeFunctions\n         return packDateTimeWithZone(fromDateTimeZone.getMillisKeepLocal(toDateTimeZone, timestamp), toTimeZoneKey);\n     }\n \n-    @Description(\"truncate to the specified precision in the session timezone\")\n+    @Description(\"Truncate to the specified precision in the session timezone.\")\n     @ScalarFunction(\"date_trunc\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.DATE)\n@@ -323,7 +323,7 @@ public final class DateTimeFunctions\n         return MILLISECONDS.toDays(millis);\n     }\n \n-    @Description(\"truncate to the specified precision in the session timezone\")\n+    @Description(\"Truncate to the specified precision in the session timezone.\")\n     @ScalarFunction(\"date_trunc\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.TIME)\n@@ -337,7 +337,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"truncate to the specified precision\")\n+    @Description(\"Truncate to the specified precision.\")\n     @ScalarFunction(\"date_trunc\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.TIME_WITH_TIME_ZONE)\n@@ -347,7 +347,7 @@ public final class DateTimeFunctions\n         return updateMillisUtc(millis, timeWithTimeZone);\n     }\n \n-    @Description(\"truncate to the specified precision in the session timezone\")\n+    @Description(\"Truncate to the specified precision in the session timezone.\")\n     @ScalarFunction(\"date_trunc\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.TIMESTAMP)\n@@ -361,7 +361,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"truncate to the specified precision\")\n+    @Description(\"Truncate to the specified precision.\")\n     @ScalarFunction(\"date_trunc\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE)\n@@ -371,7 +371,7 @@ public final class DateTimeFunctions\n         return updateMillisUtc(millis, timestampWithTimeZone);\n     }\n \n-    @Description(\"add the specified amount of date to the given date\")\n+    @Description(\"Add the specified amount of date to the given date.\")\n     @LiteralParameters(\"x\")\n     @ScalarFunction(\"date_add\")\n     @SqlType(StandardTypes.DATE)\n@@ -381,7 +381,7 @@ public final class DateTimeFunctions\n         return MILLISECONDS.toDays(millis);\n     }\n \n-    @Description(\"add the specified amount of time to the given time\")\n+    @Description(\"Add the specified amount of time to the given time.\")\n     @LiteralParameters(\"x\")\n     @ScalarFunction(\"date_add\")\n     @SqlType(StandardTypes.TIME)\n@@ -395,7 +395,7 @@ public final class DateTimeFunctions\n         return modulo24Hour(getTimeField(UTC_CHRONOLOGY, unit).add(time, toIntExact(value)));\n     }\n \n-    @Description(\"add the specified amount of time to the given time\")\n+    @Description(\"Add the specified amount of time to the given time.\")\n     @LiteralParameters(\"x\")\n     @ScalarFunction(\"date_add\")\n     @SqlType(StandardTypes.TIME_WITH_TIME_ZONE)\n@@ -409,7 +409,7 @@ public final class DateTimeFunctions\n         return updateMillisUtc(millis, timeWithTimeZone);\n     }\n \n-    @Description(\"add the specified amount of time to the given timestamp\")\n+    @Description(\"Add the specified amount of time to the given timestamp.\")\n     @LiteralParameters(\"x\")\n     @ScalarFunction(\"date_add\")\n     @SqlType(StandardTypes.TIMESTAMP)\n@@ -426,7 +426,7 @@ public final class DateTimeFunctions\n         return getTimestampField(UTC_CHRONOLOGY, unit).add(timestamp, toIntExact(value));\n     }\n \n-    @Description(\"add the specified amount of time to the given timestamp\")\n+    @Description(\"Add the specified amount of time to the given timestamp.\")\n     @LiteralParameters(\"x\")\n     @ScalarFunction(\"date_add\")\n     @SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE)\n@@ -439,7 +439,7 @@ public final class DateTimeFunctions\n         return updateMillisUtc(millis, timestampWithTimeZone);\n     }\n \n-    @Description(\"difference of the given dates in the given unit\")\n+    @Description(\"Difference of the given dates in the given unit.\")\n     @ScalarFunction(\"date_diff\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -448,7 +448,7 @@ public final class DateTimeFunctions\n         return getDateField(UTC_CHRONOLOGY, unit).getDifferenceAsLong(DAYS.toMillis(date2), DAYS.toMillis(date1));\n     }\n \n-    @Description(\"difference of the given times in the given unit\")\n+    @Description(\"Difference of the given times in the given unit.\")\n     @ScalarFunction(\"date_diff\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -463,7 +463,7 @@ public final class DateTimeFunctions\n         return getTimeField(UTC_CHRONOLOGY, unit).getDifferenceAsLong(time2, time1);\n     }\n \n-    @Description(\"difference of the given times in the given unit\")\n+    @Description(\"Difference of the given times in the given unit.\")\n     @ScalarFunction(\"date_diff\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -475,7 +475,7 @@ public final class DateTimeFunctions\n         return getTimeField(unpackChronology(timeWithTimeZone1), unit).getDifferenceAsLong(unpackMillisUtc(timeWithTimeZone2), unpackMillisUtc(timeWithTimeZone1));\n     }\n \n-    @Description(\"difference of the given times in the given unit\")\n+    @Description(\"Difference of the given times in the given unit.\")\n     @ScalarFunction(\"date_diff\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -492,7 +492,7 @@ public final class DateTimeFunctions\n         return getTimestampField(UTC_CHRONOLOGY, unit).getDifferenceAsLong(timestamp2, timestamp1);\n     }\n \n-    @Description(\"difference of the given times in the given unit\")\n+    @Description(\"Difference of the given times in the given unit.\")\n     @ScalarFunction(\"date_diff\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -564,7 +564,7 @@ public final class DateTimeFunctions\n         throw new PrestoException(INVALID_FUNCTION_ARGUMENT, \"'\" + unitString + \"' is not a valid Timestamp field\");\n     }\n \n-    @Description(\"parses the specified date/time by the given format\")\n+    @Description(\"Parses the specified date/time by the given format.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE)\n@@ -593,7 +593,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"formats the given time by the given format\")\n+    @Description(\"Formats the given time by the given format.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.VARCHAR)\n@@ -639,7 +639,7 @@ public final class DateTimeFunctions\n         return false;\n     }\n \n-    @Description(\"formats the given time by the given format\")\n+    @Description(\"Formats the given time by the given format.\")\n     @ScalarFunction(\"format_datetime\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.VARCHAR)\n@@ -714,7 +714,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"millisecond of the second of the given timestamp\")\n+    @Description(\"Millisecond of the second of the given timestamp.\")\n     @ScalarFunction(\"millisecond\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long millisecondFromTimestamp(@SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -725,7 +725,7 @@ public final class DateTimeFunctions\n         return MILLISECOND_OF_SECOND.get(timestamp);\n     }\n \n-    @Description(\"millisecond of the second of the given timestamp\")\n+    @Description(\"Millisecond of the second of the given timestamp.\")\n     @ScalarFunction(\"millisecond\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long millisecondFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -734,7 +734,7 @@ public final class DateTimeFunctions\n         return MILLISECOND_OF_SECOND.get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"millisecond of the second of the given time\")\n+    @Description(\"Millisecond of the second of the given time.\")\n     @ScalarFunction(\"millisecond\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long millisecondFromTime(@SqlType(StandardTypes.TIME) long time)\n@@ -745,7 +745,7 @@ public final class DateTimeFunctions\n         return MILLISECOND_OF_SECOND.get(time);\n     }\n \n-    @Description(\"millisecond of the second of the given time\")\n+    @Description(\"Millisecond of the second of the given time.\")\n     @ScalarFunction(\"millisecond\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long millisecondFromTimeWithTimeZone(@SqlType(StandardTypes.TIME_WITH_TIME_ZONE) long time)\n@@ -754,7 +754,7 @@ public final class DateTimeFunctions\n         return MILLISECOND_OF_SECOND.get(unpackMillisUtc(time));\n     }\n \n-    @Description(\"millisecond of the second of the given interval\")\n+    @Description(\"Millisecond of the second of the given interval.\")\n     @ScalarFunction(\"millisecond\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long millisecondFromInterval(@SqlType(StandardTypes.INTERVAL_DAY_TO_SECOND) long milliseconds)\n@@ -762,7 +762,7 @@ public final class DateTimeFunctions\n         return milliseconds % MILLISECONDS_IN_SECOND;\n     }\n \n-    @Description(\"second of the minute of the given timestamp\")\n+    @Description(\"Second of the minute of the given timestamp.\")\n     @ScalarFunction(\"second\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long secondFromTimestamp(@SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -773,7 +773,7 @@ public final class DateTimeFunctions\n         return SECOND_OF_MINUTE.get(timestamp);\n     }\n \n-    @Description(\"second of the minute of the given timestamp\")\n+    @Description(\"Second of the minute of the given timestamp.\")\n     @ScalarFunction(\"second\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long secondFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -782,7 +782,7 @@ public final class DateTimeFunctions\n         return SECOND_OF_MINUTE.get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"second of the minute of the given time\")\n+    @Description(\"Second of the minute of the given time.\")\n     @ScalarFunction(\"second\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long secondFromTime(@SqlType(StandardTypes.TIME) long time)\n@@ -793,7 +793,7 @@ public final class DateTimeFunctions\n         return SECOND_OF_MINUTE.get(time);\n     }\n \n-    @Description(\"second of the minute of the given time\")\n+    @Description(\"Second of the minute of the given time.\")\n     @ScalarFunction(\"second\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long secondFromTimeWithTimeZone(@SqlType(StandardTypes.TIME_WITH_TIME_ZONE) long time)\n@@ -802,7 +802,7 @@ public final class DateTimeFunctions\n         return SECOND_OF_MINUTE.get(unpackMillisUtc(time));\n     }\n \n-    @Description(\"second of the minute of the given interval\")\n+    @Description(\"Second of the minute of the given interval.\")\n     @ScalarFunction(\"second\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long secondFromInterval(@SqlType(StandardTypes.INTERVAL_DAY_TO_SECOND) long milliseconds)\n@@ -810,7 +810,7 @@ public final class DateTimeFunctions\n         return (milliseconds % MILLISECONDS_IN_MINUTE) / MILLISECONDS_IN_SECOND;\n     }\n \n-    @Description(\"minute of the hour of the given timestamp\")\n+    @Description(\"Minute of the hour of the given timestamp.\")\n     @ScalarFunction(\"minute\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long minuteFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -823,7 +823,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"minute of the hour of the given timestamp\")\n+    @Description(\"Minute of the hour of the given timestamp.\")\n     @ScalarFunction(\"minute\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long minuteFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -831,7 +831,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).minuteOfHour().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"minute of the hour of the given time\")\n+    @Description(\"Minute of the hour of the given time.\")\n     @ScalarFunction(\"minute\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long minuteFromTime(ConnectorSession session, @SqlType(StandardTypes.TIME) long time)\n@@ -844,7 +844,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"minute of the hour of the given time\")\n+    @Description(\"Minute of the hour of the given time.\")\n     @ScalarFunction(\"minute\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long minuteFromTimeWithTimeZone(@SqlType(StandardTypes.TIME_WITH_TIME_ZONE) long timeWithTimeZone)\n@@ -852,7 +852,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timeWithTimeZone).minuteOfHour().get(unpackMillisUtc(timeWithTimeZone));\n     }\n \n-    @Description(\"minute of the hour of the given interval\")\n+    @Description(\"Minute of the hour of the given interval.\")\n     @ScalarFunction(\"minute\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long minuteFromInterval(@SqlType(StandardTypes.INTERVAL_DAY_TO_SECOND) long milliseconds)\n@@ -860,7 +860,7 @@ public final class DateTimeFunctions\n         return (milliseconds % MILLISECONDS_IN_HOUR) / MILLISECONDS_IN_MINUTE;\n     }\n \n-    @Description(\"hour of the day of the given timestamp\")\n+    @Description(\"Hour of the day of the given timestamp.\")\n     @ScalarFunction(\"hour\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long hourFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -873,7 +873,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"hour of the day of the given timestamp\")\n+    @Description(\"Hour of the day of the given timestamp.\")\n     @ScalarFunction(\"hour\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long hourFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -881,7 +881,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).hourOfDay().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"hour of the day of the given time\")\n+    @Description(\"Hour of the day of the given time.\")\n     @ScalarFunction(\"hour\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long hourFromTime(ConnectorSession session, @SqlType(StandardTypes.TIME) long time)\n@@ -894,7 +894,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"hour of the day of the given time\")\n+    @Description(\"Hour of the day of the given time.\")\n     @ScalarFunction(\"hour\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long hourFromTimeWithTimeZone(@SqlType(StandardTypes.TIME_WITH_TIME_ZONE) long timeWithTimeZone)\n@@ -902,7 +902,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timeWithTimeZone).hourOfDay().get(unpackMillisUtc(timeWithTimeZone));\n     }\n \n-    @Description(\"hour of the day of the given interval\")\n+    @Description(\"Hour of the day of the given interval.\")\n     @ScalarFunction(\"hour\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long hourFromInterval(@SqlType(StandardTypes.INTERVAL_DAY_TO_SECOND) long milliseconds)\n@@ -910,7 +910,7 @@ public final class DateTimeFunctions\n         return (milliseconds % MILLISECONDS_IN_DAY) / MILLISECONDS_IN_HOUR;\n     }\n \n-    @Description(\"day of the week of the given timestamp\")\n+    @Description(\"Day of the week of the given timestamp.\")\n     @ScalarFunction(value = \"day_of_week\", alias = \"dow\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayOfWeekFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -923,7 +923,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"day of the week of the given timestamp\")\n+    @Description(\"Day of the week of the given timestamp.\")\n     @ScalarFunction(value = \"day_of_week\", alias = \"dow\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayOfWeekFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -931,7 +931,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).dayOfWeek().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"day of the week of the given date\")\n+    @Description(\"Day of the week of the given date.\")\n     @ScalarFunction(value = \"day_of_week\", alias = \"dow\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayOfWeekFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -939,7 +939,7 @@ public final class DateTimeFunctions\n         return DAY_OF_WEEK.get(DAYS.toMillis(date));\n     }\n \n-    @Description(\"day of the month of the given timestamp\")\n+    @Description(\"Day of the month of the given timestamp.\")\n     @ScalarFunction(value = \"day\", alias = \"day_of_month\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -952,7 +952,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"day of the month of the given timestamp\")\n+    @Description(\"Day of the month of the given timestamp.\")\n     @ScalarFunction(value = \"day\", alias = \"day_of_month\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -960,7 +960,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).dayOfMonth().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"day of the month of the given date\")\n+    @Description(\"Day of the month of the given date.\")\n     @ScalarFunction(value = \"day\", alias = \"day_of_month\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -968,7 +968,7 @@ public final class DateTimeFunctions\n         return DAY_OF_MONTH.get(DAYS.toMillis(date));\n     }\n \n-    @Description(\"day of the month of the given interval\")\n+    @Description(\"Day of the month of the given interval.\")\n     @ScalarFunction(value = \"day\", alias = \"day_of_month\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayFromInterval(@SqlType(StandardTypes.INTERVAL_DAY_TO_SECOND) long milliseconds)\n@@ -976,7 +976,7 @@ public final class DateTimeFunctions\n         return milliseconds / MILLISECONDS_IN_DAY;\n     }\n \n-    @Description(\"last day of the month of the given timestamp\")\n+    @Description(\"Last day of the month of the given timestamp.\")\n     @ScalarFunction(\"last_day_of_month\")\n     @SqlType(StandardTypes.DATE)\n     public static long lastDayOfMonthFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -986,7 +986,7 @@ public final class DateTimeFunctions\n         return MILLISECONDS.toDays(millis);\n     }\n \n-    @Description(\"last day of the month of the given timestamp\")\n+    @Description(\"Last day of the month of the given timestamp.\")\n     @ScalarFunction(\"last_day_of_month\")\n     @SqlType(StandardTypes.DATE)\n     public static long lastDayOfMonthFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -999,7 +999,7 @@ public final class DateTimeFunctions\n         return MILLISECONDS.toDays(millis);\n     }\n \n-    @Description(\"last day of the month of the given date\")\n+    @Description(\"Last day of the month of the given date.\")\n     @ScalarFunction(\"last_day_of_month\")\n     @SqlType(StandardTypes.DATE)\n     public static long lastDayOfMonthFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -1008,7 +1008,7 @@ public final class DateTimeFunctions\n         return MILLISECONDS.toDays(millis);\n     }\n \n-    @Description(\"day of the year of the given timestamp\")\n+    @Description(\"Day of the year of the given timestamp.\")\n     @ScalarFunction(value = \"day_of_year\", alias = \"doy\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayOfYearFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -1021,7 +1021,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"day of the year of the given timestamp\")\n+    @Description(\"Day of the year of the given timestamp.\")\n     @ScalarFunction(value = \"day_of_year\", alias = \"doy\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayOfYearFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -1029,7 +1029,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).dayOfYear().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"day of the year of the given date\")\n+    @Description(\"Day of the year of the given date.\")\n     @ScalarFunction(value = \"day_of_year\", alias = \"doy\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long dayOfYearFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -1037,7 +1037,7 @@ public final class DateTimeFunctions\n         return DAY_OF_YEAR.get(DAYS.toMillis(date));\n     }\n \n-    @Description(\"week of the year of the given timestamp\")\n+    @Description(\"Week of the year of the given timestamp.\")\n     @ScalarFunction(value = \"week\", alias = \"week_of_year\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long weekFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -1050,7 +1050,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"week of the year of the given timestamp\")\n+    @Description(\"Week of the year of the given timestamp.\")\n     @ScalarFunction(value = \"week\", alias = \"week_of_year\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long weekFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -1058,7 +1058,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).weekOfWeekyear().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"week of the year of the given date\")\n+    @Description(\"Week of the year of the given date.\")\n     @ScalarFunction(value = \"week\", alias = \"week_of_year\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long weekFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -1066,7 +1066,7 @@ public final class DateTimeFunctions\n         return WEEK_OF_YEAR.get(DAYS.toMillis(date));\n     }\n \n-    @Description(\"year of the ISO week of the given timestamp\")\n+    @Description(\"Year of the ISO week of the given timestamp.\")\n     @ScalarFunction(value = \"year_of_week\", alias = \"yow\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long yearOfWeekFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -1079,7 +1079,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"year of the ISO week of the given timestamp\")\n+    @Description(\"Year of the ISO week of the given timestamp.\")\n     @ScalarFunction(value = \"year_of_week\", alias = \"yow\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long yearOfWeekFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -1087,7 +1087,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).weekyear().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"year of the ISO week of the given date\")\n+    @Description(\"Year of the ISO week of the given date.\")\n     @ScalarFunction(value = \"year_of_week\", alias = \"yow\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long yearOfWeekFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -1095,7 +1095,7 @@ public final class DateTimeFunctions\n         return YEAR_OF_WEEK.get(DAYS.toMillis(date));\n     }\n \n-    @Description(\"month of the year of the given timestamp\")\n+    @Description(\"Month of the year of the given timestamp.\")\n     @ScalarFunction(\"month\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long monthFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -1108,7 +1108,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"month of the year of the given timestamp\")\n+    @Description(\"Month of the year of the given timestamp.\")\n     @ScalarFunction(\"month\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long monthFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -1116,7 +1116,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).monthOfYear().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"month of the year of the given date\")\n+    @Description(\"Month of the year of the given date.\")\n     @ScalarFunction(\"month\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long monthFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -1124,7 +1124,7 @@ public final class DateTimeFunctions\n         return MONTH_OF_YEAR.get(DAYS.toMillis(date));\n     }\n \n-    @Description(\"month of the year of the given interval\")\n+    @Description(\"Month of the year of the given interval.\")\n     @ScalarFunction(\"month\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long monthFromInterval(@SqlType(StandardTypes.INTERVAL_YEAR_TO_MONTH) long months)\n@@ -1132,7 +1132,7 @@ public final class DateTimeFunctions\n         return months % 12;\n     }\n \n-    @Description(\"quarter of the year of the given timestamp\")\n+    @Description(\"Quarter of the year of the given timestamp.\")\n     @ScalarFunction(\"quarter\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long quarterFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -1145,7 +1145,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"quarter of the year of the given timestamp\")\n+    @Description(\"Quarter of the year of the given timestamp.\")\n     @ScalarFunction(\"quarter\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long quarterFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -1153,7 +1153,7 @@ public final class DateTimeFunctions\n         return QUARTER_OF_YEAR.getField(unpackChronology(timestampWithTimeZone)).get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"quarter of the year of the given date\")\n+    @Description(\"Quarter of the year of the given date.\")\n     @ScalarFunction(\"quarter\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long quarterFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -1161,7 +1161,7 @@ public final class DateTimeFunctions\n         return QUARTER.get(DAYS.toMillis(date));\n     }\n \n-    @Description(\"year of the given timestamp\")\n+    @Description(\"Year of the given timestamp.\")\n     @ScalarFunction(\"year\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long yearFromTimestamp(ConnectorSession session, @SqlType(StandardTypes.TIMESTAMP) long timestamp)\n@@ -1174,7 +1174,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"year of the given timestamp\")\n+    @Description(\"Year of the given timestamp.\")\n     @ScalarFunction(\"year\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long yearFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -1182,7 +1182,7 @@ public final class DateTimeFunctions\n         return unpackChronology(timestampWithTimeZone).year().get(unpackMillisUtc(timestampWithTimeZone));\n     }\n \n-    @Description(\"year of the given date\")\n+    @Description(\"Year of the given date.\")\n     @ScalarFunction(\"year\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long yearFromDate(@SqlType(StandardTypes.DATE) long date)\n@@ -1190,7 +1190,7 @@ public final class DateTimeFunctions\n         return YEAR.get(DAYS.toMillis(date));\n     }\n \n-    @Description(\"year of the given interval\")\n+    @Description(\"Year of the given interval.\")\n     @ScalarFunction(\"year\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long yearFromInterval(@SqlType(StandardTypes.INTERVAL_YEAR_TO_MONTH) long months)\n@@ -1198,7 +1198,7 @@ public final class DateTimeFunctions\n         return months / 12;\n     }\n \n-    @Description(\"time zone minute of the given timestamp\")\n+    @Description(\"Time zone minute of the given timestamp.\")\n     @ScalarFunction(\"timezone_minute\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long timeZoneMinuteFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -1206,7 +1206,7 @@ public final class DateTimeFunctions\n         return extractZoneOffsetMinutes(timestampWithTimeZone) % 60;\n     }\n \n-    @Description(\"time zone hour of the given timestamp\")\n+    @Description(\"Time zone hour of the given timestamp.\")\n     @ScalarFunction(\"timezone_hour\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long timeZoneHourFromTimestampWithTimeZone(@SqlType(StandardTypes.TIMESTAMP_WITH_TIME_ZONE) long timestampWithTimeZone)\n@@ -1339,7 +1339,7 @@ public final class DateTimeFunctions\n         }\n     }\n \n-    @Description(\"convert duration string to an interval\")\n+    @Description(\"Convert duration string to an interval.\")\n     @ScalarFunction(\"parse_duration\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.INTERVAL_DAY_TO_SECOND)\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/EmptyMapConstructor.java b/presto-main/src/main/java/io/prestosql/operator/scalar/EmptyMapConstructor.java\nindex 52b34a23f39..6fc997e0ca0 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/EmptyMapConstructor.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/EmptyMapConstructor.java\n@@ -22,7 +22,7 @@ import io.prestosql.spi.function.TypeParameter;\n import io.prestosql.spi.type.MapType;\n import io.prestosql.spi.type.Type;\n \n-@Description(\"Creates an empty map\")\n+@Description(\"Creates an empty map.\")\n @ScalarFunction(\"map\")\n public final class EmptyMapConstructor\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/FailureFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/FailureFunction.java\nindex d6680ebd763..b14470873a4 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/FailureFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/FailureFunction.java\n@@ -30,7 +30,7 @@ public final class FailureFunction\n     private FailureFunction() {}\n \n     // We shouldn't be using UNKNOWN as an explicit type. This will be fixed when we fix type inference\n-    @Description(\"Decodes json to an exception and throws it\")\n+    @Description(\"Decodes json to an exception and throws it.\")\n     @ScalarFunction(value = \"fail\", hidden = true)\n     @SqlType(\"unknown\")\n     public static boolean failWithException(@SqlType(StandardTypes.JSON) Slice failureInfoSlice)\n@@ -40,7 +40,7 @@ public final class FailureFunction\n         throw new PrestoException(StandardErrorCode.GENERIC_USER_ERROR, failureInfo.toException());\n     }\n \n-    @Description(\"Throws an exception with a given message\")\n+    @Description(\"Throws an exception with a given message.\")\n     @ScalarFunction(value = \"fail\", hidden = true)\n     @SqlType(\"unknown\")\n     public static boolean fail(@SqlType(StandardTypes.VARCHAR) Slice message)\n@@ -48,7 +48,7 @@ public final class FailureFunction\n         throw new PrestoException(StandardErrorCode.GENERIC_USER_ERROR, message.toStringUtf8());\n     }\n \n-    @Description(\"Throws an exception with a given error code and message\")\n+    @Description(\"Throws an exception with a given error code and message.\")\n     @ScalarFunction(value = \"fail\", hidden = true)\n     @SqlType(\"unknown\")\n     public static boolean fail(\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/HmacFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/HmacFunctions.java\nindex dd837de71ba..98ef7bbda09 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/HmacFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/HmacFunctions.java\n@@ -26,7 +26,7 @@ public final class HmacFunctions\n {\n     private HmacFunctions() {}\n \n-    @Description(\"Compute HMAC with MD5\")\n+    @Description(\"Compute HMAC with MD5.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice hmacMd5(@SqlType(StandardTypes.VARBINARY) Slice slice, @SqlType(StandardTypes.VARBINARY) Slice key)\n@@ -34,7 +34,7 @@ public final class HmacFunctions\n         return wrappedBuffer(Hashing.hmacMd5(key.getBytes()).hashBytes(slice.getBytes()).asBytes());\n     }\n \n-    @Description(\"Compute HMAC with SHA1\")\n+    @Description(\"Compute HMAC with SHA1.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice hmacSha1(@SqlType(StandardTypes.VARBINARY) Slice slice, @SqlType(StandardTypes.VARBINARY) Slice key)\n@@ -42,7 +42,7 @@ public final class HmacFunctions\n         return wrappedBuffer(Hashing.hmacSha1(key.getBytes()).hashBytes(slice.getBytes()).asBytes());\n     }\n \n-    @Description(\"Compute HMAC with SHA256\")\n+    @Description(\"Compute HMAC with SHA256.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice hmacSha256(@SqlType(StandardTypes.VARBINARY) Slice slice, @SqlType(StandardTypes.VARBINARY) Slice key)\n@@ -50,7 +50,7 @@ public final class HmacFunctions\n         return wrappedBuffer(Hashing.hmacSha256(key.getBytes()).hashBytes(slice.getBytes()).asBytes());\n     }\n \n-    @Description(\"Compute HMAC with SHA512\")\n+    @Description(\"Compute HMAC with SHA512.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice hmacSha512(@SqlType(StandardTypes.VARBINARY) Slice slice, @SqlType(StandardTypes.VARBINARY) Slice key)\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/HyperLogLogFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/HyperLogLogFunctions.java\nindex 9b0bed49e9b..5c6d0602d83 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/HyperLogLogFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/HyperLogLogFunctions.java\n@@ -26,7 +26,7 @@ public final class HyperLogLogFunctions\n     private HyperLogLogFunctions() {}\n \n     @ScalarFunction\n-    @Description(\"compute the cardinality of a HyperLogLog instance\")\n+    @Description(\"Compute the cardinality of a HyperLogLog instance.\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long cardinality(@SqlType(StandardTypes.HYPER_LOG_LOG) Slice serializedHll)\n     {\n@@ -34,7 +34,7 @@ public final class HyperLogLogFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"an empty HyperLogLog instance\")\n+    @Description(\"An empty HyperLogLog instance.\")\n     @SqlType(StandardTypes.HYPER_LOG_LOG)\n     public static Slice emptyApproxSet()\n     {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/JoniRegexpFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/JoniRegexpFunctions.java\nindex 18be1a799dc..3941473dcaf 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/JoniRegexpFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/JoniRegexpFunctions.java\n@@ -48,7 +48,7 @@ public final class JoniRegexpFunctions\n {\n     private JoniRegexpFunctions() {}\n \n-    @Description(\"returns whether the pattern is contained within the string\")\n+    @Description(\"Returns whether the pattern is contained within the string.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BOOLEAN)\n@@ -75,7 +75,7 @@ public final class JoniRegexpFunctions\n         }\n     }\n \n-    @Description(\"removes substrings matching a regular expression\")\n+    @Description(\"Removes substrings matching a regular expression.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -84,7 +84,7 @@ public final class JoniRegexpFunctions\n         return regexpReplace(source, pattern, Slices.EMPTY_SLICE);\n     }\n \n-    @Description(\"replaces substrings matching a regular expression by given string\")\n+    @Description(\"Replaces substrings matching a regular expression by given string.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\", \"z\"})\n     // Longest possible output is when the pattern is empty, than the replacement will be placed in between\n@@ -197,7 +197,7 @@ public final class JoniRegexpFunctions\n         }\n     }\n \n-    @Description(\"string(s) extracted using the given pattern\")\n+    @Description(\"String(s) extracted using the given pattern.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"array(varchar(x))\")\n@@ -206,7 +206,7 @@ public final class JoniRegexpFunctions\n         return regexpExtractAll(source, pattern, 0);\n     }\n \n-    @Description(\"group(s) extracted using the given pattern\")\n+    @Description(\"Group(s) extracted using the given pattern.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"array(varchar(x))\")\n@@ -239,7 +239,7 @@ public final class JoniRegexpFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"string extracted using the given pattern\")\n+    @Description(\"String extracted using the given pattern.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -249,7 +249,7 @@ public final class JoniRegexpFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"returns regex group of extracted string with a pattern\")\n+    @Description(\"Returns regex group of extracted string with a pattern.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -277,7 +277,7 @@ public final class JoniRegexpFunctions\n \n     @ScalarFunction\n     @LiteralParameters(\"x\")\n-    @Description(\"returns array of strings split by pattern\")\n+    @Description(\"Returns array of strings split by pattern.\")\n     @SqlType(\"array(varchar(x))\")\n     public static Block regexpSplit(@SqlType(\"varchar(x)\") Slice source, @SqlType(JoniRegexpType.NAME) JoniRegexp pattern)\n     {\n@@ -312,7 +312,7 @@ public final class JoniRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns the index of the matched substring\")\n+    @Description(\"Returns the index of the matched substring.\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long regexpPosition(@SqlType(\"varchar(x)\") Slice source, @SqlType(JoniRegexpType.NAME) JoniRegexp pattern)\n@@ -321,7 +321,7 @@ public final class JoniRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns the index of the matched substring starting from the specified position\")\n+    @Description(\"Returns the index of the matched substring starting from the specified position.\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long regexpPosition(@SqlType(\"varchar(x)\") Slice source,\n@@ -332,7 +332,7 @@ public final class JoniRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns the index of the n-th matched substring starting from the specified position\")\n+    @Description(\"Returns the index of the n-th matched substring starting from the specified position.\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long regexpPosition(@SqlType(\"varchar(x)\") Slice source,\n@@ -375,7 +375,7 @@ public final class JoniRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns the number of times that a pattern occurs in a string\")\n+    @Description(\"Returns the number of times that a pattern occurs in a string.\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long regexpCount(@SqlType(\"varchar(x)\") Slice source, @SqlType(JoniRegexpType.NAME) JoniRegexp pattern)\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/JoniRegexpReplaceLambdaFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/JoniRegexpReplaceLambdaFunction.java\nindex 18bd4d63bd6..87156b856ee 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/JoniRegexpReplaceLambdaFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/JoniRegexpReplaceLambdaFunction.java\n@@ -36,7 +36,7 @@ import static io.airlift.slice.SliceUtf8.lengthOfCodePointFromStartByte;\n import static io.prestosql.spi.type.VarcharType.VARCHAR;\n \n @ScalarFunction(\"regexp_replace\")\n-@Description(\"replaces substrings matching a regular expression using a lambda function\")\n+@Description(\"Replaces substrings matching a regular expression using a lambda function.\")\n public final class JoniRegexpReplaceLambdaFunction\n {\n     private final PageBuilder pageBuilder = new PageBuilder(ImmutableList.of(VARCHAR));\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/MapCardinalityFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/MapCardinalityFunction.java\nindex 3f1cfbd6f45..9d96874c80e 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/MapCardinalityFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/MapCardinalityFunction.java\n@@ -21,7 +21,7 @@ import io.prestosql.spi.function.TypeParameter;\n import io.prestosql.spi.type.StandardTypes;\n \n @ScalarFunction(\"cardinality\")\n-@Description(\"Returns the cardinality (the number of key-value pairs) of the map\")\n+@Description(\"Returns the cardinality (the number of key-value pairs) of the map.\")\n public final class MapCardinalityFunction\n {\n     private MapCardinalityFunction() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/MapEntriesFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/MapEntriesFunction.java\nindex f67ab351b80..ae58144daf7 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/MapEntriesFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/MapEntriesFunction.java\n@@ -28,7 +28,7 @@ import io.prestosql.spi.type.Type;\n import static com.google.common.base.Verify.verify;\n \n @ScalarFunction(\"map_entries\")\n-@Description(\"construct an array of entries from a given map\")\n+@Description(\"Construct an array of entries from a given map.\")\n public class MapEntriesFunction\n {\n     private final PageBuilder pageBuilder;\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/MapFromEntriesFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/MapFromEntriesFunction.java\nindex 64bf29bb081..d1507550597 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/MapFromEntriesFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/MapFromEntriesFunction.java\n@@ -33,7 +33,7 @@ import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n import static java.lang.String.format;\n \n @ScalarFunction(\"map_from_entries\")\n-@Description(\"construct a map from an array of entries\")\n+@Description(\"Construct a map from an array of entries.\")\n public final class MapFromEntriesFunction\n {\n     private final PageBuilder pageBuilder;\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/MapKeys.java b/presto-main/src/main/java/io/prestosql/operator/scalar/MapKeys.java\nindex 109070574d4..f01f1c56c0a 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/MapKeys.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/MapKeys.java\n@@ -22,7 +22,7 @@ import io.prestosql.spi.function.TypeParameter;\n import io.prestosql.spi.type.Type;\n \n @ScalarFunction(\"map_keys\")\n-@Description(\"Returns the keys of the given map(K,V) as an array\")\n+@Description(\"Returns the keys of the given map(K,V) as an array.\")\n public final class MapKeys\n {\n     private MapKeys() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/MapValues.java b/presto-main/src/main/java/io/prestosql/operator/scalar/MapValues.java\nindex a27769f1966..8a091dbb0cb 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/MapValues.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/MapValues.java\n@@ -22,7 +22,7 @@ import io.prestosql.spi.function.TypeParameter;\n import io.prestosql.spi.type.Type;\n \n @ScalarFunction(\"map_values\")\n-@Description(\"Returns the values of the given map(K,V) as an array\")\n+@Description(\"Returns the values of the given map(K,V) as an array.\")\n public final class MapValues\n {\n     private MapValues() {}\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/MathFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/MathFunctions.java\nindex 4c01533be8c..acbe3905ab2 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/MathFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/MathFunctions.java\n@@ -94,7 +94,7 @@ public final class MathFunctions\n \n     private MathFunctions() {}\n \n-    @Description(\"absolute value\")\n+    @Description(\"Absolute value.\")\n     @ScalarFunction(\"abs\")\n     @SqlType(StandardTypes.TINYINT)\n     public static long absTinyint(@SqlType(StandardTypes.TINYINT) long num)\n@@ -103,7 +103,7 @@ public final class MathFunctions\n         return Math.abs(num);\n     }\n \n-    @Description(\"absolute value\")\n+    @Description(\"Absolute value.\")\n     @ScalarFunction(\"abs\")\n     @SqlType(StandardTypes.SMALLINT)\n     public static long absSmallint(@SqlType(StandardTypes.SMALLINT) long num)\n@@ -112,7 +112,7 @@ public final class MathFunctions\n         return Math.abs(num);\n     }\n \n-    @Description(\"absolute value\")\n+    @Description(\"Absolute value.\")\n     @ScalarFunction(\"abs\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long absInteger(@SqlType(StandardTypes.INTEGER) long num)\n@@ -121,7 +121,7 @@ public final class MathFunctions\n         return Math.abs(num);\n     }\n \n-    @Description(\"absolute value\")\n+    @Description(\"Absolute value.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long abs(@SqlType(StandardTypes.BIGINT) long num)\n@@ -130,7 +130,7 @@ public final class MathFunctions\n         return Math.abs(num);\n     }\n \n-    @Description(\"absolute value\")\n+    @Description(\"Absolute value.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double abs(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -139,7 +139,7 @@ public final class MathFunctions\n     }\n \n     @ScalarFunction(\"abs\")\n-    @Description(\"absolute value\")\n+    @Description(\"Absolute value.\")\n     public static final class Abs\n     {\n         private Abs() {}\n@@ -166,7 +166,7 @@ public final class MathFunctions\n         }\n     }\n \n-    @Description(\"absolute value\")\n+    @Description(\"Absolute value.\")\n     @ScalarFunction(\"abs\")\n     @SqlType(StandardTypes.REAL)\n     public static long absFloat(@SqlType(StandardTypes.REAL) long num)\n@@ -174,7 +174,7 @@ public final class MathFunctions\n         return floatToRawIntBits(Math.abs(intBitsToFloat((int) num)));\n     }\n \n-    @Description(\"arc cosine\")\n+    @Description(\"Arc cosine.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double acos(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -182,7 +182,7 @@ public final class MathFunctions\n         return Math.acos(num);\n     }\n \n-    @Description(\"arc sine\")\n+    @Description(\"Arc sine.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double asin(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -190,7 +190,7 @@ public final class MathFunctions\n         return Math.asin(num);\n     }\n \n-    @Description(\"arc tangent\")\n+    @Description(\"Arc tangent.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double atan(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -198,7 +198,7 @@ public final class MathFunctions\n         return Math.atan(num);\n     }\n \n-    @Description(\"arc tangent of given fraction\")\n+    @Description(\"Arc tangent of given fraction.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double atan2(@SqlType(StandardTypes.DOUBLE) double num1, @SqlType(StandardTypes.DOUBLE) double num2)\n@@ -206,7 +206,7 @@ public final class MathFunctions\n         return Math.atan2(num1, num2);\n     }\n \n-    @Description(\"cube root\")\n+    @Description(\"Cube root.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double cbrt(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -214,7 +214,7 @@ public final class MathFunctions\n         return Math.cbrt(num);\n     }\n \n-    @Description(\"round up to nearest integer\")\n+    @Description(\"Round up to nearest integer.\")\n     @ScalarFunction(value = \"ceiling\", alias = \"ceil\")\n     @SqlType(StandardTypes.TINYINT)\n     public static long ceilingTinyint(@SqlType(StandardTypes.TINYINT) long num)\n@@ -222,7 +222,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round up to nearest integer\")\n+    @Description(\"Round up to nearest integer.\")\n     @ScalarFunction(value = \"ceiling\", alias = \"ceil\")\n     @SqlType(StandardTypes.SMALLINT)\n     public static long ceilingSmallint(@SqlType(StandardTypes.SMALLINT) long num)\n@@ -230,7 +230,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round up to nearest integer\")\n+    @Description(\"Round up to nearest integer.\")\n     @ScalarFunction(value = \"ceiling\", alias = \"ceil\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long ceilingInteger(@SqlType(StandardTypes.INTEGER) long num)\n@@ -238,7 +238,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round up to nearest integer\")\n+    @Description(\"Round up to nearest integer.\")\n     @ScalarFunction(alias = \"ceil\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long ceiling(@SqlType(StandardTypes.BIGINT) long num)\n@@ -246,7 +246,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round up to nearest integer\")\n+    @Description(\"Round up to nearest integer.\")\n     @ScalarFunction(alias = \"ceil\")\n     @SqlType(StandardTypes.DOUBLE)\n     public static double ceiling(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -254,7 +254,7 @@ public final class MathFunctions\n         return Math.ceil(num);\n     }\n \n-    @Description(\"round up to nearest integer\")\n+    @Description(\"Round up to nearest integer.\")\n     @ScalarFunction(value = \"ceiling\", alias = \"ceil\")\n     @SqlType(StandardTypes.REAL)\n     public static long ceilingFloat(@SqlType(StandardTypes.REAL) long num)\n@@ -263,7 +263,7 @@ public final class MathFunctions\n     }\n \n     @ScalarFunction(value = \"ceiling\", alias = \"ceil\")\n-    @Description(\"round up to nearest integer\")\n+    @Description(\"Round up to nearest integer.\")\n     public static final class Ceiling\n     {\n         private Ceiling() {}\n@@ -302,7 +302,7 @@ public final class MathFunctions\n         }\n     }\n \n-    @Description(\"round to integer by dropping digits after decimal point\")\n+    @Description(\"Round to integer by dropping digits after decimal point.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double truncate(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -310,7 +310,7 @@ public final class MathFunctions\n         return Math.signum(num) * Math.floor(Math.abs(num));\n     }\n \n-    @Description(\"round to integer by dropping digits after decimal point\")\n+    @Description(\"Round to integer by dropping digits after decimal point.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.REAL)\n     public static long truncate(@SqlType(StandardTypes.REAL) long num)\n@@ -319,7 +319,7 @@ public final class MathFunctions\n         return floatToRawIntBits((float) (Math.signum(numInFloat) * Math.floor(Math.abs(numInFloat))));\n     }\n \n-    @Description(\"cosine\")\n+    @Description(\"Cosine.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double cos(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -327,7 +327,7 @@ public final class MathFunctions\n         return Math.cos(num);\n     }\n \n-    @Description(\"hyperbolic cosine\")\n+    @Description(\"Hyperbolic cosine.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double cosh(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -335,7 +335,7 @@ public final class MathFunctions\n         return Math.cosh(num);\n     }\n \n-    @Description(\"converts an angle in radians to degrees\")\n+    @Description(\"Converts an angle in radians to degrees.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double degrees(@SqlType(StandardTypes.DOUBLE) double radians)\n@@ -343,7 +343,7 @@ public final class MathFunctions\n         return Math.toDegrees(radians);\n     }\n \n-    @Description(\"Euler's number\")\n+    @Description(\"Euler's number.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double e()\n@@ -351,7 +351,7 @@ public final class MathFunctions\n         return Math.E;\n     }\n \n-    @Description(\"Euler's number raised to the given power\")\n+    @Description(\"Euler's number raised to the given power.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double exp(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -359,7 +359,7 @@ public final class MathFunctions\n         return Math.exp(num);\n     }\n \n-    @Description(\"round down to nearest integer\")\n+    @Description(\"Round down to nearest integer.\")\n     @ScalarFunction(\"floor\")\n     @SqlType(StandardTypes.TINYINT)\n     public static long floorTinyint(@SqlType(StandardTypes.TINYINT) long num)\n@@ -367,7 +367,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round down to nearest integer\")\n+    @Description(\"Round down to nearest integer.\")\n     @ScalarFunction(\"floor\")\n     @SqlType(StandardTypes.SMALLINT)\n     public static long floorSmallint(@SqlType(StandardTypes.SMALLINT) long num)\n@@ -375,7 +375,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round down to nearest integer\")\n+    @Description(\"Round down to nearest integer.\")\n     @ScalarFunction(\"floor\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long floorInteger(@SqlType(StandardTypes.INTEGER) long num)\n@@ -383,7 +383,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round down to nearest integer\")\n+    @Description(\"Round down to nearest integer.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long floor(@SqlType(StandardTypes.BIGINT) long num)\n@@ -391,7 +391,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round down to nearest integer\")\n+    @Description(\"Round down to nearest integer.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double floor(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -400,7 +400,7 @@ public final class MathFunctions\n     }\n \n     @ScalarFunction(\"floor\")\n-    @Description(\"round down to nearest integer\")\n+    @Description(\"Round down to nearest integer.\")\n     public static final class Floor\n     {\n         private Floor() {}\n@@ -442,7 +442,7 @@ public final class MathFunctions\n         }\n     }\n \n-    @Description(\"round down to nearest integer\")\n+    @Description(\"Round down to nearest integer.\")\n     @ScalarFunction(\"floor\")\n     @SqlType(StandardTypes.REAL)\n     public static long floorFloat(@SqlType(StandardTypes.REAL) long num)\n@@ -450,7 +450,7 @@ public final class MathFunctions\n         return floatToRawIntBits((float) floor(intBitsToFloat((int) num)));\n     }\n \n-    @Description(\"natural logarithm\")\n+    @Description(\"Natural logarithm.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double ln(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -458,7 +458,7 @@ public final class MathFunctions\n         return Math.log(num);\n     }\n \n-    @Description(\"logarithm to given base\")\n+    @Description(\"Logarithm to given base.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double log(@SqlType(StandardTypes.DOUBLE) double base, @SqlType(StandardTypes.DOUBLE) double number)\n@@ -466,7 +466,7 @@ public final class MathFunctions\n         return Math.log(number) / Math.log(base);\n     }\n \n-    @Description(\"logarithm to base 2\")\n+    @Description(\"Logarithm to base 2.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double log2(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -474,7 +474,7 @@ public final class MathFunctions\n         return Math.log(num) / Math.log(2);\n     }\n \n-    @Description(\"logarithm to base 10\")\n+    @Description(\"Logarithm to base 10.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double log10(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -482,7 +482,7 @@ public final class MathFunctions\n         return Math.log10(num);\n     }\n \n-    @Description(\"remainder of given quotient\")\n+    @Description(\"Remainder of given quotient.\")\n     @ScalarFunction(\"mod\")\n     @SqlType(StandardTypes.TINYINT)\n     public static long modTinyint(@SqlType(StandardTypes.TINYINT) long num1, @SqlType(StandardTypes.TINYINT) long num2)\n@@ -490,7 +490,7 @@ public final class MathFunctions\n         return num1 % num2;\n     }\n \n-    @Description(\"remainder of given quotient\")\n+    @Description(\"Remainder of given quotient.\")\n     @ScalarFunction(\"mod\")\n     @SqlType(StandardTypes.SMALLINT)\n     public static long modSmallint(@SqlType(StandardTypes.SMALLINT) long num1, @SqlType(StandardTypes.SMALLINT) long num2)\n@@ -498,7 +498,7 @@ public final class MathFunctions\n         return num1 % num2;\n     }\n \n-    @Description(\"remainder of given quotient\")\n+    @Description(\"Remainder of given quotient.\")\n     @ScalarFunction(\"mod\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long modInteger(@SqlType(StandardTypes.INTEGER) long num1, @SqlType(StandardTypes.INTEGER) long num2)\n@@ -506,7 +506,7 @@ public final class MathFunctions\n         return num1 % num2;\n     }\n \n-    @Description(\"remainder of given quotient\")\n+    @Description(\"Remainder of given quotient.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long mod(@SqlType(StandardTypes.BIGINT) long num1, @SqlType(StandardTypes.BIGINT) long num2)\n@@ -514,7 +514,7 @@ public final class MathFunctions\n         return num1 % num2;\n     }\n \n-    @Description(\"remainder of given quotient\")\n+    @Description(\"Remainder of given quotient.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double mod(@SqlType(StandardTypes.DOUBLE) double num1, @SqlType(StandardTypes.DOUBLE) double num2)\n@@ -531,7 +531,7 @@ public final class MathFunctions\n         return modulusScalarFunction(signature);\n     }\n \n-    @Description(\"remainder of given quotient\")\n+    @Description(\"Remainder of given quotient.\")\n     @ScalarFunction(\"mod\")\n     @SqlType(StandardTypes.REAL)\n     public static long modFloat(@SqlType(StandardTypes.REAL) long num1, @SqlType(StandardTypes.REAL) long num2)\n@@ -539,7 +539,7 @@ public final class MathFunctions\n         return floatToRawIntBits(intBitsToFloat((int) num1) % intBitsToFloat((int) num2));\n     }\n \n-    @Description(\"the constant Pi\")\n+    @Description(\"The constant Pi.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double pi()\n@@ -547,7 +547,7 @@ public final class MathFunctions\n         return Math.PI;\n     }\n \n-    @Description(\"value raised to the power of exponent\")\n+    @Description(\"Value raised to the power of exponent.\")\n     @ScalarFunction(alias = \"pow\")\n     @SqlType(StandardTypes.DOUBLE)\n     public static double power(@SqlType(StandardTypes.DOUBLE) double num, @SqlType(StandardTypes.DOUBLE) double exponent)\n@@ -555,7 +555,7 @@ public final class MathFunctions\n         return Math.pow(num, exponent);\n     }\n \n-    @Description(\"converts an angle in degrees to radians\")\n+    @Description(\"Converts an angle in degrees to radians.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double radians(@SqlType(StandardTypes.DOUBLE) double degrees)\n@@ -563,7 +563,7 @@ public final class MathFunctions\n         return Math.toRadians(degrees);\n     }\n \n-    @Description(\"a pseudo-random value\")\n+    @Description(\"A pseudo-random value.\")\n     @ScalarFunction(alias = \"rand\", deterministic = false)\n     @SqlType(StandardTypes.DOUBLE)\n     public static double random()\n@@ -571,7 +571,7 @@ public final class MathFunctions\n         return ThreadLocalRandom.current().nextDouble();\n     }\n \n-    @Description(\"a pseudo-random number between 0 and value (exclusive)\")\n+    @Description(\"A pseudo-random number between 0 and value (exclusive).\")\n     @ScalarFunction(value = \"random\", alias = \"rand\", deterministic = false)\n     @SqlType(StandardTypes.TINYINT)\n     public static long randomTinyint(@SqlType(StandardTypes.TINYINT) long value)\n@@ -580,7 +580,7 @@ public final class MathFunctions\n         return ThreadLocalRandom.current().nextInt((int) value);\n     }\n \n-    @Description(\"a pseudo-random number between 0 and value (exclusive)\")\n+    @Description(\"A pseudo-random number between 0 and value (exclusive).\")\n     @ScalarFunction(value = \"random\", alias = \"rand\", deterministic = false)\n     @SqlType(StandardTypes.SMALLINT)\n     public static long randomSmallint(@SqlType(StandardTypes.SMALLINT) long value)\n@@ -589,7 +589,7 @@ public final class MathFunctions\n         return ThreadLocalRandom.current().nextInt((int) value);\n     }\n \n-    @Description(\"a pseudo-random number between 0 and value (exclusive)\")\n+    @Description(\"A pseudo-random number between 0 and value (exclusive).\")\n     @ScalarFunction(value = \"random\", alias = \"rand\", deterministic = false)\n     @SqlType(StandardTypes.INTEGER)\n     public static long randomInteger(@SqlType(StandardTypes.INTEGER) long value)\n@@ -598,7 +598,7 @@ public final class MathFunctions\n         return ThreadLocalRandom.current().nextInt((int) value);\n     }\n \n-    @Description(\"a pseudo-random number between 0 and value (exclusive)\")\n+    @Description(\"A pseudo-random number between 0 and value (exclusive).\")\n     @ScalarFunction(alias = \"rand\", deterministic = false)\n     @SqlType(StandardTypes.BIGINT)\n     public static long random(@SqlType(StandardTypes.BIGINT) long value)\n@@ -607,7 +607,7 @@ public final class MathFunctions\n         return ThreadLocalRandom.current().nextLong(value);\n     }\n \n-    @Description(\"inverse of normal cdf given a mean, std, and probability\")\n+    @Description(\"Inverse of normal cdf given a mean, std, and probability.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double inverseNormalCdf(@SqlType(StandardTypes.DOUBLE) double mean, @SqlType(StandardTypes.DOUBLE) double sd, @SqlType(StandardTypes.DOUBLE) double p)\n@@ -618,7 +618,7 @@ public final class MathFunctions\n         return mean + sd * 1.4142135623730951 * Erf.erfInv(2 * p - 1);\n     }\n \n-    @Description(\"normal cdf given a mean, standard deviation, and value\")\n+    @Description(\"Normal cdf given a mean, standard deviation, and value.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double normalCdf(\n@@ -630,7 +630,7 @@ public final class MathFunctions\n         return 0.5 * (1 + Erf.erf((value - mean) / (standardDeviation * Math.sqrt(2))));\n     }\n \n-    @Description(\"inverse of Beta cdf given a, b parameters and probability\")\n+    @Description(\"Inverse of Beta cdf given a, b parameters and probability.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double inverseBetaCdf(\n@@ -644,7 +644,7 @@ public final class MathFunctions\n         return distribution.inverseCumulativeProbability(p);\n     }\n \n-    @Description(\"Beta cdf given the a, b parameters and value\")\n+    @Description(\"Beta cdf given the a, b parameters and value.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double betaCdf(\n@@ -658,7 +658,7 @@ public final class MathFunctions\n         return distribution.cumulativeProbability(value);\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction(\"round\")\n     @SqlType(StandardTypes.TINYINT)\n     public static long roundTinyint(@SqlType(StandardTypes.TINYINT) long num)\n@@ -666,7 +666,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction(\"round\")\n     @SqlType(StandardTypes.SMALLINT)\n     public static long roundSmallint(@SqlType(StandardTypes.SMALLINT) long num)\n@@ -674,7 +674,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction(\"round\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long roundInteger(@SqlType(StandardTypes.INTEGER) long num)\n@@ -682,7 +682,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long round(@SqlType(StandardTypes.BIGINT) long num)\n@@ -690,7 +690,7 @@ public final class MathFunctions\n         return num;\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction(\"round\")\n     @SqlType(StandardTypes.TINYINT)\n     public static long roundTinyint(@SqlType(StandardTypes.TINYINT) long num, @SqlType(StandardTypes.INTEGER) long decimals)\n@@ -704,7 +704,7 @@ public final class MathFunctions\n         }\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction(\"round\")\n     @SqlType(StandardTypes.SMALLINT)\n     public static long roundSmallint(@SqlType(StandardTypes.SMALLINT) long num, @SqlType(StandardTypes.INTEGER) long decimals)\n@@ -718,7 +718,7 @@ public final class MathFunctions\n         }\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction(\"round\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long roundInteger(@SqlType(StandardTypes.INTEGER) long num, @SqlType(StandardTypes.INTEGER) long decimals)\n@@ -732,7 +732,7 @@ public final class MathFunctions\n         }\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long round(@SqlType(StandardTypes.BIGINT) long num, @SqlType(StandardTypes.INTEGER) long decimals)\n@@ -755,7 +755,7 @@ public final class MathFunctions\n         }\n     }\n \n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double round(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -763,7 +763,7 @@ public final class MathFunctions\n         return round(num, 0);\n     }\n \n-    @Description(\"round to given number of decimal places\")\n+    @Description(\"Round to given number of decimal places.\")\n     @ScalarFunction(\"round\")\n     @SqlType(StandardTypes.REAL)\n     public static long roundFloat(@SqlType(StandardTypes.REAL) long num)\n@@ -771,7 +771,7 @@ public final class MathFunctions\n         return roundFloat(num, 0);\n     }\n \n-    @Description(\"round to given number of decimal places\")\n+    @Description(\"Round to given number of decimal places.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double round(@SqlType(StandardTypes.DOUBLE) double num, @SqlType(StandardTypes.INTEGER) long decimals)\n@@ -788,7 +788,7 @@ public final class MathFunctions\n         return Math.round(num * factor) / factor;\n     }\n \n-    @Description(\"round to given number of decimal places\")\n+    @Description(\"Round to given number of decimal places.\")\n     @ScalarFunction(\"round\")\n     @SqlType(StandardTypes.REAL)\n     public static long roundFloat(@SqlType(StandardTypes.REAL) long num, @SqlType(StandardTypes.INTEGER) long decimals)\n@@ -807,7 +807,7 @@ public final class MathFunctions\n     }\n \n     @ScalarFunction(\"round\")\n-    @Description(\"round to nearest integer\")\n+    @Description(\"Round to nearest integer.\")\n     public static final class Round\n     {\n         private Round() {}\n@@ -858,7 +858,7 @@ public final class MathFunctions\n     }\n \n     @ScalarFunction(\"round\")\n-    @Description(\"round to given number of decimal places\")\n+    @Description(\"Round to given number of decimal places.\")\n     public static final class RoundN\n     {\n         @LiteralParameters({\"p\", \"s\", \"rp\"})\n@@ -923,7 +923,7 @@ public final class MathFunctions\n     }\n \n     @ScalarFunction(\"truncate\")\n-    @Description(\"round to integer by dropping digits after decimal point\")\n+    @Description(\"Round to integer by dropping digits after decimal point.\")\n     public static final class Truncate\n     {\n         @LiteralParameters({\"p\", \"s\", \"rp\"})\n@@ -963,7 +963,7 @@ public final class MathFunctions\n     }\n \n     @ScalarFunction(\"truncate\")\n-    @Description(\"round to integer by dropping given number of digits after decimal point\")\n+    @Description(\"Round to integer by dropping given number of digits after decimal point.\")\n     public static final class TruncateN\n     {\n         private TruncateN() {}\n@@ -1007,7 +1007,7 @@ public final class MathFunctions\n         }\n     }\n \n-    @Description(\"signum\")\n+    @Description(\"Signum.\")\n     @ScalarFunction(\"sign\")\n     public static final class Sign\n     {\n@@ -1043,7 +1043,7 @@ public final class MathFunctions\n         return (long) Math.signum(num);\n     }\n \n-    @Description(\"signum\")\n+    @Description(\"Signum.\")\n     @ScalarFunction(\"sign\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long signInteger(@SqlType(StandardTypes.INTEGER) long num)\n@@ -1051,7 +1051,7 @@ public final class MathFunctions\n         return (long) Math.signum(num);\n     }\n \n-    @Description(\"signum\")\n+    @Description(\"Signum.\")\n     @ScalarFunction(\"sign\")\n     @SqlType(StandardTypes.SMALLINT)\n     public static long signSmallint(@SqlType(StandardTypes.SMALLINT) long num)\n@@ -1059,7 +1059,7 @@ public final class MathFunctions\n         return (long) Math.signum(num);\n     }\n \n-    @Description(\"signum\")\n+    @Description(\"Signum.\")\n     @ScalarFunction(\"sign\")\n     @SqlType(StandardTypes.TINYINT)\n     public static long signTinyint(@SqlType(StandardTypes.TINYINT) long num)\n@@ -1067,7 +1067,7 @@ public final class MathFunctions\n         return (long) Math.signum(num);\n     }\n \n-    @Description(\"signum\")\n+    @Description(\"Signum.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double sign(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -1075,7 +1075,7 @@ public final class MathFunctions\n         return Math.signum(num);\n     }\n \n-    @Description(\"signum\")\n+    @Description(\"Signum.\")\n     @ScalarFunction(\"sign\")\n     @SqlType(StandardTypes.REAL)\n     public static long signFloat(@SqlType(StandardTypes.REAL) long num)\n@@ -1083,7 +1083,7 @@ public final class MathFunctions\n         return floatToRawIntBits((Math.signum(intBitsToFloat((int) num))));\n     }\n \n-    @Description(\"sine\")\n+    @Description(\"Sine.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double sin(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -1091,7 +1091,7 @@ public final class MathFunctions\n         return Math.sin(num);\n     }\n \n-    @Description(\"square root\")\n+    @Description(\"Square root.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double sqrt(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -1099,7 +1099,7 @@ public final class MathFunctions\n         return Math.sqrt(num);\n     }\n \n-    @Description(\"tangent\")\n+    @Description(\"Tangent.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double tan(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -1107,7 +1107,7 @@ public final class MathFunctions\n         return Math.tan(num);\n     }\n \n-    @Description(\"hyperbolic tangent\")\n+    @Description(\"Hyperbolic tangent.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double tanh(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -1115,7 +1115,7 @@ public final class MathFunctions\n         return Math.tanh(num);\n     }\n \n-    @Description(\"test if value is not-a-number\")\n+    @Description(\"Test if value is not-a-number.\")\n     @ScalarFunction(\"is_nan\")\n     @SqlType(StandardTypes.BOOLEAN)\n     public static boolean isNaN(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -1123,7 +1123,7 @@ public final class MathFunctions\n         return Double.isNaN(num);\n     }\n \n-    @Description(\"test if value is finite\")\n+    @Description(\"Test if value is finite.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BOOLEAN)\n     public static boolean isFinite(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -1131,7 +1131,7 @@ public final class MathFunctions\n         return Doubles.isFinite(num);\n     }\n \n-    @Description(\"test if value is infinite\")\n+    @Description(\"Test if value is infinite.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BOOLEAN)\n     public static boolean isInfinite(@SqlType(StandardTypes.DOUBLE) double num)\n@@ -1139,7 +1139,7 @@ public final class MathFunctions\n         return Double.isInfinite(num);\n     }\n \n-    @Description(\"constant representing not-a-number\")\n+    @Description(\"Constant representing not-a-number.\")\n     @ScalarFunction(\"nan\")\n     @SqlType(StandardTypes.DOUBLE)\n     public static double NaN()\n@@ -1147,7 +1147,7 @@ public final class MathFunctions\n         return Double.NaN;\n     }\n \n-    @Description(\"Infinity\")\n+    @Description(\"Infinity.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.DOUBLE)\n     public static double infinity()\n@@ -1155,7 +1155,7 @@ public final class MathFunctions\n         return Double.POSITIVE_INFINITY;\n     }\n \n-    @Description(\"convert a number to a string in the given base\")\n+    @Description(\"Convert a number to a string in the given base.\")\n     @ScalarFunction\n     @SqlType(\"varchar(64)\")\n     public static Slice toBase(@SqlType(StandardTypes.BIGINT) long value, @SqlType(StandardTypes.BIGINT) long radix)\n@@ -1164,7 +1164,7 @@ public final class MathFunctions\n         return utf8Slice(Long.toString(value, (int) radix));\n     }\n \n-    @Description(\"convert a string in the given base to a number\")\n+    @Description(\"Convert a string in the given base to a number.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -1185,7 +1185,7 @@ public final class MathFunctions\n                 INVALID_FUNCTION_ARGUMENT, \"Radix must be between %d and %d\", MIN_RADIX, MAX_RADIX);\n     }\n \n-    @Description(\"The bucket number of a value given a lower and upper bound and the number of buckets\")\n+    @Description(\"The bucket number of a value given a lower and upper bound and the number of buckets.\")\n     @ScalarFunction(\"width_bucket\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long widthBucket(@SqlType(StandardTypes.DOUBLE) double operand, @SqlType(StandardTypes.DOUBLE) double bound1, @SqlType(StandardTypes.DOUBLE) double bound2, @SqlType(StandardTypes.BIGINT) long bucketCount)\n@@ -1223,7 +1223,7 @@ public final class MathFunctions\n         return result;\n     }\n \n-    @Description(\"The bucket number of a value given an array of bins\")\n+    @Description(\"The bucket number of a value given an array of bins.\")\n     @ScalarFunction(\"width_bucket\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long widthBucket(@SqlType(StandardTypes.DOUBLE) double operand, @SqlType(\"array(double)\") Block bins)\n@@ -1262,7 +1262,7 @@ public final class MathFunctions\n         return lower;\n     }\n \n-    @Description(\"cosine similarity between the given sparse vectors\")\n+    @Description(\"Cosine similarity between the given sparse vectors.\")\n     @ScalarFunction\n     @SqlNullable\n     @SqlType(StandardTypes.DOUBLE)\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/MultimapFromEntriesFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/MultimapFromEntriesFunction.java\nindex 714c8c4985c..c8c464a58cc 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/MultimapFromEntriesFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/MultimapFromEntriesFunction.java\n@@ -35,7 +35,7 @@ import static com.google.common.base.Verify.verify;\n import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n \n @ScalarFunction(\"multimap_from_entries\")\n-@Description(\"construct a multimap from an array of entries\")\n+@Description(\"Construct a multimap from an array of entries.\")\n public final class MultimapFromEntriesFunction\n {\n     private static final String NAME = \"multimap_from_entries\";\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/Re2JRegexpFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/Re2JRegexpFunctions.java\nindex 5fac93ec39d..99a57c8b23c 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/Re2JRegexpFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/Re2JRegexpFunctions.java\n@@ -35,7 +35,7 @@ public final class Re2JRegexpFunctions\n {\n     private Re2JRegexpFunctions() {}\n \n-    @Description(\"returns substrings matching a regular expression\")\n+    @Description(\"Returns substrings matching a regular expression.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BOOLEAN)\n@@ -44,7 +44,7 @@ public final class Re2JRegexpFunctions\n         return pattern.matches(source);\n     }\n \n-    @Description(\"removes substrings matching a regular expression\")\n+    @Description(\"Removes substrings matching a regular expression.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -53,7 +53,7 @@ public final class Re2JRegexpFunctions\n         return regexpReplace(source, pattern, Slices.EMPTY_SLICE);\n     }\n \n-    @Description(\"replaces substrings matching a regular expression by given string\")\n+    @Description(\"Replaces substrings matching a regular expression by given string.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\", \"z\"})\n     // Longest possible output is when the pattern is empty, than the replacement will be placed in between\n@@ -68,7 +68,7 @@ public final class Re2JRegexpFunctions\n         return pattern.replace(source, replacement);\n     }\n \n-    @Description(\"string(s) extracted using the given pattern\")\n+    @Description(\"String(s) extracted using the given pattern.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"array(varchar(x))\")\n@@ -77,7 +77,7 @@ public final class Re2JRegexpFunctions\n         return regexpExtractAll(source, pattern, 0);\n     }\n \n-    @Description(\"group(s) extracted using the given pattern\")\n+    @Description(\"Group(s) extracted using the given pattern.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"array(varchar(x))\")\n@@ -87,7 +87,7 @@ public final class Re2JRegexpFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"string extracted using the given pattern\")\n+    @Description(\"String extracted using the given pattern.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -97,7 +97,7 @@ public final class Re2JRegexpFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"returns regex group of extracted string with a pattern\")\n+    @Description(\"Returns regex group of extracted string with a pattern.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -107,7 +107,7 @@ public final class Re2JRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns array of strings split by pattern\")\n+    @Description(\"Returns array of strings split by pattern.\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"array(varchar(x))\")\n     public static Block regexpSplit(@SqlType(\"varchar(x)\") Slice source, @SqlType(Re2JRegexpType.NAME) Re2JRegexp pattern)\n@@ -116,7 +116,7 @@ public final class Re2JRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns the index of the matched substring.\")\n+    @Description(\"Returns the index of the matched substring.\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long regexpPosition(@SqlType(\"varchar(x)\") Slice source, @SqlType(Re2JRegexpType.NAME) Re2JRegexp pattern)\n@@ -125,7 +125,7 @@ public final class Re2JRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns the index of the matched substring starting from the specified position\")\n+    @Description(\"Returns the index of the matched substring starting from the specified position.\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long regexpPosition(@SqlType(\"varchar(x)\") Slice source,\n@@ -136,7 +136,7 @@ public final class Re2JRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns the index of the n-th matched substring starting from the specified position\")\n+    @Description(\"Returns the index of the n-th matched substring starting from the specified position.\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long regexpPosition(@SqlType(\"varchar(x)\") Slice source,\n@@ -172,7 +172,7 @@ public final class Re2JRegexpFunctions\n     }\n \n     @ScalarFunction\n-    @Description(\"returns the number of times that a pattern occurs in a string\")\n+    @Description(\"Returns the number of times that a pattern occurs in a string.\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long regexpCount(@SqlType(\"varchar(x)\") Slice source, @SqlType(Re2JRegexpType.NAME) Re2JRegexp pattern)\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/Re2JRegexpReplaceLambdaFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/Re2JRegexpReplaceLambdaFunction.java\nindex b9c00ea37e4..fcfbec0a899 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/Re2JRegexpReplaceLambdaFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/Re2JRegexpReplaceLambdaFunction.java\n@@ -33,7 +33,7 @@ import io.prestosql.type.Re2JRegexpType;\n import static io.prestosql.spi.type.VarcharType.VARCHAR;\n \n @ScalarFunction(\"regexp_replace\")\n-@Description(\"replaces substrings matching a regular expression using a lambda function\")\n+@Description(\"Replaces substrings matching a regular expression using a lambda function.\")\n public final class Re2JRegexpReplaceLambdaFunction\n {\n     private final PageBuilder pageBuilder = new PageBuilder(ImmutableList.of(VARCHAR));\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/RepeatFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/RepeatFunction.java\nindex dc56878cef1..ed48ebb93e2 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/RepeatFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/RepeatFunction.java\n@@ -30,7 +30,7 @@ import static io.prestosql.util.Failures.checkCondition;\n import static java.lang.Math.toIntExact;\n \n @ScalarFunction(\"repeat\")\n-@Description(\"Repeat an element for a given number of times\")\n+@Description(\"Repeat an element for a given number of times.\")\n public final class RepeatFunction\n {\n     private static final long MAX_RESULT_ENTRIES = 10_000;\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/SequenceFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/SequenceFunction.java\nindex 03bfdbb2b7c..5c2a63b4856 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/SequenceFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/SequenceFunction.java\n@@ -43,7 +43,7 @@ public final class SequenceFunction\n \n     private SequenceFunction() {}\n \n-    @Description(\"Sequence function to generate synthetic arrays\")\n+    @Description(\"Sequence function to generate synthetic arrays.\")\n     @ScalarFunction(\"sequence\")\n     @SqlType(\"array(bigint)\")\n     public static Block sequence(\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/SessionFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/SessionFunctions.java\nindex 280eaa7c708..890da9376c9 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/SessionFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/SessionFunctions.java\n@@ -28,7 +28,7 @@ public final class SessionFunctions\n     private SessionFunctions() {}\n \n     @ScalarFunction(value = \"$current_user\", hidden = true)\n-    @Description(\"current user\")\n+    @Description(\"Current user.\")\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice currentUser(ConnectorSession session)\n     {\n@@ -36,7 +36,7 @@ public final class SessionFunctions\n     }\n \n     @ScalarFunction(value = \"$current_path\", hidden = true)\n-    @Description(\"retrieve current path\")\n+    @Description(\"Retrieve current path.\")\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice currentPath(ConnectorSession session)\n     {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/SplitToMapFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/SplitToMapFunction.java\nindex b5d50291568..c9bdeda733e 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/SplitToMapFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/SplitToMapFunction.java\n@@ -35,7 +35,7 @@ import static io.prestosql.spi.type.VarcharType.VARCHAR;\n import static io.prestosql.util.Failures.checkCondition;\n import static java.lang.String.format;\n \n-@Description(\"creates a map using entryDelimiter and keyValueDelimiter\")\n+@Description(\"Creates a map using entryDelimiter and keyValueDelimiter.\")\n @ScalarFunction(\"split_to_map\")\n public class SplitToMapFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/SplitToMultimapFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/SplitToMultimapFunction.java\nindex c04c0aee5c2..612ef99931c 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/SplitToMultimapFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/SplitToMultimapFunction.java\n@@ -36,7 +36,7 @@ import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n import static io.prestosql.spi.type.VarcharType.VARCHAR;\n import static io.prestosql.util.Failures.checkCondition;\n \n-@Description(\"creates a multimap by splitting a string into key/value pairs\")\n+@Description(\"Creates a multimap by splitting a string into key/value pairs.\")\n @ScalarFunction(\"split_to_multimap\")\n public class SplitToMultimapFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\nindex 8b1db9d7775..2d5eb0b3e8c 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\n@@ -65,7 +65,7 @@ public final class StringFunctions\n {\n     private StringFunctions() {}\n \n-    @Description(\"convert Unicode code point to a string\")\n+    @Description(\"Convert Unicode code point to a string.\")\n     @ScalarFunction\n     @SqlType(\"varchar(1)\")\n     public static Slice chr(@SqlType(StandardTypes.BIGINT) long codepoint)\n@@ -78,7 +78,7 @@ public final class StringFunctions\n         }\n     }\n \n-    @Description(\"returns Unicode code point of a single character string\")\n+    @Description(\"Returns Unicode code point of a single character string.\")\n     @ScalarFunction(\"codepoint\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long codepoint(@SqlType(\"varchar(1)\") Slice slice)\n@@ -88,7 +88,7 @@ public final class StringFunctions\n         return getCodePointAt(slice, 0);\n     }\n \n-    @Description(\"count of code points of the given string\")\n+    @Description(\"Count of code points of the given string.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -97,7 +97,7 @@ public final class StringFunctions\n         return countCodePoints(slice);\n     }\n \n-    @Description(\"count of code points of the given string\")\n+    @Description(\"Count of code points of the given string.\")\n     @ScalarFunction(\"length\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -106,7 +106,7 @@ public final class StringFunctions\n         return x;\n     }\n \n-    @Description(\"returns length of a character string without trailing spaces\")\n+    @Description(\"Returns length of a character string without trailing spaces.\")\n     @ScalarFunction(value = \"$space_trimmed_length\", hidden = true)\n     @SqlType(StandardTypes.BIGINT)\n     public static long spaceTrimmedLength(@SqlType(\"varchar\") Slice slice)\n@@ -114,7 +114,7 @@ public final class StringFunctions\n         return countCodePoints(slice, 0, byteCountWithoutTrailingSpace(slice, 0, slice.length()));\n     }\n \n-    @Description(\"greedily removes occurrences of a pattern in a string\")\n+    @Description(\"Greedily removes occurrences of a pattern in a string.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(\"varchar(x)\")\n@@ -123,7 +123,7 @@ public final class StringFunctions\n         return replace(str, search, Slices.EMPTY_SLICE);\n     }\n \n-    @Description(\"greedily replaces occurrences of a pattern with a string\")\n+    @Description(\"Greedily replaces occurrences of a pattern with a string.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\", \"z\", \"u\"})\n     @Constraint(variable = \"u\", expression = \"min(2147483647, x + z * (x + 1))\")\n@@ -190,7 +190,7 @@ public final class StringFunctions\n         return buffer.slice(0, indexBuffer);\n     }\n \n-    @Description(\"reverse all code points in a given string\")\n+    @Description(\"Reverse all code points in a given string.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -199,7 +199,7 @@ public final class StringFunctions\n         return SliceUtf8.reverse(slice);\n     }\n \n-    @Description(\"returns index of first occurrence of a substring (or 0 if not found)\")\n+    @Description(\"Returns index of first occurrence of a substring (or 0 if not found).\")\n     @ScalarFunction(\"strpos\")\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(StandardTypes.BIGINT)\n@@ -208,7 +208,7 @@ public final class StringFunctions\n         return stringPosition(string, substring, 1);\n     }\n \n-    @Description(\"returns index of n-th occurrence of a substring (or 0 if not found)\")\n+    @Description(\"Returns index of n-th occurrence of a substring (or 0 if not found).\")\n     @ScalarFunction(\"strpos\")\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(StandardTypes.BIGINT)\n@@ -268,7 +268,7 @@ public final class StringFunctions\n         return index + 1;\n     }\n \n-    @Description(\"suffix starting at given index\")\n+    @Description(\"Suffix starting at given index.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -306,7 +306,7 @@ public final class StringFunctions\n         return utf8.slice(indexStart, indexEnd - indexStart);\n     }\n \n-    @Description(\"suffix starting at given index\")\n+    @Description(\"Suffix starting at given index.\")\n     @ScalarFunction(\"substr\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -315,7 +315,7 @@ public final class StringFunctions\n         return substr(utf8, start);\n     }\n \n-    @Description(\"substring of given length starting at an index\")\n+    @Description(\"Substring of given length starting at an index.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -364,7 +364,7 @@ public final class StringFunctions\n         return utf8.slice(indexStart, indexEnd - indexStart);\n     }\n \n-    @Description(\"substring of given length starting at an index\")\n+    @Description(\"Substring of given length starting at an index.\")\n     @ScalarFunction(\"substr\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -419,7 +419,7 @@ public final class StringFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"splits a string by a delimiter and returns the specified field (counting from one)\")\n+    @Description(\"Splits a string by a delimiter and returns the specified field (counting from one).\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(\"varchar(x)\")\n@@ -468,7 +468,7 @@ public final class StringFunctions\n         return null;\n     }\n \n-    @Description(\"removes whitespace from the beginning of a string\")\n+    @Description(\"Removes whitespace from the beginning of a string.\")\n     @ScalarFunction(\"ltrim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -477,7 +477,7 @@ public final class StringFunctions\n         return SliceUtf8.leftTrim(slice);\n     }\n \n-    @Description(\"removes whitespace from the beginning of a string\")\n+    @Description(\"Removes whitespace from the beginning of a string.\")\n     @ScalarFunction(\"ltrim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -486,7 +486,7 @@ public final class StringFunctions\n         return SliceUtf8.leftTrim(slice);\n     }\n \n-    @Description(\"removes whitespace from the end of a string\")\n+    @Description(\"Removes whitespace from the end of a string.\")\n     @ScalarFunction(\"rtrim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -495,7 +495,7 @@ public final class StringFunctions\n         return SliceUtf8.rightTrim(slice);\n     }\n \n-    @Description(\"removes whitespace from the end of a string\")\n+    @Description(\"Removes whitespace from the end of a string.\")\n     @ScalarFunction(\"rtrim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -504,7 +504,7 @@ public final class StringFunctions\n         return rightTrim(slice);\n     }\n \n-    @Description(\"removes whitespace from the beginning and end of a string\")\n+    @Description(\"Removes whitespace from the beginning and end of a string.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -513,7 +513,7 @@ public final class StringFunctions\n         return SliceUtf8.trim(slice);\n     }\n \n-    @Description(\"removes whitespace from the beginning and end of a string\")\n+    @Description(\"Removes whitespace from the beginning and end of a string.\")\n     @ScalarFunction(\"trim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -522,7 +522,7 @@ public final class StringFunctions\n         return trim(slice);\n     }\n \n-    @Description(\"remove the longest string containing only given characters from the beginning of a string\")\n+    @Description(\"Remove the longest string containing only given characters from the beginning of a string.\")\n     @ScalarFunction(\"ltrim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -531,7 +531,7 @@ public final class StringFunctions\n         return SliceUtf8.leftTrim(slice, codePointsToTrim);\n     }\n \n-    @Description(\"remove the longest string containing only given characters from the beginning of a string\")\n+    @Description(\"Remove the longest string containing only given characters from the beginning of a string.\")\n     @ScalarFunction(\"ltrim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -540,7 +540,7 @@ public final class StringFunctions\n         return leftTrim(slice, codePointsToTrim);\n     }\n \n-    @Description(\"remove the longest string containing only given characters from the end of a string\")\n+    @Description(\"Remove the longest string containing only given characters from the end of a string.\")\n     @ScalarFunction(\"rtrim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -549,7 +549,7 @@ public final class StringFunctions\n         return SliceUtf8.rightTrim(slice, codePointsToTrim);\n     }\n \n-    @Description(\"remove the longest string containing only given characters from the end of a string\")\n+    @Description(\"Remove the longest string containing only given characters from the end of a string.\")\n     @ScalarFunction(\"rtrim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -558,7 +558,7 @@ public final class StringFunctions\n         return trimTrailingSpaces(rightTrim(slice, codePointsToTrim));\n     }\n \n-    @Description(\"remove the longest string containing only given characters from the beginning and end of a string\")\n+    @Description(\"Remove the longest string containing only given characters from the beginning and end of a string.\")\n     @ScalarFunction(\"trim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -567,7 +567,7 @@ public final class StringFunctions\n         return SliceUtf8.trim(slice, codePointsToTrim);\n     }\n \n-    @Description(\"remove the longest string containing only given characters from the beginning and end of a string\")\n+    @Description(\"Remove the longest string containing only given characters from the beginning and end of a string.\")\n     @ScalarFunction(\"trim\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -617,7 +617,7 @@ public final class StringFunctions\n         return codePoints;\n     }\n \n-    @Description(\"converts the string to lower case\")\n+    @Description(\"Converts the string to lower case.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -626,7 +626,7 @@ public final class StringFunctions\n         return toLowerCase(slice);\n     }\n \n-    @Description(\"converts the string to lower case\")\n+    @Description(\"Converts the string to lower case.\")\n     @ScalarFunction(\"lower\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -635,7 +635,7 @@ public final class StringFunctions\n         return lower(slice);\n     }\n \n-    @Description(\"converts the string to upper case\")\n+    @Description(\"Converts the string to upper case.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -644,7 +644,7 @@ public final class StringFunctions\n         return toUpperCase(slice);\n     }\n \n-    @Description(\"converts the string to upper case\")\n+    @Description(\"Converts the string to upper case.\")\n     @ScalarFunction(\"upper\")\n     @LiteralParameters(\"x\")\n     @SqlType(\"char(x)\")\n@@ -706,7 +706,7 @@ public final class StringFunctions\n         return buffer;\n     }\n \n-    @Description(\"pads a string on the left\")\n+    @Description(\"Pads a string on the left.\")\n     @ScalarFunction(\"lpad\")\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(StandardTypes.VARCHAR)\n@@ -715,7 +715,7 @@ public final class StringFunctions\n         return pad(text, targetLength, padString, 0);\n     }\n \n-    @Description(\"pads a string on the right\")\n+    @Description(\"Pads a string on the right.\")\n     @ScalarFunction(\"rpad\")\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(StandardTypes.VARCHAR)\n@@ -724,7 +724,7 @@ public final class StringFunctions\n         return pad(text, targetLength, padString, text.length());\n     }\n \n-    @Description(\"computes Levenshtein distance between two strings\")\n+    @Description(\"Computes Levenshtein distance between two strings.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(StandardTypes.BIGINT)\n@@ -776,7 +776,7 @@ public final class StringFunctions\n         return distances[rightCodePoints.length - 1];\n     }\n \n-    @Description(\"computes Hamming distance between two strings\")\n+    @Description(\"Computes Hamming distance between two strings.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(StandardTypes.BIGINT)\n@@ -807,7 +807,7 @@ public final class StringFunctions\n         return distance;\n     }\n \n-    @Description(\"transforms the string to normalized form\")\n+    @Description(\"Transforms the string to normalized form.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(StandardTypes.VARCHAR)\n@@ -823,7 +823,7 @@ public final class StringFunctions\n         return utf8Slice(Normalizer.normalize(slice.toStringUtf8(), targetForm));\n     }\n \n-    @Description(\"decodes the UTF-8 encoded string\")\n+    @Description(\"Decodes the UTF-8 encoded string.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice fromUtf8(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -831,7 +831,7 @@ public final class StringFunctions\n         return SliceUtf8.fixInvalidUtf8(slice);\n     }\n \n-    @Description(\"decodes the UTF-8 encoded string\")\n+    @Description(\"Decodes the UTF-8 encoded string.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.VARCHAR)\n@@ -857,7 +857,7 @@ public final class StringFunctions\n         return SliceUtf8.fixInvalidUtf8(slice, replacementCodePoint);\n     }\n \n-    @Description(\"decodes the UTF-8 encoded string\")\n+    @Description(\"Decodes the UTF-8 encoded string.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice fromUtf8(@SqlType(StandardTypes.VARBINARY) Slice slice, @SqlType(StandardTypes.BIGINT) long replacementCodePoint)\n@@ -868,7 +868,7 @@ public final class StringFunctions\n         return SliceUtf8.fixInvalidUtf8(slice, OptionalInt.of((int) replacementCodePoint));\n     }\n \n-    @Description(\"encodes the string to UTF-8\")\n+    @Description(\"Encodes the string to UTF-8.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.VARBINARY)\n@@ -878,7 +878,7 @@ public final class StringFunctions\n     }\n \n     // TODO: implement N arguments char concat\n-    @Description(\"concatenates given character strings\")\n+    @Description(\"Concatenates given character strings.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\", \"u\"})\n     @Constraint(variable = \"u\", expression = \"x + y\")\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/TryFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/TryFunction.java\nindex 28682012d18..c25a66d74b1 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/TryFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/TryFunction.java\n@@ -32,7 +32,7 @@ import static io.prestosql.spi.StandardErrorCode.INVALID_CAST_ARGUMENT;\n import static io.prestosql.spi.StandardErrorCode.INVALID_FUNCTION_ARGUMENT;\n import static io.prestosql.spi.StandardErrorCode.NUMERIC_VALUE_OUT_OF_RANGE;\n \n-@Description(\"internal try function for desugaring TRY\")\n+@Description(\"Internal try function for desugaring TRY.\")\n @ScalarFunction(value = NAME, hidden = true, deterministic = false)\n public final class TryFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/TypeOfFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/TypeOfFunction.java\nindex 249832cac77..2b0efb26ea1 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/TypeOfFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/TypeOfFunction.java\n@@ -24,7 +24,7 @@ import io.prestosql.spi.type.Type;\n \n import static io.airlift.slice.Slices.utf8Slice;\n \n-@Description(\"textual representation of expression type\")\n+@Description(\"Textual representation of expression type.\")\n @ScalarFunction(\"typeof\")\n public final class TypeOfFunction\n {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/UrlFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/UrlFunctions.java\nindex a97c1f9586f..d81753d2e78 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/UrlFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/UrlFunctions.java\n@@ -48,7 +48,7 @@ public final class UrlFunctions\n     private UrlFunctions() {}\n \n     @SqlNullable\n-    @Description(\"extract protocol from url\")\n+    @Description(\"Extract protocol from url.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -59,7 +59,7 @@ public final class UrlFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"extract host from url\")\n+    @Description(\"Extract host from url.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -70,7 +70,7 @@ public final class UrlFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"extract port from url\")\n+    @Description(\"Extract port from url.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.BIGINT)\n@@ -84,7 +84,7 @@ public final class UrlFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"extract part from url\")\n+    @Description(\"Extract part from url.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -95,7 +95,7 @@ public final class UrlFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"extract query from url\")\n+    @Description(\"Extract query from url.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -106,7 +106,7 @@ public final class UrlFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"extract fragment from url\")\n+    @Description(\"Extract fragment from url.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -117,7 +117,7 @@ public final class UrlFunctions\n     }\n \n     @SqlNullable\n-    @Description(\"extract query parameter from url\")\n+    @Description(\"Extract query parameter from url.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\"})\n     @SqlType(\"varchar(x)\")\n@@ -146,7 +146,7 @@ public final class UrlFunctions\n         return null;\n     }\n \n-    @Description(\"escape a string for use in URL query parameter names and values\")\n+    @Description(\"Escape a string for use in URL query parameter names and values.\")\n     @ScalarFunction\n     @LiteralParameters({\"x\", \"y\"})\n     @Constraint(variable = \"y\", expression = \"min(2147483647, x * 12)\")\n@@ -157,7 +157,7 @@ public final class UrlFunctions\n         return slice(escaper.escape(value.toStringUtf8()));\n     }\n \n-    @Description(\"unescape a URL-encoded string\")\n+    @Description(\"Unescape a URL-encoded string.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/VarbinaryFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/VarbinaryFunctions.java\nindex c526d8f7f49..f5dc97634a6 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/VarbinaryFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/VarbinaryFunctions.java\n@@ -38,7 +38,7 @@ public final class VarbinaryFunctions\n {\n     private VarbinaryFunctions() {}\n \n-    @Description(\"length of the given binary\")\n+    @Description(\"Length of the given binary.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long length(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -46,7 +46,7 @@ public final class VarbinaryFunctions\n         return slice.length();\n     }\n \n-    @Description(\"encode binary data as base64\")\n+    @Description(\"Encode binary data as base64.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice toBase64(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -54,7 +54,7 @@ public final class VarbinaryFunctions\n         return Slices.wrappedBuffer(Base64.getEncoder().encode(slice.getBytes()));\n     }\n \n-    @Description(\"decode base64 encoded binary data\")\n+    @Description(\"Decode base64 encoded binary data.\")\n     @ScalarFunction(\"from_base64\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.VARBINARY)\n@@ -68,7 +68,7 @@ public final class VarbinaryFunctions\n         }\n     }\n \n-    @Description(\"decode base64 encoded binary data\")\n+    @Description(\"Decode base64 encoded binary data.\")\n     @ScalarFunction(\"from_base64\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice fromBase64Varbinary(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -81,7 +81,7 @@ public final class VarbinaryFunctions\n         }\n     }\n \n-    @Description(\"encode binary data as base64 using the URL safe alphabet\")\n+    @Description(\"Encode binary data as base64 using the URL safe alphabet.\")\n     @ScalarFunction(\"to_base64url\")\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice toBase64Url(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -89,7 +89,7 @@ public final class VarbinaryFunctions\n         return Slices.wrappedBuffer(Base64.getUrlEncoder().encode(slice.getBytes()));\n     }\n \n-    @Description(\"decode URL safe base64 encoded binary data\")\n+    @Description(\"Decode URL safe base64 encoded binary data.\")\n     @ScalarFunction(\"from_base64url\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.VARBINARY)\n@@ -103,7 +103,7 @@ public final class VarbinaryFunctions\n         }\n     }\n \n-    @Description(\"decode URL safe base64 encoded binary data\")\n+    @Description(\"Decode URL safe base64 encoded binary data.\")\n     @ScalarFunction(\"from_base64url\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice fromBase64UrlVarbinary(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -116,7 +116,7 @@ public final class VarbinaryFunctions\n         }\n     }\n \n-    @Description(\"encode binary data as hex\")\n+    @Description(\"Encode binary data as hex.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice toHex(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -124,7 +124,7 @@ public final class VarbinaryFunctions\n         return Slices.utf8Slice(BaseEncoding.base16().encode(slice.getBytes()));\n     }\n \n-    @Description(\"decode hex encoded binary data\")\n+    @Description(\"Decode hex encoded binary data.\")\n     @ScalarFunction(\"from_hex\")\n     @LiteralParameters(\"x\")\n     @SqlType(StandardTypes.VARBINARY)\n@@ -141,7 +141,7 @@ public final class VarbinaryFunctions\n         return Slices.wrappedBuffer(result);\n     }\n \n-    @Description(\"encode value as a 64-bit 2's complement big endian varbinary\")\n+    @Description(\"Encode value as a 64-bit 2's complement big endian varbinary.\")\n     @ScalarFunction(\"to_big_endian_64\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice toBigEndian64(@SqlType(StandardTypes.BIGINT) long value)\n@@ -151,7 +151,7 @@ public final class VarbinaryFunctions\n         return slice;\n     }\n \n-    @Description(\"decode bigint value from a 64-bit 2's complement big endian varbinary\")\n+    @Description(\"Decode bigint value from a 64-bit 2's complement big endian varbinary.\")\n     @ScalarFunction(\"from_big_endian_64\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long fromBigEndian64(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -162,7 +162,7 @@ public final class VarbinaryFunctions\n         return Long.reverseBytes(slice.getLong(0));\n     }\n \n-    @Description(\"encode value as a 32-bit 2's complement big endian varbinary\")\n+    @Description(\"Encode value as a 32-bit 2's complement big endian varbinary.\")\n     @ScalarFunction(\"to_big_endian_32\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice toBigEndian32(@SqlType(StandardTypes.INTEGER) long value)\n@@ -172,7 +172,7 @@ public final class VarbinaryFunctions\n         return slice;\n     }\n \n-    @Description(\"decode bigint value from a 32-bit 2's complement big endian varbinary\")\n+    @Description(\"Decode bigint value from a 32-bit 2's complement big endian varbinary.\")\n     @ScalarFunction(\"from_big_endian_32\")\n     @SqlType(StandardTypes.INTEGER)\n     public static long fromBigEndian32(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -183,7 +183,7 @@ public final class VarbinaryFunctions\n         return Integer.reverseBytes(slice.getInt(0));\n     }\n \n-    @Description(\"encode value as a big endian varbinary according to IEEE 754 single-precision floating-point format\")\n+    @Description(\"Encode value as a big endian varbinary according to IEEE 754 single-precision floating-point format.\")\n     @ScalarFunction(\"to_ieee754_32\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice toIEEE754Binary32(@SqlType(StandardTypes.REAL) long value)\n@@ -193,7 +193,7 @@ public final class VarbinaryFunctions\n         return slice;\n     }\n \n-    @Description(\"decode the 32-bit big-endian binary in IEEE 754 single-precision floating-point format\")\n+    @Description(\"Decode the 32-bit big-endian binary in IEEE 754 single-precision floating-point format.\")\n     @ScalarFunction(\"from_ieee754_32\")\n     @SqlType(StandardTypes.REAL)\n     public static long fromIEEE754Binary32(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -202,7 +202,7 @@ public final class VarbinaryFunctions\n         return Integer.reverseBytes(slice.getInt(0));\n     }\n \n-    @Description(\"encode value as a big endian varbinary according to IEEE 754 double-precision floating-point format\")\n+    @Description(\"Encode value as a big endian varbinary according to IEEE 754 double-precision floating-point format.\")\n     @ScalarFunction(\"to_ieee754_64\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice toIEEE754Binary64(@SqlType(StandardTypes.DOUBLE) double value)\n@@ -212,7 +212,7 @@ public final class VarbinaryFunctions\n         return slice;\n     }\n \n-    @Description(\"decode the 64-bit big-endian binary in IEEE 754 double-precision floating-point format\")\n+    @Description(\"Decode the 64-bit big-endian binary in IEEE 754 double-precision floating-point format.\")\n     @ScalarFunction(\"from_ieee754_64\")\n     @SqlType(StandardTypes.DOUBLE)\n     public static double fromIEEE754Binary64(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -221,7 +221,7 @@ public final class VarbinaryFunctions\n         return Double.longBitsToDouble(Long.reverseBytes(slice.getLong(0)));\n     }\n \n-    @Description(\"compute md5 hash\")\n+    @Description(\"Compute md5 hash.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice md5(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -229,7 +229,7 @@ public final class VarbinaryFunctions\n         return Slices.wrappedBuffer(Hashing.md5().hashBytes(slice.getBytes()).asBytes());\n     }\n \n-    @Description(\"compute sha1 hash\")\n+    @Description(\"Compute sha1 hash.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice sha1(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -237,7 +237,7 @@ public final class VarbinaryFunctions\n         return Slices.wrappedBuffer(Hashing.sha1().hashBytes(slice.getBytes()).asBytes());\n     }\n \n-    @Description(\"compute sha256 hash\")\n+    @Description(\"Compute sha256 hash.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice sha256(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -245,7 +245,7 @@ public final class VarbinaryFunctions\n         return Slices.wrappedBuffer(Hashing.sha256().hashBytes(slice.getBytes()).asBytes());\n     }\n \n-    @Description(\"compute sha512 hash\")\n+    @Description(\"Compute sha512 hash.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice sha512(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -267,7 +267,7 @@ public final class VarbinaryFunctions\n         throw new PrestoException(INVALID_FUNCTION_ARGUMENT, \"invalid hex character: \" + (char) b);\n     }\n \n-    @Description(\"compute xxhash64 hash\")\n+    @Description(\"Compute xxhash64 hash.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice xxhash64(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -277,7 +277,7 @@ public final class VarbinaryFunctions\n         return hash;\n     }\n \n-    @Description(\"compute SpookyHashV2 32-bit hash\")\n+    @Description(\"Compute SpookyHashV2 32-bit hash.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice spookyHashV2_32(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -287,7 +287,7 @@ public final class VarbinaryFunctions\n         return hash;\n     }\n \n-    @Description(\"compute SpookyHashV2 64-bit hash\")\n+    @Description(\"Compute SpookyHashV2 64-bit hash.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice spookyHashV2_64(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -297,7 +297,7 @@ public final class VarbinaryFunctions\n         return hash;\n     }\n \n-    @Description(\"decode hex encoded binary data\")\n+    @Description(\"Decode hex encoded binary data.\")\n     @ScalarFunction(\"from_hex\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice fromHexVarbinary(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -305,7 +305,7 @@ public final class VarbinaryFunctions\n         return fromHexVarchar(slice);\n     }\n \n-    @Description(\"compute CRC-32\")\n+    @Description(\"Compute CRC-32.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.BIGINT)\n     public static long crc32(@SqlType(StandardTypes.VARBINARY) Slice slice)\n@@ -315,7 +315,7 @@ public final class VarbinaryFunctions\n         return crc32.getValue();\n     }\n \n-    @Description(\"suffix starting at given index\")\n+    @Description(\"Suffix starting at given index.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice substr(@SqlType(StandardTypes.VARBINARY) Slice slice, @SqlType(StandardTypes.BIGINT) long start)\n@@ -323,7 +323,7 @@ public final class VarbinaryFunctions\n         return substr(slice, start, slice.length() - start + 1);\n     }\n \n-    @Description(\"substring of given length starting at an index\")\n+    @Description(\"Substring of given length starting at an index.\")\n     @ScalarFunction\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice substr(@SqlType(StandardTypes.VARBINARY) Slice slice, @SqlType(StandardTypes.BIGINT) long start, @SqlType(StandardTypes.BIGINT) long length)\n@@ -406,7 +406,7 @@ public final class VarbinaryFunctions\n         return buffer;\n     }\n \n-    @Description(\"pads a varbinary on the left\")\n+    @Description(\"Pads a varbinary on the left.\")\n     @ScalarFunction(\"lpad\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice leftPad(@SqlType(\"varbinary\") Slice inputSlice, @SqlType(StandardTypes.BIGINT) long targetLength, @SqlType(\"varbinary\") Slice padBytes)\n@@ -414,7 +414,7 @@ public final class VarbinaryFunctions\n         return pad(inputSlice, targetLength, padBytes, 0);\n     }\n \n-    @Description(\"pads a varbinary on the right\")\n+    @Description(\"Pads a varbinary on the right.\")\n     @ScalarFunction(\"rpad\")\n     @SqlType(StandardTypes.VARBINARY)\n     public static Slice rightPad(@SqlType(\"varbinary\") Slice inputSlice, @SqlType(StandardTypes.BIGINT) long targetLength, @SqlType(\"varbinary\") Slice padBytes)\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/WilsonInterval.java b/presto-main/src/main/java/io/prestosql/operator/scalar/WilsonInterval.java\nindex 51beaacac1e..a4a7825c0aa 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/WilsonInterval.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/WilsonInterval.java\n@@ -26,7 +26,7 @@ public final class WilsonInterval\n     private WilsonInterval() {}\n \n     @ScalarFunction\n-    @Description(\"binomial confidence interval lower bound using Wilson score\")\n+    @Description(\"Binomial confidence interval lower bound using Wilson score.\")\n     @SqlType(StandardTypes.DOUBLE)\n     public static double wilsonIntervalLower(@SqlType(StandardTypes.BIGINT) long successes, @SqlType(StandardTypes.BIGINT) long trials, @SqlType(StandardTypes.DOUBLE) double z)\n     {\n@@ -34,7 +34,7 @@ public final class WilsonInterval\n     }\n \n     @ScalarFunction\n-    @Description(\"binomial confidence interval upper bound using Wilson score\")\n+    @Description(\"Binomial confidence interval upper bound using Wilson score.\")\n     @SqlType(StandardTypes.DOUBLE)\n     public static double wilsonIntervalUpper(@SqlType(StandardTypes.BIGINT) long successes, @SqlType(StandardTypes.BIGINT) long trials, @SqlType(StandardTypes.DOUBLE) double z)\n     {\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/WordStemFunction.java b/presto-main/src/main/java/io/prestosql/operator/scalar/WordStemFunction.java\nindex c20bc901f1e..87e2632daca 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/WordStemFunction.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/WordStemFunction.java\n@@ -75,7 +75,7 @@ public final class WordStemFunction\n             .put(utf8Slice(\"tr\"), TurkishStemmer::new)\n             .build();\n \n-    @Description(\"returns the stem of a word in the English language\")\n+    @Description(\"Returns the stem of a word in the English language.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -84,7 +84,7 @@ public final class WordStemFunction\n         return wordStem(slice, new EnglishStemmer());\n     }\n \n-    @Description(\"returns the stem of a word in the given language\")\n+    @Description(\"Returns the stem of a word in the given language.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\ndiff --git a/presto-main/src/main/java/io/prestosql/sql/planner/CompilerConfig.java b/presto-main/src/main/java/io/prestosql/sql/planner/CompilerConfig.java\nindex 112e623f120..d76fe613ef0 100644\n--- a/presto-main/src/main/java/io/prestosql/sql/planner/CompilerConfig.java\n+++ b/presto-main/src/main/java/io/prestosql/sql/planner/CompilerConfig.java\n@@ -31,7 +31,7 @@ public class CompilerConfig\n     }\n \n     @Config(\"compiler.expression-cache-size\")\n-    @Description(\"Reuse compiled expressions across multiple queries\")\n+    @Description(\"Reuse compiled expressions across multiple queries.\")\n     public CompilerConfig setExpressionCacheSize(int expressionCacheSize)\n     {\n         this.expressionCacheSize = expressionCacheSize;\ndiff --git a/presto-main/src/main/java/io/prestosql/type/UuidOperators.java b/presto-main/src/main/java/io/prestosql/type/UuidOperators.java\nindex 49432f02a31..f72ab4a08af 100644\n--- a/presto-main/src/main/java/io/prestosql/type/UuidOperators.java\n+++ b/presto-main/src/main/java/io/prestosql/type/UuidOperators.java\n@@ -52,7 +52,7 @@ public final class UuidOperators\n {\n     private UuidOperators() {}\n \n-    @Description(\"generates a random UUID\")\n+    @Description(\"Generates a random UUID.\")\n     @ScalarFunction(deterministic = false)\n     @SqlType(StandardTypes.UUID)\n     public static Slice uuid()\ndiff --git a/presto-mongodb/src/main/java/io/prestosql/plugin/mongodb/ObjectIdFunctions.java b/presto-mongodb/src/main/java/io/prestosql/plugin/mongodb/ObjectIdFunctions.java\nindex d2d3c5a5b0d..cc3370070ee 100644\n--- a/presto-mongodb/src/main/java/io/prestosql/plugin/mongodb/ObjectIdFunctions.java\n+++ b/presto-mongodb/src/main/java/io/prestosql/plugin/mongodb/ObjectIdFunctions.java\n@@ -47,7 +47,7 @@ public final class ObjectIdFunctions\n {\n     private ObjectIdFunctions() {}\n \n-    @Description(\"mongodb ObjectId\")\n+    @Description(\"Mongodb ObjectId.\")\n     @ScalarFunction(\"objectid\")\n     @SqlType(\"ObjectId\")\n     public static Slice ObjectId()\n@@ -55,7 +55,7 @@ public final class ObjectIdFunctions\n         return Slices.wrappedBuffer(new ObjectId().toByteArray());\n     }\n \n-    @Description(\"mongodb ObjectId from the given string\")\n+    @Description(\"Mongodb ObjectId from the given string.\")\n     @ScalarFunction(\"objectid\")\n     @SqlType(\"ObjectId\")\n     public static Slice ObjectId(@SqlType(StandardTypes.VARCHAR) Slice value)\ndiff --git a/presto-teradata-functions/src/main/java/io/prestosql/teradata/functions/TeradataDateFunctions.java b/presto-teradata-functions/src/main/java/io/prestosql/teradata/functions/TeradataDateFunctions.java\nindex 3671abca7d4..c5d018e86b1 100644\n--- a/presto-teradata-functions/src/main/java/io/prestosql/teradata/functions/TeradataDateFunctions.java\n+++ b/presto-teradata-functions/src/main/java/io/prestosql/teradata/functions/TeradataDateFunctions.java\n@@ -59,7 +59,7 @@ public final class TeradataDateFunctions\n     {\n     }\n \n-    @Description(\"Formats a timestamp\")\n+    @Description(\"Formats a timestamp.\")\n     @ScalarFunction(\"to_char\")\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice toChar(\n@@ -74,7 +74,7 @@ public final class TeradataDateFunctions\n         return utf8Slice(formatter.print(unpackMillisUtc(timestampWithTimeZone)));\n     }\n \n-    @Description(\"Converts a string to a DATE data type\")\n+    @Description(\"Converts a string to a DATE data type.\")\n     @ScalarFunction(\"to_date\")\n     @SqlType(StandardTypes.DATE)\n     public static long toDate(ConnectorSession session, @SqlType(StandardTypes.VARCHAR) Slice dateTime, @SqlType(StandardTypes.VARCHAR) Slice formatString)\n@@ -90,7 +90,7 @@ public final class TeradataDateFunctions\n         }\n     }\n \n-    @Description(\"Converts a string to a TIMESTAMP data type\")\n+    @Description(\"Converts a string to a TIMESTAMP data type.\")\n     @ScalarFunction(\"to_timestamp\")\n     @SqlType(StandardTypes.TIMESTAMP)\n     public static long toTimestamp(\ndiff --git a/presto-teradata-functions/src/main/java/io/prestosql/teradata/functions/TeradataStringFunctions.java b/presto-teradata-functions/src/main/java/io/prestosql/teradata/functions/TeradataStringFunctions.java\nindex f096562d0ac..33d368f53f8 100644\n--- a/presto-teradata-functions/src/main/java/io/prestosql/teradata/functions/TeradataStringFunctions.java\n+++ b/presto-teradata-functions/src/main/java/io/prestosql/teradata/functions/TeradataStringFunctions.java\n@@ -34,7 +34,7 @@ public final class TeradataStringFunctions\n {\n     private TeradataStringFunctions() {}\n \n-    @Description(\"Returns index of first occurrence of a substring (or 0 if not found)\")\n+    @Description(\"Returns index of first occurrence of a substring (or 0 if not found).\")\n     @ScalarFunction(\"index\")\n     @SqlType(StandardTypes.BIGINT)\n     public static long index(\n@@ -55,7 +55,7 @@ public final class TeradataStringFunctions\n         }\n     }\n \n-    @Description(\"suffix starting at given index\")\n+    @Description(\"Suffix starting at given index.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -77,7 +77,7 @@ public final class TeradataStringFunctions\n         }\n     }\n \n-    @Description(\"substring of given length starting at an index\")\n+    @Description(\"Substring of given length starting at an index.\")\n     @ScalarFunction\n     @LiteralParameters(\"x\")\n     @SqlType(\"varchar(x)\")\n@@ -100,7 +100,7 @@ public final class TeradataStringFunctions\n         }\n     }\n \n-    @Description(\"Returns the hexadecimal representation of the UTF-16BE encoding of the argument\")\n+    @Description(\"Returns the hexadecimal representation of the UTF-16BE encoding of the argument.\")\n     @ScalarFunction(\"char2hexint\")\n     @SqlType(StandardTypes.VARCHAR)\n     public static Slice char2HexInt(@SqlType(StandardTypes.VARCHAR) Slice string)\n"}
{"instance_id": "trinodb__trino-2575", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/connector/informationschema/InformationSchemaMetadata.java b/presto-main/src/main/java/io/prestosql/connector/informationschema/InformationSchemaMetadata.java\nindex 1981e3092f9..98ee3661f60 100644\n--- a/presto-main/src/main/java/io/prestosql/connector/informationschema/InformationSchemaMetadata.java\n+++ b/presto-main/src/main/java/io/prestosql/connector/informationschema/InformationSchemaMetadata.java\n@@ -362,6 +362,6 @@ public class InformationSchemaMetadata\n \n     private boolean isLowerCase(String value)\n     {\n-        return value.toLowerCase(ENGLISH).equals(value);\n+        return !value.isEmpty() && value.toLowerCase(ENGLISH).equals(value);\n     }\n }\ndiff --git a/presto-main/src/main/java/io/prestosql/metadata/MetadataUtil.java b/presto-main/src/main/java/io/prestosql/metadata/MetadataUtil.java\nindex ef2e32fd233..a2862da5fa8 100644\n--- a/presto-main/src/main/java/io/prestosql/metadata/MetadataUtil.java\n+++ b/presto-main/src/main/java/io/prestosql/metadata/MetadataUtil.java\n@@ -83,6 +83,9 @@ public final class MetadataUtil\n         if (value == null) {\n             throw new NullPointerException(format(\"%s is null\", name));\n         }\n+        if (value.isEmpty()) {\n+            throw new IllegalArgumentException(format(\"%s is empty\", name));\n+        }\n         checkArgument(value.equals(value.toLowerCase(ENGLISH)), \"%s is not lowercase: %s\", name, value);\n         return value;\n     }\n"}
{"instance_id": "sveltejs__svelte-728", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex ded4c54c2..952490bb3 100644\n--- a/package.json\n+++ b/package.json\n@@ -63,7 +63,7 @@\n     \"estree-walker\": \"^0.5.0\",\n     \"fuzzyset.js\": \"0.0.1\",\n     \"glob\": \"^7.1.1\",\n-    \"jsdom\": \"^9.9.1\",\n+    \"jsdom\": \"^9.12.0\",\n     \"locate-character\": \"^2.0.0\",\n     \"magic-string\": \"^0.22.3\",\n     \"mocha\": \"^3.2.0\",\ndiff --git a/src/generators/dom/visitors/Component/Binding.ts b/src/generators/dom/visitors/Component/Binding.ts\nindex e87ab0bff..a839a3a7b 100644\n--- a/src/generators/dom/visitors/Component/Binding.ts\n+++ b/src/generators/dom/visitors/Component/Binding.ts\n@@ -88,9 +88,9 @@ export default function visitBinding(\n \t`);\n \n \tlocal.update.addBlock(deindent`\n-\t\tif ( !${updating} && ${dependencies\n+\t\tif ( !${updating} && (${dependencies\n \t\t.map(dependency => `'${dependency}' in changed`)\n-\t\t.join(' || ')} ) {\n+\t\t.join(' || ')}) ) {\n \t\t\t${updating} = true;\n \t\t\t${local.name}._set({ ${attribute.name}: ${snippet} });\n \t\t\t${updating} = false;\ndiff --git a/src/shared/index.js b/src/shared/index.js\nindex 119f50452..9921437ef 100644\n--- a/src/shared/index.js\n+++ b/src/shared/index.js\n@@ -105,9 +105,12 @@ export function onDev(eventName, handler) {\n }\n \n export function set(newState) {\n-\tthis._set(assign({}, newState));\n-\tif (this._root._lock) return;\n+\tif (this._root._lock) {\n+\t\tthis._set(assign({}, newState));\n+\t\treturn;\n+\t}\n \tthis._root._lock = true;\n+\tthis._set(assign({}, newState));\n \tcallAll(this._root._beforecreate);\n \tcallAll(this._root._oncreate);\n \tcallAll(this._root._aftercreate);\n"}
{"instance_id": "trinodb__trino-3392", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\nindex eb1297c29b2..f2cad64d121 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\n@@ -199,6 +199,18 @@ public final class StringFunctions\n         return SliceUtf8.reverse(slice);\n     }\n \n+    @Description(\"Determine whether source starts with prefix or not\")\n+    @ScalarFunction(\"starts_with\")\n+    @LiteralParameters({\"x\", \"y\"})\n+    @SqlType(StandardTypes.BOOLEAN)\n+    public static boolean startsWith(@SqlType(\"varchar(x)\") Slice source, @SqlType(\"varchar(y)\") Slice prefix)\n+    {\n+        if (source.length() < prefix.length()) {\n+            return false;\n+        }\n+        return source.equals(0, prefix.length(), prefix, 0, prefix.length());\n+    }\n+\n     @Description(\"Returns index of first occurrence of a substring (or 0 if not found)\")\n     @ScalarFunction(\"strpos\")\n     @LiteralParameters({\"x\", \"y\"})\n"}
{"instance_id": "trinodb__trino-3208", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/connector/system/jdbc/TableJdbcTable.java b/presto-main/src/main/java/io/prestosql/connector/system/jdbc/TableJdbcTable.java\nindex 7e85dd22a73..9a991fe382d 100644\n--- a/presto-main/src/main/java/io/prestosql/connector/system/jdbc/TableJdbcTable.java\n+++ b/presto-main/src/main/java/io/prestosql/connector/system/jdbc/TableJdbcTable.java\n@@ -97,11 +97,18 @@ public class TableJdbcTable\n         for (String catalog : filter(listCatalogs(session, metadata, accessControl).keySet(), catalogFilter)) {\n             QualifiedTablePrefix prefix = tablePrefix(catalog, schemaFilter, tableFilter);\n \n+            Set<SchemaTableName> tables = listTables(session, metadata, accessControl, prefix);\n             Set<SchemaTableName> views = listViews(session, metadata, accessControl, prefix);\n-            for (SchemaTableName name : listTables(session, metadata, accessControl, prefix)) {\n-                boolean isView = views.contains(name);\n-                if ((includeTables && !isView) || (includeViews && isView)) {\n-                    table.addRow(tableRow(catalog, name, isView ? \"VIEW\" : \"TABLE\"));\n+            if (includeTables) {\n+                for (SchemaTableName name : tables) {\n+                    if (!views.contains(name)) {\n+                        table.addRow(tableRow(catalog, name, \"TABLE\"));\n+                    }\n+                }\n+            }\n+            if (includeViews) {\n+                for (SchemaTableName name : views) {\n+                    table.addRow(tableRow(catalog, name, \"VIEW\"));\n                 }\n             }\n         }\n"}
{"instance_id": "trinodb__trino-4393", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/BackgroundHiveSplitLoader.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/BackgroundHiveSplitLoader.java\nindex 5e770f27a52..8ee09d218f5 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/BackgroundHiveSplitLoader.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/BackgroundHiveSplitLoader.java\n@@ -567,7 +567,17 @@ public class BackgroundHiveSplitLoader\n             String fileName = file.getPath().getName();\n             OptionalInt bucket = getBucketNumber(fileName);\n             if (bucket.isPresent()) {\n-                bucketFiles.put(bucket.getAsInt(), file);\n+                int bucketNumber = bucket.getAsInt();\n+                if (bucketNumber >= partitionBucketCount) {\n+                    throw new PrestoException(HIVE_INVALID_BUCKET_FILES, format(\n+                            \"Hive table '%s' is corrupt. The file '%s' is for bucket %s, but the partition bucket count is %s for partition: %s\",\n+                            table.getSchemaTableName(),\n+                            fileName,\n+                            bucketNumber,\n+                            partitionBucketCount,\n+                            splitFactory.getPartitionName()));\n+                }\n+                bucketFiles.put(bucketNumber, file);\n                 continue;\n             }\n \n"}
{"instance_id": "trinodb__trino-3599", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\nindex 2fb86d047f8..81c7c71c14b 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\n@@ -309,10 +309,10 @@ public final class StringFunctions\n     @Description(\"Suffix starting at given index\")\n     @ScalarFunction(\"substr\")\n     @LiteralParameters(\"x\")\n-    @SqlType(\"char(x)\")\n+    @SqlType(\"varchar(x)\")\n     public static Slice charSubstr(@SqlType(\"char(x)\") Slice utf8, @SqlType(StandardTypes.BIGINT) long start)\n     {\n-        return substr(utf8, start);\n+        return substr(trimTrailingSpaces(utf8), start);\n     }\n \n     @Description(\"Substring of given length starting at an index\")\n@@ -367,10 +367,10 @@ public final class StringFunctions\n     @Description(\"Substring of given length starting at an index\")\n     @ScalarFunction(\"substr\")\n     @LiteralParameters(\"x\")\n-    @SqlType(\"char(x)\")\n+    @SqlType(\"varchar(x)\")\n     public static Slice charSubstr(@SqlType(\"char(x)\") Slice utf8, @SqlType(StandardTypes.BIGINT) long start, @SqlType(StandardTypes.BIGINT) long length)\n     {\n-        return trimTrailingSpaces(substr(utf8, start, length));\n+        return substr(trimTrailingSpaces(utf8), start, length);\n     }\n \n     @ScalarFunction\n"}
{"instance_id": "yt-dlp__yt-dlp-5195", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/yt_dlp/cookies.py b/yt_dlp/cookies.py\nindex 3032d0712..1bfb464e5 100644\n--- a/yt_dlp/cookies.py\n+++ b/yt_dlp/cookies.py\n@@ -1084,7 +1084,11 @@ def load(self, data):\n             elif value is not None:\n                 morsel = self.get(key, http.cookies.Morsel())\n                 real_value, coded_value = self.value_decode(value)\n-                morsel.set(key, real_value, coded_value)\n+                try:\n+                    morsel.set(key, real_value, coded_value)\n+                except http.cookies.CookieError:\n+                    morsel = None\n+                    continue\n                 self[key] = morsel\n \n             else:\n"}
{"instance_id": "yt-dlp__yt-dlp-4841", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/yt_dlp/utils.py b/yt_dlp/utils.py\nindex 90042aa8b..53939f290 100644\n--- a/yt_dlp/utils.py\n+++ b/yt_dlp/utils.py\n@@ -2479,7 +2479,7 @@ def url_basename(url):\n \n \n def base_url(url):\n-    return re.match(r'https?://[^?#&]+/', url).group()\n+    return re.match(r'https?://[^?#]+/', url).group()\n \n \n def urljoin(base, path):\n"}
{"instance_id": "trinodb__trino-3603", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/AddLocalExchanges.java b/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/AddLocalExchanges.java\nindex 25c568303bf..64ad05a5c41 100644\n--- a/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/AddLocalExchanges.java\n+++ b/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/AddLocalExchanges.java\n@@ -54,10 +54,15 @@ import io.prestosql.sql.planner.plan.TableFinishNode;\n import io.prestosql.sql.planner.plan.TableWriterNode;\n import io.prestosql.sql.planner.plan.TopNNode;\n import io.prestosql.sql.planner.plan.TopNRowNumberNode;\n+import io.prestosql.sql.planner.plan.ProjectNode;\n import io.prestosql.sql.planner.plan.UnionNode;\n import io.prestosql.sql.planner.plan.WindowNode;\n+import io.prestosql.sql.tree.Expression;\n+import io.prestosql.sql.tree.SymbolReference;\n \n import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.Map;\n import java.util.Iterator;\n import java.util.List;\n import java.util.Optional;\n@@ -168,6 +173,29 @@ public class AddLocalExchanges\n                     singleStream().withOrderSensitivity());\n         }\n \n+        @Override\n+        public PlanWithProperties visitProject(ProjectNode node, StreamPreferredProperties parentPreferences)\n+        {\n+            // For trivial projections (where all assignments are just symbol references),\n+            // we can pass through the parent preferences translated to the source symbols.\n+            // This avoids adding unnecessary local exchanges around trivial projections.\n+            Map<Symbol, Symbol> identities = computeIdentityTranslations(node.getAssignments().getMap());\n+\n+            StreamPreferredProperties translatedPreferences = parentPreferences.translate(symbol -> Optional.ofNullable(identities.get(symbol)));\n+            return planAndEnforceChildren(node, translatedPreferences, translatedPreferences);\n+        }\n+\n+        private Map<Symbol, Symbol> computeIdentityTranslations(Map<Symbol, Expression> assignments)\n+        {\n+            Map<Symbol, Symbol> outputToInput = new HashMap<>();\n+            for (Map.Entry<Symbol, Expression> assignment : assignments.entrySet()) {\n+                if (assignment.getValue() instanceof SymbolReference) {\n+                    outputToInput.put(assignment.getKey(), Symbol.from(assignment.getValue()));\n+                }\n+            }\n+            return outputToInput;\n+        }\n+\n         //\n         // Nodes that always require a single stream\n         //\n"}
{"instance_id": "yt-dlp__yt-dlp-5933", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/yt_dlp/options.py b/yt_dlp/options.py\nindex 83e851b19..11f7ef62b 100644\n--- a/yt_dlp/options.py\n+++ b/yt_dlp/options.py\n@@ -79,6 +79,13 @@ def _read_user_conf(package_name, default=None):\n         return default if default is not None else [], None\n \n     def _read_system_conf(package_name, default=None):\n+        # /etc/package_name.conf\n+        system_conf_file = os.path.join('/etc', '%s.conf' % package_name)\n+        system_conf = Config.read_file(system_conf_file, default=None)\n+        if system_conf is not None:\n+            return system_conf, system_conf_file\n+\n+        # /etc/package_name/config or /etc/package_name/config.txt\n         system_conf, system_conf_file = _load_from_config_dirs(get_system_config_dirs(package_name))\n         if system_conf is not None:\n             return system_conf, system_conf_file\n"}
{"instance_id": "yt-dlp__yt-dlp-9862", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/yt_dlp/YoutubeDL.py b/yt_dlp/YoutubeDL.py\nindex e56c3ed3c..3c879044c 100644\n--- a/yt_dlp/YoutubeDL.py\n+++ b/yt_dlp/YoutubeDL.py\n@@ -2191,7 +2191,6 @@ def _select_formats(self, formats, selector):\n         }))\n \n     def _default_format_spec(self, info_dict, download=True):\n-        download = download and not self.params.get('simulate')\n         prefer_best = download and (\n             self.params['outtmpl']['default'] == '-'\n             or info_dict.get('is_live') and not self.params.get('live_from_start'))\n"}
{"instance_id": "yt-dlp__yt-dlp-10390", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/yt_dlp/extractor/youtube.py b/yt_dlp/extractor/youtube.py\nindex 18e0ee91c..779c10a3d 100644\n--- a/yt_dlp/extractor/youtube.py\n+++ b/yt_dlp/extractor/youtube.py\n@@ -3130,8 +3130,21 @@ def _decrypt_nsig(self, s, video_id, player_url):\n \n     def _extract_n_function_name(self, jscode):\n         funcname, idx = self._search_regex(\n-            r'\\.get\\(\"n\"\\)\\)&&\\(b=(?P<nfunc>[a-zA-Z0-9$]+)(?:\\[(?P<idx>\\d+)\\])?\\([a-zA-Z0-9]\\)',\n-            jscode, 'Initial JS player n function name', group=('nfunc', 'idx'))\n+            r'''(?x)\n+                # Pattern 1: .get(\"n\"))&&(b=funcname[idx](a)\n+                \\.get\\(\"n\"\\)\\)&&\\(b=(?P<nfunc>[a-zA-Z0-9$]+)(?:\\[(?P<idx>\\d+)\\])?\\([a-zA-Z0-9]\\)\n+            ''',\n+            jscode, 'Initial JS player n function name', group=('nfunc', 'idx'), default=(None, None))\n+        if not funcname:\n+            # Pattern 2: (b=String.fromCharCode(110),c=a.get(b))&&(c=funcname[idx](c),a.set(b,c)\n+            funcname, idx = self._search_regex(\n+                r'\\(b=String\\.fromCharCode\\(110\\),c=a\\.get\\(b\\)\\)&&\\(c=(?P<nfunc>[a-zA-Z0-9$]+)(?:\\[(?P<idx>\\d+)\\])?\\([a-zA-Z0-9]\\)',\n+                jscode, 'Initial JS player n function name', group=('nfunc', 'idx'), default=(None, None))\n+        if not funcname:\n+            # Pattern 3: ||null)h=funcname[idx](h),V[  (array indexing pattern)\n+            funcname, idx = self._search_regex(\n+                r'\\|\\|null\\)(?P<var>[a-zA-Z])=(?P<nfunc>[a-zA-Z0-9$]+)(?:\\[(?P<idx>\\d+)\\])?\\((?P=var)\\),[a-zA-Z]\\[',\n+                jscode, 'Initial JS player n function name', group=('nfunc', 'idx'))\n         if not idx:\n             return funcname\n \n"}
{"instance_id": "trinodb__trino-3859", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/sql/relational/optimizer/ExpressionOptimizer.java b/presto-main/src/main/java/io/prestosql/sql/relational/optimizer/ExpressionOptimizer.java\nindex d859c2772f0..6508edc805e 100644\n--- a/presto-main/src/main/java/io/prestosql/sql/relational/optimizer/ExpressionOptimizer.java\n+++ b/presto-main/src/main/java/io/prestosql/sql/relational/optimizer/ExpressionOptimizer.java\n@@ -16,6 +16,7 @@ package io.prestosql.sql.relational.optimizer;\n import com.google.common.collect.ImmutableList;\n import com.google.common.collect.Iterables;\n import io.prestosql.Session;\n+import io.prestosql.metadata.FunctionKind;\n import io.prestosql.metadata.FunctionMetadata;\n import io.prestosql.metadata.Metadata;\n import io.prestosql.spi.connector.ConnectorSession;\n@@ -98,7 +99,9 @@ public class ExpressionOptimizer\n \n             // TODO: optimize function calls with lambda arguments. For example, apply(x -> x + 2, 1)\n             FunctionMetadata functionMetadata = metadata.getFunctionMetadata(call.getResolvedFunction());\n-            if (Iterables.all(arguments, instanceOf(ConstantExpression.class)) && functionMetadata.isDeterministic()) {\n+            if (functionMetadata.getKind() == FunctionKind.SCALAR &&\n+                    Iterables.all(arguments, instanceOf(ConstantExpression.class)) &&\n+                    functionMetadata.isDeterministic()) {\n                 MethodHandle method = metadata.getScalarFunctionImplementation(call.getResolvedFunction()).getMethodHandle();\n \n                 if (method.type().parameterCount() > 0 && method.type().parameterType(0) == ConnectorSession.class) {\n"}
{"instance_id": "mui__material-ui-12968", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/docs/src/pages/demos/text-fields/FilledTextFieldComposition.js b/docs/src/pages/demos/text-fields/FilledTextFieldComposition.js\nnew file mode 100644\nindex 0000000000..2787f700d9\n--- /dev/null\n+++ b/docs/src/pages/demos/text-fields/FilledTextFieldComposition.js\n@@ -0,0 +1,61 @@\n+import React from 'react';\n+import PropTypes from 'prop-types';\n+import { withStyles } from '@material-ui/core/styles';\n+import FilledInput from '@material-ui/core/FilledInput';\n+import InputLabel from '@material-ui/core/InputLabel';\n+import FormHelperText from '@material-ui/core/FormHelperText';\n+import FormControl from '@material-ui/core/FormControl';\n+\n+const styles = theme => ({\n+  container: {\n+    display: 'flex',\n+    flexWrap: 'wrap',\n+  },\n+  formControl: {\n+    margin: theme.spacing.unit,\n+  },\n+});\n+\n+class FilledTextFieldComposition extends React.Component {\n+  state = {\n+    name: 'Composed TextField',\n+  };\n+\n+  handleChange = event => {\n+    this.setState({ name: event.target.value });\n+  };\n+\n+  render() {\n+    const { classes } = this.props;\n+\n+    return (\n+      <div className={classes.container}>\n+        <FormControl className={classes.formControl} variant=\"filled\">\n+          <InputLabel htmlFor=\"name-filled-simple\">Name</InputLabel>\n+          <FilledInput id=\"name-filled-simple\" value={this.state.name} onChange={this.handleChange} />\n+        </FormControl>\n+        <FormControl className={classes.formControl} variant=\"filled\" aria-describedby=\"name-filled-helper-text\">\n+          <InputLabel htmlFor=\"name-filled-helper\">Name</InputLabel>\n+          <FilledInput id=\"name-filled-helper\" value={this.state.name} onChange={this.handleChange} />\n+          <FormHelperText id=\"name-filled-helper-text\">Some important helper text</FormHelperText>\n+        </FormControl>\n+        <FormControl className={classes.formControl} variant=\"filled\" disabled>\n+          <InputLabel htmlFor=\"name-filled-disabled\">Name</InputLabel>\n+          <FilledInput id=\"name-filled-disabled\" value={this.state.name} onChange={this.handleChange} />\n+          <FormHelperText>Disabled</FormHelperText>\n+        </FormControl>\n+        <FormControl className={classes.formControl} variant=\"filled\" error aria-describedby=\"name-filled-error-text\">\n+          <InputLabel htmlFor=\"name-filled-error\">Name</InputLabel>\n+          <FilledInput id=\"name-filled-error\" value={this.state.name} onChange={this.handleChange} />\n+          <FormHelperText id=\"name-filled-error-text\">Error</FormHelperText>\n+        </FormControl>\n+      </div>\n+    );\n+  }\n+}\n+\n+FilledTextFieldComposition.propTypes = {\n+  classes: PropTypes.object.isRequired,\n+};\n+\n+export default withStyles(styles)(FilledTextFieldComposition);\ndiff --git a/docs/src/pages/demos/text-fields/OutlinedTextFieldComposition.js b/docs/src/pages/demos/text-fields/OutlinedTextFieldComposition.js\nnew file mode 100644\nindex 0000000000..88c505c689\n--- /dev/null\n+++ b/docs/src/pages/demos/text-fields/OutlinedTextFieldComposition.js\n@@ -0,0 +1,107 @@\n+import React from 'react';\n+import PropTypes from 'prop-types';\n+import { withStyles } from '@material-ui/core/styles';\n+import OutlinedInput from '@material-ui/core/OutlinedInput';\n+import InputLabel from '@material-ui/core/InputLabel';\n+import FormHelperText from '@material-ui/core/FormHelperText';\n+import FormControl from '@material-ui/core/FormControl';\n+\n+const styles = theme => ({\n+  container: {\n+    display: 'flex',\n+    flexWrap: 'wrap',\n+  },\n+  formControl: {\n+    margin: theme.spacing.unit,\n+  },\n+});\n+\n+class OutlinedTextFieldComposition extends React.Component {\n+  state = {\n+    name: 'Composed TextField',\n+  };\n+\n+  labelRef = React.createRef();\n+\n+  componentDidMount() {\n+    this.forceUpdate();\n+  }\n+\n+  handleChange = event => {\n+    this.setState({ name: event.target.value });\n+  };\n+\n+  render() {\n+    const { classes } = this.props;\n+\n+    return (\n+      <div className={classes.container}>\n+        <FormControl className={classes.formControl} variant=\"outlined\">\n+          <InputLabel\n+            ref={this.labelRef}\n+            htmlFor=\"name-outlined-simple\"\n+          >\n+            Name\n+          </InputLabel>\n+          <OutlinedInput\n+            id=\"name-outlined-simple\"\n+            value={this.state.name}\n+            onChange={this.handleChange}\n+            labelWidth={this.labelRef.current ? this.labelRef.current.offsetWidth : 0}\n+          />\n+        </FormControl>\n+        <FormControl className={classes.formControl} variant=\"outlined\" aria-describedby=\"name-outlined-helper-text\">\n+          <InputLabel\n+            ref={this.labelRef}\n+            htmlFor=\"name-outlined-helper\"\n+          >\n+            Name\n+          </InputLabel>\n+          <OutlinedInput\n+            id=\"name-outlined-helper\"\n+            value={this.state.name}\n+            onChange={this.handleChange}\n+            labelWidth={this.labelRef.current ? this.labelRef.current.offsetWidth : 0}\n+          />\n+          <FormHelperText id=\"name-outlined-helper-text\">Some important helper text</FormHelperText>\n+        </FormControl>\n+        <FormControl className={classes.formControl} variant=\"outlined\" disabled>\n+          <InputLabel\n+            ref={this.labelRef}\n+            htmlFor=\"name-outlined-disabled\"\n+          >\n+            Name\n+          </InputLabel>\n+          <OutlinedInput\n+            id=\"name-outlined-disabled\"\n+            value={this.state.name}\n+            onChange={this.handleChange}\n+            labelWidth={this.labelRef.current ? this.labelRef.current.offsetWidth : 0}\n+          />\n+          <FormHelperText>Disabled</FormHelperText>\n+        </FormControl>\n+        <FormControl className={classes.formControl} variant=\"outlined\" error aria-describedby=\"name-outlined-error-text\">\n+          <InputLabel\n+            ref={this.labelRef}\n+            htmlFor=\"name-outlined-error\"\n+          >\n+            Name\n+          </InputLabel>\n+          <OutlinedInput\n+            id=\"name-outlined-error\"\n+            value={this.state.name}\n+            onChange={this.handleChange}\n+            labelWidth={this.labelRef.current ? this.labelRef.current.offsetWidth : 0}\n+          />\n+          <FormHelperText id=\"name-outlined-error-text\">Error</FormHelperText>\n+        </FormControl>\n+      </div>\n+    );\n+  }\n+}\n+\n+OutlinedTextFieldComposition.propTypes = {\n+  classes: PropTypes.object.isRequired,\n+};\n+\n+export default withStyles(styles)(OutlinedTextFieldComposition);\ndiff --git a/docs/src/pages/demos/text-fields/text-fields.md b/docs/src/pages/demos/text-fields/text-fields.md\nindex 2809b8953e..8ccd85460f 100644\n--- a/docs/src/pages/demos/text-fields/text-fields.md\n+++ b/docs/src/pages/demos/text-fields/text-fields.md\n@@ -37,6 +37,18 @@ The component takes care of the most used properties, then it's up to the user t\n \n {{\"demo\": \"pages/demos/text-fields/ComposedTextField.js\"}}\n \n+### Filled\n+\n+When using [`FilledInput`](/api/filled-input) instead of [`Input`](/api/input), you need to pass `variant=\"filled\"` to [`FormControl`](/api/form-control) so that [`InputLabel`](/api/input-label) and [`FormHelperText`](/api/form-helper-text) are styled correctly.\n+\n+{{\"demo\": \"pages/demos/text-fields/FilledTextFieldComposition.js\"}}\n+\n+### Outlined\n+\n+When using [`OutlinedInput`](/api/outlined-input) instead of [`Input`](/api/input), you need to pass `variant=\"outlined\"` to [`FormControl`](/api/form-control) so that [`InputLabel`](/api/input-label) and [`FormHelperText`](/api/form-helper-text) are styled correctly. You also need to provide a `labelWidth` prop to [`OutlinedInput`](/api/outlined-input) so that the outline notch has the correct width.\n+\n+{{\"demo\": \"pages/demos/text-fields/OutlinedTextFieldComposition.js\"}}\n+\n ## Inputs\n \n {{\"demo\": \"pages/demos/text-fields/Inputs.js\"}}\n"}
{"instance_id": "trinodb__trino-2081", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/metadata/FunctionRegistry.java b/presto-main/src/main/java/io/prestosql/metadata/FunctionRegistry.java\nindex e5ea57abd3c..49e884845ef 100644\n--- a/presto-main/src/main/java/io/prestosql/metadata/FunctionRegistry.java\n+++ b/presto-main/src/main/java/io/prestosql/metadata/FunctionRegistry.java\n@@ -200,6 +200,7 @@ import io.prestosql.type.setdigest.SetDigestOperators;\n import javax.annotation.concurrent.ThreadSafe;\n \n import java.util.ArrayList;\n+import java.util.Arrays;\n import java.util.Collection;\n import java.util.List;\n import java.util.Map;\n@@ -1063,7 +1064,7 @@ public class FunctionRegistry\n \n     private ResolvedFunction resolveCoercion(Signature signature)\n     {\n-        Collection<FunctionMetadata> allCandidates = functions.get(QualifiedName.of(signature.getName()));\n+        Collection<FunctionMetadata> allCandidates = functions.get(toQualifiedName(signature.getName()));\n \n         List<TypeSignatureProvider> argumentTypeSignatureProviders = fromTypeSignatures(signature.getArgumentTypes());\n \n@@ -1130,6 +1131,16 @@ public class FunctionRegistry\n         return boundVariables.isPresent();\n     }\n \n+    /**\n+     * Converts a function name string (which may contain dots) to a QualifiedName.\n+     * For example, \"default.pretradedate\" becomes a QualifiedName with parts [\"default\", \"pretradedate\"].\n+     */\n+    private static QualifiedName toQualifiedName(String name)\n+    {\n+        String[] parts = name.split(\"\\\\.\");\n+        return QualifiedName.of(parts[0], Arrays.copyOfRange(parts, 1, parts.length));\n+    }\n+\n     private static class FunctionMap\n     {\n         private final Map<FunctionId, SqlFunction> functions;\n@@ -1152,7 +1163,7 @@ public class FunctionRegistry\n                     .putAll(map.functionsByName);\n             functions.stream()\n                     .map(SqlFunction::getFunctionMetadata)\n-                    .forEach(functionMetadata -> functionsByName.put(QualifiedName.of(functionMetadata.getSignature().getName()), functionMetadata));\n+                    .forEach(functionMetadata -> functionsByName.put(toQualifiedName(functionMetadata.getSignature().getName()), functionMetadata));\n             this.functionsByName = functionsByName.build();\n \n             // Make sure all functions with the same name are aggregations or none of them are\n"}
{"instance_id": "microsoft__vscode-157682", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/editor/contrib/codeAction/browser/codeAction.ts b/src/vs/editor/contrib/codeAction/browser/codeAction.ts\nindex 009f7b05ca8..019ee53425f 100644\n--- a/src/vs/editor/contrib/codeAction/browser/codeAction.ts\n+++ b/src/vs/editor/contrib/codeAction/browser/codeAction.ts\n@@ -72,11 +72,15 @@ class ManagedCodeActionSet extends Disposable implements CodeActionSet {\n \n \tprivate static codeActionsComparator({ action: a }: CodeActionItem, { action: b }: CodeActionItem): number {\n \t\tif (isNonEmptyArray(a.diagnostics)) {\n-\t\t\treturn -1;\n+\t\t\tif (isNonEmptyArray(b.diagnostics)) {\n+\t\t\t\treturn ManagedCodeActionSet.codeActionsPreferredComparator(a, b);\n+\t\t\t} else {\n+\t\t\t\treturn -1;\n+\t\t\t}\n \t\t} else if (isNonEmptyArray(b.diagnostics)) {\n \t\t\treturn 1;\n \t\t} else {\n-\t\t\treturn ManagedCodeActionSet.codeActionsPreferredComparator(a, b); // both have no diagnostics\n+\t\t\treturn ManagedCodeActionSet.codeActionsPreferredComparator(a, b);\n \t\t}\n \t}\n \n"}
{"instance_id": "huggingface__transformers-13693", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py b/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\nindex 6aa60df5..fa4937e1 100644\n--- a/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\n+++ b/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\n@@ -16,7 +16,7 @@\n Feature extractor class for Wav2Vec2\n \"\"\"\n \n-from typing import List, Optional, Union\n+from typing import Dict, List, Optional, Union\n \n import numpy as np\n \n@@ -78,6 +78,130 @@ class Wav2Vec2FeatureExtractor(SequenceFeatureExtractor):\n         self.return_attention_mask = return_attention_mask\n         self.do_normalize = do_normalize\n \n+    def _normalize_input_values(\n+        self,\n+        processed_features: Union[\n+            BatchFeature,\n+            List[BatchFeature],\n+            Dict[str, BatchFeature],\n+            Dict[str, List[BatchFeature]],\n+            List[Dict[str, BatchFeature]],\n+        ],\n+    ) -> Union[\n+        BatchFeature,\n+        List[BatchFeature],\n+        Dict[str, BatchFeature],\n+        Dict[str, List[BatchFeature]],\n+        List[Dict[str, BatchFeature]],\n+    ]:\n+        \"\"\"\n+        Normalize input_values to float32 dtype.\n+        \"\"\"\n+        # If we have a list of dicts, normalize each dict's input_values\n+        if isinstance(processed_features, (list, tuple)) and isinstance(processed_features[0], (dict, BatchFeature)):\n+            for i, feature_dict in enumerate(processed_features):\n+                if \"input_values\" in feature_dict:\n+                    input_values = feature_dict[\"input_values\"]\n+                    if isinstance(input_values, np.ndarray) and input_values.dtype == np.float64:\n+                        processed_features[i][\"input_values\"] = input_values.astype(np.float32)\n+        # If we have a dict with input_values\n+        elif isinstance(processed_features, (dict, BatchFeature)):\n+            if \"input_values\" in processed_features:\n+                input_values = processed_features[\"input_values\"]\n+                # If input_values is a list of arrays\n+                if isinstance(input_values, (list, tuple)):\n+                    processed_features[\"input_values\"] = [\n+                        array.astype(np.float32) if isinstance(array, np.ndarray) and array.dtype == np.float64 else array\n+                        for array in input_values\n+                    ]\n+                # If input_values is a single array\n+                elif isinstance(input_values, np.ndarray) and input_values.dtype == np.float64:\n+                    processed_features[\"input_values\"] = input_values.astype(np.float32)\n+\n+        return processed_features\n+\n+    def pad(\n+        self,\n+        processed_features: Union[\n+            BatchFeature,\n+            List[BatchFeature],\n+            Dict[str, BatchFeature],\n+            Dict[str, List[BatchFeature]],\n+            List[Dict[str, BatchFeature]],\n+        ],\n+        padding: Union[bool, str, PaddingStrategy] = True,\n+        max_length: Optional[int] = None,\n+        truncation: bool = False,\n+        pad_to_multiple_of: Optional[int] = None,\n+        return_attention_mask: Optional[bool] = None,\n+        return_tensors: Optional[Union[str, TensorType]] = None,\n+    ) -> BatchFeature:\n+        \"\"\"\n+        Pad input values / input vectors or a batch of input values / input vectors up to predefined length or to the\n+        max sequence length in the batch.\n+\n+        Padding side (left/right) padding values are defined at the feature extractor level (with\n+        ``self.padding_side``, ``self.padding_value``)\n+\n+        .. note::\n+\n+            If the ``processed_features`` passed are dictionary of numpy arrays, PyTorch tensors or TensorFlow tensors,\n+            the result will use the same type unless you provide a different tensor type with ``return_tensors``. In\n+            the case of PyTorch tensors, you will lose the specific device of your tensors however.\n+\n+        Args:\n+            processed_features (:class:`~transformers.BatchFeature`, list of :class:`~transformers.BatchFeature`, :obj:`Dict[str, List[float]]`, :obj:`Dict[str, List[List[float]]` or :obj:`List[Dict[str, List[float]]]`):\n+                Processed inputs. Can represent one input (:class:`~transformers.BatchFeature` or :obj:`Dict[str,\n+                List[float]]`) or a batch of input values / vectors (list of :class:`~transformers.BatchFeature`,\n+                `Dict[str, List[List[float]]]` or `List[Dict[str, List[float]]]`) so you can use this method during\n+                preprocessing as well as in a PyTorch Dataloader collate function.\n+\n+                Instead of :obj:`List[float]` you can have tensors (numpy arrays, PyTorch tensors or TensorFlow\n+                tensors), see the note above for the return type.\n+            padding (:obj:`bool`, :obj:`str` or :class:`~transformers.file_utils.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n+                Select a strategy to pad the returned sequences (according to the model's padding side and padding\n+                index) among:\n+\n+                * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a\n+                  single sequence if provided).\n+                * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n+                  maximum acceptable input length for the model if that argument is not provided.\n+                * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n+                  different lengths).\n+            max_length (:obj:`int`, `optional`):\n+                Maximum length of the returned list and optionally padding length (see above).\n+            truncation (:obj:`bool`):\n+                Activates truncation to cut input sequences longer than :obj:`max_length` to :obj:`max_length`.\n+            pad_to_multiple_of (:obj:`int`, `optional`):\n+                If set will pad the sequence to a multiple of the provided value.\n+\n+                This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability\n+                >= 7.5 (Volta), or on TPUs which benefit from having sequence lengths be a multiple of 128.\n+            return_attention_mask (:obj:`bool`, `optional`):\n+                Whether to return the attention mask. If left to the default, will return the attention mask according\n+                to the specific feature_extractor's default.\n+\n+                `What are attention masks? <../glossary.html#attention-mask>`__\n+            return_tensors (:obj:`str` or :class:`~transformers.file_utils.TensorType`, `optional`):\n+                If set, will return tensors instead of list of python integers. Acceptable values are:\n+\n+                * :obj:`'tf'`: Return TensorFlow :obj:`tf.constant` objects.\n+                * :obj:`'pt'`: Return PyTorch :obj:`torch.Tensor` objects.\n+                * :obj:`'np'`: Return Numpy :obj:`np.ndarray` objects.\n+        \"\"\"\n+        # Normalize input_values to float32 before padding\n+        processed_features = self._normalize_input_values(processed_features)\n+\n+        return super().pad(\n+            processed_features,\n+            padding=padding,\n+            max_length=max_length,\n+            truncation=truncation,\n+            pad_to_multiple_of=pad_to_multiple_of,\n+            return_attention_mask=return_attention_mask,\n+            return_tensors=return_tensors,\n+        )\n+\n     @staticmethod\n     def zero_mean_unit_var_norm(\n         input_values: List[np.ndarray], attention_mask: List[np.ndarray], padding_value: float = 0.0\n"}
{"instance_id": "microsoft__vscode-177084", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\nindex 57dcd68c78a..d5b790c5a1d 100644\n--- a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\n+++ b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\n@@ -204,8 +204,9 @@ export function toLinkSuffix(match: RegExpExecArray | null): ILinkSuffix | null\n \t};\n }\n \n-// Paths cannot start with opening brackets\n-const linkWithSuffixPathCharacters = /(?<path>[^\\s\\[\\({][^\\s]*)$/;\n+// Paths cannot start with opening brackets or pipe characters\n+// Also exclude pipe characters from the path to avoid matching log separators like \"|ERROR|\"\n+const linkWithSuffixPathCharacters = /(?<path>[^\\s\\[\\({|][^\\s|]*)$/;\n \n export function detectLinks(line: string, os: OperatingSystem) {\n \t// 1: Detect all links on line via suffixes first\n"}
{"instance_id": "mui__material-ui-19794", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex 2678596db..b24375c25 100644\n--- a/package.json\n+++ b/package.json\n@@ -104,7 +104,6 @@\n     \"fs-extra\": \"^8.1.0\",\n     \"glob\": \"^7.1.2\",\n     \"glob-gitignore\": \"^1.0.11\",\n-    \"lodash\": \"^4.17.15\",\n     \"jsdom\": \"^16.0.0\",\n     \"karma\": \"^4.3.0\",\n     \"karma-browserstack-launcher\": \"~1.4.0\",\n@@ -114,7 +113,8 @@\n     \"karma-sourcemap-loader\": \"^0.3.7\",\n     \"karma-webpack\": \"^4.0.2\",\n     \"lerna\": \"^3.16.4\",\n-    \"mocha\": \"^7.0.0\",\n+    \"lodash\": \"^4.17.15\",\n+    \"mocha\": \"^8.4.0\",\n     \"node-fetch\": \"^ 2.6.0\",\n     \"nyc\": \"^15.0.0\",\n     \"prettier\": \"1.17.0\",\n@@ -172,6 +172,5 @@\n     \"packages/*\",\n     \"docs\",\n     \"framer\"\n-  ],\n-  \"dependencies\": {}\n+  ]\n }\ndiff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 9957ed76d..f427d0aa9 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -768,7 +768,7 @@ export default function useAutocomplete(props) {\n   };\n \n   // Focus the input when first interacting with the combobox\n-  const handleClick = () => {\n+  const handleClick = event => {\n     if (\n       firstFocus.current &&\n       inputRef.current.selectionEnd - inputRef.current.selectionStart === 0\n@@ -783,6 +783,34 @@ export default function useAutocomplete(props) {\n     firstFocus.current = false;\n   };\n \n+  // Handle the click event on the root element to close the popup when clicking outside the input\n+  const handleRootClick = event => {\n+    handleClick(event);\n+\n+    // Ignore the event when clicking on the input\n+    if (event.target.getAttribute('id') === id) {\n+      return;\n+    }\n+\n+    // Ignore the event when clicking on a button (popup indicator or clear button)\n+    if (event.target.tagName === 'BUTTON' || event.target.closest('button') !== null) {\n+      return;\n+    }\n+\n+    // Ignore the event when clicking on a tag\n+    if (\n+      event.target.hasAttribute('data-tag-index') ||\n+      event.target.closest('[data-tag-index]') !== null\n+    ) {\n+      return;\n+    }\n+\n+    // Close the popup when clicking on the root element (e.g., the outline)\n+    if (popupOpen) {\n+      handleClose(event);\n+    }\n+  };\n+\n   const handleInputMouseDown = event => {\n     if (inputValue === '' && (!disableOpenOnFocus || inputRef.current === document.activeElement)) {\n       handlePopupIndicator(event);\n@@ -831,7 +859,7 @@ export default function useAutocomplete(props) {\n       ...other,\n       onKeyDown: handleKeyDown(other),\n       onMouseDown: handleMouseDown,\n-      onClick: handleClick,\n+      onClick: handleRootClick,\n     }),\n     getInputLabelProps: () => ({\n       id: `${id}-label`,\n"}
{"instance_id": "sveltejs__svelte-5452", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/render_dom/invalidate.ts b/src/compiler/compile/render_dom/invalidate.ts\nindex b045db079..b0e7129af 100644\n--- a/src/compiler/compile/render_dom/invalidate.ts\n+++ b/src/compiler/compile/render_dom/invalidate.ts\n@@ -47,6 +47,7 @@ export function invalidate(renderer: Renderer, scope: Scope, node: Node, names:\n \n \t\t\tconst pass_value = (\n \t\t\t\t!main_execution_context && \n+\t\t\t\t!is_store_value &&\n \t\t\t\t(\n \t\t\t\t\textra_args.length > 0 ||\n \t\t\t\t\t(node.type === 'AssignmentExpression' && node.left.type !== 'Identifier') ||\n@@ -61,13 +62,19 @@ export function invalidate(renderer: Renderer, scope: Scope, node: Node, names:\n \t\t\t\t});\n \t\t\t}\n \n-\t\t\tlet invalidate = is_store_value\n-\t\t\t\t? x`@set_store_value(${head.name.slice(1)}, ${node}, ${head.name})`\n-\t\t\t\t: !main_execution_context\n-\t\t\t\t\t? x`$$invalidate(${renderer.context_lookup.get(head.name).index}, ${node}, ${extra_args})`\n-\t\t\t\t\t: extra_args.length\n-\t\t\t\t\t\t? [node, ...extra_args]\n-\t\t\t\t\t\t: node;\n+\t\t\tlet invalidate;\n+\t\t\tif (is_store_value) {\n+\t\t\t\tinvalidate = x`@set_store_value(${head.name.slice(1)}, ${node}, ${head.name})`;\n+\t\t\t\tif (extra_args.length > 0) {\n+\t\t\t\t\tinvalidate = [invalidate, ...extra_args].reduce((lhs, rhs) => x`${lhs}, ${rhs}`);\n+\t\t\t\t}\n+\t\t\t} else if (!main_execution_context) {\n+\t\t\t\tinvalidate = x`$$invalidate(${renderer.context_lookup.get(head.name).index}, ${node}, ${extra_args})`;\n+\t\t\t} else if (extra_args.length) {\n+\t\t\t\tinvalidate = [node, ...extra_args];\n+\t\t\t} else {\n+\t\t\t\tinvalidate = node;\n+\t\t\t}\n \n \t\t\tif (head.subscribable && head.reassigned) {\n \t\t\t\tconst subscribe = `$$subscribe_${head.name}`;\n"}
{"instance_id": "microsoft__vscode-109750", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/platform/configuration/common/configurationRegistry.ts b/src/vs/platform/configuration/common/configurationRegistry.ts\nindex fceaa0a0e8..8bc9618ba3 100644\n--- a/src/vs/platform/configuration/common/configurationRegistry.ts\n+++ b/src/vs/platform/configuration/common/configurationRegistry.ts\n@@ -227,9 +227,15 @@ class ConfigurationRegistry implements IConfigurationRegistry {\n \t\tfor (const defaultConfiguration of defaultConfigurations) {\n \t\t\tfor (const key in defaultConfiguration) {\n \t\t\t\tproperties.push(key);\n-\t\t\t\tthis.defaultValues[key] = defaultConfiguration[key];\n \n \t\t\t\tif (OVERRIDE_PROPERTY_PATTERN.test(key)) {\n+\t\t\t\t\tconst existingDefaultValue = this.defaultValues[key];\n+\t\t\t\t\tif (existingDefaultValue) {\n+\t\t\t\t\t\t// Merge the new default value with the existing one\n+\t\t\t\t\t\tthis.defaultValues[key] = { ...existingDefaultValue, ...defaultConfiguration[key] };\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tthis.defaultValues[key] = defaultConfiguration[key];\n+\t\t\t\t\t}\n \t\t\t\t\tconst property: IConfigurationPropertySchema = {\n \t\t\t\t\t\ttype: 'object',\n \t\t\t\t\t\tdefault: this.defaultValues[key],\n@@ -240,6 +246,7 @@ class ConfigurationRegistry implements IConfigurationRegistry {\n \t\t\t\t\tthis.configurationProperties[key] = property;\n \t\t\t\t\tthis.defaultLanguageConfigurationOverridesNode.properties![key] = property;\n \t\t\t\t} else {\n+\t\t\t\t\tthis.defaultValues[key] = defaultConfiguration[key];\n \t\t\t\t\tconst property = this.configurationProperties[key];\n \t\t\t\t\tif (property) {\n \t\t\t\t\t\tthis.updatePropertyDefaultValue(key, property);\n@@ -259,11 +266,28 @@ class ConfigurationRegistry implements IConfigurationRegistry {\n \t\tfor (const defaultConfiguration of defaultConfigurations) {\n \t\t\tfor (const key in defaultConfiguration) {\n \t\t\t\tproperties.push(key);\n-\t\t\t\tdelete this.defaultValues[key];\n \t\t\t\tif (OVERRIDE_PROPERTY_PATTERN.test(key)) {\n-\t\t\t\t\tdelete this.configurationProperties[key];\n-\t\t\t\t\tdelete this.defaultLanguageConfigurationOverridesNode.properties![key];\n+\t\t\t\t\tconst defaultValue = this.defaultValues[key];\n+\t\t\t\t\tif (defaultValue) {\n+\t\t\t\t\t\t// Remove the properties that were contributed by this extension\n+\t\t\t\t\t\tfor (const subKey in defaultConfiguration[key]) {\n+\t\t\t\t\t\t\tdelete defaultValue[subKey];\n+\t\t\t\t\t\t}\n+\t\t\t\t\t\t// If there are no more properties, delete the entire default value\n+\t\t\t\t\t\tif (Object.keys(defaultValue).length === 0) {\n+\t\t\t\t\t\t\tdelete this.defaultValues[key];\n+\t\t\t\t\t\t\tdelete this.configurationProperties[key];\n+\t\t\t\t\t\t\tdelete this.defaultLanguageConfigurationOverridesNode.properties![key];\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t// Update the property with the remaining default value\n+\t\t\t\t\t\t\tconst property: IConfigurationPropertySchema = this.configurationProperties[key];\n+\t\t\t\t\t\t\tif (property) {\n+\t\t\t\t\t\t\t\tproperty.default = defaultValue;\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n+\t\t\t\t\t}\n \t\t\t\t} else {\n+\t\t\t\t\tdelete this.defaultValues[key];\n \t\t\t\t\tconst property = this.configurationProperties[key];\n \t\t\t\t\tif (property) {\n \t\t\t\t\t\tthis.updatePropertyDefaultValue(key, property);\n"}
{"instance_id": "microsoft__vscode-113837", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/base/browser/ui/highlightedlabel/highlightedLabel.ts b/src/vs/base/browser/ui/highlightedlabel/highlightedLabel.ts\nindex 552f1e57d1..802bf05a8c 100644\n--- a/src/vs/base/browser/ui/highlightedlabel/highlightedLabel.ts\n+++ b/src/vs/base/browser/ui/highlightedlabel/highlightedLabel.ts\n@@ -62,7 +62,6 @@ export class HighlightedLabel {\n \t\t\tif (pos < highlight.start) {\n \t\t\t\tconst substring = this.text.substring(pos, highlight.start);\n \t\t\t\tchildren.push(dom.$('span', undefined, ...this.supportIcons ? renderLabelWithIcons(substring) : [substring]));\n-\t\t\t\tpos = highlight.end;\n \t\t\t}\n \n \t\t\tconst substring = this.text.substring(highlight.start, highlight.end);\n"}
{"instance_id": "sveltejs__svelte-6414", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/package.json b/package.json\nindex d3bfe1438..3b06dfa60 100644\n--- a/package.json\n+++ b/package.json\n@@ -110,7 +110,7 @@\n     \"acorn\": \"^7.4.0\",\n     \"agadoo\": \"^1.1.0\",\n     \"c8\": \"^5.0.1\",\n-    \"code-red\": \"^0.1.4\",\n+    \"code-red\": \"0.1.4\",\n     \"codecov\": \"^3.5.0\",\n     \"css-tree\": \"^1.1.2\",\n     \"eslint\": \"^7.15.0\",\ndiff --git a/src/compiler/compile/render_dom/wrappers/Slot.ts b/src/compiler/compile/render_dom/wrappers/Slot.ts\nindex d4629550b..5f60a1766 100644\n--- a/src/compiler/compile/render_dom/wrappers/Slot.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Slot.ts\n@@ -169,15 +169,39 @@ export default class SlotWrapper extends Wrapper {\n \t\t\tcondition = x`!#current || ${condition}`;\n \t\t}\n \n-\t\tconst slot_update = get_slot_spread_changes_fn ? b`\n-\t\t\tif (${slot}.p && ${condition}) {\n-\t\t\t\t@update_slot_spread(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, #dirty, ${get_slot_changes_fn}, ${get_slot_spread_changes_fn}, ${get_slot_context_fn});\n-\t\t\t}\n-\t\t` : b`\n-\t\t\tif (${slot}.p && ${condition}) {\n-\t\t\t\t@update_slot(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, #dirty, ${get_slot_changes_fn}, ${get_slot_context_fn});\n-\t\t\t}\n-\t\t`;\n+\t\t// When the slot is coming back from an outro, we need to force update the slot\n+\t\t// by passing -1 as the slot_changes. This ensures that the slot content is\n+\t\t// updated even if the dirty bits don't reflect the changes that happened during the outro.\n+\t\tlet slot_update;\n+\t\tif (block.has_outros) {\n+\t\t\tslot_update = get_slot_spread_changes_fn\n+\t\t\t\t? b`\n+\t\t\t\t\tif (${slot}.p && ${condition}) {\n+\t\t\t\t\t\t@update_slot_base(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, !#current\n+\t\t\t\t\t\t\t? @get_all_dirty_from_scope(${renderer.reference('$$scope')})\n+\t\t\t\t\t\t\t: ${get_slot_spread_changes_fn}(#dirty) | @get_slot_changes(${slot_definition}, ${renderer.reference('$$scope')}, #dirty, ${get_slot_changes_fn}), ${get_slot_context_fn});\n+\t\t\t\t\t}\n+\t\t\t\t`\n+\t\t\t\t: b`\n+\t\t\t\t\tif (${slot}.p && ${condition}) {\n+\t\t\t\t\t\t@update_slot_base(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, !#current\n+\t\t\t\t\t\t\t? @get_all_dirty_from_scope(${renderer.reference('$$scope')})\n+\t\t\t\t\t\t\t: @get_slot_changes(${slot_definition}, ${renderer.reference('$$scope')}, #dirty, ${get_slot_changes_fn}), ${get_slot_context_fn});\n+\t\t\t\t\t}\n+\t\t\t\t`;\n+\t\t} else {\n+\t\t\tslot_update = get_slot_spread_changes_fn\n+\t\t\t\t? b`\n+\t\t\t\t\tif (${slot}.p && ${condition}) {\n+\t\t\t\t\t\t@update_slot_spread(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, #dirty, ${get_slot_changes_fn}, ${get_slot_spread_changes_fn}, ${get_slot_context_fn});\n+\t\t\t\t\t}\n+\t\t\t\t`\n+\t\t\t\t: b`\n+\t\t\t\t\tif (${slot}.p && ${condition}) {\n+\t\t\t\t\t\t@update_slot(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, #dirty, ${get_slot_changes_fn}, ${get_slot_context_fn});\n+\t\t\t\t\t}\n+\t\t\t\t`;\n+\t\t}\n \t\tconst fallback_update = has_fallback && fallback_dynamic_dependencies.length > 0 && b`\n \t\t\tif (${slot_or_fallback} && ${slot_or_fallback}.p && ${renderer.dirty(fallback_dynamic_dependencies)}) {\n \t\t\t\t${slot_or_fallback}.p(#ctx, #dirty);\ndiff --git a/src/runtime/internal/utils.ts b/src/runtime/internal/utils.ts\nindex 084019fb5..df169c906 100644\n--- a/src/runtime/internal/utils.ts\n+++ b/src/runtime/internal/utils.ts\n@@ -109,20 +109,33 @@ export function get_slot_changes(definition, $$scope, dirty, fn) {\n \treturn $$scope.dirty;\n }\n \n-export function update_slot(slot, slot_definition, ctx, $$scope, dirty, get_slot_changes_fn, get_slot_context_fn) {\n-\tconst slot_changes = get_slot_changes(slot_definition, $$scope, dirty, get_slot_changes_fn);\n+export function get_all_dirty_from_scope($$scope) {\n+\tif ($$scope.ctx.length > 32) {\n+\t\tconst dirty = [];\n+\t\tconst length = $$scope.ctx.length / 32;\n+\t\tfor (let i = 0; i < length; i++) {\n+\t\t\tdirty[i] = -1;\n+\t\t}\n+\t\treturn dirty;\n+\t}\n+\treturn -1;\n+}\n+\n+export function update_slot_base(slot, slot_definition, ctx, $$scope, slot_changes, get_slot_context_fn) {\n \tif (slot_changes) {\n \t\tconst slot_context = get_slot_context(slot_definition, ctx, $$scope, get_slot_context_fn);\n \t\tslot.p(slot_context, slot_changes);\n \t}\n }\n \n+export function update_slot(slot, slot_definition, ctx, $$scope, dirty, get_slot_changes_fn, get_slot_context_fn) {\n+\tconst slot_changes = get_slot_changes(slot_definition, $$scope, dirty, get_slot_changes_fn);\n+\tupdate_slot_base(slot, slot_definition, ctx, $$scope, slot_changes, get_slot_context_fn);\n+}\n+\n export function update_slot_spread(slot, slot_definition, ctx, $$scope, dirty, get_slot_changes_fn, get_slot_spread_changes_fn, get_slot_context_fn) {\n \tconst slot_changes = get_slot_spread_changes_fn(dirty) | get_slot_changes(slot_definition, $$scope, dirty, get_slot_changes_fn);\n-\tif (slot_changes) {\n-\t\tconst slot_context = get_slot_context(slot_definition, ctx, $$scope, get_slot_context_fn);\n-\t\tslot.p(slot_context, slot_changes);\n-\t}\n+\tupdate_slot_base(slot, slot_definition, ctx, $$scope, slot_changes, get_slot_context_fn);\n }\n \n export function exclude_internal_props(props) {\n"}
{"instance_id": "mui__material-ui-42412", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": " "}
{"instance_id": "keras-team__keras-18553", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/keras/backend/torch/nn.py b/keras/backend/torch/nn.py\nindex c04584c48..4a826302a 100644\n--- a/keras/backend/torch/nn.py\n+++ b/keras/backend/torch/nn.py\n@@ -202,6 +202,7 @@ def max_pool(\n     inputs = convert_to_tensor(inputs)\n     num_spatial_dims = inputs.ndim - 2\n     pool_size = standardize_tuple(pool_size, num_spatial_dims, \"pool_size\")\n+    padding = padding.lower()\n     if strides is None:\n         strides = pool_size\n     else:\n@@ -255,6 +256,7 @@ def average_pool(\n     inputs = convert_to_tensor(inputs)\n     num_spatial_dims = inputs.ndim - 2\n     pool_size = standardize_tuple(pool_size, num_spatial_dims, \"pool_size\")\n+    padding = padding.lower()\n     if strides is None:\n         strides = pool_size\n     else:\n@@ -331,6 +333,7 @@ def conv(\n     kernel = convert_to_tensor(kernel)\n     num_spatial_dims = inputs.ndim - 2\n     strides = standardize_tuple(strides, num_spatial_dims, \"strides\")\n+    padding = padding.lower()\n \n     data_format = standardize_data_format(data_format)\n     if data_format == \"channels_last\":\n"}
{"instance_id": "sveltejs__svelte-3394", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/compiler/compile/nodes/shared/Expression.ts b/src/compiler/compile/nodes/shared/Expression.ts\nindex 938cd843..b67c18ba 100644\n--- a/src/compiler/compile/nodes/shared/Expression.ts\n+++ b/src/compiler/compile/nodes/shared/Expression.ts\n@@ -10,6 +10,7 @@ import Wrapper from '../../render_dom/wrappers/shared/Wrapper';\n \n import TemplateScope from './TemplateScope';\n import get_object from '../../utils/get_object';\n+import unwrap_parens from '../../utils/unwrap_parens';\n import { nodes_match } from '../../../utils/nodes_match';\n import Block from '../../render_dom/Block';\n import { INode } from '../interfaces';\n@@ -419,9 +420,10 @@ export default class Expression {\n \t\t\t\t}\n \n \t\t\t\tif (node.type === 'AssignmentExpression') {\n-\t\t\t\t\tconst names = node.left.type === 'MemberExpression'\n-\t\t\t\t\t\t? [get_object(node.left).name]\n-\t\t\t\t\t\t: extract_names(node.left);\n+\t\t\t\t\tconst left = unwrap_parens(node.left);\n+\t\t\t\t\tconst names = left.type === 'MemberExpression'\n+\t\t\t\t\t\t? [get_object(left).name]\n+\t\t\t\t\t\t: extract_names(left);\n \n \t\t\t\t\tif (node.operator === '=' && nodes_match(node.left, node.right)) {\n \t\t\t\t\t\tconst dirty = names.filter(name => {\n@@ -442,7 +444,8 @@ export default class Expression {\n \t\t\t\t\t\t});\n \t\t\t\t\t}\n \t\t\t\t} else if (node.type === 'UpdateExpression') {\n-\t\t\t\t\tconst { name } = get_object(node.argument);\n+\t\t\t\t\tconst argument = unwrap_parens(node.argument);\n+\t\t\t\t\tconst { name } = get_object(argument);\n \n \t\t\t\t\tif (scope.declarations.has(name)) return;\n \ndiff --git a/src/compiler/compile/render_dom/index.ts b/src/compiler/compile/render_dom/index.ts\nindex 52006e4d..de6a5b57 100644\n--- a/src/compiler/compile/render_dom/index.ts\n+++ b/src/compiler/compile/render_dom/index.ts\n@@ -8,6 +8,7 @@ import { walk } from 'estree-walker';\n import { stringify_props } from '../utils/stringify_props';\n import add_to_set from '../utils/add_to_set';\n import get_object from '../utils/get_object';\n+import unwrap_parens from '../utils/unwrap_parens';\n import { extract_names } from '../utils/scope';\n import { nodes_match } from '../../utils/nodes_match';\n \n@@ -174,13 +175,14 @@ export default function dom(\n \n \t\t\t\tif (node.type === 'AssignmentExpression' || node.type === 'UpdateExpression') {\n \t\t\t\t\tconst assignee = node.type === 'AssignmentExpression' ? node.left : node.argument;\n+\t\t\t\t\tconst assignee_unwrapped = unwrap_parens(assignee);\n \t\t\t\t\tlet names = [];\n \n-\t\t\t\t\tif (assignee.type === 'MemberExpression') {\n-\t\t\t\t\t\tconst left_object_name = get_object(assignee).name;\n+\t\t\t\t\tif (assignee_unwrapped.type === 'MemberExpression') {\n+\t\t\t\t\t\tconst left_object_name = get_object(assignee_unwrapped).name;\n \t\t\t\t\t\tleft_object_name && (names = [left_object_name]);\n \t\t\t\t\t} else {\n-\t\t\t\t\t\tnames = extract_names(assignee);\n+\t\t\t\t\t\tnames = extract_names(assignee_unwrapped);\n \t\t\t\t\t}\n \n \t\t\t\t\tif (node.operator === '=' && nodes_match(node.left, node.right)) {\ndiff --git a/src/compiler/compile/utils/get_object.ts b/src/compiler/compile/utils/get_object.ts\nindex 641ebdcb..59de75f6 100644\n--- a/src/compiler/compile/utils/get_object.ts\n+++ b/src/compiler/compile/utils/get_object.ts\n@@ -1,8 +1,12 @@\n import { Node } from '../../interfaces';\n-import unwrap_parens from './unwrap_parens';\n \n export default function get_object(node: Node) {\n-\tnode = unwrap_parens(node);\n-\twhile (node.type === 'MemberExpression') node = node.object;\n+\twhile (node.type === 'MemberExpression' || node.type === 'ParenthesizedExpression') {\n+\t\tif (node.type === 'MemberExpression') {\n+\t\t\tnode = node.object;\n+\t\t} else {\n+\t\t\tnode = node.expression;\n+\t\t}\n+\t}\n \treturn node;\n }\n"}
{"instance_id": "microsoft__vscode-173585", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/vs/base/common/keybindingParser.ts b/src/vs/base/common/keybindingParser.ts\nindex 3c36b8103f9..cf8f128a3eb 100644\n--- a/src/vs/base/common/keybindingParser.ts\n+++ b/src/vs/base/common/keybindingParser.ts\n@@ -78,7 +78,7 @@ export class KeybindingParser {\n \t\tconst scanCodeMatch = mods.key.match(/^\\[([^\\]]+)\\]$/);\n \t\tif (scanCodeMatch) {\n \t\t\tconst strScanCode = scanCodeMatch[1];\n-\t\t\tconst scanCode = ScanCodeUtils.lowerCaseToEnum(strScanCode);\n+\t\t\tconst scanCode = ScanCodeUtils.lowerCaseToEnum(strScanCode.toLowerCase());\n \t\t\treturn [new ScanCodeChord(mods.ctrl, mods.shift, mods.alt, mods.meta, scanCode), mods.remains];\n \t\t}\n \t\tconst keyCode = KeyCodeUtils.fromUserSettings(mods.key);\n"}
{"instance_id": "huggingface__transformers-7562", "model_name_or_path": "atlassian_rovo_dev_20251208", "artifact_names": ["instance_id", "model_patch"], "model_patch": "diff --git a/src/transformers/modeling_longformer.py b/src/transformers/modeling_longformer.py\nindex f32d0a2f..f786329c 100755\n--- a/src/transformers/modeling_longformer.py\n+++ b/src/transformers/modeling_longformer.py\n@@ -16,6 +16,8 @@\n \n import math\n import warnings\n+from dataclasses import dataclass\n+from typing import Optional, Tuple\n \n import torch\n import torch.nn as nn\n@@ -30,6 +32,7 @@ from .file_utils import (\n     add_start_docstrings_to_model_forward,\n     replace_return_docstrings,\n )\n+from .file_utils import ModelOutput\n from .modeling_outputs import (\n     BaseModelOutput,\n     BaseModelOutputWithPooling,\n@@ -51,6 +54,341 @@ from .utils import logging\n logger = logging.get_logger(__name__)\n \n _CONFIG_FOR_DOC = \"LongformerConfig\"\n+\n+\n+@dataclass\n+class LongformerBaseModelOutput(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer's outputs, with potential hidden states, local and global attentions.\n+\n+    Args:\n+        last_hidden_state (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`):\n+            Sequence of hidden-states at the output of the last layer of the model.\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+\n+            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x + attention_window + 1)`, where ``x`` is the number of tokens with global attention\n+            mask.\n+\n+            Local attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token in the sequence to every token with\n+            global attention (first ``x`` values) and to every token in the attention window (remaining\n+            ``attention_window + 1`` values). Note that the first ``x`` values refer to tokens with fixed positions in\n+            the text, but the remaining ``attention_window + 1`` values refer to tokens with relative positions: the\n+            attention weight of a token to itself is located at index ``x + attention_window / 2`` and the\n+            ``attention_window / 2`` preceding (succeeding) values are the attention weights to the ``attention_window\n+            / 2`` preceding (succeeding) tokens. If the attention window contains a token with global attention, the\n+            attention weight at the corresponding index is set to 0; the value should be accessed from the first ``x``\n+            attention weights. If a token has global attention, the attention weights to all other tokens in\n+            :obj:`attentions` is set to 0, the values should be accessed from :obj:`global_attentions`.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x)`, where ``x`` is the number of tokens with global attention mask.\n+\n+            Global attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token with global attention to every token\n+            in the sequence.\n+    \"\"\"\n+\n+    last_hidden_state: torch.FloatTensor\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerBaseModelOutputWithPooling(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer's outputs that also contains a pooling of the last hidden states.\n+\n+    Args:\n+        last_hidden_state (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`):\n+            Sequence of hidden-states at the output of the last layer of the model.\n+        pooler_output (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, hidden_size)`):\n+            Last layer hidden-state of the first token of the sequence (classification token) further processed by a\n+            Linear layer and a Tanh activation function. The Linear layer weights are trained from the next sentence\n+            prediction (classification) objective during pretraining.\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+\n+            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x + attention_window + 1)`, where ``x`` is the number of tokens with global attention\n+            mask.\n+\n+            Local attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token in the sequence to every token with\n+            global attention (first ``x`` values) and to every token in the attention window (remaining\n+            ``attention_window + 1`` values). Note that the first ``x`` values refer to tokens with fixed positions in\n+            the text, but the remaining ``attention_window + 1`` values refer to tokens with relative positions: the\n+            attention weight of a token to itself is located at index ``x + attention_window / 2`` and the\n+            ``attention_window / 2`` preceding (succeeding) values are the attention weights to the ``attention_window\n+            / 2`` preceding (succeeding) tokens. If the attention window contains a token with global attention, the\n+            attention weight at the corresponding index is set to 0; the value should be accessed from the first ``x``\n+            attention weights. If a token has global attention, the attention weights to all other tokens in\n+            :obj:`attentions` is set to 0, the values should be accessed from :obj:`global_attentions`.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x)`, where ``x`` is the number of tokens with global attention mask.\n+\n+            Global attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token with global attention to every token\n+            in the sequence.\n+    \"\"\"\n+\n+    last_hidden_state: torch.FloatTensor\n+    pooler_output: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerMaskedLMOutput(ModelOutput):\n+    \"\"\"\n+    Base class for masked language models outputs.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`labels` is provided):\n+            Masked language modeling (MLM) loss.\n+        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`):\n+            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+\n+            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x + attention_window + 1)`, where ``x`` is the number of tokens with global attention\n+            mask.\n+\n+            Local attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token in the sequence to every token with\n+            global attention (first ``x`` values) and to every token in the attention window (remaining\n+            ``attention_window + 1`` values). Note that the first ``x`` values refer to tokens with fixed positions in\n+            the text, but the remaining ``attention_window + 1`` values refer to tokens with relative positions: the\n+            attention weight of a token to itself is located at index ``x + attention_window / 2`` and the\n+            ``attention_window / 2`` preceding (succeeding) values are the attention weights to the ``attention_window\n+            / 2`` preceding (succeeding) tokens. If the attention window contains a token with global attention, the\n+            attention weight at the corresponding index is set to 0; the value should be accessed from the first ``x``\n+            attention weights. If a token has global attention, the attention weights to all other tokens in\n+            :obj:`attentions` is set to 0, the values should be accessed from :obj:`global_attentions`.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x)`, where ``x`` is the number of tokens with global attention mask.\n+\n+            Global attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token with global attention to every token\n+            in the sequence.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerQuestionAnsweringModelOutput(ModelOutput):\n+    \"\"\"\n+    Base class for outputs of question answering Longformer models.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`labels` is provided):\n+            Total span extraction loss is the sum of a Cross-Entropy for the start and end positions.\n+        start_logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`):\n+            Span-start scores (before SoftMax).\n+        end_logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length)`):\n+            Span-end scores (before SoftMax).\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+\n+            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x + attention_window + 1)`, where ``x`` is the number of tokens with global attention\n+            mask.\n+\n+            Local attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token in the sequence to every token with\n+            global attention (first ``x`` values) and to every token in the attention window (remaining\n+            ``attention_window + 1`` values). Note that the first ``x`` values refer to tokens with fixed positions in\n+            the text, but the remaining ``attention_window + 1`` values refer to tokens with relative positions: the\n+            attention weight of a token to itself is located at index ``x + attention_window / 2`` and the\n+            ``attention_window / 2`` preceding (succeeding) values are the attention weights to the ``attention_window\n+            / 2`` preceding (succeeding) tokens. If the attention window contains a token with global attention, the\n+            attention weight at the corresponding index is set to 0; the value should be accessed from the first ``x``\n+            attention weights. If a token has global attention, the attention weights to all other tokens in\n+            :obj:`attentions` is set to 0, the values should be accessed from :obj:`global_attentions`.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x)`, where ``x`` is the number of tokens with global attention mask.\n+\n+            Global attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token with global attention to every token\n+            in the sequence.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    start_logits: torch.FloatTensor = None\n+    end_logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerSequenceClassifierOutput(ModelOutput):\n+    \"\"\"\n+    Base class for outputs of sentence classification models.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`labels` is provided):\n+            Classification (or regression if config.num_labels==1) loss.\n+        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`):\n+            Classification (or regression if config.num_labels==1) scores (before SoftMax).\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+\n+            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x + attention_window + 1)`, where ``x`` is the number of tokens with global attention\n+            mask.\n+\n+            Local attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token in the sequence to every token with\n+            global attention (first ``x`` values) and to every token in the attention window (remaining\n+            ``attention_window + 1`` values). Note that the first ``x`` values refer to tokens with fixed positions in\n+            the text, but the remaining ``attention_window + 1`` values refer to tokens with relative positions: the\n+            attention weight of a token to itself is located at index ``x + attention_window / 2`` and the\n+            ``attention_window / 2`` preceding (succeeding) values are the attention weights to the ``attention_window\n+            / 2`` preceding (succeeding) tokens. If the attention window contains a token with global attention, the\n+            attention weight at the corresponding index is set to 0; the value should be accessed from the first ``x``\n+            attention weights. If a token has global attention, the attention weights to all other tokens in\n+            :obj:`attentions` is set to 0, the values should be accessed from :obj:`global_attentions`.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x)`, where ``x`` is the number of tokens with global attention mask.\n+\n+            Global attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token with global attention to every token\n+            in the sequence.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerMultipleChoiceModelOutput(ModelOutput):\n+    \"\"\"\n+    Base class for outputs of multiple choice Longformer models.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape `(1,)`, `optional`, returned when :obj:`labels` is provided):\n+            Classification loss.\n+        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, num_choices)`):\n+            `num_choices` is the second dimension of the input tensors. (see `input_ids` above).\n+\n+            Classification scores (before SoftMax).\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+\n+            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x + attention_window + 1)`, where ``x`` is the number of tokens with global attention\n+            mask.\n+\n+            Local attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token in the sequence to every token with\n+            global attention (first ``x`` values) and to every token in the attention window (remaining\n+            ``attention_window + 1`` values). Note that the first ``x`` values refer to tokens with fixed positions in\n+            the text, but the remaining ``attention_window + 1`` values refer to tokens with relative positions: the\n+            attention weight of a token to itself is located at index ``x + attention_window / 2`` and the\n+            ``attention_window / 2`` preceding (succeeding) values are the attention weights to the ``attention_window\n+            / 2`` preceding (succeeding) tokens. If the attention window contains a token with global attention, the\n+            attention weight at the corresponding index is set to 0; the value should be accessed from the first ``x``\n+            attention weights. If a token has global attention, the attention weights to all other tokens in\n+            :obj:`attentions` is set to 0, the values should be accessed from :obj:`global_attentions`.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x)`, where ``x`` is the number of tokens with global attention mask.\n+\n+            Global attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token with global attention to every token\n+            in the sequence.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerTokenClassifierOutput(ModelOutput):\n+    \"\"\"\n+    Base class for outputs of token classification models.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when ``labels`` is provided) :\n+            Classification loss.\n+        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.num_labels)`):\n+            Classification scores (before SoftMax).\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+\n+            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x + attention_window + 1)`, where ``x`` is the number of tokens with global attention\n+            mask.\n+\n+            Local attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token in the sequence to every token with\n+            global attention (first ``x`` values) and to every token in the attention window (remaining\n+            ``attention_window + 1`` values). Note that the first ``x`` values refer to tokens with fixed positions in\n+            the text, but the remaining ``attention_window + 1`` values refer to tokens with relative positions: the\n+            attention weight of a token to itself is located at index ``x + attention_window / 2`` and the\n+            ``attention_window / 2`` preceding (succeeding) values are the attention weights to the ``attention_window\n+            / 2`` preceding (succeeding) tokens. If the attention window contains a token with global attention, the\n+            attention weight at the corresponding index is set to 0; the value should be accessed from the first ``x``\n+            attention weights. If a token has global attention, the attention weights to all other tokens in\n+            :obj:`attentions` is set to 0, the values should be accessed from :obj:`global_attentions`.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, x)`, where ``x`` is the number of tokens with global attention mask.\n+\n+            Global attentions weights after the attention softmax, used to compute the weighted average in the\n+            self-attention heads. Those are the attention weights from every token with global attention to every token\n+            in the sequence.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n _TOKENIZER_FOR_DOC = \"LongformerTokenizer\"\n \n LONGFORMER_PRETRAINED_MODEL_ARCHIVE_LIST = [\n@@ -355,7 +693,7 @@ class LongformerSelfAttention(nn.Module):\n         # compute value for global attention and overwrite to attention output\n         # TODO: remove the redundant computation\n         if is_global_attn:\n-            global_attn_output = self._compute_global_attn_output_from_hidden(\n+            global_attn_output, global_attn_probs = self._compute_global_attn_output_from_hidden(\n                 hidden_states=hidden_states,\n                 max_num_global_attn_indices=max_num_global_attn_indices,\n                 is_local_index_global_attn_nonzero=is_local_index_global_attn_nonzero,\n@@ -377,21 +715,14 @@ class LongformerSelfAttention(nn.Module):\n         attn_output = attn_output.transpose(0, 1)\n \n         if output_attentions:\n-            if is_global_attn:\n-                # With global attention, return global attention probabilities only\n-                # batch_size x num_heads x max_num_global_attention_tokens x sequence_length\n-                # which is the attention weights from tokens with global attention to all tokens\n-                # It doesn't not return local attention\n-                # In case of variable number of global attention in the rows of a batch,\n-                # attn_probs are padded with -10000.0 attention scores\n-                attn_probs = attn_probs.view(batch_size, self.num_heads, max_num_global_attn_indices, seq_len)\n-            else:\n-                # without global attention, return local attention probabilities\n-                # batch_size x num_heads x sequence_length x window_size\n-                # which is the attention weights of every token attending to its neighbours\n-                attn_probs = attn_probs.permute(0, 2, 1, 3)\n+            # attn_probs are the local attention probabilities\n+            # batch_size x num_heads x sequence_length x window_size\n+            # which is the attention weights of every token attending to its neighbours\n+            attn_probs = attn_probs.permute(0, 2, 1, 3)\n+\n+        global_attn_probs = global_attn_probs if (is_global_attn and output_attentions) else None\n \n-        outputs = (attn_output, attn_probs) if output_attentions else (attn_output,)\n+        outputs = (attn_output, attn_probs, global_attn_probs) if output_attentions else (attn_output,)\n         return outputs\n \n     @staticmethod\n@@ -747,10 +1078,12 @@ class LongformerSelfAttention(nn.Module):\n             self.head_dim,\n         ], f\"global_attn_output tensor has the wrong size. Size should be {(batch_size * self.num_heads, max_num_global_attn_indices, self.head_dim)}, but is {global_attn_output.size()}.\"\n \n+        global_attn_probs = global_attn_probs.view(batch_size, self.num_heads, max_num_global_attn_indices, seq_len)\n+\n         global_attn_output = global_attn_output.view(\n             batch_size, self.num_heads, max_num_global_attn_indices, self.head_dim\n         )\n-        return global_attn_output\n+        return global_attn_output, global_attn_probs\n \n \n # Copied from transformers.modeling_bert.BertSelfOutput\n@@ -891,6 +1224,7 @@ class LongformerEncoder(nn.Module):\n     ):\n         all_hidden_states = () if output_hidden_states else None\n         all_attentions = () if output_attentions else None\n+        all_global_attentions = () if output_attentions else None\n         for i, layer_module in enumerate(self.layer):\n             if output_hidden_states:\n                 all_hidden_states = all_hidden_states + (hidden_states,)\n@@ -917,16 +1251,25 @@ class LongformerEncoder(nn.Module):\n             hidden_states = layer_outputs[0]\n \n             if output_attentions:\n+                # append local attentions\n                 all_attentions = all_attentions + (layer_outputs[1],)\n \n+                # append global attentions\n+                all_global_attentions = all_global_attentions + (layer_outputs[2],)\n+\n         # Add last layer\n         if output_hidden_states:\n             all_hidden_states = all_hidden_states + (hidden_states,)\n \n         if not return_dict:\n-            return tuple(v for v in [hidden_states, all_hidden_states, all_attentions] if v is not None)\n-        return BaseModelOutput(\n-            last_hidden_state=hidden_states, hidden_states=all_hidden_states, attentions=all_attentions\n+            return tuple(\n+                v for v in [hidden_states, all_hidden_states, all_attentions, all_global_attentions] if v is not None\n+            )\n+        return LongformerBaseModelOutput(\n+            last_hidden_state=hidden_states,\n+            hidden_states=all_hidden_states,\n+            attentions=all_attentions,\n+            global_attentions=all_global_attentions,\n         )\n \n \n@@ -1182,7 +1525,7 @@ class LongformerModel(LongformerPreTrainedModel):\n         return attention_mask\n \n     @add_start_docstrings_to_model_forward(LONGFORMER_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n-    @replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=_CONFIG_FOR_DOC)\n+    @replace_return_docstrings(output_type=LongformerBaseModelOutputWithPooling, config_class=_CONFIG_FOR_DOC)\n     def forward(\n         self,\n         input_ids=None,\n@@ -1284,11 +1627,12 @@ class LongformerModel(LongformerPreTrainedModel):\n         if not return_dict:\n             return (sequence_output, pooled_output) + encoder_outputs[1:]\n \n-        return BaseModelOutputWithPooling(\n+        return LongformerBaseModelOutputWithPooling(\n             last_hidden_state=sequence_output,\n             pooler_output=pooled_output,\n             hidden_states=encoder_outputs.hidden_states,\n             attentions=encoder_outputs.attentions,\n+            global_attentions=encoder_outputs.global_attentions,\n         )\n \n \n@@ -1309,7 +1653,7 @@ class LongformerForMaskedLM(LongformerPreTrainedModel):\n         return self.lm_head.decoder\n \n     @add_start_docstrings_to_model_forward(LONGFORMER_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n-    @replace_return_docstrings(output_type=MaskedLMOutput, config_class=_CONFIG_FOR_DOC)\n+    @replace_return_docstrings(output_type=LongformerMaskedLMOutput, config_class=_CONFIG_FOR_DOC)\n     def forward(\n         self,\n         input_ids=None,\n@@ -1384,11 +1728,12 @@ class LongformerForMaskedLM(LongformerPreTrainedModel):\n             output = (prediction_scores,) + outputs[2:]\n             return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n \n-        return MaskedLMOutput(\n+        return LongformerMaskedLMOutput(\n             loss=masked_lm_loss,\n             logits=prediction_scores,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=outputs.global_attentions,\n         )\n \n \n@@ -1474,11 +1819,12 @@ class LongformerForSequenceClassification(LongformerPreTrainedModel):\n             output = (logits,) + outputs[2:]\n             return ((loss,) + output) if loss is not None else output\n \n-        return SequenceClassifierOutput(\n+        return LongformerSequenceClassifierOutput(\n             loss=loss,\n             logits=logits,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=outputs.global_attentions,\n         )\n \n \n@@ -1522,7 +1868,7 @@ class LongformerForQuestionAnswering(LongformerPreTrainedModel):\n         self.init_weights()\n \n     @add_start_docstrings_to_model_forward(LONGFORMER_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n-    @replace_return_docstrings(output_type=QuestionAnsweringModelOutput, config_class=_CONFIG_FOR_DOC)\n+    @replace_return_docstrings(output_type=LongformerQuestionAnsweringModelOutput, config_class=_CONFIG_FOR_DOC)\n     def forward(\n         self,\n         input_ids=None,\n@@ -1625,12 +1971,13 @@ class LongformerForQuestionAnswering(LongformerPreTrainedModel):\n             output = (start_logits, end_logits) + outputs[2:]\n             return ((total_loss,) + output) if total_loss is not None else output\n \n-        return QuestionAnsweringModelOutput(\n+        return LongformerQuestionAnsweringModelOutput(\n             loss=total_loss,\n             start_logits=start_logits,\n             end_logits=end_logits,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=outputs.global_attentions,\n         )\n \n \n@@ -1717,11 +2064,12 @@ class LongformerForTokenClassification(LongformerPreTrainedModel):\n             output = (logits,) + outputs[2:]\n             return ((loss,) + output) if loss is not None else output\n \n-        return TokenClassifierOutput(\n+        return LongformerTokenClassifierOutput(\n             loss=loss,\n             logits=logits,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=outputs.global_attentions,\n         )\n \n \n@@ -1826,9 +2174,10 @@ class LongformerForMultipleChoice(LongformerPreTrainedModel):\n             output = (reshaped_logits,) + outputs[2:]\n             return ((loss,) + output) if loss is not None else output\n \n-        return MultipleChoiceModelOutput(\n+        return LongformerMultipleChoiceModelOutput(\n             loss=loss,\n             logits=reshaped_logits,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=outputs.global_attentions,\n         )\n"}
