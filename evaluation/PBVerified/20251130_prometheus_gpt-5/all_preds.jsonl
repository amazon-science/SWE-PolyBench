{"instance_id": "google__gson-2337", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/stream/JsonReader.java b/gson/src/main/java/com/google/gson/stream/JsonReader.java\nindex 559ab2db..6946a96a 100644\n--- a/gson/src/main/java/com/google/gson/stream/JsonReader.java\n+++ b/gson/src/main/java/com/google/gson/stream/JsonReader.java\n@@ -992,7 +992,7 @@ public class JsonReader implements Closeable {\n    * not include it in the returned string.\n    *\n    * @param quote either ' or \".\n-   * @throws NumberFormatException if any unicode escape sequences are\n+   * @throws MalformedJsonException if any unicode escape sequences are\n    *     malformed.\n    */\n   private String nextQuotedValue(char quote) throws IOException {\n@@ -1587,7 +1587,7 @@ public class JsonReader implements Closeable {\n    * been read. This supports both unicode escapes \"u000A\" and two-character\n    * escapes \"\\n\".\n    *\n-   * @throws NumberFormatException if any unicode escape sequences are\n+   * @throws MalformedJsonException if any unicode escape sequences are\n    *     malformed.\n    */\n   @SuppressWarnings(\"fallthrough\")\n@@ -1614,7 +1614,7 @@ public class JsonReader implements Closeable {\n         } else if (c >= 'A' && c <= 'F') {\n           result += (c - 'A' + 10);\n         } else {\n-          throw new NumberFormatException(\"\\\\u\" + new String(buffer, pos, 4));\n+          throw syntaxError(\"Invalid unicode escape sequence: \" + \"\\\\u\" + new String(buffer, pos, 4));\n         }\n       }\n       pos += 4;\n"}
{"instance_id": "google__gson-2498", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/UserGuide.md b/UserGuide.md\nindex aa0b831c..72f71c7f 100644\n--- a/UserGuide.md\n+++ b/UserGuide.md\n@@ -156,7 +156,7 @@ BagOfPrimitives obj2 = gson.fromJson(json, BagOfPrimitives.class);\n   * While deserializing, a missing entry in JSON results in setting the corresponding field in the object to its default value: null for object types, zero for numeric types, and false for booleans.\n * If a field is _synthetic_, it is ignored and not included in JSON serialization or deserialization.\n * Fields corresponding to the outer classes in inner classes are ignored and not included in serialization or deserialization.\n-* Anonymous and local classes are excluded. They will be serialized as JSON `null` and when deserialized their JSON value is ignored and `null` is returned. Convert the classes to `static` nested classes to enable serialization and deserialization for them.\n+* Anonymous and local classes are excluded by default. They will be serialized as JSON `null` and when deserialized their JSON value is ignored and `null` is returned. Convert the classes to `static` nested classes to enable serialization and deserialization for them. Alternatively, use `GsonBuilder.enableAnonymousAndLocalClassSerialization()` to allow serialization of anonymous and local classes; note that deserialization of such classes remains unsupported.\n \n ### Nested Classes (including Inner Classes)\n \ndiff --git a/gson/src/main/java/com/google/gson/GsonBuilder.java b/gson/src/main/java/com/google/gson/GsonBuilder.java\nindex 0d9bef02..1ac347ec 100644\n--- a/gson/src/main/java/com/google/gson/GsonBuilder.java\n+++ b/gson/src/main/java/com/google/gson/GsonBuilder.java\n@@ -354,6 +354,20 @@ public final class GsonBuilder {\n     return this;\n   }\n \n+  /**\n+   * Enables serialization of anonymous and local classes. By default such classes are serialized\n+   * as JSON null and their JSON value is ignored during deserialization with null being returned.\n+   * With this option enabled only serialization behavior is changed while deserialization of\n+   * anonymous and local classes remains unsupported.\n+   *\n+   * @return a reference to this {@code GsonBuilder} object to fulfill the \"Builder\" pattern\n+   */\n+  @CanIgnoreReturnValue\n+  public GsonBuilder enableAnonymousAndLocalClassSerialization() {\n+    excluder = excluder.enableAnonymousAndLocalClassSerialization();\n+    return this;\n+  }\n+\n   /**\n    * Configures Gson to apply a specific serialization policy for {@code Long} and {@code long}\n    * objects.\ndiff --git a/gson/src/main/java/com/google/gson/internal/Excluder.java b/gson/src/main/java/com/google/gson/internal/Excluder.java\nindex b3d2288a..a703a7c6 100644\n--- a/gson/src/main/java/com/google/gson/internal/Excluder.java\n+++ b/gson/src/main/java/com/google/gson/internal/Excluder.java\n@@ -53,6 +53,7 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n   private int modifiers = Modifier.TRANSIENT | Modifier.STATIC;\n   private boolean serializeInnerClasses = true;\n   private boolean requireExpose;\n+  private boolean allowAnonymousAndLocalClassSerialization;\n   private List<ExclusionStrategy> serializationStrategies = Collections.emptyList();\n   private List<ExclusionStrategy> deserializationStrategies = Collections.emptyList();\n \n@@ -92,6 +93,17 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n     return result;\n   }\n \n+  /**\n+   * Enables serialization of anonymous and local classes while still excluding them from\n+   * deserialization. By default, anonymous and local classes are excluded for both serialization\n+   * and deserialization.\n+   */\n+  public Excluder enableAnonymousAndLocalClassSerialization() {\n+    Excluder result = clone();\n+    result.allowAnonymousAndLocalClassSerialization = true;\n+    return result;\n+  }\n+\n   public Excluder withExclusionStrategy(\n       ExclusionStrategy exclusionStrategy, boolean serialization, boolean deserialization) {\n     Excluder result = clone();\n@@ -109,10 +121,11 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n   @Override\n   public <T> TypeAdapter<T> create(final Gson gson, final TypeToken<T> type) {\n     Class<?> rawType = type.getRawType();\n-    boolean excludeClass = excludeClassChecks(rawType);\n+    boolean excludeClassForSerialize = excludeClassChecks(rawType, true);\n+    boolean excludeClassForDeserialize = excludeClassChecks(rawType, false);\n \n-    final boolean skipSerialize = excludeClass || excludeClassInStrategy(rawType, true);\n-    final boolean skipDeserialize = excludeClass || excludeClassInStrategy(rawType, false);\n+    final boolean skipSerialize = excludeClassForSerialize || excludeClassInStrategy(rawType, true);\n+    final boolean skipDeserialize = excludeClassForDeserialize || excludeClassInStrategy(rawType, false);\n \n     if (!skipSerialize && !skipDeserialize) {\n       return null;\n@@ -173,6 +186,8 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n     }\n \n     if (isAnonymousOrNonStaticLocal(field.getType())) {\n+      // Exclude fields of anonymous/local type always; fields are declared types and should not\n+      // be anonymous/local in normal code. Keeping existing behavior for safety.\n       return true;\n     }\n \n@@ -189,7 +204,7 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n     return false;\n   }\n \n-  private boolean excludeClassChecks(Class<?> clazz) {\n+  private boolean excludeClassChecks(Class<?> clazz, boolean serialize) {\n     if (version != Excluder.IGNORE_VERSIONS\n         && !isValidVersion(clazz.getAnnotation(Since.class), clazz.getAnnotation(Until.class))) {\n       return true;\n@@ -199,11 +214,16 @@ public final class Excluder implements TypeAdapterFactory, Cloneable {\n       return true;\n     }\n \n-    return isAnonymousOrNonStaticLocal(clazz);\n+    if (isAnonymousOrNonStaticLocal(clazz)) {\n+      // Exclude anonymous/local classes by default; allow serialization if explicitly enabled\n+      return !(serialize && allowAnonymousAndLocalClassSerialization);\n+    }\n+\n+    return false;\n   }\n \n   public boolean excludeClass(Class<?> clazz, boolean serialize) {\n-    return excludeClassChecks(clazz) || excludeClassInStrategy(clazz, serialize);\n+    return excludeClassChecks(clazz, serialize) || excludeClassInStrategy(clazz, serialize);\n   }\n \n   private boolean excludeClassInStrategy(Class<?> clazz, boolean serialize) {\n"}
{"instance_id": "apache__rocketmq-7563", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/tools/src/main/java/org/apache/rocketmq/tools/command/consumer/ConsumerProgressSubCommand.java b/tools/src/main/java/org/apache/rocketmq/tools/command/consumer/ConsumerProgressSubCommand.java\nindex 97125b854..83ef21b3c 100644\n--- a/tools/src/main/java/org/apache/rocketmq/tools/command/consumer/ConsumerProgressSubCommand.java\n+++ b/tools/src/main/java/org/apache/rocketmq/tools/command/consumer/ConsumerProgressSubCommand.java\n@@ -151,7 +151,13 @@ public class ConsumerProgressSubCommand implements SubCommand {\n                 for (MessageQueue mq : mqList) {\n                     OffsetWrapper offsetWrapper = consumeStats.getOffsetTable().get(mq);\n                     long diff = offsetWrapper.getBrokerOffset() - offsetWrapper.getConsumerOffset();\n+                    if (diff < 0) {\n+                        diff = 0;\n+                    }\n                     long inflight = offsetWrapper.getPullOffset() - offsetWrapper.getConsumerOffset();\n+                    if (inflight < 0) {\n+                        inflight = 0;\n+                    }\n                     diffTotal += diff;\n                     inflightTotal += inflight;\n                     String lastTime = \"\";\n"}
{"instance_id": "google__gson-2376", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/UserGuide.md b/UserGuide.md\nindex f5198654..4080f2aa 100644\n--- a/UserGuide.md\n+++ b/UserGuide.md\n@@ -227,7 +227,9 @@ String json = gson.toJson(ints);  // ==> [1,2,3,4,5]\n // Deserialization\n TypeToken<Collection<Integer>> collectionType = new TypeToken<Collection<Integer>>(){};\n // Note: For older Gson versions it is necessary to use `collectionType.getType()` as argument below,\n-// this is however not type-safe and care must be taken to specify the correct type for the local variable\n+// this is however not type-safe and care must be taken to specify the correct type for the local variable.\n+// Also ensure that the TypeToken captures concrete types; using a type variable (e.g., `new TypeToken<T>() {}`)\n+// does not provide runtime type information and will be rejected.\n Collection<Integer> ints2 = gson.fromJson(json, collectionType);\n // ==> ints2 is same as ints\n ```\n@@ -270,7 +272,9 @@ String json = \"{\\\"key\\\": \\\"value\\\"}\";\n \n // Deserialization\n // Note: For older Gson versions it is necessary to use `mapType.getType()` as argument below,\n-// this is however not type-safe and care must be taken to specify the correct type for the local variable\n+// this is however not type-safe and care must be taken to specify the correct type for the local variable.\n+// Also ensure that the TypeToken captures concrete types; using a type variable (e.g., `new TypeToken<T>() {}`)\n+// does not provide runtime type information and will be rejected.\n Map<String, String> stringMap = gson.fromJson(json, mapType);\n // ==> stringMap is {key=value}\n ```\n@@ -337,6 +341,8 @@ gson.fromJson(json, fooType);\n \n The idiom used to get `fooType` actually defines an anonymous local inner class containing a method `getType()` that returns the fully parameterized type.\n \n+Note: TypeToken must capture fully specified, concrete types. Creating a TypeToken with a type variable (for example inside a generic method using `new TypeToken<T>() {}`) does not provide the necessary runtime type information and is unsupported; Gson will throw an exception for such usage.\n+\n ### Serializing and Deserializing Collection with Objects of Arbitrary Types\n \n Sometimes you are dealing with JSON array that contains mixed types. For example:\ndiff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex 0219c1a1..a31278a6 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -681,6 +681,14 @@ public final class Gson {\n     return getAdapter(TypeToken.get(type));\n   }\n \n+  private static void validateDeserializationTargetType(Type type, String apiName) {\n+    if (com.google.gson.internal.$Gson$Types.containsTypeVariable(type)) {\n+      throw new IllegalArgumentException(\"Type provided to \" + apiName + \" contains unresolved type variables: \" + type\n+          + \". Gson cannot deserialize to a type with missing generic type information.\"\n+          + \"\\nSee \" + com.google.gson.internal.TroubleshootingGuide.createUrl(\"type-token-type-variable\"));\n+    }\n+  }\n+\n   /**\n    * This method serializes the specified object into its equivalent representation as a tree of\n    * {@link JsonElement}s. This method should be used when the specified object is not a generic\n@@ -1056,6 +1064,7 @@ public final class Gson {\n    */\n   @SuppressWarnings({\"unchecked\", \"TypeParameterUnusedInFormals\"})\n   public <T> T fromJson(String json, Type typeOfT) throws JsonSyntaxException {\n+    validateDeserializationTargetType(typeOfT, \"fromJson(String, Type)\");\n     return (T) fromJson(json, TypeToken.get(typeOfT));\n   }\n \n@@ -1088,6 +1097,7 @@ public final class Gson {\n     if (json == null) {\n       return null;\n     }\n+    validateDeserializationTargetType(typeOfT.getType(), \"fromJson(String, TypeToken)\");\n     StringReader reader = new StringReader(json);\n     return fromJson(reader, typeOfT);\n   }\n@@ -1149,6 +1159,7 @@ public final class Gson {\n    */\n   @SuppressWarnings({\"unchecked\", \"TypeParameterUnusedInFormals\"})\n   public <T> T fromJson(Reader json, Type typeOfT) throws JsonIOException, JsonSyntaxException {\n+    validateDeserializationTargetType(typeOfT, \"fromJson(Reader, Type)\");\n     return (T) fromJson(json, TypeToken.get(typeOfT));\n   }\n \n@@ -1178,6 +1189,7 @@ public final class Gson {\n    * @since 2.10\n    */\n   public <T> T fromJson(Reader json, TypeToken<T> typeOfT) throws JsonIOException, JsonSyntaxException {\n+    validateDeserializationTargetType(typeOfT.getType(), \"fromJson(Reader, TypeToken)\");\n     JsonReader jsonReader = newJsonReader(json);\n     T object = fromJson(jsonReader, typeOfT);\n     assertFullConsumption(object, jsonReader);\n@@ -1231,6 +1243,7 @@ public final class Gson {\n    */\n   @SuppressWarnings({\"unchecked\", \"TypeParameterUnusedInFormals\"})\n   public <T> T fromJson(JsonReader reader, Type typeOfT) throws JsonIOException, JsonSyntaxException {\n+    validateDeserializationTargetType(typeOfT, \"fromJson(JsonReader, Type)\");\n     return (T) fromJson(reader, TypeToken.get(typeOfT));\n   }\n \n@@ -1268,6 +1281,7 @@ public final class Gson {\n    * @since 2.10\n    */\n   public <T> T fromJson(JsonReader reader, TypeToken<T> typeOfT) throws JsonIOException, JsonSyntaxException {\n+    validateDeserializationTargetType(typeOfT.getType(), \"fromJson(JsonReader, TypeToken)\");\n     boolean isEmpty = true;\n     Strictness oldStrictness = reader.getStrictness();\n \n@@ -1354,6 +1368,7 @@ public final class Gson {\n    */\n   @SuppressWarnings({\"unchecked\", \"TypeParameterUnusedInFormals\"})\n   public <T> T fromJson(JsonElement json, Type typeOfT) throws JsonSyntaxException {\n+    validateDeserializationTargetType(typeOfT, \"fromJson(JsonElement, Type)\");\n     return (T) fromJson(json, TypeToken.get(typeOfT));\n   }\n \n@@ -1383,6 +1398,7 @@ public final class Gson {\n     if (json == null) {\n       return null;\n     }\n+    validateDeserializationTargetType(typeOfT.getType(), \"fromJson(JsonElement, TypeToken)\");\n     return fromJson(new JsonTreeReader(json), typeOfT);\n   }\n \ndiff --git a/gson/src/main/java/com/google/gson/internal/$Gson$Types.java b/gson/src/main/java/com/google/gson/internal/$Gson$Types.java\nindex 470e67df..23ae41a7 100644\n--- a/gson/src/main/java/com/google/gson/internal/$Gson$Types.java\n+++ b/gson/src/main/java/com/google/gson/internal/$Gson$Types.java\n@@ -232,6 +232,49 @@ public final class $Gson$Types {\n     return type instanceof Class ? ((Class<?>) type).getName() : type.toString();\n   }\n \n+  /**\n+   * Returns true if the given {@code type} is or contains a {@link TypeVariable} anywhere within\n+   * its structure (e.g., as a type argument, array component type, or wildcard bound).\n+   */\n+  public static boolean containsTypeVariable(Type type) {\n+    if (type instanceof TypeVariable) {\n+      return true;\n+    } else if (type instanceof Class) {\n+      // Raw classes have no type variables in their runtime Type\n+      return false;\n+    } else if (type instanceof ParameterizedType) {\n+      ParameterizedType p = (ParameterizedType) type;\n+      Type owner = p.getOwnerType();\n+      if (owner != null && containsTypeVariable(owner)) {\n+        return true;\n+      }\n+      for (Type arg : p.getActualTypeArguments()) {\n+        if (containsTypeVariable(arg)) {\n+          return true;\n+        }\n+      }\n+      return false;\n+    } else if (type instanceof GenericArrayType) {\n+      GenericArrayType g = (GenericArrayType) type;\n+      return containsTypeVariable(g.getGenericComponentType());\n+    } else if (type instanceof WildcardType) {\n+      WildcardType w = (WildcardType) type;\n+      for (Type upper : w.getUpperBounds()) {\n+        if (containsTypeVariable(upper)) {\n+          return true;\n+        }\n+      }\n+      for (Type lower : w.getLowerBounds()) {\n+        if (containsTypeVariable(lower)) {\n+          return true;\n+        }\n+      }\n+      return false;\n+    } else {\n+      return false;\n+    }\n+  }\n+\n   /**\n    * Returns the generic supertype for {@code supertype}. For example, given a class {@code\n    * IntegerSet}, the result for when supertype is {@code Set.class} is {@code Set<Integer>} and the\ndiff --git a/gson/src/main/java/com/google/gson/reflect/TypeToken.java b/gson/src/main/java/com/google/gson/reflect/TypeToken.java\nindex 3921a70b..5d836ccb 100644\n--- a/gson/src/main/java/com/google/gson/reflect/TypeToken.java\n+++ b/gson/src/main/java/com/google/gson/reflect/TypeToken.java\n@@ -93,7 +93,13 @@ public class TypeToken<T> {\n     if (superclass instanceof ParameterizedType) {\n       ParameterizedType parameterized = (ParameterizedType) superclass;\n       if (parameterized.getRawType() == TypeToken.class) {\n-        return $Gson$Types.canonicalize(parameterized.getActualTypeArguments()[0]);\n+        Type captured = $Gson$Types.canonicalize(parameterized.getActualTypeArguments()[0]);\n+        if ($Gson$Types.containsTypeVariable(captured)) {\n+          throw new IllegalStateException(\"TypeToken must not be created with a type variable or a type containing type variables: \"\n+              + captured + \". Create a TypeToken with fully specified, concrete types.\"\n+              + \"\\nSee \" + TroubleshootingGuide.createUrl(\"type-token-type-variable\"));\n+        }\n+        return captured;\n       }\n     }\n     // Check for raw TypeToken as superclass\n"}
{"instance_id": "apache__dubbo-3317", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/README.md b/README.md\nindex 5b00da2116..340d45586f 100644\n--- a/README.md\n+++ b/README.md\n@@ -130,7 +130,7 @@ public class Application {\n \n ```bash\n # mvn clean package\n-# mvn -Djava.net.preferIPv4Stack=true -Dexec.mainClass=org.apache.dubbo.demo.provider.Application exec:java\n+# mvn -Dexec.mainClass=org.apache.dubbo.demo.provider.Application exec:java\n ```\n \n ### Call remote service in consumer\n@@ -159,7 +159,7 @@ public class Application {\n \n ```bash\n # mvn clean package\n-# mvn -Djava.net.preferIPv4Stack=true -Dexec.mainClass=org.apache.dubbo.demo.consumer.Application exec:java\n+# mvn -Dexec.mainClass=org.apache.dubbo.demo.consumer.Application exec:java\n ```\n \n The consumer will print out `Hello world` on the screen.\ndiff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/NetUtils.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/NetUtils.java\nindex fafe1518f9..f7a174f715 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/NetUtils.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/NetUtils.java\n@@ -1,346 +1,386 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.common.utils;\r\n-\r\n-import org.apache.dubbo.common.Constants;\r\n-import org.apache.dubbo.common.URL;\r\n-import org.apache.dubbo.common.logger.Logger;\r\n-import org.apache.dubbo.common.logger.LoggerFactory;\r\n-\r\n-import java.io.IOException;\r\n-import java.net.Inet6Address;\r\n-import java.net.InetAddress;\r\n-import java.net.InetSocketAddress;\r\n-import java.net.NetworkInterface;\r\n-import java.net.ServerSocket;\r\n-import java.net.UnknownHostException;\r\n-import java.util.Enumeration;\r\n-import java.util.Map;\r\n-import java.util.Random;\r\n-import java.util.regex.Pattern;\r\n-\r\n-/**\r\n- * IP and Port Helper for RPC\r\n- */\r\n-public class NetUtils {\r\n-\r\n-    private static final Logger logger = LoggerFactory.getLogger(NetUtils.class);\r\n-    private static final int RND_PORT_START = 30000;\r\n-\r\n-    private static final int RND_PORT_RANGE = 10000;\r\n-\r\n-    private static final Random RANDOM = new Random(System.currentTimeMillis());\r\n-    private static final int MIN_PORT = 0;\r\n-    private static final int MAX_PORT = 65535;\r\n-    private static final Pattern ADDRESS_PATTERN = Pattern.compile(\"^\\\\d{1,3}(\\\\.\\\\d{1,3}){3}\\\\:\\\\d{1,5}$\");\r\n-    private static final Pattern LOCAL_IP_PATTERN = Pattern.compile(\"127(\\\\.\\\\d{1,3}){3}$\");\r\n-    private static final Pattern IP_PATTERN = Pattern.compile(\"\\\\d{1,3}(\\\\.\\\\d{1,3}){3,5}$\");\r\n-    private static final Map<String, String> hostNameCache = new LRUCache<String, String>(1000);\r\n-    private static volatile InetAddress LOCAL_ADDRESS = null;\r\n-\r\n-    public static int getRandomPort() {\r\n-        return RND_PORT_START + RANDOM.nextInt(RND_PORT_RANGE);\r\n-    }\r\n-\r\n-    public static int getAvailablePort() {\r\n-        ServerSocket ss = null;\r\n-        try {\r\n-            ss = new ServerSocket();\r\n-            ss.bind(null);\r\n-            return ss.getLocalPort();\r\n-        } catch (IOException e) {\r\n-            return getRandomPort();\r\n-        } finally {\r\n-            if (ss != null) {\r\n-                try {\r\n-                    ss.close();\r\n-                } catch (IOException e) {\r\n-                }\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    public static int getAvailablePort(int port) {\r\n-        if (port <= 0) {\r\n-            return getAvailablePort();\r\n-        }\r\n-        for (int i = port; i < MAX_PORT; i++) {\r\n-            ServerSocket ss = null;\r\n-            try {\r\n-                ss = new ServerSocket(i);\r\n-                return i;\r\n-            } catch (IOException e) {\r\n-                // continue\r\n-            } finally {\r\n-                if (ss != null) {\r\n-                    try {\r\n-                        ss.close();\r\n-                    } catch (IOException e) {\r\n-                    }\r\n-                }\r\n-            }\r\n-        }\r\n-        return port;\r\n-    }\r\n-\r\n-    public static boolean isInvalidPort(int port) {\r\n-        return port <= MIN_PORT || port > MAX_PORT;\r\n-    }\r\n-\r\n-    public static boolean isValidAddress(String address) {\r\n-        return ADDRESS_PATTERN.matcher(address).matches();\r\n-    }\r\n-\r\n-    public static boolean isLocalHost(String host) {\r\n-        return host != null\r\n-                && (LOCAL_IP_PATTERN.matcher(host).matches()\r\n-                || host.equalsIgnoreCase(Constants.LOCALHOST_KEY));\r\n-    }\r\n-\r\n-    public static boolean isAnyHost(String host) {\r\n-        return Constants.ANYHOST_VALUE.equals(host);\r\n-    }\r\n-\r\n-    public static boolean isInvalidLocalHost(String host) {\r\n-        return host == null\r\n-                || host.length() == 0\r\n-                || host.equalsIgnoreCase(Constants.LOCALHOST_KEY)\r\n-                || host.equals(Constants.ANYHOST_VALUE)\r\n-                || (LOCAL_IP_PATTERN.matcher(host).matches());\r\n-    }\r\n-\r\n-    public static boolean isValidLocalHost(String host) {\r\n-        return !isInvalidLocalHost(host);\r\n-    }\r\n-\r\n-    public static InetSocketAddress getLocalSocketAddress(String host, int port) {\r\n-        return isInvalidLocalHost(host) ?\r\n-                new InetSocketAddress(port) : new InetSocketAddress(host, port);\r\n-    }\r\n-\r\n-    static boolean isValidAddress(InetAddress address) {\r\n-        if (address == null || address.isLoopbackAddress()) {\r\n-            return false;\r\n-        }\r\n-        String name = address.getHostAddress();\r\n-        return (name != null\r\n-                && IP_PATTERN.matcher(name).matches()\r\n-                && !Constants.ANYHOST_VALUE.equals(name)\r\n-                && !Constants.LOCALHOST_VALUE.equals(name));\r\n-    }\r\n-\r\n-    /**\r\n-     * Check if an ipv6 address is reachable.\r\n-     *\r\n-     * @param address the given address\r\n-     * @return true if it is reachable\r\n-     */\r\n-    static boolean isValidV6Address(Inet6Address address) {\r\n-        boolean preferIpv6 = Boolean.getBoolean(\"java.net.preferIPv6Addresses\");\r\n-        if (!preferIpv6) {\r\n-            return false;\r\n-        }\r\n-        try {\r\n-            return address.isReachable(100);\r\n-        } catch (IOException e) {\r\n-            // ignore\r\n-        }\r\n-        return false;\r\n-    }\r\n-\r\n-    /**\r\n-     * normalize the ipv6 Address, convert scope name to scope id.\r\n-     * e.g.\r\n-     * convert\r\n-     * fe80:0:0:0:894:aeec:f37d:23e1%en0\r\n-     * to\r\n-     * fe80:0:0:0:894:aeec:f37d:23e1%5\r\n-     * <p>\r\n-     * The %5 after ipv6 address is called scope id.\r\n-     * see java doc of {@link Inet6Address} for more details.\r\n-     *\r\n-     * @param address the input address\r\n-     * @return the normalized address, with scope id converted to int\r\n-     */\r\n-    static InetAddress normalizeV6Address(Inet6Address address) {\r\n-        String addr = address.getHostAddress();\r\n-        int i = addr.lastIndexOf('%');\r\n-        if (i > 0) {\r\n-            try {\r\n-                return InetAddress.getByName(addr.substring(0, i) + '%' + address.getScopeId());\r\n-            } catch (UnknownHostException e) {\r\n-                // ignore\r\n-                logger.debug(\"Unknown IPV6 address: \", e);\r\n-            }\r\n-        }\r\n-        return address;\r\n-    }\r\n-\r\n-    public static String getLocalHost() {\r\n-        InetAddress address = getLocalAddress();\r\n-        return address == null ? Constants.LOCALHOST_VALUE : address.getHostAddress();\r\n-    }\r\n-\r\n-    public static String filterLocalHost(String host) {\r\n-        if (host == null || host.length() == 0) {\r\n-            return host;\r\n-        }\r\n-        if (host.contains(\"://\")) {\r\n-            URL u = URL.valueOf(host);\r\n-            if (NetUtils.isInvalidLocalHost(u.getHost())) {\r\n-                return u.setHost(NetUtils.getLocalHost()).toFullString();\r\n-            }\r\n-        } else if (host.contains(\":\")) {\r\n-            int i = host.lastIndexOf(':');\r\n-            if (NetUtils.isInvalidLocalHost(host.substring(0, i))) {\r\n-                return NetUtils.getLocalHost() + host.substring(i);\r\n-            }\r\n-        } else {\r\n-            if (NetUtils.isInvalidLocalHost(host)) {\r\n-                return NetUtils.getLocalHost();\r\n-            }\r\n-        }\r\n-        return host;\r\n-    }\r\n-\r\n-    /**\r\n-     * Find first valid IP from local network card\r\n-     *\r\n-     * @return first valid local IP\r\n-     */\r\n-    public static InetAddress getLocalAddress() {\r\n-        if (LOCAL_ADDRESS != null) {\r\n-            return LOCAL_ADDRESS;\r\n-        }\r\n-        InetAddress localAddress = getLocalAddress0();\r\n-        LOCAL_ADDRESS = localAddress;\r\n-        return localAddress;\r\n-    }\r\n-\r\n-    private static InetAddress getLocalAddress0() {\r\n-        InetAddress localAddress = null;\r\n-        try {\r\n-            localAddress = InetAddress.getLocalHost();\r\n-            if (localAddress instanceof Inet6Address) {\r\n-                Inet6Address address = (Inet6Address) localAddress;\r\n-                if (isValidV6Address(address)) {\r\n-                    return normalizeV6Address(address);\r\n-                }\r\n-            } else if (isValidAddress(localAddress)) {\r\n-                return localAddress;\r\n-            }\r\n-        } catch (Throwable e) {\r\n-            logger.warn(e);\r\n-        }\r\n-        try {\r\n-            Enumeration<NetworkInterface> interfaces = NetworkInterface.getNetworkInterfaces();\r\n-            if (null == interfaces) {\r\n-                return localAddress;\r\n-            }\r\n-            while (interfaces.hasMoreElements()) {\r\n-                try {\r\n-                    NetworkInterface network = interfaces.nextElement();\r\n-                    Enumeration<InetAddress> addresses = network.getInetAddresses();\r\n-                    while (addresses.hasMoreElements()) {\r\n-                        try {\r\n-                            InetAddress address = addresses.nextElement();\r\n-                            if (address instanceof Inet6Address) {\r\n-                                Inet6Address v6Address = (Inet6Address) address;\r\n-                                if (isValidV6Address(v6Address)) {\r\n-                                    return normalizeV6Address(v6Address);\r\n-                                }\r\n-                            } else if (isValidAddress(address)) {\r\n-                                return address;\r\n-                            }\r\n-                        } catch (Throwable e) {\r\n-                            logger.warn(e);\r\n-                        }\r\n-                    }\r\n-                } catch (Throwable e) {\r\n-                    logger.warn(e);\r\n-                }\r\n-            }\r\n-        } catch (Throwable e) {\r\n-            logger.warn(e);\r\n-        }\r\n-        return localAddress;\r\n-    }\r\n-\r\n-    public static String getHostName(String address) {\r\n-        try {\r\n-            int i = address.indexOf(':');\r\n-            if (i > -1) {\r\n-                address = address.substring(0, i);\r\n-            }\r\n-            String hostname = hostNameCache.get(address);\r\n-            if (hostname != null && hostname.length() > 0) {\r\n-                return hostname;\r\n-            }\r\n-            InetAddress inetAddress = InetAddress.getByName(address);\r\n-            if (inetAddress != null) {\r\n-                hostname = inetAddress.getHostName();\r\n-                hostNameCache.put(address, hostname);\r\n-                return hostname;\r\n-            }\r\n-        } catch (Throwable e) {\r\n-            // ignore\r\n-        }\r\n-        return address;\r\n-    }\r\n-\r\n-    /**\r\n-     * @param hostName\r\n-     * @return ip address or hostName if UnknownHostException\r\n-     */\r\n-    public static String getIpByHost(String hostName) {\r\n-        try {\r\n-            return InetAddress.getByName(hostName).getHostAddress();\r\n-        } catch (UnknownHostException e) {\r\n-            return hostName;\r\n-        }\r\n-    }\r\n-\r\n-    public static String toAddressString(InetSocketAddress address) {\r\n-        return address.getAddress().getHostAddress() + \":\" + address.getPort();\r\n-    }\r\n-\r\n-    public static InetSocketAddress toAddress(String address) {\r\n-        int i = address.indexOf(':');\r\n-        String host;\r\n-        int port;\r\n-        if (i > -1) {\r\n-            host = address.substring(0, i);\r\n-            port = Integer.parseInt(address.substring(i + 1));\r\n-        } else {\r\n-            host = address;\r\n-            port = 0;\r\n-        }\r\n-        return new InetSocketAddress(host, port);\r\n-    }\r\n-\r\n-    public static String toURL(String protocol, String host, int port, String path) {\r\n-        StringBuilder sb = new StringBuilder();\r\n-        sb.append(protocol).append(\"://\");\r\n-        sb.append(host).append(':').append(port);\r\n-        if (path.charAt(0) != '/') {\r\n-            sb.append('/');\r\n-        }\r\n-        sb.append(path);\r\n-        return sb.toString();\r\n-    }\r\n-\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.common.utils;\n+\n+import org.apache.dubbo.common.Constants;\n+import org.apache.dubbo.common.URL;\n+import org.apache.dubbo.common.logger.Logger;\n+import org.apache.dubbo.common.logger.LoggerFactory;\n+\n+import java.io.IOException;\n+import java.net.Inet6Address;\n+import java.net.InetAddress;\n+import java.net.InetSocketAddress;\n+import java.net.NetworkInterface;\n+import java.net.ServerSocket;\n+import java.net.UnknownHostException;\n+import java.util.Enumeration;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.regex.Pattern;\n+\n+/**\n+ * IP and Port Helper for RPC\n+ */\n+public class NetUtils {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(NetUtils.class);\n+    private static final int RND_PORT_START = 30000;\n+\n+    private static final int RND_PORT_RANGE = 10000;\n+\n+    private static final Random RANDOM = new Random(System.currentTimeMillis());\n+    private static final int MIN_PORT = 0;\n+    private static final int MAX_PORT = 65535;\n+    private static final Pattern ADDRESS_PATTERN = Pattern.compile(\"^\\\\d{1,3}(\\\\.\\\\d{1,3}){3}\\\\:\\\\d{1,5}$\");\n+    private static final Pattern LOCAL_IP_PATTERN = Pattern.compile(\"127(\\\\.\\\\d{1,3}){3}$\");\n+    private static final Pattern IP_PATTERN = Pattern.compile(\"\\\\d{1,3}(\\\\.\\\\d{1,3}){3,5}$\");\n+    private static final Map<String, String> hostNameCache = new LRUCache<String, String>(1000);\n+    private static volatile InetAddress LOCAL_ADDRESS = null;\n+\n+    public static int getRandomPort() {\n+        return RND_PORT_START + RANDOM.nextInt(RND_PORT_RANGE);\n+    }\n+\n+    public static int getAvailablePort() {\n+        ServerSocket ss = null;\n+        try {\n+            ss = new ServerSocket();\n+            ss.bind(null);\n+            return ss.getLocalPort();\n+        } catch (IOException e) {\n+            return getRandomPort();\n+        } finally {\n+            if (ss != null) {\n+                try {\n+                    ss.close();\n+                } catch (IOException e) {\n+                }\n+            }\n+        }\n+    }\n+\n+    public static int getAvailablePort(int port) {\n+        if (port <= 0) {\n+            return getAvailablePort();\n+        }\n+        for (int i = port; i < MAX_PORT; i++) {\n+            ServerSocket ss = null;\n+            try {\n+                ss = new ServerSocket(i);\n+                return i;\n+            } catch (IOException e) {\n+                // continue\n+            } finally {\n+                if (ss != null) {\n+                    try {\n+                        ss.close();\n+                    } catch (IOException e) {\n+                    }\n+                }\n+            }\n+        }\n+        return port;\n+    }\n+\n+    public static boolean isInvalidPort(int port) {\n+        return port <= MIN_PORT || port > MAX_PORT;\n+    }\n+\n+    public static boolean isValidAddress(String address) {\n+        return ADDRESS_PATTERN.matcher(address).matches();\n+    }\n+\n+    public static boolean isLocalHost(String host) {\n+        return host != null\n+                && (LOCAL_IP_PATTERN.matcher(host).matches()\n+                || host.equalsIgnoreCase(Constants.LOCALHOST_KEY));\n+    }\n+\n+    public static boolean isAnyHost(String host) {\n+        return Constants.ANYHOST_VALUE.equals(host);\n+    }\n+\n+    public static boolean isInvalidLocalHost(String host) {\n+        return host == null\n+                || host.length() == 0\n+                || host.equalsIgnoreCase(Constants.LOCALHOST_KEY)\n+                || host.equals(Constants.ANYHOST_VALUE)\n+                || (LOCAL_IP_PATTERN.matcher(host).matches());\n+    }\n+\n+    public static boolean isValidLocalHost(String host) {\n+        return !isInvalidLocalHost(host);\n+    }\n+\n+    public static InetSocketAddress getLocalSocketAddress(String host, int port) {\n+        return isInvalidLocalHost(host) ?\n+                new InetSocketAddress(port) : new InetSocketAddress(host, port);\n+    }\n+\n+    static boolean isValidAddress(InetAddress address) {\n+        if (address == null || address.isLoopbackAddress()) {\n+            return false;\n+        }\n+        String name = address.getHostAddress();\n+        return (name != null\n+                && IP_PATTERN.matcher(name).matches()\n+                && !Constants.ANYHOST_VALUE.equals(name)\n+                && !Constants.LOCALHOST_VALUE.equals(name));\n+    }\n+\n+    /**\n+     * Check if an ipv6 address is reachable.\n+     *\n+     * @param address the given address\n+     * @return true if it is reachable\n+     */\n+    static boolean isValidV6Address(Inet6Address address) {\n+        boolean preferIpv6 = Boolean.getBoolean(\"java.net.preferIPv6Addresses\");\n+        if (!preferIpv6) {\n+            return false;\n+        }\n+        try {\n+            return address.isReachable(100);\n+        } catch (IOException e) {\n+            // ignore\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * normalize the ipv6 Address, convert scope name to scope id.\n+     * e.g.\n+     * convert\n+     * fe80:0:0:0:894:aeec:f37d:23e1%en0\n+     * to\n+     * fe80:0:0:0:894:aeec:f37d:23e1%5\n+     * <p>\n+     * The %5 after ipv6 address is called scope id.\n+     * see java doc of {@link Inet6Address} for more details.\n+     *\n+     * @param address the input address\n+     * @return the normalized address, with scope id converted to int\n+     */\n+    static InetAddress normalizeV6Address(Inet6Address address) {\n+        String addr = address.getHostAddress();\n+        int i = addr.lastIndexOf('%');\n+        if (i > 0) {\n+            try {\n+                return InetAddress.getByName(addr.substring(0, i) + '%' + address.getScopeId());\n+            } catch (UnknownHostException e) {\n+                // ignore\n+                logger.debug(\"Unknown IPV6 address: \", e);\n+            }\n+        }\n+        return address;\n+    }\n+\n+    public static String getLocalHost() {\n+        InetAddress address = getLocalAddress();\n+        return address == null ? Constants.LOCALHOST_VALUE : address.getHostAddress();\n+    }\n+\n+    public static String filterLocalHost(String host) {\n+        if (host == null || host.length() == 0) {\n+            return host;\n+        }\n+        if (host.contains(\"://\")) {\n+            URL u = URL.valueOf(host);\n+            if (NetUtils.isInvalidLocalHost(u.getHost())) {\n+                return u.setHost(NetUtils.getLocalHost()).toFullString();\n+            }\n+        } else if (host.contains(\":\")) {\n+            int i = host.lastIndexOf(':');\n+            if (NetUtils.isInvalidLocalHost(host.substring(0, i))) {\n+                return NetUtils.getLocalHost() + host.substring(i);\n+            }\n+        } else {\n+            if (NetUtils.isInvalidLocalHost(host)) {\n+                return NetUtils.getLocalHost();\n+            }\n+        }\n+        return host;\n+    }\n+\n+    /**\n+     * Find first valid IP from local network card\n+     *\n+     * @return first valid local IP\n+     */\n+    public static InetAddress getLocalAddress() {\n+        if (LOCAL_ADDRESS != null) {\n+            return LOCAL_ADDRESS;\n+        }\n+        InetAddress localAddress = getLocalAddress0();\n+        LOCAL_ADDRESS = localAddress;\n+        return localAddress;\n+    }\n+\n+    private static InetAddress getLocalAddress0() {\n+        InetAddress localAddress = null;\n+        try {\n+            localAddress = InetAddress.getLocalHost();\n+            if (localAddress instanceof Inet6Address) {\n+                Inet6Address address = (Inet6Address) localAddress;\n+                if (isValidV6Address(address)) {\n+                    return normalizeV6Address(address);\n+                }\n+            } else if (isValidAddress(localAddress)) {\n+                return localAddress;\n+            }\n+        } catch (Throwable e) {\n+            logger.warn(e);\n+        }\n+        try {\n+            Enumeration<NetworkInterface> interfaces = NetworkInterface.getNetworkInterfaces();\n+            if (null == interfaces) {\n+                return localAddress;\n+            }\n+            while (interfaces.hasMoreElements()) {\n+                try {\n+                    NetworkInterface network = interfaces.nextElement();\n+                    Enumeration<InetAddress> addresses = network.getInetAddresses();\n+                    while (addresses.hasMoreElements()) {\n+                        try {\n+                            InetAddress address = addresses.nextElement();\n+                            if (address instanceof Inet6Address) {\n+                                Inet6Address v6Address = (Inet6Address) address;\n+                                if (isValidV6Address(v6Address)) {\n+                                    return normalizeV6Address(v6Address);\n+                                }\n+                            } else if (isValidAddress(address)) {\n+                                return address;\n+                            }\n+                        } catch (Throwable e) {\n+                            logger.warn(e);\n+                        }\n+                    }\n+                } catch (Throwable e) {\n+                    logger.warn(e);\n+                }\n+            }\n+        } catch (Throwable e) {\n+            logger.warn(e);\n+        }\n+        return localAddress;\n+    }\n+\n+    public static String getHostName(String address) {\n+        try {\n+            int i = address.indexOf(':');\n+            if (i > -1) {\n+                address = address.substring(0, i);\n+            }\n+            String hostname = hostNameCache.get(address);\n+            if (hostname != null && hostname.length() > 0) {\n+                return hostname;\n+            }\n+            InetAddress inetAddress = InetAddress.getByName(address);\n+            if (inetAddress != null) {\n+                hostname = inetAddress.getHostName();\n+                hostNameCache.put(address, hostname);\n+                return hostname;\n+            }\n+        } catch (Throwable e) {\n+            // ignore\n+        }\n+        return address;\n+    }\n+\n+    /**\n+     * @param hostName\n+     * @return ip address or hostName if UnknownHostException\n+     */\n+    public static String getIpByHost(String hostName) {\n+        try {\n+            return InetAddress.getByName(hostName).getHostAddress();\n+        } catch (UnknownHostException e) {\n+            return hostName;\n+        }\n+    }\n+\n+    public static String toAddressString(InetSocketAddress address) {\n+        return address.getAddress().getHostAddress() + \":\" + address.getPort();\n+    }\n+\n+    public static InetSocketAddress toAddress(String address) {\n+        int i = address.indexOf(':');\n+        String host;\n+        int port;\n+        if (i > -1) {\n+            host = address.substring(0, i);\n+            port = Integer.parseInt(address.substring(i + 1));\n+        } else {\n+            host = address;\n+            port = 0;\n+        }\n+        return new InetSocketAddress(host, port);\n+    }\n+\n+    public static String toURL(String protocol, String host, int port, String path) {\n+        StringBuilder sb = new StringBuilder();\n+        sb.append(protocol).append(\"://\");\n+        sb.append(host).append(':').append(port);\n+        if (path.charAt(0) != '/') {\n+            sb.append('/');\n+        }\n+        sb.append(path);\n+        return sb.toString();\n+    }\n+\n+    /**\n+     * Select a multicast-capable network interface that matches the address family of the given group.\n+     * Returns null if no suitable interface is found.\n+     */\n+    public static NetworkInterface getMulticastNetworkInterface(InetAddress group) {\n+        boolean isV6 = group instanceof Inet6Address;\n+        try {\n+            Enumeration<NetworkInterface> interfaces = NetworkInterface.getNetworkInterfaces();\n+            if (interfaces == null) {\n+                return null;\n+            }\n+            while (interfaces.hasMoreElements()) {\n+                NetworkInterface nif = interfaces.nextElement();\n+                try {\n+                    if (!nif.isUp() || nif.isLoopback() || !nif.supportsMulticast()) {\n+                        continue;\n+                    }\n+                    Enumeration<InetAddress> addresses = nif.getInetAddresses();\n+                    while (addresses.hasMoreElements()) {\n+                        InetAddress addr = addresses.nextElement();\n+                        if (isV6) {\n+                            if (addr instanceof Inet6Address) {\n+                                return nif;\n+                            }\n+                        } else {\n+                            if (!(addr instanceof Inet6Address) && isValidAddress(addr)) {\n+                                return nif;\n+                            }\n+                        }\n+                    }\n+                } catch (Throwable e) {\n+                    logger.warn(e);\n+                }\n+            }\n+        } catch (Throwable e) {\n+            logger.warn(e);\n+        }\n+        return null;\n+    }\n+\n }\n\\ No newline at end of file\ndiff --git a/dubbo-registry/dubbo-registry-multicast/src/main/java/org/apache/dubbo/registry/multicast/MulticastRegistry.java b/dubbo-registry/dubbo-registry-multicast/src/main/java/org/apache/dubbo/registry/multicast/MulticastRegistry.java\nindex 5498e9efbf..f654332727 100644\n--- a/dubbo-registry/dubbo-registry-multicast/src/main/java/org/apache/dubbo/registry/multicast/MulticastRegistry.java\n+++ b/dubbo-registry/dubbo-registry-multicast/src/main/java/org/apache/dubbo/registry/multicast/MulticastRegistry.java\n@@ -1,437 +1,450 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.registry.multicast;\r\n-\r\n-import org.apache.dubbo.common.Constants;\r\n-import org.apache.dubbo.common.URL;\r\n-import org.apache.dubbo.common.logger.Logger;\r\n-import org.apache.dubbo.common.logger.LoggerFactory;\r\n-import org.apache.dubbo.common.utils.ConcurrentHashSet;\r\n-import org.apache.dubbo.common.utils.ExecutorUtil;\r\n-import org.apache.dubbo.common.utils.NamedThreadFactory;\r\n-import org.apache.dubbo.common.utils.NetUtils;\r\n-import org.apache.dubbo.common.utils.UrlUtils;\r\n-import org.apache.dubbo.common.utils.CollectionUtils;\r\n-import org.apache.dubbo.registry.NotifyListener;\r\n-import org.apache.dubbo.registry.support.FailbackRegistry;\r\n-\r\n-import java.io.IOException;\r\n-import java.net.DatagramPacket;\r\n-import java.net.InetAddress;\r\n-import java.net.InetSocketAddress;\r\n-import java.net.MulticastSocket;\r\n-import java.net.Socket;\r\n-import java.util.ArrayList;\r\n-import java.util.Arrays;\r\n-import java.util.HashSet;\r\n-import java.util.List;\r\n-import java.util.Map;\r\n-import java.util.Set;\r\n-import java.util.concurrent.ConcurrentHashMap;\r\n-import java.util.concurrent.ConcurrentMap;\r\n-import java.util.concurrent.Executors;\r\n-import java.util.concurrent.ScheduledExecutorService;\r\n-import java.util.concurrent.ScheduledFuture;\r\n-import java.util.concurrent.TimeUnit;\r\n-\r\n-/**\r\n- * MulticastRegistry\r\n- */\r\n-public class MulticastRegistry extends FailbackRegistry {\r\n-\r\n-    // logging output\r\n-    private static final Logger logger = LoggerFactory.getLogger(MulticastRegistry.class);\r\n-\r\n-    private static final int DEFAULT_MULTICAST_PORT = 1234;\r\n-\r\n-    private final InetAddress multicastAddress;\r\n-\r\n-    private final MulticastSocket multicastSocket;\r\n-\r\n-    private final int multicastPort;\r\n-\r\n-    private final ConcurrentMap<URL, Set<URL>> received = new ConcurrentHashMap<URL, Set<URL>>();\r\n-\r\n-    private final ScheduledExecutorService cleanExecutor = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"DubboMulticastRegistryCleanTimer\", true));\r\n-\r\n-    private final ScheduledFuture<?> cleanFuture;\r\n-\r\n-    private final int cleanPeriod;\r\n-\r\n-    private volatile boolean admin = false;\r\n-\r\n-    public MulticastRegistry(URL url) {\r\n-        super(url);\r\n-        if (url.isAnyHost()) {\r\n-            throw new IllegalStateException(\"registry address == null\");\r\n-        }\r\n-        try {\r\n-            multicastAddress = InetAddress.getByName(url.getHost());\r\n-            if (!multicastAddress.isMulticastAddress()) {\r\n-                throw new IllegalArgumentException(\"Invalid multicast address \" + url.getHost() +\r\n-                        \", ipv4 multicast address scope: 224.0.0.0 - 239.255.255.255.\");\r\n-            }\r\n-            multicastPort = url.getPort() <= 0 ? DEFAULT_MULTICAST_PORT : url.getPort();\r\n-            multicastSocket = new MulticastSocket(multicastPort);\r\n-            multicastSocket.setLoopbackMode(false);\r\n-            multicastSocket.joinGroup(multicastAddress);\r\n-            Thread thread = new Thread(new Runnable() {\r\n-                @Override\r\n-                public void run() {\r\n-                    byte[] buf = new byte[2048];\r\n-                    DatagramPacket recv = new DatagramPacket(buf, buf.length);\r\n-                    while (!multicastSocket.isClosed()) {\r\n-                        try {\r\n-                            multicastSocket.receive(recv);\r\n-                            String msg = new String(recv.getData()).trim();\r\n-                            int i = msg.indexOf('\\n');\r\n-                            if (i > 0) {\r\n-                                msg = msg.substring(0, i).trim();\r\n-                            }\r\n-                            MulticastRegistry.this.receive(msg, (InetSocketAddress) recv.getSocketAddress());\r\n-                            Arrays.fill(buf, (byte) 0);\r\n-                        } catch (Throwable e) {\r\n-                            if (!multicastSocket.isClosed()) {\r\n-                                logger.error(e.getMessage(), e);\r\n-                            }\r\n-                        }\r\n-                    }\r\n-                }\r\n-            }, \"DubboMulticastRegistryReceiver\");\r\n-            thread.setDaemon(true);\r\n-            thread.start();\r\n-        } catch (IOException e) {\r\n-            throw new IllegalStateException(e.getMessage(), e);\r\n-        }\r\n-        this.cleanPeriod = url.getParameter(Constants.SESSION_TIMEOUT_KEY, Constants.DEFAULT_SESSION_TIMEOUT);\r\n-        if (url.getParameter(\"clean\", true)) {\r\n-            this.cleanFuture = cleanExecutor.scheduleWithFixedDelay(new Runnable() {\r\n-                @Override\r\n-                public void run() {\r\n-                    try {\r\n-                        clean(); // Remove the expired\r\n-                    } catch (Throwable t) { // Defensive fault tolerance\r\n-                        logger.error(\"Unexpected exception occur at clean expired provider, cause: \" + t.getMessage(), t);\r\n-                    }\r\n-                }\r\n-            }, cleanPeriod, cleanPeriod, TimeUnit.MILLISECONDS);\r\n-        } else {\r\n-            this.cleanFuture = null;\r\n-        }\r\n-    }\r\n-\r\n-    /**\r\n-     * Remove the expired providers, only when \"clean\" parameter is true.\r\n-     */\r\n-    private void clean() {\r\n-        if (admin) {\r\n-            for (Set<URL> providers : new HashSet<Set<URL>>(received.values())) {\r\n-                for (URL url : new HashSet<URL>(providers)) {\r\n-                    if (isExpired(url)) {\r\n-                        if (logger.isWarnEnabled()) {\r\n-                            logger.warn(\"Clean expired provider \" + url);\r\n-                        }\r\n-                        doUnregister(url);\r\n-                    }\r\n-                }\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    private boolean isExpired(URL url) {\r\n-        if (!url.getParameter(Constants.DYNAMIC_KEY, true)\r\n-                || url.getPort() <= 0\r\n-                || Constants.CONSUMER_PROTOCOL.equals(url.getProtocol())\r\n-                || Constants.ROUTE_PROTOCOL.equals(url.getProtocol())\r\n-                || Constants.OVERRIDE_PROTOCOL.equals(url.getProtocol())) {\r\n-            return false;\r\n-        }\r\n-        Socket socket = null;\r\n-        try {\r\n-            socket = new Socket(url.getHost(), url.getPort());\r\n-        } catch (Throwable e) {\r\n-            try {\r\n-                Thread.sleep(100);\r\n-            } catch (Throwable e2) {\r\n-            }\r\n-            Socket socket2 = null;\r\n-            try {\r\n-                socket2 = new Socket(url.getHost(), url.getPort());\r\n-            } catch (Throwable e2) {\r\n-                return true;\r\n-            } finally {\r\n-                if (socket2 != null) {\r\n-                    try {\r\n-                        socket2.close();\r\n-                    } catch (Throwable e2) {\r\n-                    }\r\n-                }\r\n-            }\r\n-        } finally {\r\n-            if (socket != null) {\r\n-                try {\r\n-                    socket.close();\r\n-                } catch (Throwable e) {\r\n-                }\r\n-            }\r\n-        }\r\n-        return false;\r\n-    }\r\n-\r\n-    private void receive(String msg, InetSocketAddress remoteAddress) {\r\n-        if (logger.isInfoEnabled()) {\r\n-            logger.info(\"Receive multicast message: \" + msg + \" from \" + remoteAddress);\r\n-        }\r\n-        if (msg.startsWith(Constants.REGISTER)) {\r\n-            URL url = URL.valueOf(msg.substring(Constants.REGISTER.length()).trim());\r\n-            registered(url);\r\n-        } else if (msg.startsWith(Constants.UNREGISTER)) {\r\n-            URL url = URL.valueOf(msg.substring(Constants.UNREGISTER.length()).trim());\r\n-            unregistered(url);\r\n-        } else if (msg.startsWith(Constants.SUBSCRIBE)) {\r\n-            URL url = URL.valueOf(msg.substring(Constants.SUBSCRIBE.length()).trim());\r\n-            Set<URL> urls = getRegistered();\r\n-            if (CollectionUtils.isNotEmpty(urls)) {\r\n-                for (URL u : urls) {\r\n-                    if (UrlUtils.isMatch(url, u)) {\r\n-                        String host = remoteAddress != null && remoteAddress.getAddress() != null\r\n-                                ? remoteAddress.getAddress().getHostAddress() : url.getIp();\r\n-                        if (url.getParameter(\"unicast\", true) // Whether the consumer's machine has only one process\r\n-                                && !NetUtils.getLocalHost().equals(host)) { // Multiple processes in the same machine cannot be unicast with unicast or there will be only one process receiving information\r\n-                            unicast(Constants.REGISTER + \" \" + u.toFullString(), host);\r\n-                        } else {\r\n-                            multicast(Constants.REGISTER + \" \" + u.toFullString());\r\n-                        }\r\n-                    }\r\n-                }\r\n-            }\r\n-        }/* else if (msg.startsWith(UNSUBSCRIBE)) {\r\n-        }*/\r\n-    }\r\n-\r\n-    private void multicast(String msg) {\r\n-        if (logger.isInfoEnabled()) {\r\n-            logger.info(\"Send multicast message: \" + msg + \" to \" + multicastAddress + \":\" + multicastPort);\r\n-        }\r\n-        try {\r\n-            byte[] data = (msg + \"\\n\").getBytes();\r\n-            DatagramPacket hi = new DatagramPacket(data, data.length, multicastAddress, multicastPort);\r\n-            multicastSocket.send(hi);\r\n-        } catch (Exception e) {\r\n-            throw new IllegalStateException(e.getMessage(), e);\r\n-        }\r\n-    }\r\n-\r\n-    private void unicast(String msg, String host) {\r\n-        if (logger.isInfoEnabled()) {\r\n-            logger.info(\"Send unicast message: \" + msg + \" to \" + host + \":\" + multicastPort);\r\n-        }\r\n-        try {\r\n-            byte[] data = (msg + \"\\n\").getBytes();\r\n-            DatagramPacket hi = new DatagramPacket(data, data.length, InetAddress.getByName(host), multicastPort);\r\n-            multicastSocket.send(hi);\r\n-        } catch (Exception e) {\r\n-            throw new IllegalStateException(e.getMessage(), e);\r\n-        }\r\n-    }\r\n-\r\n-    @Override\r\n-    public void doRegister(URL url) {\r\n-        multicast(Constants.REGISTER + \" \" + url.toFullString());\r\n-    }\r\n-\r\n-    @Override\r\n-    public void doUnregister(URL url) {\r\n-        multicast(Constants.UNREGISTER + \" \" + url.toFullString());\r\n-    }\r\n-\r\n-    @Override\r\n-    public void doSubscribe(URL url, NotifyListener listener) {\r\n-        if (Constants.ANY_VALUE.equals(url.getServiceInterface())) {\r\n-            admin = true;\r\n-        }\r\n-        multicast(Constants.SUBSCRIBE + \" \" + url.toFullString());\r\n-        synchronized (listener) {\r\n-            try {\r\n-                listener.wait(url.getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT));\r\n-            } catch (InterruptedException e) {\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    @Override\r\n-    public void doUnsubscribe(URL url, NotifyListener listener) {\r\n-        if (!Constants.ANY_VALUE.equals(url.getServiceInterface())\r\n-                && url.getParameter(Constants.REGISTER_KEY, true)) {\r\n-            unregister(url);\r\n-        }\r\n-        multicast(Constants.UNSUBSCRIBE + \" \" + url.toFullString());\r\n-    }\r\n-\r\n-    @Override\r\n-    public boolean isAvailable() {\r\n-        try {\r\n-            return multicastSocket != null;\r\n-        } catch (Throwable t) {\r\n-            return false;\r\n-        }\r\n-    }\r\n-\r\n-    /**\r\n-     * Remove the expired providers(if clean is true), leave the multicast group and close the multicast socket.\r\n-     */\r\n-    @Override\r\n-    public void destroy() {\r\n-        super.destroy();\r\n-        try {\r\n-            ExecutorUtil.cancelScheduledFuture(cleanFuture);\r\n-        } catch (Throwable t) {\r\n-            logger.warn(t.getMessage(), t);\r\n-        }\r\n-        try {\r\n-            multicastSocket.leaveGroup(multicastAddress);\r\n-            multicastSocket.close();\r\n-        } catch (Throwable t) {\r\n-            logger.warn(t.getMessage(), t);\r\n-        }\r\n-        ExecutorUtil.gracefulShutdown(cleanExecutor, cleanPeriod);\r\n-    }\r\n-\r\n-    protected void registered(URL url) {\r\n-        for (Map.Entry<URL, Set<NotifyListener>> entry : getSubscribed().entrySet()) {\r\n-            URL key = entry.getKey();\r\n-            if (UrlUtils.isMatch(key, url)) {\r\n-                Set<URL> urls = received.get(key);\r\n-                if (urls == null) {\r\n-                    received.putIfAbsent(key, new ConcurrentHashSet<URL>());\r\n-                    urls = received.get(key);\r\n-                }\r\n-                urls.add(url);\r\n-                List<URL> list = toList(urls);\r\n-                for (NotifyListener listener : entry.getValue()) {\r\n-                    notify(key, listener, list);\r\n-                    synchronized (listener) {\r\n-                        listener.notify();\r\n-                    }\r\n-                }\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    protected void unregistered(URL url) {\r\n-        for (Map.Entry<URL, Set<NotifyListener>> entry : getSubscribed().entrySet()) {\r\n-            URL key = entry.getKey();\r\n-            if (UrlUtils.isMatch(key, url)) {\r\n-                Set<URL> urls = received.get(key);\r\n-                if (urls != null) {\r\n-                    urls.remove(url);\r\n-                }\r\n-                if (urls == null || urls.isEmpty()) {\r\n-                    if (urls == null) {\r\n-                        urls = new ConcurrentHashSet<URL>();\r\n-                    }\r\n-                    URL empty = url.setProtocol(Constants.EMPTY_PROTOCOL);\r\n-                    urls.add(empty);\r\n-                }\r\n-                List<URL> list = toList(urls);\r\n-                for (NotifyListener listener : entry.getValue()) {\r\n-                    notify(key, listener, list);\r\n-                }\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    protected void subscribed(URL url, NotifyListener listener) {\r\n-        List<URL> urls = lookup(url);\r\n-        notify(url, listener, urls);\r\n-    }\r\n-\r\n-    private List<URL> toList(Set<URL> urls) {\r\n-        List<URL> list = new ArrayList<URL>();\r\n-        if (CollectionUtils.isNotEmpty(urls)) {\r\n-            for (URL url : urls) {\r\n-                list.add(url);\r\n-            }\r\n-        }\r\n-        return list;\r\n-    }\r\n-\r\n-    @Override\r\n-    public void register(URL url) {\r\n-        super.register(url);\r\n-        registered(url);\r\n-    }\r\n-\r\n-    @Override\r\n-    public void unregister(URL url) {\r\n-        super.unregister(url);\r\n-        unregistered(url);\r\n-    }\r\n-\r\n-    @Override\r\n-    public void subscribe(URL url, NotifyListener listener) {\r\n-        super.subscribe(url, listener);\r\n-        subscribed(url, listener);\r\n-    }\r\n-\r\n-    @Override\r\n-    public void unsubscribe(URL url, NotifyListener listener) {\r\n-        super.unsubscribe(url, listener);\r\n-        received.remove(url);\r\n-    }\r\n-\r\n-    @Override\r\n-    public List<URL> lookup(URL url) {\r\n-        List<URL> urls = new ArrayList<URL>();\r\n-        Map<String, List<URL>> notifiedUrls = getNotified().get(url);\r\n-        if (notifiedUrls != null && notifiedUrls.size() > 0) {\r\n-            for (List<URL> values : notifiedUrls.values()) {\r\n-                urls.addAll(values);\r\n-            }\r\n-        }\r\n-        if (urls.isEmpty()) {\r\n-            List<URL> cacheUrls = getCacheUrls(url);\r\n-            if (CollectionUtils.isNotEmpty(cacheUrls)) {\r\n-                urls.addAll(cacheUrls);\r\n-            }\r\n-        }\r\n-        if (urls.isEmpty()) {\r\n-            for (URL u : getRegistered()) {\r\n-                if (UrlUtils.isMatch(url, u)) {\r\n-                    urls.add(u);\r\n-                }\r\n-            }\r\n-        }\r\n-        if (Constants.ANY_VALUE.equals(url.getServiceInterface())) {\r\n-            for (URL u : getSubscribed().keySet()) {\r\n-                if (UrlUtils.isMatch(url, u)) {\r\n-                    urls.add(u);\r\n-                }\r\n-            }\r\n-        }\r\n-        return urls;\r\n-    }\r\n-\r\n-    public MulticastSocket getMulticastSocket() {\r\n-        return multicastSocket;\r\n-    }\r\n-\r\n-    public Map<URL, Set<URL>> getReceived() {\r\n-        return received;\r\n-    }\r\n-\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.registry.multicast;\n+\n+import org.apache.dubbo.common.Constants;\n+import org.apache.dubbo.common.URL;\n+import org.apache.dubbo.common.logger.Logger;\n+import org.apache.dubbo.common.logger.LoggerFactory;\n+import org.apache.dubbo.common.utils.ConcurrentHashSet;\n+import org.apache.dubbo.common.utils.ExecutorUtil;\n+import org.apache.dubbo.common.utils.NamedThreadFactory;\n+import org.apache.dubbo.common.utils.NetUtils;\n+import org.apache.dubbo.common.utils.UrlUtils;\n+import org.apache.dubbo.common.utils.CollectionUtils;\n+import org.apache.dubbo.registry.NotifyListener;\n+import org.apache.dubbo.registry.support.FailbackRegistry;\n+\n+import java.io.IOException;\n+import java.net.DatagramPacket;\n+import java.net.InetAddress;\n+import java.net.InetSocketAddress;\n+import java.net.MulticastSocket;\n+import java.net.Socket;\n+import java.net.NetworkInterface;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledExecutorService;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+\n+/**\n+ * MulticastRegistry\n+ */\n+public class MulticastRegistry extends FailbackRegistry {\n+\n+    // logging output\n+    private static final Logger logger = LoggerFactory.getLogger(MulticastRegistry.class);\n+\n+    private static final int DEFAULT_MULTICAST_PORT = 1234;\n+\n+    private final InetAddress multicastAddress;\n+\n+    private final MulticastSocket multicastSocket;\n+\n+    private final NetworkInterface multicastNetworkInterface;\n+\n+    private final int multicastPort;\n+\n+    private final ConcurrentMap<URL, Set<URL>> received = new ConcurrentHashMap<URL, Set<URL>>();\n+\n+    private final ScheduledExecutorService cleanExecutor = Executors.newScheduledThreadPool(1, new NamedThreadFactory(\"DubboMulticastRegistryCleanTimer\", true));\n+\n+    private final ScheduledFuture<?> cleanFuture;\n+\n+    private final int cleanPeriod;\n+\n+    private volatile boolean admin = false;\n+\n+    public MulticastRegistry(URL url) {\n+        super(url);\n+        if (url.isAnyHost()) {\n+            throw new IllegalStateException(\"registry address == null\");\n+        }\n+        try {\n+            multicastAddress = InetAddress.getByName(url.getHost());\n+            if (!multicastAddress.isMulticastAddress()) {\n+                throw new IllegalArgumentException(\"Invalid multicast address \" + url.getHost() +\n+                        \", IPv4 multicast range: 224.0.0.0-239.255.255.255, IPv6 multicast range: ff00::/8.\");\n+            }\n+            multicastPort = url.getPort() <= 0 ? DEFAULT_MULTICAST_PORT : url.getPort();\n+            multicastSocket = new MulticastSocket(multicastPort);\n+            multicastSocket.setLoopbackMode(false);\n+            multicastNetworkInterface = NetUtils.getMulticastNetworkInterface(multicastAddress);\n+            if (multicastNetworkInterface != null) {\n+                multicastSocket.setNetworkInterface(multicastNetworkInterface);\n+                multicastSocket.joinGroup(new InetSocketAddress(multicastAddress, multicastPort), multicastNetworkInterface);\n+            } else {\n+                multicastSocket.joinGroup(multicastAddress);\n+            }\n+            Thread thread = new Thread(new Runnable() {\n+                @Override\n+                public void run() {\n+                    byte[] buf = new byte[2048];\n+                    DatagramPacket recv = new DatagramPacket(buf, buf.length);\n+                    while (!multicastSocket.isClosed()) {\n+                        try {\n+                            multicastSocket.receive(recv);\n+                            String msg = new String(recv.getData()).trim();\n+                            int i = msg.indexOf('\\n');\n+                            if (i > 0) {\n+                                msg = msg.substring(0, i).trim();\n+                            }\n+                            MulticastRegistry.this.receive(msg, (InetSocketAddress) recv.getSocketAddress());\n+                            Arrays.fill(buf, (byte) 0);\n+                        } catch (Throwable e) {\n+                            if (!multicastSocket.isClosed()) {\n+                                logger.error(e.getMessage(), e);\n+                            }\n+                        }\n+                    }\n+                }\n+            }, \"DubboMulticastRegistryReceiver\");\n+            thread.setDaemon(true);\n+            thread.start();\n+        } catch (IOException e) {\n+            throw new IllegalStateException(e.getMessage(), e);\n+        }\n+        this.cleanPeriod = url.getParameter(Constants.SESSION_TIMEOUT_KEY, Constants.DEFAULT_SESSION_TIMEOUT);\n+        if (url.getParameter(\"clean\", true)) {\n+            this.cleanFuture = cleanExecutor.scheduleWithFixedDelay(new Runnable() {\n+                @Override\n+                public void run() {\n+                    try {\n+                        clean(); // Remove the expired\n+                    } catch (Throwable t) { // Defensive fault tolerance\n+                        logger.error(\"Unexpected exception occur at clean expired provider, cause: \" + t.getMessage(), t);\n+                    }\n+                }\n+            }, cleanPeriod, cleanPeriod, TimeUnit.MILLISECONDS);\n+        } else {\n+            this.cleanFuture = null;\n+        }\n+    }\n+\n+    /**\n+     * Remove the expired providers, only when \"clean\" parameter is true.\n+     */\n+    private void clean() {\n+        if (admin) {\n+            for (Set<URL> providers : new HashSet<Set<URL>>(received.values())) {\n+                for (URL url : new HashSet<URL>(providers)) {\n+                    if (isExpired(url)) {\n+                        if (logger.isWarnEnabled()) {\n+                            logger.warn(\"Clean expired provider \" + url);\n+                        }\n+                        doUnregister(url);\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    private boolean isExpired(URL url) {\n+        if (!url.getParameter(Constants.DYNAMIC_KEY, true)\n+                || url.getPort() <= 0\n+                || Constants.CONSUMER_PROTOCOL.equals(url.getProtocol())\n+                || Constants.ROUTE_PROTOCOL.equals(url.getProtocol())\n+                || Constants.OVERRIDE_PROTOCOL.equals(url.getProtocol())) {\n+            return false;\n+        }\n+        Socket socket = null;\n+        try {\n+            socket = new Socket(url.getHost(), url.getPort());\n+        } catch (Throwable e) {\n+            try {\n+                Thread.sleep(100);\n+            } catch (Throwable e2) {\n+            }\n+            Socket socket2 = null;\n+            try {\n+                socket2 = new Socket(url.getHost(), url.getPort());\n+            } catch (Throwable e2) {\n+                return true;\n+            } finally {\n+                if (socket2 != null) {\n+                    try {\n+                        socket2.close();\n+                    } catch (Throwable e2) {\n+                    }\n+                }\n+            }\n+        } finally {\n+            if (socket != null) {\n+                try {\n+                    socket.close();\n+                } catch (Throwable e) {\n+                }\n+            }\n+        }\n+        return false;\n+    }\n+\n+    private void receive(String msg, InetSocketAddress remoteAddress) {\n+        if (logger.isInfoEnabled()) {\n+            logger.info(\"Receive multicast message: \" + msg + \" from \" + remoteAddress);\n+        }\n+        if (msg.startsWith(Constants.REGISTER)) {\n+            URL url = URL.valueOf(msg.substring(Constants.REGISTER.length()).trim());\n+            registered(url);\n+        } else if (msg.startsWith(Constants.UNREGISTER)) {\n+            URL url = URL.valueOf(msg.substring(Constants.UNREGISTER.length()).trim());\n+            unregistered(url);\n+        } else if (msg.startsWith(Constants.SUBSCRIBE)) {\n+            URL url = URL.valueOf(msg.substring(Constants.SUBSCRIBE.length()).trim());\n+            Set<URL> urls = getRegistered();\n+            if (CollectionUtils.isNotEmpty(urls)) {\n+                for (URL u : urls) {\n+                    if (UrlUtils.isMatch(url, u)) {\n+                        String host = remoteAddress != null && remoteAddress.getAddress() != null\n+                                ? remoteAddress.getAddress().getHostAddress() : url.getIp();\n+                        if (url.getParameter(\"unicast\", true) // Whether the consumer's machine has only one process\n+                                && !NetUtils.getLocalHost().equals(host)) { // Multiple processes in the same machine cannot be unicast with unicast or there will be only one process receiving information\n+                            unicast(Constants.REGISTER + \" \" + u.toFullString(), host);\n+                        } else {\n+                            multicast(Constants.REGISTER + \" \" + u.toFullString());\n+                        }\n+                    }\n+                }\n+            }\n+        }/* else if (msg.startsWith(UNSUBSCRIBE)) {\n+        }*/\n+    }\n+\n+    private void multicast(String msg) {\n+        if (logger.isInfoEnabled()) {\n+            logger.info(\"Send multicast message: \" + msg + \" to \" + multicastAddress + \":\" + multicastPort);\n+        }\n+        try {\n+            byte[] data = (msg + \"\\n\").getBytes();\n+            DatagramPacket hi = new DatagramPacket(data, data.length, multicastAddress, multicastPort);\n+            multicastSocket.send(hi);\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e.getMessage(), e);\n+        }\n+    }\n+\n+    private void unicast(String msg, String host) {\n+        if (logger.isInfoEnabled()) {\n+            logger.info(\"Send unicast message: \" + msg + \" to \" + host + \":\" + multicastPort);\n+        }\n+        try {\n+            byte[] data = (msg + \"\\n\").getBytes();\n+            DatagramPacket hi = new DatagramPacket(data, data.length, InetAddress.getByName(host), multicastPort);\n+            multicastSocket.send(hi);\n+        } catch (Exception e) {\n+            throw new IllegalStateException(e.getMessage(), e);\n+        }\n+    }\n+\n+    @Override\n+    public void doRegister(URL url) {\n+        multicast(Constants.REGISTER + \" \" + url.toFullString());\n+    }\n+\n+    @Override\n+    public void doUnregister(URL url) {\n+        multicast(Constants.UNREGISTER + \" \" + url.toFullString());\n+    }\n+\n+    @Override\n+    public void doSubscribe(URL url, NotifyListener listener) {\n+        if (Constants.ANY_VALUE.equals(url.getServiceInterface())) {\n+            admin = true;\n+        }\n+        multicast(Constants.SUBSCRIBE + \" \" + url.toFullString());\n+        synchronized (listener) {\n+            try {\n+                listener.wait(url.getParameter(Constants.TIMEOUT_KEY, Constants.DEFAULT_TIMEOUT));\n+            } catch (InterruptedException e) {\n+            }\n+        }\n+    }\n+\n+    @Override\n+    public void doUnsubscribe(URL url, NotifyListener listener) {\n+        if (!Constants.ANY_VALUE.equals(url.getServiceInterface())\n+                && url.getParameter(Constants.REGISTER_KEY, true)) {\n+            unregister(url);\n+        }\n+        multicast(Constants.UNSUBSCRIBE + \" \" + url.toFullString());\n+    }\n+\n+    @Override\n+    public boolean isAvailable() {\n+        try {\n+            return multicastSocket != null;\n+        } catch (Throwable t) {\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Remove the expired providers(if clean is true), leave the multicast group and close the multicast socket.\n+     */\n+    @Override\n+    public void destroy() {\n+        super.destroy();\n+        try {\n+            ExecutorUtil.cancelScheduledFuture(cleanFuture);\n+        } catch (Throwable t) {\n+            logger.warn(t.getMessage(), t);\n+        }\n+        try {\n+            if (multicastNetworkInterface != null) {\n+                multicastSocket.leaveGroup(new InetSocketAddress(multicastAddress, multicastPort), multicastNetworkInterface);\n+            } else {\n+                multicastSocket.leaveGroup(multicastAddress);\n+            }\n+            multicastSocket.close();\n+        } catch (Throwable t) {\n+            logger.warn(t.getMessage(), t);\n+        }\n+        ExecutorUtil.gracefulShutdown(cleanExecutor, cleanPeriod);\n+    }\n+\n+    protected void registered(URL url) {\n+        for (Map.Entry<URL, Set<NotifyListener>> entry : getSubscribed().entrySet()) {\n+            URL key = entry.getKey();\n+            if (UrlUtils.isMatch(key, url)) {\n+                Set<URL> urls = received.get(key);\n+                if (urls == null) {\n+                    received.putIfAbsent(key, new ConcurrentHashSet<URL>());\n+                    urls = received.get(key);\n+                }\n+                urls.add(url);\n+                List<URL> list = toList(urls);\n+                for (NotifyListener listener : entry.getValue()) {\n+                    notify(key, listener, list);\n+                    synchronized (listener) {\n+                        listener.notify();\n+                    }\n+                }\n+            }\n+        }\n+    }\n+\n+    protected void unregistered(URL url) {\n+        for (Map.Entry<URL, Set<NotifyListener>> entry : getSubscribed().entrySet()) {\n+            URL key = entry.getKey();\n+            if (UrlUtils.isMatch(key, url)) {\n+                Set<URL> urls = received.get(key);\n+                if (urls != null) {\n+                    urls.remove(url);\n+                }\n+                if (urls == null || urls.isEmpty()) {\n+                    if (urls == null) {\n+                        urls = new ConcurrentHashSet<URL>();\n+                    }\n+                    URL empty = url.setProtocol(Constants.EMPTY_PROTOCOL);\n+                    urls.add(empty);\n+                }\n+                List<URL> list = toList(urls);\n+                for (NotifyListener listener : entry.getValue()) {\n+                    notify(key, listener, list);\n+                }\n+            }\n+        }\n+    }\n+\n+    protected void subscribed(URL url, NotifyListener listener) {\n+        List<URL> urls = lookup(url);\n+        notify(url, listener, urls);\n+    }\n+\n+    private List<URL> toList(Set<URL> urls) {\n+        List<URL> list = new ArrayList<URL>();\n+        if (CollectionUtils.isNotEmpty(urls)) {\n+            for (URL url : urls) {\n+                list.add(url);\n+            }\n+        }\n+        return list;\n+    }\n+\n+    @Override\n+    public void register(URL url) {\n+        super.register(url);\n+        registered(url);\n+    }\n+\n+    @Override\n+    public void unregister(URL url) {\n+        super.unregister(url);\n+        unregistered(url);\n+    }\n+\n+    @Override\n+    public void subscribe(URL url, NotifyListener listener) {\n+        super.subscribe(url, listener);\n+        subscribed(url, listener);\n+    }\n+\n+    @Override\n+    public void unsubscribe(URL url, NotifyListener listener) {\n+        super.unsubscribe(url, listener);\n+        received.remove(url);\n+    }\n+\n+    @Override\n+    public List<URL> lookup(URL url) {\n+        List<URL> urls = new ArrayList<URL>();\n+        Map<String, List<URL>> notifiedUrls = getNotified().get(url);\n+        if (notifiedUrls != null && notifiedUrls.size() > 0) {\n+            for (List<URL> values : notifiedUrls.values()) {\n+                urls.addAll(values);\n+            }\n+        }\n+        if (urls.isEmpty()) {\n+            List<URL> cacheUrls = getCacheUrls(url);\n+            if (CollectionUtils.isNotEmpty(cacheUrls)) {\n+                urls.addAll(cacheUrls);\n+            }\n+        }\n+        if (urls.isEmpty()) {\n+            for (URL u : getRegistered()) {\n+                if (UrlUtils.isMatch(url, u)) {\n+                    urls.add(u);\n+                }\n+            }\n+        }\n+        if (Constants.ANY_VALUE.equals(url.getServiceInterface())) {\n+            for (URL u : getSubscribed().keySet()) {\n+                if (UrlUtils.isMatch(url, u)) {\n+                    urls.add(u);\n+                }\n+            }\n+        }\n+        return urls;\n+    }\n+\n+    public MulticastSocket getMulticastSocket() {\n+        return multicastSocket;\n+    }\n+\n+    public Map<URL, Set<URL>> getReceived() {\n+        return received;\n+    }\n+\n+}\n"}
{"instance_id": "google__gson-2410", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/README.md b/README.md\nindex 04eb1c94..e9588f5d 100644\n--- a/README.md\n+++ b/README.md\n@@ -80,7 +80,7 @@ JDK 11 or newer is required for building, JDK 17 is recommended.\n \n ### Contributing\n \n-See the [contributing guide](https://github.com/google/.github/blob/master/CONTRIBUTING.md).  \n+See the [contributing guide](https://github.com/google/.github/blob/main/CONTRIBUTING.md).  \n Please perform a quick search to check if there are already existing issues or pull requests related to your contribution.\n \n Keep in mind that Gson is in maintenance mode. If you want to add a new feature, please first search for existing GitHub issues, or create a new one to discuss the feature and get feedback.\ndiff --git a/gson/src/main/java/com/google/gson/internal/TroubleshootingGuide.java b/gson/src/main/java/com/google/gson/internal/TroubleshootingGuide.java\nindex 69c1b06d..d0fbc1a4 100644\n--- a/gson/src/main/java/com/google/gson/internal/TroubleshootingGuide.java\n+++ b/gson/src/main/java/com/google/gson/internal/TroubleshootingGuide.java\n@@ -7,6 +7,6 @@ public class TroubleshootingGuide {\n    * Creates a URL referring to the specified troubleshooting section.\n    */\n   public static String createUrl(String id) {\n-    return \"https://github.com/google/gson/blob/master/Troubleshooting.md#\" + id;\n+    return \"https://github.com/google/gson/blob/main/Troubleshooting.md#\" + id;\n   }\n }\n"}
{"instance_id": "apolloconfig__apollo-4207", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/component/config/PortalConfig.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/component/config/PortalConfig.java\nindex 8ae2a4ac4..3c205fba1 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/component/config/PortalConfig.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/component/config/PortalConfig.java\n@@ -210,6 +210,15 @@ public class PortalConfig extends RefreshableConfig {\n     return getBooleanProperty(\"email.enabled\", false);\n   }\n \n+  // Common password fragments configuration\n+  public String passwordCommonFragments() {\n+    return getValue(\"password.common.fragments\", null);\n+  }\n+\n+  public String passwordCommonFragmentsFilePath() {\n+    return getValue(\"password.common.fragments.file.path\", null);\n+  }\n+\n   public String emailConfigHost() {\n     return getValue(\"email.config.host\", \"\");\n   }\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/AuthUserPasswordChecker.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/AuthUserPasswordChecker.java\nindex a51997062..6f7c61d3a 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/AuthUserPasswordChecker.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/AuthUserPasswordChecker.java\n@@ -17,8 +17,6 @@\n package com.ctrip.framework.apollo.portal.util.checker;\n \n import com.google.common.base.Strings;\n-import java.util.Arrays;\n-import java.util.List;\n import java.util.regex.Pattern;\n import org.springframework.stereotype.Component;\n \n@@ -28,14 +26,11 @@ public class AuthUserPasswordChecker implements UserPasswordChecker {\n   private static final Pattern PWD_PATTERN = Pattern\n       .compile(\"^(?=.*[0-9].*)(?=.*[a-zA-Z].*).{8,20}$\");\n \n-  private static final List<String> LIST_OF_CODE_FRAGMENT = Arrays.asList(\n-      \"111\", \"222\", \"333\", \"444\", \"555\", \"666\", \"777\", \"888\", \"999\", \"000\",\n-      \"001122\", \"112233\", \"223344\", \"334455\", \"445566\", \"556677\", \"667788\", \"778899\", \"889900\",\n-      \"009988\", \"998877\", \"887766\", \"776655\", \"665544\", \"554433\", \"443322\", \"332211\", \"221100\",\n-      \"0123\", \"1234\", \"2345\", \"3456\", \"4567\", \"5678\", \"6789\", \"7890\",\n-      \"0987\", \"9876\", \"8765\", \"7654\", \"6543\", \"5432\", \"4321\", \"3210\",\n-      \"1q2w\", \"2w3e\", \"3e4r\", \"5t6y\", \"abcd\", \"qwer\", \"asdf\", \"zxcv\"\n-  );\n+  private final CommonPasswordFragmentsProvider fragmentsProvider;\n+\n+  public AuthUserPasswordChecker(CommonPasswordFragmentsProvider fragmentsProvider) {\n+    this.fragmentsProvider = fragmentsProvider;\n+  }\n \n   @Override\n   public CheckResult checkWeakPassword(String password) {\n@@ -58,8 +53,9 @@ public class AuthUserPasswordChecker implements UserPasswordChecker {\n     if (Strings.isNullOrEmpty(password)) {\n       return true;\n     }\n-    for (String s : LIST_OF_CODE_FRAGMENT) {\n-      if (password.toLowerCase().contains(s)) {\n+    String lower = password.toLowerCase();\n+    for (String s : fragmentsProvider.getFragments()) {\n+      if (lower.contains(s)) {\n         return true;\n       }\n     }\ndiff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/CommonPasswordFragmentsProvider.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/CommonPasswordFragmentsProvider.java\nnew file mode 100644\nindex 000000000..fd59e62d2\n--- /dev/null\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/util/checker/CommonPasswordFragmentsProvider.java\n@@ -0,0 +1,230 @@\n+/*\n+ * Copyright 2022 Apollo Authors\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package com.ctrip.framework.apollo.portal.util.checker;\n+\n+import com.ctrip.framework.apollo.portal.component.config.PortalConfig;\n+import com.google.common.base.Strings;\n+import com.google.common.collect.Lists;\n+import com.google.gson.Gson;\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.nio.charset.StandardCharsets;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.nio.file.attribute.FileTime;\n+import java.util.Collection;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+import org.springframework.core.io.ClassPathResource;\n+import org.springframework.stereotype.Component;\n+\n+/**\n+ * Provider for commonly used password fragments. Supports dynamic configuration via:\n+ * 1) Database/server config key: \"password.common.fragments\" (comma-separated or JSON array)\n+ * 2) File path: \"password.common.fragments.file.path\" (absolute path or classpath:resource)\n+ * 3) Default resource: classpath file \"password-common-fragments.txt\"\n+ */\n+@Component\n+public class CommonPasswordFragmentsProvider {\n+\n+  private static final Logger logger = LoggerFactory.getLogger(CommonPasswordFragmentsProvider.class);\n+  private static final Gson GSON = new Gson();\n+  private static final String DEFAULT_RESOURCE = \"password-common-fragments.txt\";\n+\n+  private final PortalConfig portalConfig;\n+\n+  private volatile Set<String> fragments = new LinkedHashSet<>();\n+  private volatile String lastDbConfig = null;\n+  private volatile String lastFilePath = null;\n+  private volatile FileTime lastFileModifiedTime = null;\n+\n+  public CommonPasswordFragmentsProvider(PortalConfig portalConfig) {\n+    this.portalConfig = portalConfig;\n+    reloadIfNecessary(true);\n+  }\n+\n+  /**\n+   * Returns the current set of fragments (all lowercase).\n+   * Will reload if underlying configuration changed.\n+   */\n+  public Collection<String> getFragments() {\n+    reloadIfNecessary(false);\n+    return fragments;\n+  }\n+\n+  private synchronized void reloadIfNecessary(boolean force) {\n+    String dbConfig = safeTrimToNull(portalConfig.passwordCommonFragments());\n+    String filePath = safeTrimToNull(portalConfig.passwordCommonFragmentsFilePath());\n+\n+    boolean needReload = force;\n+\n+    if (!equalsNullSafe(dbConfig, lastDbConfig)) {\n+      needReload = true;\n+    }\n+\n+    if (!equalsNullSafe(filePath, lastFilePath)) {\n+      needReload = true;\n+    } else if (!Strings.isNullOrEmpty(filePath)) {\n+      // check file modified time\n+      FileTime currentMTime = getFileModifiedTime(filePath);\n+      if (!equalsNullSafe(currentMTime, lastFileModifiedTime)) {\n+        needReload = true;\n+      }\n+    }\n+\n+    if (!needReload) {\n+      return;\n+    }\n+\n+    Set<String> newFragments = new LinkedHashSet<>();\n+\n+    // 1) DB/server config\n+    if (!Strings.isNullOrEmpty(dbConfig)) {\n+      try {\n+        newFragments.addAll(parseFragmentsFromString(dbConfig));\n+        logger.info(\"Loaded password common fragments from server config, count={}\", newFragments.size());\n+      } catch (Exception ex) {\n+        logger.warn(\"Failed to parse password common fragments from server config, falling back.\", ex);\n+      }\n+    }\n+\n+    // 2) External file path (if db didn't provide or parse failed, or to augment)\n+    if (newFragments.isEmpty() && !Strings.isNullOrEmpty(filePath)) {\n+      try {\n+        newFragments.addAll(readFragmentsFromFile(filePath));\n+        lastFileModifiedTime = getFileModifiedTime(filePath);\n+        logger.info(\"Loaded password common fragments from file '{}', count={}\", filePath, newFragments.size());\n+      } catch (Exception ex) {\n+        logger.warn(\"Failed to read password common fragments from file '{}', falling back.\", filePath, ex);\n+      }\n+    }\n+\n+    // 3) Default resource\n+    if (newFragments.isEmpty()) {\n+      try {\n+        newFragments.addAll(readFragmentsFromDefaultResource());\n+        logger.info(\"Loaded password common fragments from default resource, count={}\", newFragments.size());\n+      } catch (Exception ex) {\n+        logger.error(\"Failed to read default password fragments resource, continuing with empty set.\", ex);\n+      }\n+    }\n+\n+    // Normalize to lowercase and trim\n+    Set<String> normalized = newFragments.stream()\n+        .map(s -> s == null ? null : s.trim().toLowerCase())\n+        .filter(s -> !Strings.isNullOrEmpty(s))\n+        .collect(Collectors.toCollection(LinkedHashSet::new));\n+\n+    this.fragments = normalized;\n+    this.lastDbConfig = dbConfig;\n+    this.lastFilePath = filePath;\n+    if (!Strings.isNullOrEmpty(filePath)) {\n+      this.lastFileModifiedTime = getFileModifiedTime(filePath);\n+    } else {\n+      this.lastFileModifiedTime = null;\n+    }\n+  }\n+\n+  private static List<String> parseFragmentsFromString(String dbConfig) {\n+    String cfg = dbConfig.trim();\n+    List<String> result = Lists.newArrayList();\n+    if (cfg.startsWith(\"[\")) {\n+      // try JSON array\n+      try {\n+        List<?> list = GSON.fromJson(cfg, List.class);\n+        for (Object o : list) {\n+          if (o != null) {\n+            result.add(String.valueOf(o));\n+          }\n+        }\n+        return result;\n+      } catch (Exception ignored) {\n+        // fall through to CSV parsing\n+      }\n+    }\n+    // CSV parsing\n+    for (String part : cfg.split(\",\")) {\n+      if (!Strings.isNullOrEmpty(part)) {\n+        result.add(part.trim());\n+      }\n+    }\n+    return result;\n+  }\n+\n+  private static List<String> readFragmentsFromDefaultResource() throws IOException {\n+    ClassPathResource resource = new ClassPathResource(DEFAULT_RESOURCE);\n+    try (InputStream in = resource.getInputStream();\n+         BufferedReader reader = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8))) {\n+      return reader.lines()\n+          .map(String::trim)\n+          .filter(s -> !s.isEmpty() && !s.startsWith(\"#\"))\n+          .collect(Collectors.toList());\n+    }\n+  }\n+\n+  private static List<String> readFragmentsFromFile(String filePath) throws IOException {\n+    if (filePath.startsWith(\"classpath:\")) {\n+      String path = filePath.substring(\"classpath:\".length());\n+      ClassPathResource resource = new ClassPathResource(path);\n+      try (InputStream in = resource.getInputStream();\n+           BufferedReader reader = new BufferedReader(new InputStreamReader(in, StandardCharsets.UTF_8))) {\n+        return reader.lines()\n+            .map(String::trim)\n+            .filter(s -> !s.isEmpty() && !s.startsWith(\"#\"))\n+            .collect(Collectors.toList());\n+      }\n+    }\n+    Path path = Paths.get(filePath);\n+    try (BufferedReader reader = Files.newBufferedReader(path, StandardCharsets.UTF_8)) {\n+      return reader.lines()\n+          .map(String::trim)\n+          .filter(s -> !s.isEmpty() && !s.startsWith(\"#\"))\n+          .collect(Collectors.toList());\n+    }\n+  }\n+\n+  private static FileTime getFileModifiedTime(String filePath) {\n+    try {\n+      if (filePath.startsWith(\"classpath:\")) {\n+        // classpath resources don't have reliable mtime; return null\n+        return null;\n+      }\n+      Path path = Paths.get(filePath);\n+      return Files.getLastModifiedTime(path);\n+    } catch (Exception e) {\n+      return null;\n+    }\n+  }\n+\n+  private static String safeTrimToNull(String s) {\n+    if (s == null) return null;\n+    String t = s.trim();\n+    return t.isEmpty() ? null : t;\n+  }\n+\n+  private static boolean equalsNullSafe(Object a, Object b) {\n+    if (a == b) return true;\n+    if (a == null || b == null) return false;\n+    return a.equals(b);\n+  }\n+}\ndiff --git a/apollo-portal/src/main/resources/application.yml b/apollo-portal/src/main/resources/application.yml\nindex a47d64db4..a7b857384 100644\n--- a/apollo-portal/src/main/resources/application.yml\n+++ b/apollo-portal/src/main/resources/application.yml\n@@ -48,3 +48,7 @@ management:\n       order: DOWN, OUT_OF_SERVICE, UNKNOWN, UP\n     ldap:\n       enabled: false # disable ldap health check by default\n+\n+# Example configuration for commonly used password fragments\n+# password.common.fragments: \"111,222,333,444,abcd,qwer,asdf\"\n+# password.common.fragments.file.path: \"/path/to/password-common-fragments.txt\"\ndiff --git a/apollo-portal/src/main/resources/password-common-fragments.txt b/apollo-portal/src/main/resources/password-common-fragments.txt\nnew file mode 100644\nindex 000000000..09f9cff24\n--- /dev/null\n+++ b/apollo-portal/src/main/resources/password-common-fragments.txt\n@@ -0,0 +1,54 @@\n+# Default commonly used password fragments\n+# One fragment per line; lines starting with '#' are comments\n+111\n+222\n+333\n+444\n+555\n+666\n+777\n+888\n+999\n+000\n+001122\n+112233\n+223344\n+334455\n+445566\n+556677\n+667788\n+778899\n+889900\n+009988\n+998877\n+887766\n+776655\n+665544\n+554433\n+443322\n+332211\n+221100\n+0123\n+1234\n+2345\n+3456\n+4567\n+5678\n+6789\n+7890\n+0987\n+9876\n+8765\n+7654\n+6543\n+5432\n+4321\n+3210\n+1q2w\n+2w3e\n+3e4r\n+5t6y\n+abcd\n+qwer\n+asdf\n+zxcv\n"}
{"instance_id": "google__gson-2475", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/stream/JsonWriter.java b/gson/src/main/java/com/google/gson/stream/JsonWriter.java\nindex 07848b06..fc1c2c89 100644\n--- a/gson/src/main/java/com/google/gson/stream/JsonWriter.java\n+++ b/gson/src/main/java/com/google/gson/stream/JsonWriter.java\n@@ -498,6 +498,10 @@ public class JsonWriter implements Closeable, Flushable {\n     if (stackSize == 0) {\n       throw new IllegalStateException(\"JsonWriter is closed.\");\n     }\n+    int context = peek();\n+    if (context != EMPTY_OBJECT && context != NONEMPTY_OBJECT) {\n+      throw new IllegalStateException(\"Nesting problem.\");\n+    }\n     deferredName = name;\n     return this;\n   }\n"}
{"instance_id": "google__gson-2134", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java b/gson/src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java\nindex 99ec679a..3c311947 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/util/ISO8601Utils.java\n@@ -149,7 +149,15 @@ public class ISO8601Utils\n             boolean hasT = checkOffset(date, offset, 'T');\n             \n             if (!hasT && (date.length() <= offset)) {\n-                Calendar calendar = new GregorianCalendar(year, month - 1, day);\n+                Calendar calendar = new GregorianCalendar();\n+                calendar.setLenient(false);\n+                calendar.set(Calendar.YEAR, year);\n+                calendar.set(Calendar.MONTH, month - 1);\n+                calendar.set(Calendar.DAY_OF_MONTH, day);\n+                calendar.set(Calendar.HOUR_OF_DAY, hour);\n+                calendar.set(Calendar.MINUTE, minutes);\n+                calendar.set(Calendar.SECOND, seconds);\n+                calendar.set(Calendar.MILLISECOND, milliseconds);\n \n                 pos.setIndex(offset);\n                 return calendar.getTime();\n"}
{"instance_id": "apache__dubbo-3855", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/support/RpcUtils.java b/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/support/RpcUtils.java\nindex 5e9e74a9a6..ba2c21381d 100644\n--- a/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/support/RpcUtils.java\n+++ b/dubbo-rpc/dubbo-rpc-api/src/main/java/org/apache/dubbo/rpc/support/RpcUtils.java\n@@ -37,6 +37,7 @@ import static org.apache.dubbo.common.constants.CommonConstants.$INVOKE_ASYNC;\n import static org.apache.dubbo.common.constants.CommonConstants.GENERIC_PARAMETER_DESC;\n import static org.apache.dubbo.common.constants.CommonConstants.TIMEOUT_ATTACHMENT_KEY;\n import static org.apache.dubbo.common.constants.CommonConstants.TIMEOUT_KEY;\n+import static org.apache.dubbo.common.constants.CommonConstants.HIDE_KEY_PREFIX;\n import static org.apache.dubbo.rpc.Constants.$ECHO;\n import static org.apache.dubbo.rpc.Constants.$ECHO_PARAMETER_DESC;\n import static org.apache.dubbo.rpc.Constants.ASYNC_KEY;\n@@ -165,10 +166,20 @@ public class RpcUtils {\n             }\n         }\n \n-        if (Boolean.TRUE.toString().equals(inv.getAttachment(ASYNC_KEY))) {\n-            isAsync = true;\n+        String config;\n+        String methodName = getMethodName(inv);\n+        String hiddenKey = methodName + HIDE_KEY_PREFIX + ASYNC_KEY;\n+        if ((config = inv.getAttachment(hiddenKey)) != null) {\n+            isAsync = Boolean.parseBoolean(config);\n+        } else if ((config = inv.getAttachment(ASYNC_KEY)) != null) {\n+            isAsync = Boolean.parseBoolean(config);\n         } else {\n-            isAsync = url.getMethodParameter(getMethodName(inv), ASYNC_KEY, false);\n+            String methodConfig = url.getMethodParameter(methodName, ASYNC_KEY);\n+            if (methodConfig != null) {\n+                isAsync = Boolean.parseBoolean(methodConfig);\n+            } else {\n+                isAsync = url.getParameter(ASYNC_KEY, false);\n+            }\n         }\n         return isAsync;\n     }\n@@ -216,10 +227,15 @@ public class RpcUtils {\n \n     public static boolean isOneway(URL url, Invocation inv) {\n         boolean isOneway;\n-        if (Boolean.FALSE.toString().equals(inv.getAttachment(RETURN_KEY))) {\n-            isOneway = true;\n+        String config;\n+        String methodName = getMethodName(inv);\n+        String hiddenKey = methodName + HIDE_KEY_PREFIX + RETURN_KEY;\n+        if ((config = inv.getAttachment(hiddenKey)) != null) {\n+            isOneway = !Boolean.parseBoolean(config);\n+        } else if ((config = inv.getAttachment(RETURN_KEY)) != null) {\n+            isOneway = !Boolean.parseBoolean(config);\n         } else {\n-            isOneway = !url.getMethodParameter(getMethodName(inv), RETURN_KEY, true);\n+            isOneway = !url.getMethodParameter(methodName, RETURN_KEY, true);\n         }\n         return isOneway;\n     }\n"}
{"instance_id": "google__gson-2071", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\nindex aa1e3ff6..cb138725 100644\n--- a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n+++ b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n@@ -23,6 +23,7 @@ import java.lang.reflect.Type;\n import java.util.ArrayDeque;\n import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.EnumMap;\n import java.util.EnumSet;\n import java.util.LinkedHashMap;\n import java.util.LinkedHashSet;\n@@ -217,6 +218,22 @@ public final class ConstructorConstructor {\n             return (T) new TreeMap<Object, Object>();\n           }\n         };\n+      } else if (EnumMap.class.isAssignableFrom(rawType)) {\n+        return new ObjectConstructor<T>() {\n+          @SuppressWarnings(\"rawtypes\")\n+          @Override public T construct() {\n+            if (type instanceof ParameterizedType) {\n+              Type keyType = ((ParameterizedType) type).getActualTypeArguments()[0];\n+              if (keyType instanceof Class) {\n+                return (T) new EnumMap((Class) keyType);\n+              } else {\n+                throw new JsonIOException(\"Invalid EnumMap type: \" + type.toString());\n+              }\n+            } else {\n+              throw new JsonIOException(\"Invalid EnumMap type: \" + type.toString());\n+            }\n+          }\n+        };\n       } else if (type instanceof ParameterizedType && !(String.class.isAssignableFrom(\n           TypeToken.get(((ParameterizedType) type).getActualTypeArguments()[0]).getRawType()))) {\n         return new ObjectConstructor<T>() {\n"}
{"instance_id": "google__gson-2435", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex 0219c1a1..6eaad6d4 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -345,11 +345,12 @@ public final class Gson {\n     factories.add(ArrayTypeAdapter.FACTORY);\n     factories.add(TypeAdapters.CLASS_FACTORY);\n \n+    this.jsonAdapterFactory = new JsonAdapterAnnotationTypeAdapterFactory(constructorConstructor);\n+    factories.add(jsonAdapterFactory);\n+\n     // type adapters for composite and user-defined types\n     factories.add(new CollectionTypeAdapterFactory(constructorConstructor));\n     factories.add(new MapTypeAdapterFactory(constructorConstructor, complexMapKeySerialization));\n-    this.jsonAdapterFactory = new JsonAdapterAnnotationTypeAdapterFactory(constructorConstructor);\n-    factories.add(jsonAdapterFactory);\n     factories.add(TypeAdapters.ENUM_FACTORY);\n     factories.add(new ReflectiveTypeAdapterFactory(\n         constructorConstructor, fieldNamingStrategy, excluder, jsonAdapterFactory, reflectionFilters));\n@@ -648,8 +649,9 @@ public final class Gson {\n    * @since 2.2\n    */\n   public <T> TypeAdapter<T> getDelegateAdapter(TypeAdapterFactory skipPast, TypeToken<T> type) {\n-    // Hack. If the skipPast factory isn't registered, assume the factory is being requested via\n-    // our @JsonAdapter annotation.\n+    // If the skipPast factory isn't registered, assume the request originates from @JsonAdapter and\n+    // set skipPast to jsonAdapterFactory so the next applicable core factory (e.g., collection / map) is considered.\n+    // This relies on jsonAdapterFactory being registered before composite factories.\n     if (!factories.contains(skipPast)) {\n       skipPast = jsonAdapterFactory;\n     }\n"}
{"instance_id": "google__gson-2060", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex e45ac2f4..ba6c1526 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -257,6 +257,7 @@ public final class Gson {\n     factories.add(TypeAdapters.newFactory(float.class, Float.class,\n             floatAdapter(serializeSpecialFloatingPointValues)));\n     factories.add(NumberTypeAdapter.getFactory(numberToNumberStrategy));\n+    factories.add(TypeAdapters.LAZILY_PARSED_NUMBER_FACTORY);\n     factories.add(TypeAdapters.ATOMIC_INTEGER_FACTORY);\n     factories.add(TypeAdapters.ATOMIC_BOOLEAN_FACTORY);\n     factories.add(TypeAdapters.newFactory(AtomicLong.class, atomicLongAdapter(longAdapter)));\ndiff --git a/gson/src/main/java/com/google/gson/internal/bind/ObjectTypeAdapter.java b/gson/src/main/java/com/google/gson/internal/bind/ObjectTypeAdapter.java\nindex b50f61e1..e9874818 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/ObjectTypeAdapter.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/ObjectTypeAdapter.java\n@@ -116,6 +116,12 @@ public final class ObjectTypeAdapter extends TypeAdapter<Object> {\n       return;\n     }\n \n+    // Handle LazilyParsedNumber explicitly to avoid reflective serialization into an object\n+    if (value instanceof com.google.gson.internal.LazilyParsedNumber) {\n+      out.value((Number) value);\n+      return;\n+    }\n+\n     TypeAdapter<Object> typeAdapter = (TypeAdapter<Object>) gson.getAdapter(value.getClass());\n     if (typeAdapter instanceof ObjectTypeAdapter) {\n       out.beginObject();\ndiff --git a/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java b/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\nindex 81870bc9..85fda20c 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\n@@ -677,6 +677,28 @@ public final class TypeAdapters {\n \n   public static final TypeAdapterFactory LOCALE_FACTORY = newFactory(Locale.class, LOCALE);\n \n+  // Adapter to ensure LazilyParsedNumber serializes as a JSON number rather than an object\n+  public static final TypeAdapter<LazilyParsedNumber> LAZILY_PARSED_NUMBER = new TypeAdapter<LazilyParsedNumber>() {\n+    @Override public LazilyParsedNumber read(JsonReader in) throws IOException {\n+      if (in.peek() == JsonToken.NULL) {\n+        in.nextNull();\n+        return null;\n+      }\n+      // Preserve exact numeric value by reading the raw string\n+      return new LazilyParsedNumber(in.nextString());\n+    }\n+\n+    @Override public void write(JsonWriter out, LazilyParsedNumber value) throws IOException {\n+      if (value == null) {\n+        out.nullValue();\n+        return;\n+      }\n+      out.value((Number) value);\n+    }\n+  };\n+\n+  public static final TypeAdapterFactory LAZILY_PARSED_NUMBER_FACTORY = newFactory(LazilyParsedNumber.class, LAZILY_PARSED_NUMBER);\n+\n   public static final TypeAdapter<JsonElement> JSON_ELEMENT = new TypeAdapter<JsonElement>() {\n     @Override public JsonElement read(JsonReader in) throws IOException {\n       if (in instanceof JsonTreeReader) {\n"}
{"instance_id": "google__gson-1703", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/Streams.java b/gson/src/main/java/com/google/gson/internal/Streams.java\nindex 0bb73aa1..e5182d4f 100644\n--- a/gson/src/main/java/com/google/gson/internal/Streams.java\n+++ b/gson/src/main/java/com/google/gson/internal/Streams.java\n@@ -82,15 +82,13 @@ public final class Streams {\n    */\n   private static final class AppendableWriter extends Writer {\n     private final Appendable appendable;\n-    private final CurrentWrite currentWrite = new CurrentWrite();\n \n     AppendableWriter(Appendable appendable) {\n       this.appendable = appendable;\n     }\n \n     @Override public void write(char[] chars, int offset, int length) throws IOException {\n-      currentWrite.chars = chars;\n-      appendable.append(currentWrite, offset, offset + length);\n+      appendable.append(new String(chars, offset, length));\n     }\n \n     @Override public void write(int i) throws IOException {\n@@ -100,21 +98,37 @@ public final class Streams {\n     @Override public void flush() {}\n     @Override public void close() {}\n \n-    /**\n-     * A mutable char sequence pointing at a single char[].\n-     */\n-    static class CurrentWrite implements CharSequence {\n-      char[] chars;\n-      @Override public int length() {\n-        return chars.length;\n-      }\n-      @Override public char charAt(int i) {\n-        return chars[i];\n-      }\n-      @Override public CharSequence subSequence(int start, int end) {\n-        return new String(chars, start, end - start);\n-      }\n+    @Override public Writer append(CharSequence csq) throws IOException {\n+      String s = (csq == null) ? \"null\" : csq.toString();\n+      appendable.append(s);\n+      return this;\n+    }\n+\n+    @Override public Writer append(CharSequence csq, int start, int end) throws IOException {\n+      CharSequence seq = (csq == null) ? \"null\" : csq;\n+      String s = seq.subSequence(start, end).toString();\n+      appendable.append(s);\n+      return this;\n+    }\n+\n+    @Override public Writer append(char c) throws IOException {\n+      appendable.append(c);\n+      return this;\n     }\n+\n+    @Override public void write(String str, int off, int len) throws IOException {\n+      appendable.append(str.substring(off, off + len));\n+    }\n+\n+    @Override public void write(String str) throws IOException {\n+      appendable.append(str);\n+    }\n+\n+    @Override public void write(char[] cbuf) throws IOException {\n+      appendable.append(new String(cbuf));\n+    }\n+\n+\n   }\n \n }\n"}
{"instance_id": "apache__dubbo-3093", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ClassHelper.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ClassHelper.java\nindex b5aa79f2fc..fa6c5c7411 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ClassHelper.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/ClassHelper.java\n@@ -266,8 +266,22 @@ public class ClassHelper {\n \n     public static Object convertPrimitive(Class<?> type, String value) {\n         if (type == char.class || type == Character.class) {\n-            return value.length() > 0 ? value.charAt(0) : '\\0';\n-        } else if (type == boolean.class || type == Boolean.class) {\n+            return (value != null && value.length() > 0) ? value.charAt(0) : '\\0';\n+        }\n+\n+        // For numeric types, return null when input is null or empty to avoid NumberFormatException\n+        if (value == null || value.length() == 0) {\n+            if (type == byte.class || type == Byte.class\n+                    || type == short.class || type == Short.class\n+                    || type == int.class || type == Integer.class\n+                    || type == long.class || type == Long.class\n+                    || type == float.class || type == Float.class\n+                    || type == double.class || type == Double.class) {\n+                return null;\n+            }\n+        }\n+\n+        if (type == boolean.class || type == Boolean.class) {\n             return Boolean.valueOf(value);\n         } else if (type == byte.class || type == Byte.class) {\n             return Byte.valueOf(value);\n"}
{"instance_id": "google__gson-2479", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/Troubleshooting.md b/Troubleshooting.md\nindex 91fd2211..50d9e979 100644\n--- a/Troubleshooting.md\n+++ b/Troubleshooting.md\n@@ -1,357 +1,363 @@\n-# Troubleshooting Guide\r\n-\r\n-This guide describes how to troubleshoot common issues when using Gson.\r\n-\r\n-<!-- The '<a id=\"...\"></a>' anchors below are used to create stable links; don't remove or rename them -->\r\n-<!-- Use only lowercase IDs, GitHub seems to not support uppercase IDs, see also https://github.com/orgs/community/discussions/50962 -->\r\n-\r\n-## <a id=\"class-cast-exception\"></a> `ClassCastException` when using deserialized object\r\n-\r\n-**Symptom:** `ClassCastException` is thrown when accessing an object deserialized by Gson\r\n-\r\n-**Reason:** Your code is most likely not type-safe\r\n-\r\n-**Solution:** Make sure your code adheres to the following:\r\n-\r\n-- Avoid raw types: Instead of calling `fromJson(..., List.class)`, create for example a `TypeToken<List<MyClass>>`.\r\n-  See the [user guide](UserGuide.md#collections-examples) for more information.\r\n-- When using `TypeToken` prefer the `Gson.fromJson` overloads with `TypeToken` parameter such as [`fromJson(Reader, TypeToken)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#fromJson(java.io.Reader,com.google.gson.reflect.TypeToken)).\r\n-  The overloads with `Type` parameter do not provide any type-safety guarantees.\r\n-- When using `TypeToken` make sure you don't capture a type variable. For example avoid something like `new TypeToken<List<T>>()` (where `T` is a type variable). Due to Java [type erasure](https://dev.java/learn/generics/type-erasure/) the actual type of `T` is not available at runtime. Refactor your code to pass around `TypeToken` instances or use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementType)` where `elementType` is a type you have to provide separately.\r\n-\r\n-## <a id=\"reflection-inaccessible\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to unnamed module'\r\n-\r\n-**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to unnamed module' is thrown\r\n-\r\n-**Reason:** You use Gson by accident to access internal fields of third-party classes\r\n-\r\n-**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data. If this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\r\n-\r\n-**Explanation:**\r\n-\r\n-When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are seeing this error because you (by accident) rely on the reflection-based adapter for third-party classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point. For the JDK it is also not possible anymore to access internal fields using reflection starting with JDK 17, see [JEP 403](https://openjdk.org/jeps/403).\r\n-\r\n-If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\r\n-\r\n-## <a id=\"reflection-inaccessible-to-module-gson\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to module com.google.gson'\r\n-\r\n-**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to module com.google.gson' is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- If the reported package is your own package then you have not configured the module declaration of your project to allow Gson to use reflection on your classes.\r\n-- If the reported package is from a third party library or the JDK see [this troubleshooting point](#inaccessibleobjectexception-module--does-not-opens--to-unnamed-module).\r\n-\r\n-**Solution:** Make sure the `module-info.java` file of your project allows Gson to use reflection on your classes, for example:\r\n-\r\n-```java\r\n-module mymodule {\r\n-    requires com.google.gson;\r\n-\r\n-    opens mypackage to com.google.gson;\r\n-}\r\n-```\r\n-\r\n-Or in case this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\r\n-\r\n-## <a id=\"android-app-random-names\"></a> Android app not working in Release mode; random property names\r\n-\r\n-**Symptom:** Your Android app is working fine in Debug mode but fails in Release mode and the JSON properties have seemingly random names such as `a`, `b`, ...\r\n-\r\n-**Reason:** You probably have not configured ProGuard / R8 correctly\r\n-\r\n-**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-## <a id=\"android-app-broken-after-app-update\"></a> Android app unable to parse JSON after app update\r\n-\r\n-**Symptom:** You released a new version of your Android app and it fails to parse JSON data created by the previous version of your app\r\n-\r\n-**Reason:** You probably have not configured ProGuard / R8 correctly; probably the field names are being obfuscated and their naming changed between the versions of your app\r\n-\r\n-**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-If you want to preserve backward compatibility for you app you can use [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) on the fields to specify the obfuscated name as alternate, for example: `@SerializedName(value = \"myprop\", alternate = \"a\")`\r\n-\r\n-Normally ProGuard and R8 produce a mapping file, this makes it easier to find out the obfuscated field names instead of having to find them out through trial and error or other means. See the [Android Studio user guide](https://developer.android.com/studio/build/shrink-code.html#retracing) for more information.\r\n-\r\n-## <a id=\"default-field-values-missing\"></a> Default field values not present after deserialization\r\n-\r\n-**Symptom:** You have assign default values to fields but after deserialization the fields have their standard value (such as `null` or `0`)\r\n-\r\n-**Reason:** Gson cannot invoke the constructor of your class and falls back to JDK `Unsafe` (or similar means)\r\n-\r\n-**Solution:** Make sure that the class:\r\n-\r\n-- is `static` (explicitly or implicitly when it is a top-level class)\r\n-- has a no-args constructor\r\n-\r\n-Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\r\n-\r\n-## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\r\n-\r\n-**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\r\n-\r\n-**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\r\n-\r\n-**Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\r\n-\r\n-Notes:\r\n-\r\n-- \"double brace-initialization\" also creates anonymous classes\r\n-- Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\r\n-\r\n-## <a id=\"map-key-wrong-json\"></a> Map keys having unexpected format in JSON\r\n-\r\n-**Symptom:** JSON output for `Map` keys is unexpected / cannot be deserialized again\r\n-\r\n-**Reason:** The `Map` key type is 'complex' and you have not configured the `GsonBuilder` properly\r\n-\r\n-**Solution:** Use [`GsonBuilder.enableComplexMapKeySerialization()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#enableComplexMapKeySerialization()). See also the [user guide](UserGuide.md#maps-examples) for more information.\r\n-\r\n-## <a id=\"malformed-json\"></a> Parsing JSON fails with `MalformedJsonException`\r\n-\r\n-**Symptom:** JSON parsing fails with `MalformedJsonException`\r\n-\r\n-**Reason:** The JSON data is actually malformed\r\n-\r\n-**Solution:** During debugging, log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Sometimes APIs might return HTML error pages (instead of JSON data) when reaching rate limits or when other errors occur. Also read the location information of the `MalformedJsonException` exception message, it indicates where exactly in the document the malformed data was detected, including the [JSONPath](https://goessner.net/articles/JsonPath/).\r\n-\r\n-For example, let's assume you want to deserialize the following JSON data:\r\n-\r\n-```json\r\n-{\r\n-  \"languages\": [\r\n-    \"English\",\r\n-    \"French\",\r\n-  ]\r\n-}\r\n-```\r\n-\r\n-This will fail with an exception similar to this one: `MalformedJsonException: Use JsonReader.setStrictness(Strictness.LENIENT) to accept malformed JSON at line 5 column 4 path $.languages[2]`  \r\n-The problem here is the trailing comma (`,`) after `\"French\"`, trailing commas are not allowed by the JSON specification. The location information \"line 5 column 4\" points to the `]` in the JSON data (with some slight inaccuracies) because Gson expected another value after `,` instead of the closing `]`. The JSONPath `$.languages[2]` in the exception message also points there: `$.` refers to the root object, `languages` refers to its member of that name and `[2]` refers to the (missing) third value in the JSON array value of that member (numbering starts at 0, so it is `[2]` instead of `[3]`).  \r\n-The proper solution here is to fix the malformed JSON data.\r\n-\r\n-To spot syntax errors in the JSON data easily you can open it in an editor with support for JSON, for example Visual Studio Code. It will highlight within the JSON data the error location and show why the JSON data is considered invalid.\r\n-\r\n-## <a id=\"number-parsed-as-double\"></a> Integral JSON number is parsed as `double`\r\n-\r\n-**Symptom:** JSON data contains an integral number such as `45` but Gson returns it as `double`\r\n-\r\n-**Reason:** When parsing a JSON number as `Object`, Gson will by default always return a `double`\r\n-\r\n-**Solution:** Use [`GsonBuilder.setObjectToNumberStrategy`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setObjectToNumberStrategy(com.google.gson.ToNumberStrategy)) to specify what type of number should be returned\r\n-\r\n-## <a id=\"default-lenient\"></a> Malformed JSON not rejected\r\n-\r\n-**Symptom:** Gson parses malformed JSON without throwing any exceptions\r\n-\r\n-**Reason:** Due to legacy reasons Gson performs parsing by default in lenient mode\r\n-\r\n-**Solution:** If you are using Gson 2.11.0 or newer, call [`GsonBuilder.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setStrictness(com.google.gson.Strictness)),\r\n-[`JsonReader.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonReader.html#setStrictness(com.google.gson.Strictness))\r\n-and [`JsonWriter.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonWriter.html#setStrictness(com.google.gson.Strictness))\r\n-with `Strictness.STRICT` to overwrite the default lenient behavior of `Gson` and make these classes strictly adhere to the JSON specification.\r\n-Otherwise if you are using an older Gson version, see the [`Gson` class documentation](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#default-lenient)\r\n-section \"JSON Strictness handling\" for alternative solutions.\r\n-\r\n-## <a id=\"unexpected-json-structure\"></a> `IllegalStateException`: \"Expected ... but was ...\"\r\n-\r\n-**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was ...\" is thrown\r\n-\r\n-**Reason:** The JSON data does not have the correct format\r\n-\r\n-**Solution:** Make sure that your classes correctly model the JSON data. Also during debugging log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Read the location information of the exception message, it indicates where exactly in the document the error occurred, including the [JSONPath](https://goessner.net/articles/JsonPath/).\r\n-\r\n-For example, let's assume you have the following Java class:\r\n-\r\n-```java\r\n-class WebPage {\r\n-    String languages;\r\n-}\r\n-```\r\n-\r\n-And you want to deserialize the following JSON data:\r\n-\r\n-```json\r\n-{\r\n-  \"languages\": [\"English\", \"French\"]\r\n-}\r\n-```\r\n-\r\n-This will fail with an exception similar to this one: `IllegalStateException: Expected a string but was BEGIN_ARRAY at line 2 column 17 path $.languages`  \r\n-This means Gson expected a JSON string value but found the beginning of a JSON array (`[`). The location information \"line 2 column 17\" points to the `[` in the JSON data (with some slight inaccuracies), so does the JSONPath `$.languages` in the exception message. It refers to the `languages` member of the root object (`$.`).  \r\n-The solution here is to change in the `WebPage` class the field `String languages` to `List<String> languages`.\r\n-\r\n-## <a id=\"adapter-not-null-safe\"></a> `IllegalStateException`: \"Expected ... but was NULL\"\r\n-\r\n-**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was NULL\" is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- A built-in adapter does not support JSON null values\r\n-- You have written a custom `TypeAdapter` which does not properly handle JSON null values\r\n-\r\n-**Solution:** If this occurs for a custom adapter you wrote, add code similar to the following at the beginning of its `read` method:\r\n-\r\n-```java\r\n-@Override\r\n-public MyClass read(JsonReader in) throws IOException {\r\n-    if (in.peek() == JsonToken.NULL) {\r\n-        in.nextNull();\r\n-        return null;\r\n-    }\r\n-\r\n-    ...\r\n-}\r\n-```\r\n-\r\n-Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html#nullSafe()) on the adapter instance you created.\r\n-\r\n-## <a id=\"serialize-nulls\"></a> Properties missing in JSON\r\n-\r\n-**Symptom:** Properties are missing in the JSON output\r\n-\r\n-**Reason:** Gson by default omits JSON null from the output (or: ProGuard / R8 is not configured correctly and removed unused fields)\r\n-\r\n-**Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\r\n-\r\n-Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\r\n-\r\n-## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\r\n-\r\n-**Symptom:** The JSON output differs when running on newer Android versions\r\n-\r\n-**Reason:** You use Gson by accident to access internal fields of Android classes\r\n-\r\n-**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data\r\n-\r\n-**Explanation:**\r\n-\r\n-When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are experiencing this issue because you (by accident) rely on the reflection-based adapter for Android classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point.\r\n-\r\n-If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\r\n-\r\n-## <a id=\"json-static-fields\"></a> JSON output contains values of `static` fields\r\n-\r\n-**Symptom:** The JSON output contains values of `static` fields\r\n-\r\n-**Reason:** You used `GsonBuilder.excludeFieldsWithModifiers` to overwrite the default excluded modifiers\r\n-\r\n-**Solution:** When calling `GsonBuilder.excludeFieldsWithModifiers` you overwrite the default excluded modifiers. Therefore, you have to explicitly exclude `static` fields if desired. This can be done by adding `Modifier.STATIC` as additional argument.\r\n-\r\n-## <a id=\"no-such-method-error\"></a> `NoSuchMethodError` when calling Gson methods\r\n-\r\n-**Symptom:** A `java.lang.NoSuchMethodError` is thrown when trying to call certain Gson methods\r\n-\r\n-**Reason:**\r\n-\r\n-- You have multiple versions of Gson on your classpath\r\n-- Or, the Gson version you compiled against is different from the one on your classpath\r\n-- Or, you are using a code shrinking tool such as ProGuard or R8 which removed methods from Gson\r\n-\r\n-**Solution:** First disable any code shrinking tools such as ProGuard or R8 and check if the issue persists. If not, you have to tweak the configuration of that tool to not modify Gson classes. Otherwise verify that the Gson JAR on your classpath is the same you are compiling against, and that there is only one Gson JAR on your classpath. See [this Stack Overflow question](https://stackoverflow.com/q/227486) to find out where a class is loaded from. For example, for debugging you could include the following code:\r\n-\r\n-```java\r\n-System.out.println(Gson.class.getProtectionDomain().getCodeSource().getLocation());\r\n-```\r\n-\r\n-If that fails with a `NullPointerException` you have to try one of the other ways to find out where a class is loaded from.\r\n-\r\n-## <a id=\"duplicate-fields\"></a> `IllegalArgumentException`: 'Class ... declares multiple JSON fields named '...''\r\n-\r\n-**Symptom:** An exception with the message 'Class ... declares multiple JSON fields named '...'' is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- The name you have specified with a [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation for a field collides with the name of another field\r\n-- The [`FieldNamingStrategy`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/FieldNamingStrategy.html) you have specified produces conflicting field names\r\n-- A field of your class has the same name as the field of a superclass\r\n-\r\n-Gson prevents multiple fields with the same name because during deserialization it would be ambiguous for which field the JSON data should be deserialized. For serialization it would cause the same field to appear multiple times in JSON. While the JSON specification permits this, it is likely that the application parsing the JSON data will not handle it correctly.\r\n-\r\n-**Solution:** First identify the fields with conflicting names based on the exception message. Then decide if you want to rename one of them using the [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation, or if you want to [exclude](UserGuide.md#excluding-fields-from-serialization-and-deserialization) one of them. When excluding one of the fields you have to include it for both serialization and deserialization (even if your application only performs one of these actions) because the duplicate field check cannot differentiate between these actions.\r\n-\r\n-## <a id=\"java-lang-class-unsupported\"></a> `UnsupportedOperationException` when serializing or deserializing `java.lang.Class`\r\n-\r\n-**Symptom:** An `UnsupportedOperationException` is thrown when trying to serialize or deserialize `java.lang.Class`\r\n-\r\n-**Reason:** Gson intentionally does not permit serializing and deserializing `java.lang.Class` for security reasons. Otherwise a malicious user could make your application load an arbitrary class from the classpath and, depending on what your application does with the `Class`, in the worst case perform a remote code execution attack.\r\n-\r\n-**Solution:** First check if you really need to serialize or deserialize a `Class`. Often it is possible to use string aliases and then map them to the known `Class`; you could write a custom [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) to do this. If the `Class` values are not known in advance, try to introduce a common base class or interface for all these classes and then verify that the deserialized class is a subclass. For example assuming the base class is called `MyBaseClass`, your custom `TypeAdapter` should load the class like this:\r\n-\r\n-```java\r\n-Class.forName(jsonString, false, getClass().getClassLoader()).asSubclass(MyBaseClass.class)\r\n-```\r\n-\r\n-This will not initialize arbitrary classes, and it will throw a `ClassCastException` if the loaded class is not the same as or a subclass of `MyBaseClass`.\r\n-\r\n-## <a id=\"type-token-raw\"></a> `IllegalStateException`: 'TypeToken must be created with a type argument' <br> `RuntimeException`: 'Missing type parameter'\r\n-\r\n-**Symptom:** An `IllegalStateException` with the message 'TypeToken must be created with a type argument' is thrown.  \r\n-For older Gson versions a `RuntimeException` with message 'Missing type parameter' is thrown.\r\n-\r\n-**Reason:**\r\n-\r\n-- You created a `TypeToken` without type argument, for example `new TypeToken() {}` (note the missing `<...>`). You always have to provide the type argument, for example like this: `new TypeToken<List<String>>() {}`. Normally the compiler will also emit a 'raw types' warning when you forget the `<...>`.\r\n-- You are using a code shrinking tool such as ProGuard or R8 (Android app builds normally have this enabled by default) but have not configured it correctly for usage with Gson.\r\n-\r\n-**Solution:** When you are using a code shrinking tool such as ProGuard or R8 you have to adjust your configuration to include the following rules:\r\n-\r\n-```\r\n-# Keep generic signatures; needed for correct type resolution\r\n--keepattributes Signature\r\n-\r\n-# Keep class TypeToken (respectively its generic signature)\r\n--keep class com.google.gson.reflect.TypeToken { *; }\r\n-\r\n-# Keep any (anonymous) classes extending TypeToken\r\n--keep class * extends com.google.gson.reflect.TypeToken\r\n-```\r\n-\r\n-See also the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-Note: For newer Gson versions these rules might be applied automatically; make sure you are using the latest Gson version and the latest version of the code shrinking tool.\r\n-\r\n-## <a id=\"r8-abstract-class\"></a> `JsonIOException`: 'Abstract classes can't be instantiated!' (R8)\r\n-\r\n-**Symptom:** A `JsonIOException` with the message 'Abstract classes can't be instantiated!' is thrown; the class mentioned in the exception message is not actually `abstract` in your source code, and you are using the code shrinking tool R8 (Android app builds normally have this configured by default).\r\n-\r\n-Note: If the class which you are trying to deserialize is actually abstract, then this exception is probably unrelated to R8 and you will have to implement a custom [`InstanceCreator`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/InstanceCreator.html) or [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) which creates an instance of a non-abstract subclass of the class.\r\n-\r\n-**Reason:** The code shrinking tool R8 performs optimizations where it removes the no-args constructor from a class and makes the class `abstract`. Due to this Gson cannot create an instance of the class.\r\n-\r\n-**Solution:** Make sure the class has a no-args constructor, then adjust your R8 configuration file to keep the constructor of the class. For example:\r\n-\r\n-```\r\n-# Keep the no-args constructor of the deserialized class\r\n--keepclassmembers class com.example.MyClass {\r\n-  <init>();\r\n-}\r\n-```\r\n-\r\n-You can also use `<init>(...);` to keep all constructors of that class, but then you might actually rely on `sun.misc.Unsafe` on both JDK and Android to create classes without no-args constructor, see [`GsonBuilder.disableJdkUnsafe()`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) for more information.\r\n-\r\n-For Android you can add this rule to the `proguard-rules.pro` file, see also the [Android documentation](https://developer.android.com/build/shrink-code#keep-code). In case the class name in the exception message is obfuscated, see the Android documentation about [retracing](https://developer.android.com/build/shrink-code#retracing).\r\n-\r\n-For Android you can alternatively use the [`@Keep` annotation](https://developer.android.com/studio/write/annotations#keep) on the class or constructor you want to keep. That might be easier than having to maintain a custom R8 configuration.\r\n-\r\n-Note that the latest Gson versions (> 2.10.1) specify a default R8 configuration. If your class is a top-level class or is `static`, has a no-args constructor and its fields are annotated with Gson's [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html), you might not have to perform any additional R8 configuration.\r\n-\r\n-## <a id=\"typetoken-type-variable\"></a> `IllegalArgumentException`: 'TypeToken type argument must not contain a type variable'\r\n-\r\n-**Symptom:** An exception with the message 'TypeToken type argument must not contain a type variable' is thrown\r\n-\r\n-**Reason:** This exception is thrown when you create an anonymous `TypeToken` subclass which captures a type variable, for example `new TypeToken<List<T>>() {}` (where `T` is a type variable). At compile time such code looks safe and you can use the type `List<T>` without any warnings. However, this code is not actually type-safe because at runtime due to [type erasure](https://dev.java/learn/generics/type-erasure/) only the upper bound of the type variable is available. For the previous example that would be `List<Object>`. When using such a `TypeToken` with any Gson methods performing deserialization this would lead to confusing and difficult to debug `ClassCastException`s. For serialization it can in some cases also lead to undesired results.\r\n-\r\n-Note: Earlier version of Gson unfortunately did not prevent capturing type variables, which caused many users to unwittingly write type-unsafe code.\r\n-\r\n-**Solution:**\r\n-\r\n-- Use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementType)` where `elementType` is a type you have to provide separately.\r\n-- For Kotlin users: Use [`reified` type parameters](https://kotlinlang.org/docs/inline-functions.html#reified-type-parameters), that means change `<T>` to `<reified T>`, if possible. If you have a chain of functions with type parameters you will probably have to make all of them `reified`.\r\n-- If you don't actually use Gson's `TypeToken` for any Gson method, use a general purpose 'type token' implementation provided by a different library instead, for example Guava's [`com.google.common.reflect.TypeToken`](https://javadoc.io/doc/com.google.guava/guava/latest/com/google/common/reflect/TypeToken.html).\r\n-\r\n-For backward compatibility it is possible to restore Gson's old behavior of allowing `TypeToken` to capture type variables by setting the [system property](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/System.html#setProperty(java.lang.String,java.lang.String)) `gson.allowCapturingTypeVariables` to `\"true\"`, **however**:\r\n-\r\n-- This does not solve any of the type-safety problems mentioned above; in the long term you should prefer one of the other solutions listed above. This system property might be removed in future Gson versions.\r\n-- You should only ever set the property to `\"true\"`, but never to any other value or manually clear it. Otherwise this might counteract any libraries you are using which might have deliberately set the system property because they rely on its behavior.\r\n+# Troubleshooting Guide\n+\n+This guide describes how to troubleshoot common issues when using Gson.\n+\n+<!-- The '<a id=\"...\"></a>' anchors below are used to create stable links; don't remove or rename them -->\n+<!-- Use only lowercase IDs, GitHub seems to not support uppercase IDs, see also https://github.com/orgs/community/discussions/50962 -->\n+\n+## <a id=\"class-cast-exception\"></a> `ClassCastException` when using deserialized object\n+\n+**Symptom:** `ClassCastException` is thrown when accessing an object deserialized by Gson\n+\n+**Reason:** Your code is most likely not type-safe\n+\n+**Solution:** Make sure your code adheres to the following:\n+\n+- Avoid raw types: Instead of calling `fromJson(..., List.class)`, create for example a `TypeToken<List<MyClass>>`.\n+  See the [user guide](UserGuide.md#collections-examples) for more information.\n+- When using `TypeToken` prefer the `Gson.fromJson` overloads with `TypeToken` parameter such as [`fromJson(Reader, TypeToken)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#fromJson(java.io.Reader,com.google.gson.reflect.TypeToken)).\n+  The overloads with `Type` parameter do not provide any type-safety guarantees.\n+- When using `TypeToken` make sure you don't capture a type variable. For example avoid something like `new TypeToken<List<T>>()` (where `T` is a type variable). Due to Java [type erasure](https://dev.java/learn/generics/type-erasure/) the actual type of `T` is not available at runtime. Refactor your code to pass around `TypeToken` instances or use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementType)` where `elementType` is a type you have to provide separately.\n+\n+## <a id=\"reflection-inaccessible\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to unnamed module'\n+\n+**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to unnamed module' is thrown\n+\n+**Reason:** You use Gson by accident to access internal fields of third-party classes\n+\n+**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data. If this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\n+\n+**Explanation:**\n+\n+When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are seeing this error because you (by accident) rely on the reflection-based adapter for third-party classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point. For the JDK it is also not possible anymore to access internal fields using reflection starting with JDK 17, see [JEP 403](https://openjdk.org/jeps/403).\n+\n+If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\n+\n+## <a id=\"reflection-inaccessible-to-module-gson\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to module com.google.gson'\n+\n+**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to module com.google.gson' is thrown\n+\n+**Reason:**\n+\n+- If the reported package is your own package then you have not configured the module declaration of your project to allow Gson to use reflection on your classes.\n+- If the reported package is from a third party library or the JDK see [this troubleshooting point](#inaccessibleobjectexception-module--does-not-opens--to-unnamed-module).\n+\n+**Solution:** Make sure the `module-info.java` file of your project allows Gson to use reflection on your classes, for example:\n+\n+```java\n+module mymodule {\n+    requires com.google.gson;\n+\n+    opens mypackage to com.google.gson;\n+}\n+```\n+\n+Or in case this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\n+\n+## <a id=\"android-app-random-names\"></a> Android app not working in Release mode; random property names\n+\n+**Symptom:** Your Android app is working fine in Debug mode but fails in Release mode and the JSON properties have seemingly random names such as `a`, `b`, ...\n+\n+**Reason:** You probably have not configured ProGuard / R8 correctly\n+\n+**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+## <a id=\"android-app-broken-after-app-update\"></a> Android app unable to parse JSON after app update\n+\n+**Symptom:** You released a new version of your Android app and it fails to parse JSON data created by the previous version of your app\n+\n+**Reason:** You probably have not configured ProGuard / R8 correctly; probably the field names are being obfuscated and their naming changed between the versions of your app\n+\n+**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+If you want to preserve backward compatibility for you app you can use [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) on the fields to specify the obfuscated name as alternate, for example: `@SerializedName(value = \"myprop\", alternate = \"a\")`\n+\n+Normally ProGuard and R8 produce a mapping file, this makes it easier to find out the obfuscated field names instead of having to find them out through trial and error or other means. See the [Android Studio user guide](https://developer.android.com/studio/build/shrink-code.html#retracing) for more information.\n+\n+## <a id=\"default-field-values-missing\"></a> Default field values not present after deserialization\n+\n+**Symptom:** You have assign default values to fields but after deserialization the fields have their standard value (such as `null` or `0`)\n+\n+**Reason:** Gson cannot invoke the constructor of your class and falls back to JDK `Unsafe` (or similar means)\n+\n+**Solution:** Make sure that the class:\n+\n+- is `static` (explicitly or implicitly when it is a top-level class)\n+- has a no-args constructor\n+\n+Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\n+\n+## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\n+\n+**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\n+\n+**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\n+\n+**Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\n+\n+Notes:\n+\n+- \"double brace-initialization\" also creates anonymous classes\n+- Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\n+\n+## <a id=\"map-key-wrong-json\"></a> Map keys having unexpected format in JSON\n+\n+**Symptom:** JSON output for `Map` keys is unexpected / cannot be deserialized again\n+\n+**Reason:** The `Map` key type is 'complex' and you have not configured the `GsonBuilder` properly\n+\n+**Solution:** Use [`GsonBuilder.enableComplexMapKeySerialization()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#enableComplexMapKeySerialization()). See also the [user guide](UserGuide.md#maps-examples) for more information.\n+\n+## <a id=\"malformed-json\"></a> Parsing JSON fails with `MalformedJsonException`\n+\n+**Symptom:** JSON parsing fails with `MalformedJsonException`\n+\n+**Reason:** The JSON data is actually malformed\n+\n+**Solution:** During debugging, log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Sometimes APIs might return HTML error pages (instead of JSON data) when reaching rate limits or when other errors occur. Also read the location information of the `MalformedJsonException` exception message, it indicates where exactly in the document the malformed data was detected, including the [JSONPath](https://goessner.net/articles/JsonPath/).\n+\n+For example, let's assume you want to deserialize the following JSON data:\n+\n+```json\n+{\n+  \"languages\": [\n+    \"English\",\n+    \"French\",\n+  ]\n+}\n+```\n+\n+This will fail with an exception similar to this one: `MalformedJsonException: Use JsonReader.setStrictness(Strictness.LENIENT) to accept malformed JSON at line 5 column 4 path $.languages[2]`  \n+The problem here is the trailing comma (`,`) after `\"French\"`, trailing commas are not allowed by the JSON specification. The location information \"line 5 column 4\" points to the `]` in the JSON data (with some slight inaccuracies) because Gson expected another value after `,` instead of the closing `]`. The JSONPath `$.languages[2]` in the exception message also points there: `$.` refers to the root object, `languages` refers to its member of that name and `[2]` refers to the (missing) third value in the JSON array value of that member (numbering starts at 0, so it is `[2]` instead of `[3]`).  \n+The proper solution here is to fix the malformed JSON data.\n+\n+To spot syntax errors in the JSON data easily you can open it in an editor with support for JSON, for example Visual Studio Code. It will highlight within the JSON data the error location and show why the JSON data is considered invalid.\n+\n+## <a id=\"number-parsed-as-double\"></a> Integral JSON number is parsed as `double`\n+\n+**Symptom:** JSON data contains an integral number such as `45` but Gson returns it as `double`\n+\n+**Reason:** When parsing a JSON number as `Object`, Gson will by default always return a `double`\n+\n+**Solution:** Use [`GsonBuilder.setObjectToNumberStrategy`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setObjectToNumberStrategy(com.google.gson.ToNumberStrategy)) to specify what type of number should be returned\n+\n+## <a id=\"default-lenient\"></a> Malformed JSON not rejected\n+\n+**Symptom:** Gson parses malformed JSON without throwing any exceptions\n+\n+**Reason:** Due to legacy reasons Gson performs parsing by default in lenient mode\n+\n+**Solution:** If you are using Gson 2.11.0 or newer, call [`GsonBuilder.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setStrictness(com.google.gson.Strictness)),\n+[`JsonReader.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonReader.html#setStrictness(com.google.gson.Strictness))\n+and [`JsonWriter.setStrictness`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonWriter.html#setStrictness(com.google.gson.Strictness))\n+with `Strictness.STRICT` to overwrite the default lenient behavior of `Gson` and make these classes strictly adhere to the JSON specification.\n+Otherwise if you are using an older Gson version, see the [`Gson` class documentation](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#default-lenient)\n+section \"JSON Strictness handling\" for alternative solutions.\n+\n+## <a id=\"unexpected-json-structure\"></a> `IllegalStateException`: \"Expected ... but was ...\"\n+\n+**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was ...\" is thrown\n+\n+**Reason:** The JSON data does not have the correct format\n+\n+**Solution:** Make sure that your classes correctly model the JSON data. Also during debugging log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Read the location information of the exception message, it indicates where exactly in the document the error occurred, including the [JSONPath](https://goessner.net/articles/JsonPath/).\n+\n+For example, let's assume you have the following Java class:\n+\n+```java\n+class WebPage {\n+    String languages;\n+}\n+```\n+\n+And you want to deserialize the following JSON data:\n+\n+```json\n+{\n+  \"languages\": [\"English\", \"French\"]\n+}\n+```\n+\n+This will fail with an exception similar to this one: `IllegalStateException: Expected a string but was BEGIN_ARRAY at line 2 column 17 path $.languages`  \n+This means Gson expected a JSON string value but found the beginning of a JSON array (`[`). The location information \"line 2 column 17\" points to the `[` in the JSON data (with some slight inaccuracies), so does the JSONPath `$.languages` in the exception message. It refers to the `languages` member of the root object (`$.`).  \n+The solution here is to change in the `WebPage` class the field `String languages` to `List<String> languages`.\n+\n+## <a id=\"adapter-not-null-safe\"></a> `IllegalStateException`: \"Expected ... but was NULL\"\n+\n+**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was NULL\" is thrown\n+\n+**Reason:**\n+\n+- A built-in adapter does not support JSON null values\n+- You have written a custom `TypeAdapter` which does not properly handle JSON null values\n+\n+**Solution:** If this occurs for a custom adapter you wrote, add code similar to the following at the beginning of its `read` method:\n+\n+```java\n+@Override\n+public MyClass read(JsonReader in) throws IOException {\n+    if (in.peek() == JsonToken.NULL) {\n+        in.nextNull();\n+        return null;\n+    }\n+\n+    ...\n+}\n+```\n+\n+Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html#nullSafe()) on the adapter instance you created.\n+\n+## <a id=\"serialize-nulls\"></a> Properties missing in JSON\n+\n+**Symptom:** Properties are missing in the JSON output\n+\n+**Reason:** Gson by default omits JSON null from the output (or: ProGuard / R8 is not configured correctly and removed unused fields)\n+\n+**Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\n+\n+Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\n+\n+## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\n+\n+**Symptom:** The JSON output differs when running on newer Android versions\n+\n+**Reason:** You use Gson by accident to access internal fields of Android classes\n+\n+**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data\n+\n+**Explanation:**\n+\n+When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are experiencing this issue because you (by accident) rely on the reflection-based adapter for Android classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point.\n+\n+If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\n+\n+## <a id=\"json-static-fields\"></a> JSON output contains values of `static` fields\n+\n+**Symptom:** The JSON output contains values of `static` fields\n+\n+**Reason:** You used `GsonBuilder.excludeFieldsWithModifiers` to overwrite the default excluded modifiers\n+\n+**Solution:** When calling `GsonBuilder.excludeFieldsWithModifiers` you overwrite the default excluded modifiers. Therefore, you have to explicitly exclude `static` fields if desired. This can be done by adding `Modifier.STATIC` as additional argument.\n+\n+## <a id=\"no-such-method-error\"></a> `NoSuchMethodError` when calling Gson methods\n+\n+**Symptom:** A `java.lang.NoSuchMethodError` is thrown when trying to call certain Gson methods\n+\n+**Reason:**\n+\n+- You have multiple versions of Gson on your classpath\n+- Or, the Gson version you compiled against is different from the one on your classpath\n+- Or, you are using a code shrinking tool such as ProGuard or R8 which removed methods from Gson\n+\n+**Solution:** First disable any code shrinking tools such as ProGuard or R8 and check if the issue persists. If not, you have to tweak the configuration of that tool to not modify Gson classes. Otherwise verify that the Gson JAR on your classpath is the same you are compiling against, and that there is only one Gson JAR on your classpath. See [this Stack Overflow question](https://stackoverflow.com/q/227486) to find out where a class is loaded from. For example, for debugging you could include the following code:\n+\n+```java\n+System.out.println(Gson.class.getProtectionDomain().getCodeSource().getLocation());\n+```\n+\n+If that fails with a `NullPointerException` you have to try one of the other ways to find out where a class is loaded from.\n+\n+## <a id=\"duplicate-fields\"></a> `IllegalArgumentException`: 'Class ... declares multiple JSON fields named '...''\n+\n+**Symptom:** An exception with the message 'Class ... declares multiple JSON fields named '...'' is thrown\n+\n+**Reason:**\n+\n+- The name you have specified with a [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation for a field collides with the name of another field\n+- The [`FieldNamingStrategy`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/FieldNamingStrategy.html) you have specified produces conflicting field names\n+- A field of your class has the same name as the field of a superclass\n+\n+Gson prevents multiple fields with the same name because during deserialization it would be ambiguous for which field the JSON data should be deserialized. For serialization it would cause the same field to appear multiple times in JSON. While the JSON specification permits this, it is likely that the application parsing the JSON data will not handle it correctly.\n+\n+**Solution:** First identify the fields with conflicting names based on the exception message. Then decide if you want to rename one of them using the [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation, or if you want to [exclude](UserGuide.md#excluding-fields-from-serialization-and-deserialization) one of them. When excluding one of the fields you have to include it for both serialization and deserialization (even if your application only performs one of these actions) because the duplicate field check cannot differentiate between these actions.\n+\n+## <a id=\"java-lang-class-unsupported\"></a> `UnsupportedOperationException` when serializing or deserializing `java.lang.Class`\n+\n+**Symptom:** An `UnsupportedOperationException` is thrown when trying to serialize or deserialize `java.lang.Class`\n+\n+**Reason:** Gson intentionally does not permit serializing and deserializing `java.lang.Class` for security reasons. Otherwise a malicious user could make your application load an arbitrary class from the classpath and, depending on what your application does with the `Class`, in the worst case perform a remote code execution attack.\n+\n+**Solution:** First check if you really need to serialize or deserialize a `Class`. Often it is possible to use string aliases and then map them to the known `Class`; you could write a custom [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) to do this. If the `Class` values are not known in advance, try to introduce a common base class or interface for all these classes and then verify that the deserialized class is a subclass. For example assuming the base class is called `MyBaseClass`, your custom `TypeAdapter` should load the class like this:\n+\n+```java\n+Class.forName(jsonString, false, getClass().getClassLoader()).asSubclass(MyBaseClass.class)\n+```\n+\n+This will not initialize arbitrary classes, and it will throw a `ClassCastException` if the loaded class is not the same as or a subclass of `MyBaseClass`.\n+\n+## <a id=\"type-token-raw\"></a> `IllegalStateException`: 'TypeToken must be created with a type argument' <br> `RuntimeException`: 'Missing type parameter'\n+\n+**Symptom:** An `IllegalStateException` with the message 'TypeToken must be created with a type argument' is thrown.  \n+For older Gson versions a `RuntimeException` with message 'Missing type parameter' is thrown.\n+\n+**Reason:**\n+\n+- You created a `TypeToken` without type argument, for example `new TypeToken() {}` (note the missing `<...>`). You always have to provide the type argument, for example like this: `new TypeToken<List<String>>() {}`. Normally the compiler will also emit a 'raw types' warning when you forget the `<...>`.\n+- You are using a code shrinking tool such as ProGuard or R8 (Android app builds normally have this enabled by default) but have not configured it correctly for usage with Gson.\n+\n+**Solution:** When you are using a code shrinking tool such as ProGuard or R8 you have to adjust your configuration to include the following rules:\n+\n+```\n+# Keep generic signatures; needed for correct type resolution\n+-keepattributes Signature\n+\n+# Keep class TypeToken (respectively its generic signature)\n+-keep class com.google.gson.reflect.TypeToken { *; }\n+\n+# Keep any (anonymous) classes extending TypeToken\n+-keep class * extends com.google.gson.reflect.TypeToken\n+```\n+\n+See also the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+Note: For newer Gson versions these rules might be applied automatically; make sure you are using the latest Gson version and the latest version of the code shrinking tool.\n+\n+## <a id=\"r8-abstract-class\"></a> `JsonIOException`: 'Abstract classes can't be instantiated!' (R8)\n+\n+**Symptom:** A `JsonIOException` with the message 'Abstract classes can't be instantiated!' is thrown; the class mentioned in the exception message is not actually `abstract` in your source code, and you are using the code shrinking tool R8 (Android app builds normally have this configured by default).\n+\n+Note: If the class which you are trying to deserialize is actually abstract, then this exception is probably unrelated to R8 and you will have to implement a custom [`InstanceCreator`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/InstanceCreator.html) or [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) which creates an instance of a non-abstract subclass of the class.\n+\n+**Reason:** The code shrinking tool R8 performs optimizations where it removes the no-args constructor from a class and makes the class `abstract`. Due to this Gson cannot create an instance of the class.\n+\n+**Solution:** Make sure the class has a no-args constructor, then adjust your R8 configuration file to keep the constructor of the class. For example:\n+\n+```\n+# Keep the no-args constructor of the deserialized class\n+-keepclassmembers class com.example.MyClass {\n+  <init>();\n+}\n+```\n+\n+You can also use `<init>(...);` to keep all constructors of that class, but then you might actually rely on `sun.misc.Unsafe` on both JDK and Android to create classes without no-args constructor, see [`GsonBuilder.disableJdkUnsafe()`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) for more information.\n+\n+For Android you can add this rule to the `proguard-rules.pro` file, see also the [Android documentation](https://developer.android.com/build/shrink-code#keep-code). In case the class name in the exception message is obfuscated, see the Android documentation about [retracing](https://developer.android.com/build/shrink-code#retracing).\n+\n+For Android you can alternatively use the [`@Keep` annotation](https://developer.android.com/studio/write/annotations#keep) on the class or constructor you want to keep. That might be easier than having to maintain a custom R8 configuration.\n+\n+Note that the latest Gson versions (> 2.10.1) specify a default R8 configuration. If your class is a top-level class or is `static`, has a no-args constructor and its fields are annotated with Gson's [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html), you might not have to perform any additional R8 configuration.\n+\n+## <a id=\"typetoken-type-variable\"></a> `IllegalArgumentException`: 'TypeToken type argument must not contain a type variable'\n+\n+**Symptom:** An exception with the message 'TypeToken type argument must not contain a type variable' is thrown\n+\n+**Reason:** This exception is thrown when you create an anonymous `TypeToken` subclass which captures a type variable, for example `new TypeToken<List<T>>() {}` (where `T` is a type variable). At compile time such code looks safe and you can use the type `List<T>` without any warnings. However, this code is not actually type-safe because at runtime due to [type erasure](https://dev.java/learn/generics/type-erasure/) only the upper bound of the type variable is available. For the previous example that would be `List<Object>`. When using such a `TypeToken` with any Gson methods performing deserialization this would lead to confusing and difficult to debug `ClassCastException`s. For serialization it can in some cases also lead to undesired results.\n+\n+Note: Earlier version of Gson unfortunately did not prevent capturing type variables, which caused many users to unwittingly write type-unsafe code.\n+\n+**Solution:**\n+\n+- Use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementType)` where `elementType` is a type you have to provide separately.\n+- For Kotlin users: Use [`reified` type parameters](https://kotlinlang.org/docs/inline-functions.html#reified-type-parameters), that means change `<T>` to `<reified T>`, if possible. If you have a chain of functions with type parameters you will probably have to make all of them `reified`.\n+- If you don't actually use Gson's `TypeToken` for any Gson method, use a general purpose 'type token' implementation provided by a different library instead, for example Guava's [`com.google.common.reflect.TypeToken`](https://javadoc.io/doc/com.google.guava/guava/latest/com/google/common/reflect/TypeToken.html).\n+\n+For backward compatibility it is possible to restore Gson's old behavior of allowing `TypeToken` to capture type variables by setting the [system property](https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/System.html#setProperty(java.lang.String,java.lang.String)) `gson.allowCapturingTypeVariables` to `\"true\"`, **however**:\n+\n+- This does not solve any of the type-safety problems mentioned above; in the long term you should prefer one of the other solutions listed above. This system property might be removed in future Gson versions.\n+- You should only ever set the property to `\"true\"`, but never to any other value or manually clear it. Otherwise this might counteract any libraries you are using which might have deliberately set the system property because they rely on its behavior.\n+\n+## <a id=\"cannot-override-object-jsonelement\"></a> Cannot override adapters for `Object` or `JsonElement` via `GsonBuilder`\n+\n+- **Symptom:** Registering a custom adapter for `Object` or for `JsonElement` (including `JsonObject`, `JsonArray`, `JsonPrimitive`, `JsonNull`) using `GsonBuilder` either has no effect or throws `IllegalArgumentException`.\n+- **Reason:** Gson's built-in adapters for these types cannot be overwritten via `GsonBuilder`; they are always used. Newer Gson versions fail fast and throw an exception if such an adapter is registered.\n+- **Solution:** Use [`@JsonAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/JsonAdapter.html) on the specific field to customize handling of `Object` or `JsonElement` values. See also the [`GsonBuilder.registerTypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#registerTypeAdapter(java.lang.reflect.Type,java.lang.Object)) and [`GsonBuilder.registerTypeHierarchyAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#registerTypeHierarchyAdapter(java.lang.Class,java.lang.Object)) documentation.\ndiff --git a/UserGuide.md b/UserGuide.md\nindex ed2fdf33..5b638cc6 100644\n--- a/UserGuide.md\n+++ b/UserGuide.md\n@@ -407,6 +407,8 @@ gson.registerTypeAdapter(MyType.class, new MyInstanceCreator());\n \n `registerTypeAdapter` call checks if the type adapter implements more than one of these interfaces and register it for all of them.\n \n+Note: Overwriting the built-in adapters for `Object` and for `JsonElement` (including `JsonObject`, `JsonArray`, `JsonPrimitive`, `JsonNull`) via `GsonBuilder` is not supported and will throw an `IllegalArgumentException`. If you need to customize handling for a specific field of one of these types, use `@JsonAdapter` on that field instead.\n+\n #### Writing a Serializer\n \n Here is an example of how to write a custom serializer for JodaTime `DateTime` class.\ndiff --git a/gson/src/main/java/com/google/gson/GsonBuilder.java b/gson/src/main/java/com/google/gson/GsonBuilder.java\nindex 68eb7d71..ae2707b4 100644\n--- a/gson/src/main/java/com/google/gson/GsonBuilder.java\n+++ b/gson/src/main/java/com/google/gson/GsonBuilder.java\n@@ -660,10 +660,19 @@ public final class GsonBuilder {\n    * {@code null} without calling the deserializer. If it is desired to handle {@code null} values,\n    * a {@link TypeAdapter} should be used instead.\n    *\n+   * <p>Important: Overwriting the built-in adapters for {@link Object} and for {@link JsonElement}\n+   * (including its subclasses such as {@link JsonObject}, {@link JsonArray}, {@link JsonPrimitive},\n+   * and {@link JsonNull}) via {@code GsonBuilder} is not supported. Attempting to register an\n+   * adapter for any of these types will throw an {@link IllegalArgumentException}. If you need to\n+   * customize the handling for a specific field of one of these types, use {@link com.google.gson.annotations.JsonAdapter}\n+   * on that field instead.</p>\n+   *\n    * @param type the type definition for the type adapter being registered\n    * @param typeAdapter This object must implement at least one of the {@link TypeAdapter},\n    * {@link InstanceCreator}, {@link JsonSerializer}, and a {@link JsonDeserializer} interfaces.\n    * @return a reference to this {@code GsonBuilder} object to fulfill the \"Builder\" pattern\n+   * @throws IllegalArgumentException if attempting to register an adapter for {@code Object} or\n+   *         for {@code JsonElement} (or any of its subclasses)\n    */\n   @CanIgnoreReturnValue\n   public GsonBuilder registerTypeAdapter(Type type, Object typeAdapter) {\n@@ -672,6 +681,15 @@ public final class GsonBuilder {\n         || typeAdapter instanceof JsonDeserializer<?>\n         || typeAdapter instanceof InstanceCreator<?>\n         || typeAdapter instanceof TypeAdapter<?>);\n+\n+    Class<?> rawType = TypeToken.get(type).getRawType();\n+    if (rawType == Object.class) {\n+      throw new IllegalArgumentException(\"Cannot register type adapter for Object with GsonBuilder; overriding the built-in Object adapter is not supported. Use @JsonAdapter on a field if you need custom handling for a specific field.\");\n+    }\n+    if (JsonElement.class.isAssignableFrom(rawType)) {\n+      throw new IllegalArgumentException(\"Cannot register type adapter for \" + rawType.getName() + \" with GsonBuilder; overriding the built-in JsonElement adapters is not supported. Use @JsonAdapter on a field if you need custom handling for a specific field.\");\n+    }\n+\n     if (typeAdapter instanceof InstanceCreator<?>) {\n       instanceCreators.put(type, (InstanceCreator<?>) typeAdapter);\n     }\n@@ -713,12 +731,20 @@ public final class GsonBuilder {\n    * type hierarchy, it is overridden. If a type adapter is registered for a specific type in\n    * the type hierarchy, it will be invoked instead of the one registered for the type hierarchy.\n    *\n+   * <p>Important: Overwriting the built-in adapters for {@link JsonElement} (including its subclasses\n+   * such as {@link JsonObject}, {@link JsonArray}, {@link JsonPrimitive}, and {@link JsonNull})\n+   * via {@code GsonBuilder} is not supported. Attempting to register a hierarchy adapter for any of\n+   * these types will throw an {@link IllegalArgumentException}. If you need to customize the handling\n+   * for a specific field, use {@link com.google.gson.annotations.JsonAdapter} on that field instead.</p>\n+   *\n    * @param baseType the class definition for the type adapter being registered for the base class\n    *        or interface\n    * @param typeAdapter This object must implement at least one of {@link TypeAdapter},\n    *        {@link JsonSerializer} or {@link JsonDeserializer} interfaces.\n    * @return a reference to this {@code GsonBuilder} object to fulfill the \"Builder\" pattern\n    * @since 1.7\n+   * @throws IllegalArgumentException if attempting to register an adapter for {@code JsonElement}\n+   *         (or any of its subclasses)\n    */\n   @CanIgnoreReturnValue\n   public GsonBuilder registerTypeHierarchyAdapter(Class<?> baseType, Object typeAdapter) {\n@@ -726,6 +752,11 @@ public final class GsonBuilder {\n     $Gson$Preconditions.checkArgument(typeAdapter instanceof JsonSerializer<?>\n         || typeAdapter instanceof JsonDeserializer<?>\n         || typeAdapter instanceof TypeAdapter<?>);\n+\n+    if (JsonElement.class.isAssignableFrom(baseType)) {\n+      throw new IllegalArgumentException(\"Cannot register type hierarchy adapter for \" + baseType.getName() + \" with GsonBuilder; overriding the built-in JsonElement adapters is not supported. Use @JsonAdapter on a field if you need custom handling for a specific field.\");\n+    }\n+\n     if (typeAdapter instanceof JsonDeserializer || typeAdapter instanceof JsonSerializer) {\n       hierarchyFactories.add(TreeTypeAdapter.newTypeHierarchyFactory(baseType, typeAdapter));\n     }\n"}
{"instance_id": "google__guava-3971", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/guava/src/com/google/common/util/concurrent/Uninterruptibles.java b/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\nindex 784efa82da..48f926fb07 100644\n--- a/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\n+++ b/guava/src/com/google/common/util/concurrent/Uninterruptibles.java\n@@ -27,6 +27,7 @@ import java.util.concurrent.BlockingQueue;\n import java.util.concurrent.CancellationException;\n import java.util.concurrent.CountDownLatch;\n import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n import java.util.concurrent.Future;\n import java.util.concurrent.Semaphore;\n import java.util.concurrent.TimeUnit;\n@@ -515,5 +516,61 @@ public final class Uninterruptibles {\n \n   // TODO(user): Add support for waitUninterruptibly.\n \n+  /** Invokes {@code executor.}{@link ExecutorService#awaitTermination(long, TimeUnit) awaitTermination(timeout, unit)} uninterruptibly. */\n+  @CanIgnoreReturnValue\n+  @GwtIncompatible // concurrency\n+  @SuppressWarnings(\"GoodTime\") // should accept a java.time.Duration\n+  public static boolean awaitTerminationUninterruptibly(\n+      ExecutorService executor, long timeout, TimeUnit unit) {\n+    boolean interrupted = false;\n+    try {\n+      long remainingNanos = unit.toNanos(timeout);\n+      long end = System.nanoTime() + remainingNanos;\n+      while (true) {\n+        try {\n+          // ExecutorService treats negative timeouts just like zero.\n+          return executor.awaitTermination(remainingNanos, NANOSECONDS);\n+        } catch (InterruptedException e) {\n+          interrupted = true;\n+          remainingNanos = end - System.nanoTime();\n+        }\n+      }\n+    } finally {\n+      if (interrupted) {\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+  }\n+\n+  /** Invokes {@code executor.}{@link ExecutorService#awaitTermination(long, TimeUnit) awaitTermination(Long.MAX_VALUE, NANOSECONDS)} uninterruptibly until termination. */\n+  @GwtIncompatible // concurrency\n+  public static void awaitTerminationUninterruptibly(ExecutorService executor) {\n+    boolean interrupted = false;\n+    try {\n+      while (true) {\n+        try {\n+          if (executor.awaitTermination(Long.MAX_VALUE, NANOSECONDS)) {\n+            return;\n+          }\n+        } catch (InterruptedException e) {\n+          interrupted = true;\n+        }\n+      }\n+    } finally {\n+      if (interrupted) {\n+        Thread.currentThread().interrupt();\n+      }\n+    }\n+  }\n+\n+  /** Invokes {@code executor.}{@link ExecutorService#awaitTermination(long, TimeUnit) awaitTermination(timeout)} uninterruptibly. */\n+  @CanIgnoreReturnValue\n+  @GwtIncompatible // java.time.Duration\n+  @Beta\n+  public static boolean awaitTerminationUninterruptibly(\n+      ExecutorService executor, Duration timeout) {\n+    return awaitTerminationUninterruptibly(executor, toNanosSaturated(timeout), TimeUnit.NANOSECONDS);\n+  }\n+\n   private Uninterruptibles() {}\n }\n"}
{"instance_id": "google__gson-2701", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/proto/README.md b/proto/README.md\nindex c6f7906a..354d3fe4 100644\n--- a/proto/README.md\n+++ b/proto/README.md\n@@ -5,3 +5,27 @@ This Maven module contains the source code for a JSON serializer and deserialize\n messages.\n \n The artifacts created by this module are currently not deployed to Maven Central.\n+\n+## Configuration: json_name support\n+\n+Gson's ProtoTypeAdapter supports optional use of protobuf's `json_name` field descriptor for\n+serialization and deserialization of field names. This behavior is disabled by default to preserve\n+backwards compatibility.\n+\n+To enable it, configure the adapter via its Builder:\n+\n+- Call `setShouldUseJsonNameFieldOption(true)` to use the `json_name` value as the JSON key for\n+  fields which specify it in their proto definitions.\n+- When enabled, case-format conversion settings are ignored for fields which have a `json_name`;\n+  their specified `json_name` is used verbatim.\n+- If both a custom serialized-name extension and `json_name` are present on the same field, the\n+  custom extension takes precedence.\n+\n+Example usage:\n+\n+```\n+ProtoTypeAdapter adapter = ProtoTypeAdapter.newBuilder()\n+    .setFieldNameSerializationFormat(CaseFormat.LOWER_UNDERSCORE, CaseFormat.LOWER_CAMEL)\n+    .setShouldUseJsonNameFieldOption(true)\n+    .build();\n+```\ndiff --git a/proto/src/main/java/com/google/gson/protobuf/ProtoTypeAdapter.java b/proto/src/main/java/com/google/gson/protobuf/ProtoTypeAdapter.java\nindex 7b872f18..e085dbbd 100644\n--- a/proto/src/main/java/com/google/gson/protobuf/ProtoTypeAdapter.java\n+++ b/proto/src/main/java/com/google/gson/protobuf/ProtoTypeAdapter.java\n@@ -89,6 +89,7 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n     private EnumSerialization enumSerialization;\n     private CaseFormat protoFormat;\n     private CaseFormat jsonFormat;\n+    private boolean shouldUseJsonNameFieldOption;\n \n     private Builder(\n         EnumSerialization enumSerialization,\n@@ -129,6 +130,17 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n       return this;\n     }\n \n+    /**\n+     * Enables or disables reading the protobuf field descriptor's {@code json_name} for\n+     * serialization and deserialization of field names. Disabled by default for backward\n+     * compatibility.\n+     */\n+    @CanIgnoreReturnValue\n+    public Builder setShouldUseJsonNameFieldOption(boolean enable) {\n+      this.shouldUseJsonNameFieldOption = enable;\n+      return this;\n+    }\n+\n     /**\n      * Adds a field proto annotation that, when set, overrides the default field name\n      * serialization/deserialization. For example, if you add the '{@code serialized_name}'\n@@ -180,7 +192,8 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n           protoFormat,\n           jsonFormat,\n           serializedNameExtensions,\n-          serializedEnumValueExtensions);\n+          serializedEnumValueExtensions,\n+          shouldUseJsonNameFieldOption);\n     }\n   }\n \n@@ -203,18 +216,21 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n   private final CaseFormat jsonFormat;\n   private final Set<Extension<FieldOptions, String>> serializedNameExtensions;\n   private final Set<Extension<EnumValueOptions, String>> serializedEnumValueExtensions;\n+  private final boolean shouldUseJsonNameFieldOption;\n \n   private ProtoTypeAdapter(\n       EnumSerialization enumSerialization,\n       CaseFormat protoFormat,\n       CaseFormat jsonFormat,\n       Set<Extension<FieldOptions, String>> serializedNameExtensions,\n-      Set<Extension<EnumValueOptions, String>> serializedEnumValueExtensions) {\n+      Set<Extension<EnumValueOptions, String>> serializedEnumValueExtensions,\n+      boolean shouldUseJsonNameFieldOption) {\n     this.enumSerialization = enumSerialization;\n     this.protoFormat = protoFormat;\n     this.jsonFormat = jsonFormat;\n     this.serializedNameExtensions = serializedNameExtensions;\n     this.serializedEnumValueExtensions = serializedEnumValueExtensions;\n+    this.shouldUseJsonNameFieldOption = shouldUseJsonNameFieldOption;\n   }\n \n   @Override\n@@ -224,7 +240,7 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n \n     for (Map.Entry<FieldDescriptor, Object> fieldPair : fields.entrySet()) {\n       final FieldDescriptor desc = fieldPair.getKey();\n-      String name = getCustSerializedName(desc.getOptions(), desc.getName());\n+      String name = getCustSerializedName(desc);\n \n       if (desc.getType() == ENUM_TYPE) {\n         // Enum collections are also returned as ENUM_TYPE\n@@ -273,7 +289,7 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n       // Call setters on all of the available fields\n       for (FieldDescriptor fieldDescriptor : protoDescriptor.getFields()) {\n         String jsonFieldName =\n-            getCustSerializedName(fieldDescriptor.getOptions(), fieldDescriptor.getName());\n+            getCustSerializedName(fieldDescriptor);\n \n         JsonElement jsonElement = jsonObject.get(jsonFieldName);\n         if (jsonElement != null && !jsonElement.isJsonNull()) {\n@@ -320,13 +336,20 @@ public class ProtoTypeAdapter implements JsonSerializer<Message>, JsonDeserializ\n    * Retrieves the custom field name from the given options, and if not found, returns the specified\n    * default name.\n    */\n-  private String getCustSerializedName(FieldOptions options, String defaultName) {\n+  private String getCustSerializedName(FieldDescriptor descriptor) {\n+    FieldOptions options = descriptor.getOptions();\n     for (Extension<FieldOptions, String> extension : serializedNameExtensions) {\n       if (options.hasExtension(extension)) {\n         return options.getExtension(extension);\n       }\n     }\n-    return protoFormat.to(jsonFormat, defaultName);\n+    if (shouldUseJsonNameFieldOption) {\n+      String jsonName = descriptor.getJsonName();\n+      if (jsonName != null && !jsonName.isEmpty()) {\n+        return jsonName;\n+      }\n+    }\n+    return protoFormat.to(jsonFormat, descriptor.getName());\n   }\n \n   /**\n"}
{"instance_id": "apache__dubbo-3622", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/Invoker.java b/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/Invoker.java\nindex 55a948083f..4945b17b67 100644\n--- a/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/Invoker.java\n+++ b/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/Invoker.java\n@@ -17,11 +17,14 @@\n \n package com.alibaba.dubbo.rpc;\n \n-import org.apache.dubbo.common.URL;\n-\n @Deprecated\n public interface Invoker<T> extends org.apache.dubbo.rpc.Invoker<T> {\n \n+    /**\n+     * 2.6.x signature: invoke with com.alibaba Invocation\n+     */\n+    Result invoke(Invocation invocation) throws RpcException;\n+\n     @Override\n     Result invoke(org.apache.dubbo.rpc.Invocation invocation) throws RpcException;\n \n@@ -29,6 +32,12 @@ public interface Invoker<T> extends org.apache.dubbo.rpc.Invoker<T> {\n         return null;\n     }\n \n+    /**\n+     * Covariant return type to keep compatibility with 2.6.x\n+     */\n+    @Override\n+    com.alibaba.dubbo.common.URL getUrl();\n+\n     class CompatibleInvoker<T> implements Invoker<T> {\n \n         private org.apache.dubbo.rpc.Invoker<T> invoker;\n@@ -48,8 +57,51 @@ public interface Invoker<T> extends org.apache.dubbo.rpc.Invoker<T> {\n         }\n \n         @Override\n-        public URL getUrl() {\n-            return invoker.getUrl();\n+        public Result invoke(Invocation invocation) throws RpcException {\n+            org.apache.dubbo.rpc.Invocation original = invocation.getOriginal();\n+            if (original == null) {\n+                // Fallback: wrap the com.alibaba Invocation to org.apache Invocation\n+                original = new org.apache.dubbo.rpc.Invocation() {\n+                    @Override\n+                    public String getMethodName() {\n+                        return invocation.getMethodName();\n+                    }\n+                    @Override\n+                    public Class<?>[] getParameterTypes() {\n+                        return invocation.getParameterTypes();\n+                    }\n+                    @Override\n+                    public Object[] getArguments() {\n+                        return invocation.getArguments();\n+                    }\n+                    @Override\n+                    public java.util.Map<String, String> getAttachments() {\n+                        return invocation.getAttachments();\n+                    }\n+                    @Override\n+                    public String getAttachment(String key) {\n+                        return invocation.getAttachment(key);\n+                    }\n+                    @Override\n+                    public String getAttachment(String key, String defaultValue) {\n+                        return invocation.getAttachment(key, defaultValue);\n+                    }\n+                    @Override\n+                    public org.apache.dubbo.rpc.Invoker<?> getInvoker() {\n+                        org.apache.dubbo.rpc.Invoker<?> originalInvoker = CompatibleInvoker.this.getOriginal();\n+                        if (originalInvoker != null) {\n+                            return originalInvoker;\n+                        }\n+                        return invoker;\n+                    }\n+                };\n+            }\n+            return new Result.CompatibleResult(invoker.invoke(original));\n+        }\n+\n+        @Override\n+        public com.alibaba.dubbo.common.URL getUrl() {\n+            return new com.alibaba.dubbo.common.URL(invoker.getUrl());\n         }\n \n         @Override\ndiff --git a/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/RpcContext.java b/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/RpcContext.java\nindex a5db891beb..d0d176b907 100644\n--- a/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/RpcContext.java\n+++ b/dubbo-compatible/src/main/java/com/alibaba/dubbo/rpc/RpcContext.java\n@@ -19,4 +19,48 @@ package com.alibaba.dubbo.rpc;\n \n @Deprecated\n public class RpcContext extends org.apache.dubbo.rpc.RpcContext {\n+\n+    private static final RpcContext INSTANCE = new RpcContext();\n+\n+    /**\n+     * 2.6.x signature: static access to current RpcContext\n+     */\n+    public static RpcContext getContext() {\n+        return INSTANCE;\n+    }\n+\n+    /**\n+     * Delegate to underlying org.apache RpcContext\n+     */\n+    private org.apache.dubbo.rpc.RpcContext delegate() {\n+        return org.apache.dubbo.rpc.RpcContext.getContext();\n+    }\n+\n+    /**\n+     * 2.6.x signature: set attachment in RpcContext\n+     */\n+    public void setAttachment(String key, String value) {\n+        delegate().setAttachment(key, value);\n+    }\n+\n+    /**\n+     * 2.6.x signature: get attachment from RpcContext\n+     */\n+    public String getAttachment(String key) {\n+        return delegate().getAttachment(key);\n+    }\n+\n+    /**\n+     * 2.6.x signature: remove attachment from RpcContext\n+     */\n+    public void removeAttachment(String key) {\n+        delegate().removeAttachment(key);\n+    }\n+\n+    /**\n+     * 2.6.x signature: get all attachments from RpcContext\n+     */\n+    public java.util.Map<String, String> getAttachments() {\n+        return delegate().getAttachments();\n+    }\n }\n"}
{"instance_id": "apolloconfig__apollo-1894", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/service/AppNamespaceService.java b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/service/AppNamespaceService.java\nindex e29ed8199..dbb2f6d2c 100644\n--- a/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/service/AppNamespaceService.java\n+++ b/apollo-portal/src/main/java/com/ctrip/framework/apollo/portal/service/AppNamespaceService.java\n@@ -105,6 +105,22 @@ public class AppNamespaceService {\n   public AppNamespace createAppNamespaceInLocal(AppNamespace appNamespace, boolean appendNamespacePrefix) {\n     String appId = appNamespace.getAppId();\n \n+    // toggle existing private namespace to public without deletion\n+    AppNamespace existing = appNamespaceRepository.findByAppIdAndName(appId, appNamespace.getName());\n+    String operator = appNamespace.getDataChangeCreatedBy();\n+    if (existing != null && appNamespace.isPublic() && !existing.isPublic()) {\n+      if (StringUtils.isEmpty(operator)) {\n+        operator = userInfoHolder.getUser().getUserId();\n+        appNamespace.setDataChangeCreatedBy(operator);\n+      }\n+      existing.setPublic(true);\n+      existing.setDataChangeLastModifiedBy(operator);\n+      AppNamespace updatedAppNamespace = appNamespaceRepository.save(existing);\n+      roleInitializationService.initNamespaceRoles(updatedAppNamespace.getAppId(), updatedAppNamespace.getName(), operator);\n+      roleInitializationService.initNamespaceEnvRoles(updatedAppNamespace.getAppId(), updatedAppNamespace.getName(), operator);\n+      return updatedAppNamespace;\n+    }\n+\n     //add app org id as prefix\n     App app = appService.load(appId);\n     if (app == null) {\n@@ -127,7 +143,6 @@ public class AppNamespaceService {\n      throw new BadRequestException(\"Invalid namespace format. format must be propertiesjsonyamlymlxml\");\n     }\n \n-    String operator = appNamespace.getDataChangeCreatedBy();\n     if (StringUtils.isEmpty(operator)) {\n       operator = userInfoHolder.getUser().getUserId();\n       appNamespace.setDataChangeCreatedBy(operator);\n"}
{"instance_id": "google__gson-2158", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java b/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\nindex 9ba13637..87e268db 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/TypeAdapters.java\n@@ -194,7 +194,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+        return;\n+      }\n+      out.value((long) value.byteValue());\n     }\n   };\n \n@@ -223,7 +227,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+        return;\n+      }\n+      out.value((long) value.shortValue());\n     }\n   };\n \n@@ -245,7 +253,11 @@ public final class TypeAdapters {\n     }\n     @Override\n     public void write(JsonWriter out, Number value) throws IOException {\n-      out.value(value);\n+      if (value == null) {\n+        out.nullValue();\n+        return;\n+      }\n+      out.value((long) value.intValue());\n     }\n   };\n   public static final TypeAdapterFactory INTEGER_FACTORY\n"}
{"instance_id": "apache__rocketmq-7532", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/AckMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/AckMessageProcessor.java\nindex 59a3e63b2..933f315d1 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/AckMessageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/AckMessageProcessor.java\n@@ -177,6 +177,10 @@ public class AckMessageProcessor implements NettyRequestProcessor {\n             // single ack\n             extraInfo = ExtraInfoUtil.split(requestHeader.getExtraInfo());\n             brokerName = ExtraInfoUtil.getBrokerName(extraInfo);\n+            String localBrokerName = this.brokerController.getBrokerConfig().getBrokerName();\n+            if (brokerName == null || brokerName.isEmpty() || !brokerName.equals(localBrokerName)) {\n+                brokerName = localBrokerName;\n+            }\n             consumeGroup = requestHeader.getConsumerGroup();\n             topic = requestHeader.getTopic();\n             qId = requestHeader.getQueueId();\n@@ -266,7 +270,6 @@ public class AckMessageProcessor implements NettyRequestProcessor {\n         msgInner.setBornHost(this.brokerController.getStoreHost());\n         msgInner.setStoreHost(this.brokerController.getStoreHost());\n         msgInner.setDeliverTimeMs(popTime + invisibleTime);\n-        msgInner.getProperties().put(MessageConst.PROPERTY_UNIQ_CLIENT_MESSAGE_ID_KEYIDX, PopMessageProcessor.genAckUniqueId(ackMsg));\n         msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));\n         PutMessageResult putMessageResult = this.brokerController.getEscapeBridge().putMessageToSpecificQueue(msgInner);\n         if (putMessageResult.getPutMessageStatus() != PutMessageStatus.PUT_OK\ndiff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java\nindex 7ed4d53ab..835820776 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/PopMessageProcessor.java\n@@ -143,6 +143,7 @@ public class PopMessageProcessor implements NettyRequestProcessor {\n                 + PopAckConstants.SPLIT + batchAckMsg.getAckOffsetList().toString()\n                 + PopAckConstants.SPLIT + batchAckMsg.getConsumerGroup()\n                 + PopAckConstants.SPLIT + batchAckMsg.getPopTime()\n+                + PopAckConstants.SPLIT + batchAckMsg.getBrokerName()\n                 + PopAckConstants.SPLIT + PopAckConstants.BATCH_ACK_TAG;\n     }\n \n@@ -590,9 +591,32 @@ public class PopMessageProcessor implements NettyRequestProcessor {\n                 atomicRestNum.set(result.getMaxOffset() - result.getNextBeginOffset() + atomicRestNum.get());\n                 String brokerName = brokerController.getBrokerConfig().getBrokerName();\n                 for (SelectMappedBufferResult mapedBuffer : result.getMessageMapedList()) {\n-                    // We should not recode buffer when popResponseReturnActualRetryTopic is true or topic is not retry topic\n+                    // Always regenerate POP_CK to avoid using stale metadata even if forwarding across brokers\n                     if (brokerController.getBrokerConfig().isPopResponseReturnActualRetryTopic() || !isRetry) {\n-                        getMessageResult.addMessage(mapedBuffer);\n+                        List<MessageExt> messageExtList = MessageDecoder.decodesBatch(mapedBuffer.getByteBuffer(),\n+                            true, false, true);\n+                        mapedBuffer.release();\n+                        for (MessageExt messageExt : messageExtList) {\n+                            try {\n+                                String ckInfo = ExtraInfoUtil.buildExtraInfo(finalOffset, popTime, requestHeader.getInvisibleTime(),\n+                                    reviveQid, messageExt.getTopic(), brokerName, messageExt.getQueueId(), messageExt.getQueueOffset());\n+                                // Overwrite POP_CK and remove stale POP-related properties\n+                                messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK, ckInfo);\n+                                messageExt.getProperties().remove(MessageConst.PROPERTY_POP_CK_OFFSET);\n+                                messageExt.getProperties().remove(MessageConst.PROPERTY_FIRST_POP_TIME);\n+\n+                                // Clear message store size to recode\n+                                messageExt.setStoreSize(0);\n+\n+                                byte[] encode = MessageDecoder.encode(messageExt, false);\n+                                ByteBuffer buffer = ByteBuffer.wrap(encode);\n+                                SelectMappedBufferResult tmpResult =\n+                                    new SelectMappedBufferResult(mapedBuffer.getStartOffset(), buffer, encode.length, null);\n+                                getMessageResult.addMessage(tmpResult);\n+                            } catch (Exception e) {\n+                                POP_LOGGER.error(\"Exception in recode message buffer, topic={}\", topic, e);\n+                            }\n+                        }\n                     } else {\n                         List<MessageExt> messageExtList = MessageDecoder.decodesBatch(mapedBuffer.getByteBuffer(),\n                             true, false, true);\n@@ -601,7 +625,10 @@ public class PopMessageProcessor implements NettyRequestProcessor {\n                             try {\n                                 String ckInfo = ExtraInfoUtil.buildExtraInfo(finalOffset, popTime, requestHeader.getInvisibleTime(),\n                                     reviveQid, messageExt.getTopic(), brokerName, messageExt.getQueueId(), messageExt.getQueueOffset());\n-                                messageExt.getProperties().putIfAbsent(MessageConst.PROPERTY_POP_CK, ckInfo);\n+                                // Overwrite POP_CK and remove stale POP-related properties\n+                                messageExt.getProperties().put(MessageConst.PROPERTY_POP_CK, ckInfo);\n+                                messageExt.getProperties().remove(MessageConst.PROPERTY_POP_CK_OFFSET);\n+                                messageExt.getProperties().remove(MessageConst.PROPERTY_FIRST_POP_TIME);\n \n                                 // Set retry message topic to origin topic and clear message store size to recode\n                                 messageExt.setTopic(requestHeader.getTopic());\n"}
{"instance_id": "google__guava-5696", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/android/guava/src/com/google/common/collect/TopKSelector.java b/android/guava/src/com/google/common/collect/TopKSelector.java\nindex 108679a180..f8cca0deaf 100644\n--- a/android/guava/src/com/google/common/collect/TopKSelector.java\n+++ b/android/guava/src/com/google/common/collect/TopKSelector.java\n@@ -185,7 +185,7 @@ final class TopKSelector<\n       iterations++;\n       if (iterations >= maxIterations) {\n         // We've already taken O(k log k), let's make sure we don't take longer than O(k log k).\n-        Arrays.sort(buffer, left, right, comparator);\n+        Arrays.sort(buffer, left, right + 1, comparator);\n         break;\n       }\n     }\ndiff --git a/guava/src/com/google/common/collect/TopKSelector.java b/guava/src/com/google/common/collect/TopKSelector.java\nindex 69b32f40cb..8411fcdea0 100644\n--- a/guava/src/com/google/common/collect/TopKSelector.java\n+++ b/guava/src/com/google/common/collect/TopKSelector.java\n@@ -186,7 +186,7 @@ final class TopKSelector<\n       iterations++;\n       if (iterations >= maxIterations) {\n         // We've already taken O(k log k), let's make sure we don't take longer than O(k log k).\n-        Arrays.sort(buffer, left, right, comparator);\n+        Arrays.sort(buffer, left, right + 1, comparator);\n         break;\n       }\n     }\n"}
{"instance_id": "google__gson-2549", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/internal/bind/DefaultDateTypeAdapter.java b/gson/src/main/java/com/google/gson/internal/bind/DefaultDateTypeAdapter.java\nindex 4a371348..2ad3f034 100644\n--- a/gson/src/main/java/com/google/gson/internal/bind/DefaultDateTypeAdapter.java\n+++ b/gson/src/main/java/com/google/gson/internal/bind/DefaultDateTypeAdapter.java\n@@ -187,10 +187,14 @@ public final class DefaultDateTypeAdapter<T extends Date> extends TypeAdapter<T>\n     // Needs to be synchronized since JDK DateFormat classes are not thread-safe\n     synchronized (dateFormats) {\n       for (DateFormat dateFormat : dateFormats) {\n+        TimeZone originalTimeZone = dateFormat.getTimeZone();\n         try {\n           return dateFormat.parse(s);\n         } catch (ParseException ignored) {\n           // OK: try the next format\n+        } finally {\n+          // Restore time zone in case parse changed it (see JDK-6609675)\n+          dateFormat.setTimeZone(originalTimeZone);\n         }\n       }\n     }\ndiff --git a/gson/src/main/java/com/google/gson/internal/sql/SqlDateTypeAdapter.java b/gson/src/main/java/com/google/gson/internal/sql/SqlDateTypeAdapter.java\nindex bebd6ca7..e95d634b 100644\n--- a/gson/src/main/java/com/google/gson/internal/sql/SqlDateTypeAdapter.java\n+++ b/gson/src/main/java/com/google/gson/internal/sql/SqlDateTypeAdapter.java\n@@ -29,6 +29,7 @@ import java.text.DateFormat;\n import java.text.ParseException;\n import java.text.SimpleDateFormat;\n import java.util.Date;\n+import java.util.TimeZone;\n \n /**\n  * Adapter for java.sql.Date. Although this class appears stateless, it is not. DateFormat captures\n@@ -62,7 +63,13 @@ final class SqlDateTypeAdapter extends TypeAdapter<java.sql.Date> {\n     try {\n       Date utilDate;\n       synchronized (this) {\n-        utilDate = format.parse(s);\n+        // Capture and restore time zone in case parse changes it (see JDK-6609675)\n+        TimeZone originalTimeZone = format.getTimeZone();\n+        try {\n+          utilDate = format.parse(s);\n+        } finally {\n+          format.setTimeZone(originalTimeZone);\n+        }\n       }\n       return new java.sql.Date(utilDate.getTime());\n     } catch (ParseException e) {\n"}
{"instance_id": "apache__dubbo-8623", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "google__gson-1989", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex 1511bbb1..1cf8b94a 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -765,6 +765,8 @@ public final class Gson {\n     if (prettyPrinting) {\n       jsonWriter.setIndent(\"  \");\n     }\n+    jsonWriter.setHtmlSafe(htmlSafe);\n+    jsonWriter.setLenient(lenient);\n     jsonWriter.setSerializeNulls(serializeNulls);\n     return jsonWriter;\n   }\n"}
{"instance_id": "apache__rocketmq-7655", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/common/src/main/java/org/apache/rocketmq/common/KeyBuilder.java b/common/src/main/java/org/apache/rocketmq/common/KeyBuilder.java\nindex f2a8c4089..aa610e236 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/KeyBuilder.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/KeyBuilder.java\n@@ -19,7 +19,7 @@ package org.apache.rocketmq.common;\n public class KeyBuilder {\n     public static final int POP_ORDER_REVIVE_QUEUE = 999;\n     private static final String POP_RETRY_SEPARATOR_V1 = \"_\";\n-    private static final String POP_RETRY_SEPARATOR_V2 = \":\";\n+    private static final String POP_RETRY_SEPARATOR_V2 = \"+\";\n \n     public static String buildPopRetryTopic(String topic, String cid) {\n         return MixAll.RETRY_GROUP_TOPIC_PREFIX + cid + POP_RETRY_SEPARATOR_V2 + topic;\n@@ -42,9 +42,9 @@ public class KeyBuilder {\n \n     public static String parseNormalTopic(String retryTopic) {\n         if (isPopRetryTopicV2(retryTopic)) {\n-            String[] result = retryTopic.split(POP_RETRY_SEPARATOR_V2);\n-            if (result.length == 2) {\n-                return result[1];\n+            int idx = retryTopic.indexOf(POP_RETRY_SEPARATOR_V2);\n+            if (idx >= 0) {\n+                return retryTopic.substring(idx + POP_RETRY_SEPARATOR_V2.length());\n             }\n         }\n         return retryTopic;\n@@ -52,9 +52,9 @@ public class KeyBuilder {\n \n     public static String parseGroup(String retryTopic) {\n         if (isPopRetryTopicV2(retryTopic)) {\n-            String[] result = retryTopic.split(POP_RETRY_SEPARATOR_V2);\n-            if (result.length == 2) {\n-                return result[0].substring(MixAll.RETRY_GROUP_TOPIC_PREFIX.length());\n+            int idx = retryTopic.indexOf(POP_RETRY_SEPARATOR_V2);\n+            if (idx >= 0) {\n+                return retryTopic.substring(MixAll.RETRY_GROUP_TOPIC_PREFIX.length(), idx);\n             }\n         }\n         return retryTopic.substring(MixAll.RETRY_GROUP_TOPIC_PREFIX.length());\ndiff --git a/common/src/main/java/org/apache/rocketmq/common/topic/TopicValidator.java b/common/src/main/java/org/apache/rocketmq/common/topic/TopicValidator.java\nindex c19592a44..c168719aa 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/topic/TopicValidator.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/topic/TopicValidator.java\n@@ -18,6 +18,7 @@ package org.apache.rocketmq.common.topic;\n \n import java.util.HashSet;\n import java.util.Set;\n+import org.apache.rocketmq.common.MixAll;\n import org.apache.rocketmq.common.UtilAll;\n \n public class TopicValidator {\n@@ -107,8 +108,23 @@ public class TopicValidator {\n             return new ValidateTopicResult(false, \"The specified topic is blank.\");\n         }\n \n-        if (isTopicOrGroupIllegal(topic)) {\n-            return new ValidateTopicResult(false, \"The specified topic contains illegal characters, allowing only ^[%|a-zA-Z0-9_-]+$\");\n+        if (topic.startsWith(MixAll.RETRY_GROUP_TOPIC_PREFIX)) {\n+            // Allow '+' specifically for pop retry topics v2\n+            int strLen = topic.length();\n+            int len = VALID_CHAR_BIT_MAP.length;\n+            for (int i = 0; i < strLen; i++) {\n+                char ch = topic.charAt(i);\n+                if (ch == '+') {\n+                    continue;\n+                }\n+                if (ch >= len || !VALID_CHAR_BIT_MAP[ch]) {\n+                    return new ValidateTopicResult(false, \"The specified topic contains illegal characters, allowing only ^[%|a-zA-Z0-9_-]+$ or '+' in retry topics\");\n+                }\n+            }\n+        } else {\n+            if (isTopicOrGroupIllegal(topic)) {\n+                return new ValidateTopicResult(false, \"The specified topic contains illegal characters, allowing only ^[%|a-zA-Z0-9_-]+$\");\n+            }\n         }\n \n         if (topic.length() > TOPIC_MAX_LENGTH) {\n"}
{"instance_id": "apache__dubbo-5783", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/CompatibleTypeUtils.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/CompatibleTypeUtils.java\nindex cce01c9c84..1776522787 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/CompatibleTypeUtils.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/CompatibleTypeUtils.java\n@@ -1,210 +1,215 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.common.utils;\r\n-\r\n-import java.lang.reflect.Array;\r\n-import java.math.BigDecimal;\r\n-import java.math.BigInteger;\r\n-import java.text.ParseException;\r\n-import java.text.SimpleDateFormat;\r\n-import java.util.ArrayList;\r\n-import java.util.Collection;\r\n-import java.util.Date;\r\n-import java.util.HashSet;\r\n-import java.util.List;\r\n-import java.util.Set;\r\n-\r\n-public class CompatibleTypeUtils {\r\n-\r\n-    private static final String DATE_FORMAT = \"yyyy-MM-dd HH:mm:ss\";\r\n-\r\n-    private CompatibleTypeUtils() {\r\n-    }\r\n-\r\n-    /**\r\n-     * Compatible type convert. Null value is allowed to pass in. If no conversion is needed, then the original value\r\n-     * will be returned.\r\n-     * <p>\r\n-     * Supported compatible type conversions include (primary types and corresponding wrappers are not listed):\r\n-     * <ul>\r\n-     * <li> String -> char, enum, Date\r\n-     * <li> byte, short, int, long -> byte, short, int, long\r\n-     * <li> float, double -> float, double\r\n-     * </ul>\r\n-     */\r\n-    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\r\n-    public static Object compatibleTypeConvert(Object value, Class<?> type) {\r\n-        if (value == null || type == null || type.isAssignableFrom(value.getClass())) {\r\n-            return value;\r\n-        }\r\n-\r\n-        if (value instanceof String) {\r\n-            String string = (String) value;\r\n-            if (char.class.equals(type) || Character.class.equals(type)) {\r\n-                if (string.length() != 1) {\r\n-                    throw new IllegalArgumentException(String.format(\"CAN NOT convert String(%s) to char!\" +\r\n-                            \" when convert String to char, the String MUST only 1 char.\", string));\r\n-                }\r\n-                return string.charAt(0);\r\n-            }\r\n-            if (type.isEnum()) {\r\n-                return Enum.valueOf((Class<Enum>) type, string);\r\n-            }\r\n-            if (type == BigInteger.class) {\r\n-                return new BigInteger(string);\r\n-            }\r\n-            if (type == BigDecimal.class) {\r\n-                return new BigDecimal(string);\r\n-            }\r\n-            if (type == Short.class || type == short.class) {\r\n-                return new Short(string);\r\n-            }\r\n-            if (type == Integer.class || type == int.class) {\r\n-                return new Integer(string);\r\n-            }\r\n-            if (type == Long.class || type == long.class) {\r\n-                return new Long(string);\r\n-            }\r\n-            if (type == Double.class || type == double.class) {\r\n-                return new Double(string);\r\n-            }\r\n-            if (type == Float.class || type == float.class) {\r\n-                return new Float(string);\r\n-            }\r\n-            if (type == Byte.class || type == byte.class) {\r\n-                return new Byte(string);\r\n-            }\r\n-            if (type == Boolean.class || type == boolean.class) {\r\n-                return Boolean.valueOf(string);\r\n-            }\r\n-            if (type == Date.class || type == java.sql.Date.class || type == java.sql.Timestamp.class\r\n-                    || type == java.sql.Time.class) {\r\n-                try {\r\n-                    Date date = new SimpleDateFormat(DATE_FORMAT).parse(string);\r\n-                    if (type == java.sql.Date.class) {\r\n-                        return new java.sql.Date(date.getTime());\r\n-                    }\r\n-                    if (type == java.sql.Timestamp.class) {\r\n-                        return new java.sql.Timestamp(date.getTime());\r\n-                    }\r\n-                    if (type == java.sql.Time.class) {\r\n-                        return new java.sql.Time(date.getTime());\r\n-                    }\r\n-                    return date;\r\n-                } catch (ParseException e) {\r\n-                    throw new IllegalStateException(\"Failed to parse date \" + value + \" by format \"\r\n-                            + DATE_FORMAT + \", cause: \" + e.getMessage(), e);\r\n-                }\r\n-            }\r\n-            if (type == Class.class) {\r\n-                try {\r\n-                    return ReflectUtils.name2class(string);\r\n-                } catch (ClassNotFoundException e) {\r\n-                    throw new RuntimeException(e.getMessage(), e);\r\n-                }\r\n-            }\r\n-            if (char[].class.equals(type)) {\r\n-                // Process string to char array for generic invoke\r\n-                // See\r\n-                // - https://github.com/apache/dubbo/issues/2003\r\n-                int len = string.length();\r\n-                char[] chars = new char[len];\r\n-                string.getChars(0, len, chars, 0);\r\n-                return chars;\r\n-            }\r\n-        }\r\n-        if (value instanceof Number) {\r\n-            Number number = (Number) value;\r\n-            if (type == byte.class || type == Byte.class) {\r\n-                return number.byteValue();\r\n-            }\r\n-            if (type == short.class || type == Short.class) {\r\n-                return number.shortValue();\r\n-            }\r\n-            if (type == int.class || type == Integer.class) {\r\n-                return number.intValue();\r\n-            }\r\n-            if (type == long.class || type == Long.class) {\r\n-                return number.longValue();\r\n-            }\r\n-            if (type == float.class || type == Float.class) {\r\n-                return number.floatValue();\r\n-            }\r\n-            if (type == double.class || type == Double.class) {\r\n-                return number.doubleValue();\r\n-            }\r\n-            if (type == BigInteger.class) {\r\n-                return BigInteger.valueOf(number.longValue());\r\n-            }\r\n-            if (type == BigDecimal.class) {\r\n-                return BigDecimal.valueOf(number.doubleValue());\r\n-            }\r\n-            if (type == Date.class) {\r\n-                return new Date(number.longValue());\r\n-            }\r\n-            if (type == boolean.class || type == Boolean.class) {\r\n-                return 0 != number.intValue();\r\n-            }\r\n-        }\r\n-        if (value instanceof Collection) {\r\n-            Collection collection = (Collection) value;\r\n-            if (type.isArray()) {\r\n-                int length = collection.size();\r\n-                Object array = Array.newInstance(type.getComponentType(), length);\r\n-                int i = 0;\r\n-                for (Object item : collection) {\r\n-                    Array.set(array, i++, item);\r\n-                }\r\n-                return array;\r\n-            }\r\n-            if (!type.isInterface()) {\r\n-                try {\r\n-                    Collection result = (Collection) type.newInstance();\r\n-                    result.addAll(collection);\r\n-                    return result;\r\n-                } catch (Throwable ignored) {\r\n-                }\r\n-            }\r\n-            if (type == List.class) {\r\n-                return new ArrayList<Object>(collection);\r\n-            }\r\n-            if (type == Set.class) {\r\n-                return new HashSet<Object>(collection);\r\n-            }\r\n-        }\r\n-        if (value.getClass().isArray() && Collection.class.isAssignableFrom(type)) {\r\n-            Collection collection;\r\n-            if (!type.isInterface()) {\r\n-                try {\r\n-                    collection = (Collection) type.newInstance();\r\n-                } catch (Throwable e) {\r\n-                    collection = new ArrayList<Object>();\r\n-                }\r\n-            } else if (type == Set.class) {\r\n-                collection = new HashSet<Object>();\r\n-            } else {\r\n-                collection = new ArrayList<Object>();\r\n-            }\r\n-            int length = Array.getLength(value);\r\n-            for (int i = 0; i < length; i++) {\r\n-                collection.add(Array.get(value, i));\r\n-            }\r\n-            return collection;\r\n-        }\r\n-        return value;\r\n-    }\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.common.utils;\n+\n+import java.lang.reflect.Array;\n+import java.math.BigDecimal;\n+import java.math.BigInteger;\n+import java.text.ParseException;\n+import java.text.SimpleDateFormat;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Set;\n+\n+public class CompatibleTypeUtils {\n+\n+    private static final String DATE_FORMAT = \"yyyy-MM-dd HH:mm:ss\";\n+\n+    private CompatibleTypeUtils() {\n+    }\n+\n+    /**\n+     * Compatible type convert. Null value is allowed to pass in. If no conversion is needed, then the original value\n+     * will be returned.\n+     * <p>\n+     * Supported compatible type conversions include (primary types and corresponding wrappers are not listed):\n+     * <ul>\n+     * <li> String -> char, enum, Date\n+     * <li> byte, short, int, long -> byte, short, int, long\n+     * <li> float, double -> float, double\n+     * </ul>\n+     */\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    public static Object compatibleTypeConvert(Object value, Class<?> type) {\n+        if (value == null || type == null || type.isAssignableFrom(value.getClass())) {\n+            return value;\n+        }\n+\n+        // Support for Java 8 time types (LocalDateTime, LocalDate, LocalTime) via reflection\n+        if (Java8TimeCompatUtils.isJava8TimeType(type)) {\n+            return Java8TimeCompatUtils.convert(value, type);\n+        }\n+\n+        if (value instanceof String) {\n+            String string = (String) value;\n+            if (char.class.equals(type) || Character.class.equals(type)) {\n+                if (string.length() != 1) {\n+                    throw new IllegalArgumentException(String.format(\"CAN NOT convert String(%s) to char!\" +\n+                            \" when convert String to char, the String MUST only 1 char.\", string));\n+                }\n+                return string.charAt(0);\n+            }\n+            if (type.isEnum()) {\n+                return Enum.valueOf((Class<Enum>) type, string);\n+            }\n+            if (type == BigInteger.class) {\n+                return new BigInteger(string);\n+            }\n+            if (type == BigDecimal.class) {\n+                return new BigDecimal(string);\n+            }\n+            if (type == Short.class || type == short.class) {\n+                return new Short(string);\n+            }\n+            if (type == Integer.class || type == int.class) {\n+                return new Integer(string);\n+            }\n+            if (type == Long.class || type == long.class) {\n+                return new Long(string);\n+            }\n+            if (type == Double.class || type == double.class) {\n+                return new Double(string);\n+            }\n+            if (type == Float.class || type == float.class) {\n+                return new Float(string);\n+            }\n+            if (type == Byte.class || type == byte.class) {\n+                return new Byte(string);\n+            }\n+            if (type == Boolean.class || type == boolean.class) {\n+                return Boolean.valueOf(string);\n+            }\n+            if (type == Date.class || type == java.sql.Date.class || type == java.sql.Timestamp.class\n+                    || type == java.sql.Time.class) {\n+                try {\n+                    Date date = new SimpleDateFormat(DATE_FORMAT).parse(string);\n+                    if (type == java.sql.Date.class) {\n+                        return new java.sql.Date(date.getTime());\n+                    }\n+                    if (type == java.sql.Timestamp.class) {\n+                        return new java.sql.Timestamp(date.getTime());\n+                    }\n+                    if (type == java.sql.Time.class) {\n+                        return new java.sql.Time(date.getTime());\n+                    }\n+                    return date;\n+                } catch (ParseException e) {\n+                    throw new IllegalStateException(\"Failed to parse date \" + value + \" by format \"\n+                            + DATE_FORMAT + \", cause: \" + e.getMessage(), e);\n+                }\n+            }\n+            if (type == Class.class) {\n+                try {\n+                    return ReflectUtils.name2class(string);\n+                } catch (ClassNotFoundException e) {\n+                    throw new RuntimeException(e.getMessage(), e);\n+                }\n+            }\n+            if (char[].class.equals(type)) {\n+                // Process string to char array for generic invoke\n+                // See\n+                // - https://github.com/apache/dubbo/issues/2003\n+                int len = string.length();\n+                char[] chars = new char[len];\n+                string.getChars(0, len, chars, 0);\n+                return chars;\n+            }\n+        }\n+        if (value instanceof Number) {\n+            Number number = (Number) value;\n+            if (type == byte.class || type == Byte.class) {\n+                return number.byteValue();\n+            }\n+            if (type == short.class || type == Short.class) {\n+                return number.shortValue();\n+            }\n+            if (type == int.class || type == Integer.class) {\n+                return number.intValue();\n+            }\n+            if (type == long.class || type == Long.class) {\n+                return number.longValue();\n+            }\n+            if (type == float.class || type == Float.class) {\n+                return number.floatValue();\n+            }\n+            if (type == double.class || type == Double.class) {\n+                return number.doubleValue();\n+            }\n+            if (type == BigInteger.class) {\n+                return BigInteger.valueOf(number.longValue());\n+            }\n+            if (type == BigDecimal.class) {\n+                return BigDecimal.valueOf(number.doubleValue());\n+            }\n+            if (type == Date.class) {\n+                return new Date(number.longValue());\n+            }\n+            if (type == boolean.class || type == Boolean.class) {\n+                return 0 != number.intValue();\n+            }\n+        }\n+        if (value instanceof Collection) {\n+            Collection collection = (Collection) value;\n+            if (type.isArray()) {\n+                int length = collection.size();\n+                Object array = Array.newInstance(type.getComponentType(), length);\n+                int i = 0;\n+                for (Object item : collection) {\n+                    Array.set(array, i++, item);\n+                }\n+                return array;\n+            }\n+            if (!type.isInterface()) {\n+                try {\n+                    Collection result = (Collection) type.newInstance();\n+                    result.addAll(collection);\n+                    return result;\n+                } catch (Throwable ignored) {\n+                }\n+            }\n+            if (type == List.class) {\n+                return new ArrayList<Object>(collection);\n+            }\n+            if (type == Set.class) {\n+                return new HashSet<Object>(collection);\n+            }\n+        }\n+        if (value.getClass().isArray() && Collection.class.isAssignableFrom(type)) {\n+            Collection collection;\n+            if (!type.isInterface()) {\n+                try {\n+                    collection = (Collection) type.newInstance();\n+                } catch (Throwable e) {\n+                    collection = new ArrayList<Object>();\n+                }\n+            } else if (type == Set.class) {\n+                collection = new HashSet<Object>();\n+            } else {\n+                collection = new ArrayList<Object>();\n+            }\n+            int length = Array.getLength(value);\n+            for (int i = 0; i < length; i++) {\n+                collection.add(Array.get(value, i));\n+            }\n+            return collection;\n+        }\n+        return value;\n+    }\n+}\ndiff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/Java8TimeCompatUtils.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/Java8TimeCompatUtils.java\nnew file mode 100644\nindex 0000000000..8cd599b3bf\n--- /dev/null\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/Java8TimeCompatUtils.java\n@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.common.utils;\n+\n+import java.lang.reflect.Method;\n+\n+/**\n+ * Java8 time compatibility utils implemented via reflection to keep Dubbo 2.6.x compatible with JDK < 8 at compile time.\n+ * Supports conversion to java.time.LocalDateTime, java.time.LocalDate, java.time.LocalTime from String, Long/Number, and java.util.Date.\n+ */\n+public final class Java8TimeCompatUtils {\n+\n+    private Java8TimeCompatUtils() {\n+    }\n+\n+    public static boolean isJava8TimeType(Class<?> targetType) {\n+        if (targetType == null) {\n+            return false;\n+        }\n+        String name = targetType.getName();\n+        return \"java.time.LocalDateTime\".equals(name)\n+                || \"java.time.LocalDate\".equals(name)\n+                || \"java.time.LocalTime\".equals(name);\n+    }\n+\n+    /**\n+     * Convert the given value to the specified Java 8 time type using reflection.\n+     */\n+    public static Object convert(Object value, Class<?> targetType) {\n+        if (value == null) {\n+            return null;\n+        }\n+        String targetName = targetType.getName();\n+        try {\n+            if (\"java.time.LocalDateTime\".equals(targetName)) {\n+                return toLocalDateTime(value);\n+            } else if (\"java.time.LocalDate\".equals(targetName)) {\n+                if (value instanceof CharSequence) {\n+                    String s = value.toString().trim();\n+                    if (s.length() == 0) return null;\n+                    Object ld = parseLocalDate(s);\n+                    if (ld != null) return ld;\n+                    if (isDigits(s)) {\n+                        Object ldt = epochMillisToLocalDateTime(Long.parseLong(s));\n+                        Class<?> ldtClass = Class.forName(\"java.time.LocalDateTime\");\n+                        Method toLocalDate = ldtClass.getMethod(\"toLocalDate\");\n+                        return toLocalDate.invoke(ldt);\n+                    }\n+                    throw new IllegalArgumentException(\"Unparseable date string: \" + s + \". Supported formats: ISO_LOCAL_DATE, yyyy-MM-dd, or epoch millis.\");\n+                }\n+                Object ldt = toLocalDateTime(value);\n+                if (ldt == null) return null;\n+                Class<?> ldtClass = Class.forName(\"java.time.LocalDateTime\");\n+                Method toLocalDate = ldtClass.getMethod(\"toLocalDate\");\n+                return toLocalDate.invoke(ldt);\n+            } else if (\"java.time.LocalTime\".equals(targetName)) {\n+                if (value instanceof CharSequence) {\n+                    String s = value.toString().trim();\n+                    if (s.length() == 0) return null;\n+                    Object lt = parseLocalTime(s);\n+                    if (lt != null) return lt;\n+                    if (isDigits(s)) {\n+                        Object ldt = epochMillisToLocalDateTime(Long.parseLong(s));\n+                        Class<?> ldtClass = Class.forName(\"java.time.LocalDateTime\");\n+                        Method toLocalTime = ldtClass.getMethod(\"toLocalTime\");\n+                        return toLocalTime.invoke(ldt);\n+                    }\n+                    throw new IllegalArgumentException(\"Unparseable time string: \" + s + \". Supported formats: ISO_LOCAL_TIME, HH:mm:ss[.SSS], or epoch millis.\");\n+                }\n+                Object ldt = toLocalDateTime(value);\n+                if (ldt == null) return null;\n+                Class<?> ldtClass = Class.forName(\"java.time.LocalDateTime\");\n+                Method toLocalTime = ldtClass.getMethod(\"toLocalTime\");\n+                return toLocalTime.invoke(ldt);\n+            }\n+        } catch (Throwable t) {\n+            throw new IllegalArgumentException(\"Failed to convert value \" + value + \" to \" + targetName + \": \" + t.getMessage(), t);\n+        }\n+        return value;\n+    }\n+\n+    private static Object toLocalDateTime(Object value) throws Exception {\n+        if (value == null) {\n+            return null;\n+        }\n+        Class<?> ldtClass = Class.forName(\"java.time.LocalDateTime\");\n+        if (ldtClass.isInstance(value)) {\n+            return value; // already LocalDateTime\n+        }\n+        if (value instanceof CharSequence) {\n+            String s = value.toString().trim();\n+            if (s.length() == 0) {\n+                return null;\n+            }\n+            // Try ISO first\n+            try {\n+                Method parse = ldtClass.getMethod(\"parse\", CharSequence.class);\n+                return parse.invoke(null, s);\n+            } catch (Throwable ignored) {\n+            }\n+            // Try common patterns: yyyy-MM-dd HH:mm:ss or with millis\n+            try {\n+                Class<?> dtfClass = Class.forName(\"java.time.format.DateTimeFormatter\");\n+                Method ofPattern = dtfClass.getMethod(\"ofPattern\", String.class);\n+                Object formatter = ofPattern.invoke(null, \"yyyy-MM-dd HH:mm:ss\");\n+                Method parse = ldtClass.getMethod(\"parse\", CharSequence.class, dtfClass);\n+                return parse.invoke(null, s, formatter);\n+            } catch (Throwable ignored) {\n+            }\n+            try {\n+                Class<?> dtfClass = Class.forName(\"java.time.format.DateTimeFormatter\");\n+                Method ofPattern = dtfClass.getMethod(\"ofPattern\", String.class);\n+                Object formatter = ofPattern.invoke(null, \"yyyy-MM-dd HH:mm:ss.SSS\");\n+                Method parse = ldtClass.getMethod(\"parse\", CharSequence.class, dtfClass);\n+                return parse.invoke(null, s, formatter);\n+            } catch (Throwable ignored) {\n+            }\n+            // If numeric string -> epoch millis\n+            if (isDigits(s)) {\n+                long epochMillis = Long.parseLong(s);\n+                return epochMillisToLocalDateTime(epochMillis);\n+            }\n+            throw new IllegalArgumentException(\"Unparseable date-time string: \" + s + \". Supported formats: ISO_LOCAL_DATE_TIME, yyyy-MM-dd HH:mm:ss[.SSS], or epoch millis.\");\n+        }\n+        if (value instanceof Number) {\n+            long epochMillis = ((Number) value).longValue();\n+            return epochMillisToLocalDateTime(epochMillis);\n+        }\n+        if (value instanceof java.util.Date) {\n+            long epochMillis = ((java.util.Date) value).getTime();\n+            return epochMillisToLocalDateTime(epochMillis);\n+        }\n+        // Unsupported source\n+        throw new IllegalArgumentException(\"Unsupported source type for Java 8 time conversion: \" + value.getClass());\n+    }\n+\n+    private static Object parseLocalDate(String s) throws Exception {\n+        Class<?> ldClass = Class.forName(\"java.time.LocalDate\");\n+        try {\n+            Method parse = ldClass.getMethod(\"parse\", CharSequence.class);\n+            return parse.invoke(null, s);\n+        } catch (Throwable ignored) {\n+        }\n+        try {\n+            Class<?> dtfClass = Class.forName(\"java.time.format.DateTimeFormatter\");\n+            Method ofPattern = dtfClass.getMethod(\"ofPattern\", String.class);\n+            Object formatter = ofPattern.invoke(null, \"yyyy-MM-dd\");\n+            Method parse = ldClass.getMethod(\"parse\", CharSequence.class, dtfClass);\n+            return parse.invoke(null, s, formatter);\n+        } catch (Throwable ignored) {\n+        }\n+        return null;\n+    }\n+\n+    private static Object parseLocalTime(String s) throws Exception {\n+        Class<?> ltClass = Class.forName(\"java.time.LocalTime\");\n+        try {\n+            Method parse = ltClass.getMethod(\"parse\", CharSequence.class);\n+            return parse.invoke(null, s);\n+        } catch (Throwable ignored) {\n+        }\n+        try {\n+            Class<?> dtfClass = Class.forName(\"java.time.format.DateTimeFormatter\");\n+            Method ofPattern = dtfClass.getMethod(\"ofPattern\", String.class);\n+            Object formatter = ofPattern.invoke(null, \"HH:mm:ss\");\n+            Method parse = ltClass.getMethod(\"parse\", CharSequence.class, dtfClass);\n+            return parse.invoke(null, s, formatter);\n+        } catch (Throwable ignored) {\n+        }\n+        try {\n+            Class<?> dtfClass = Class.forName(\"java.time.format.DateTimeFormatter\");\n+            Method ofPattern = dtfClass.getMethod(\"ofPattern\", String.class);\n+            Object formatter = ofPattern.invoke(null, \"HH:mm:ss.SSS\");\n+            Method parse = ltClass.getMethod(\"parse\", CharSequence.class, dtfClass);\n+            return parse.invoke(null, s, formatter);\n+        } catch (Throwable ignored) {\n+        }\n+        return null;\n+    }\n+\n+    private static Object epochMillisToLocalDateTime(long epochMillis) throws Exception {\n+        Class<?> instantClass = Class.forName(\"java.time.Instant\");\n+        Class<?> zoneIdClass = Class.forName(\"java.time.ZoneId\");\n+        Class<?> ldtClass = Class.forName(\"java.time.LocalDateTime\");\n+        Method ofEpochMilli = instantClass.getMethod(\"ofEpochMilli\", long.class);\n+        Object instant = ofEpochMilli.invoke(null, epochMillis);\n+        Method systemDefault = zoneIdClass.getMethod(\"systemDefault\");\n+        Object zoneId = systemDefault.invoke(null);\n+        Method ofInstant = ldtClass.getMethod(\"ofInstant\", instantClass, zoneIdClass);\n+        return ofInstant.invoke(null, instant, zoneId);\n+    }\n+\n+    private static boolean isDigits(String s) {\n+        int len = s.length();\n+        for (int i = 0; i < len; i++) {\n+            char c = s.charAt(i);\n+            if (c < '0' || c > '9') {\n+                return false;\n+            }\n+        }\n+        return true;\n+    }\n+}\n"}
{"instance_id": "google__gson-2420", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/Troubleshooting.md b/Troubleshooting.md\nindex 57e781cb..dfbc9ed4 100644\n--- a/Troubleshooting.md\n+++ b/Troubleshooting.md\n@@ -1,329 +1,337 @@\n-# Troubleshooting Guide\r\n-\r\n-This guide describes how to troubleshoot common issues when using Gson.\r\n-\r\n-<!-- The '<a id=\"...\"></a>' anchors below are used to create stable links; don't remove or rename them -->\r\n-<!-- Use only lowercase IDs, GitHub seems to not support uppercase IDs, see also https://github.com/orgs/community/discussions/50962 -->\r\n-\r\n-## <a id=\"class-cast-exception\"></a> `ClassCastException` when using deserialized object\r\n-\r\n-**Symptom:** `ClassCastException` is thrown when accessing an object deserialized by Gson\r\n-\r\n-**Reason:** Your code is most likely not type-safe\r\n-\r\n-**Solution:** Make sure your code adheres to the following:\r\n-\r\n-- Avoid raw types: Instead of calling `fromJson(..., List.class)`, create for example a `TypeToken<List<MyClass>>`.\r\n-  See the [user guide](UserGuide.md#collections-examples) for more information.\r\n-- When using `TypeToken` prefer the `Gson.fromJson` overloads with `TypeToken` parameter such as [`fromJson(Reader, TypeToken)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#fromJson(java.io.Reader,com.google.gson.reflect.TypeToken)).\r\n-  The overloads with `Type` parameter do not provide any type-safety guarantees.\r\n-- When using `TypeToken` make sure you don't capture a type variable. For example avoid something like `new TypeToken<List<T>>()` (where `T` is a type variable). Due to Java type erasure the actual type of `T` is not available at runtime. Refactor your code to pass around `TypeToken` instances or use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementClass)`.\r\n-\r\n-## <a id=\"reflection-inaccessible\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to unnamed module'\r\n-\r\n-**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to unnamed module' is thrown\r\n-\r\n-**Reason:** You use Gson by accident to access internal fields of third-party classes\r\n-\r\n-**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data. If this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\r\n-\r\n-**Explanation:**\r\n-\r\n-When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are seeing this error because you (by accident) rely on the reflection-based adapter for third-party classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point. For the JDK it is also not possible anymore to access internal fields using reflection starting with JDK 17, see [JEP 403](https://openjdk.org/jeps/403).\r\n-\r\n-If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\r\n-\r\n-## <a id=\"reflection-inaccessible-to-module-gson\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to module com.google.gson'\r\n-\r\n-**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to module com.google.gson' is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- If the reported package is your own package then you have not configured the module declaration of your project to allow Gson to use reflection on your classes.\r\n-- If the reported package is from a third party library or the JDK see [this troubleshooting point](#inaccessibleobjectexception-module--does-not-opens--to-unnamed-module).\r\n-\r\n-**Solution:** Make sure the `module-info.java` file of your project allows Gson to use reflection on your classes, for example:\r\n-\r\n-```java\r\n-module mymodule {\r\n-    requires com.google.gson;\r\n-\r\n-    opens mypackage to com.google.gson;\r\n-}\r\n-```\r\n-\r\n-Or in case this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\r\n-\r\n-## <a id=\"android-app-random-names\"></a> Android app not working in Release mode; random property names\r\n-\r\n-**Symptom:** Your Android app is working fine in Debug mode but fails in Release mode and the JSON properties have seemingly random names such as `a`, `b`, ...\r\n-\r\n-**Reason:** You probably have not configured ProGuard / R8 correctly\r\n-\r\n-**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-## <a id=\"android-app-broken-after-app-update\"></a> Android app unable to parse JSON after app update\r\n-\r\n-**Symptom:** You released a new version of your Android app and it fails to parse JSON data created by the previous version of your app\r\n-\r\n-**Reason:** You probably have not configured ProGuard / R8 correctly; probably the fields names are being obfuscated and their naming changed between the versions of your app\r\n-\r\n-**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-If you want to preserve backward compatibility for you app you can use [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) on the fields to specify the obfuscated name as alternate, for example: `@SerializedName(value = \"myprop\", alternate = \"a\")`\r\n-\r\n-Normally ProGuard and R8 produce a mapping file, this makes it easier to find out the obfuscated field names instead of having to find them out through trial and error or other means. See the [Android Studio user guide](https://developer.android.com/studio/build/shrink-code.html#retracing) for more information.\r\n-\r\n-## <a id=\"default-field-values-missing\"></a> Default field values not present after deserialization\r\n-\r\n-**Symptom:** You have assign default values to fields but after deserialization the fields have their standard value (such as `null` or `0`)\r\n-\r\n-**Reason:** Gson cannot invoke the constructor of your class and falls back to JDK `Unsafe` (or similar means)\r\n-\r\n-**Solution:** Make sure that the class:\r\n-\r\n-- is `static` (explicitly or implicitly when it is a top-level class)\r\n-- has a no-args constructor\r\n-\r\n-Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\r\n-\r\n-## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\r\n-\r\n-**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\r\n-\r\n-**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\r\n-\r\n-**Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\r\n-\r\n-Notes:\r\n-\r\n-- \"double brace-initialization\" also creates anonymous classes\r\n-- Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\r\n-\r\n-## <a id=\"map-key-wrong-json\"></a> Map keys having unexpected format in JSON\r\n-\r\n-**Symptom:** JSON output for `Map` keys is unexpected / cannot be deserialized again\r\n-\r\n-**Reason:** The `Map` key type is 'complex' and you have not configured the `GsonBuilder` properly\r\n-\r\n-**Solution:** Use [`GsonBuilder.enableComplexMapKeySerialization()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#enableComplexMapKeySerialization()). See also the [user guide](UserGuide.md#maps-examples) for more information.\r\n-\r\n-## <a id=\"malformed-json\"></a> Parsing JSON fails with `MalformedJsonException`\r\n-\r\n-**Symptom:** JSON parsing fails with `MalformedJsonException`\r\n-\r\n-**Reason:** The JSON data is actually malformed\r\n-\r\n-**Solution:** During debugging, log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Sometimes APIs might return HTML error pages (instead of JSON data) when reaching rate limits or when other errors occur. Also read the location information of the `MalformedJsonException` exception message, it indicates where exactly in the document the malformed data was detected, including the [JSONPath](https://goessner.net/articles/JsonPath/).\r\n-\r\n-For example, let's assume you want to deserialize the following JSON data:\r\n-\r\n-```json\r\n-{\r\n-  \"languages\": [\r\n-    \"English\",\r\n-    \"French\",\r\n-  ]\r\n-}\r\n-```\r\n-\r\n-This will fail with an exception similar to this one: `MalformedJsonException: Use JsonReader.setLenient(true) to accept malformed JSON at line 5 column 4 path $.languages[2]`  \r\n-The problem here is the trailing comma (`,`) after `\"French\"`, trailing commas are not allowed by the JSON specification. The location information \"line 5 column 4\" points to the `]` in the JSON data (with some slight inaccuracies) because Gson expected another value after `,` instead of the closing `]`. The JSONPath `$.languages[2]` in the exception message also points there: `$.` refers to the root object, `languages` refers to its member of that name and `[2]` refers to the (missing) third value in the JSON array value of that member (numbering starts at 0, so it is `[2]` instead of `[3]`).  \r\n-The proper solution here is to fix the malformed JSON data.\r\n-\r\n-To spot syntax errors in the JSON data easily you can open it in an editor with support for JSON, for example Visual Studio Code. It will highlight within the JSON data the error location and show why the JSON data is considered invalid.\r\n-\r\n-## <a id=\"number-parsed-as-double\"></a> Integral JSON number is parsed as `double`\r\n-\r\n-**Symptom:** JSON data contains an integral number such as `45` but Gson returns it as `double`\r\n-\r\n-**Reason:** When parsing a JSON number as `Object`, Gson will by default create always return a `double`\r\n-\r\n-**Solution:** Use [`GsonBuilder.setObjectToNumberStrategy`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setObjectToNumberStrategy(com.google.gson.ToNumberStrategy)) to specify what type of number should be returned\r\n-\r\n-## <a id=\"default-lenient\"></a> Malformed JSON not rejected\r\n-\r\n-**Symptom:** Gson parses malformed JSON without throwing any exceptions\r\n-\r\n-**Reason:** Due to legacy reasons Gson performs parsing by default in lenient mode\r\n-\r\n-**Solution:** See [`Gson` class documentation](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#default-lenient) section \"Lenient JSON handling\"\r\n-\r\n-Note: Even in non-lenient mode Gson deviates slightly from the JSON specification, see [`JsonReader.setLenient`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonReader.html#setLenient(boolean)) for more details.\r\n-\r\n-## <a id=\"unexpected-json-structure\"></a> `IllegalStateException`: \"Expected ... but was ...\"\r\n-\r\n-**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was ...\" is thrown\r\n-\r\n-**Reason:** The JSON data does not have the correct format\r\n-\r\n-**Solution:** Make sure that your classes correctly model the JSON data. Also during debugging log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Read the location information of the exception message, it indicates where exactly in the document the error occurred, including the [JSONPath](https://goessner.net/articles/JsonPath/).\r\n-\r\n-For example, let's assume you have the following Java class:\r\n-\r\n-```java\r\n-class WebPage {\r\n-    String languages;\r\n-}\r\n-```\r\n-\r\n-And you want to deserialize the following JSON data:\r\n-\r\n-```json\r\n-{\r\n-  \"languages\": [\"English\", \"French\"]\r\n-}\r\n-```\r\n-\r\n-This will fail with an exception similar to this one: `IllegalStateException: Expected a string but was BEGIN_ARRAY at line 2 column 17 path $.languages`  \r\n-This means Gson expected a JSON string value but found the beginning of a JSON array (`[`). The location information \"line 2 column 17\" points to the `[` in the JSON data (with some slight inaccuracies), so does the JSONPath `$.languages` in the exception message. It refers to the `languages` member of the root object (`$.`).  \r\n-The solution here is to change in the `WebPage` class the field `String languages` to `List<String> languages`.\r\n-\r\n-## <a id=\"adapter-not-null-safe\"></a> `IllegalStateException`: \"Expected ... but was NULL\"\r\n-\r\n-**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was NULL\" is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- A built-in adapter does not support JSON null values\r\n-- You have written a custom `TypeAdapter` which does not properly handle JSON null values\r\n-\r\n-**Solution:** If this occurs for a custom adapter you wrote, add code similar to the following at the beginning of its `read` method:\r\n-\r\n-```java\r\n-@Override\r\n-public MyClass read(JsonReader in) throws IOException {\r\n-    if (in.peek() == JsonToken.NULL) {\r\n-        in.nextNull();\r\n-        return null;\r\n-    }\r\n-\r\n-    ...\r\n-}\r\n-```\r\n-\r\n-Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html#nullSafe()) on the adapter instance you created.\r\n-\r\n-## <a id=\"serialize-nulls\"></a> Properties missing in JSON\r\n-\r\n-**Symptom:** Properties are missing in the JSON output\r\n-\r\n-**Reason:** Gson by default omits JSON null from the output (or: ProGuard / R8 is not configured correctly and removed unused fields)\r\n-\r\n-**Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\r\n-\r\n-Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\r\n-\r\n-## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\r\n-\r\n-**Symptom:** The JSON output differs when running on newer Android versions\r\n-\r\n-**Reason:** You use Gson by accident to access internal fields of Android classes\r\n-\r\n-**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data\r\n-\r\n-**Explanation:**\r\n-\r\n-When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are experiencing this issue because you (by accident) rely on the reflection-based adapter for Android classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point.\r\n-\r\n-If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\r\n-\r\n-## <a id=\"json-static-fields\"></a> JSON output contains values of `static` fields\r\n-\r\n-**Symptom:** The JSON output contains values of `static` fields\r\n-\r\n-**Reason:** You used `GsonBuilder.excludeFieldsWithModifiers` to overwrite the default excluded modifiers\r\n-\r\n-**Solution:** When calling `GsonBuilder.excludeFieldsWithModifiers` you overwrite the default excluded modifiers. Therefore, you have to explicitly exclude `static` fields if desired. This can be done by adding `Modifier.STATIC` as additional argument.\r\n-\r\n-## <a id=\"no-such-method-error\"></a> `NoSuchMethodError` when calling Gson methods\r\n-\r\n-**Symptom:** A `java.lang.NoSuchMethodError` is thrown when trying to call certain Gson methods\r\n-\r\n-**Reason:**\r\n-\r\n-- You have multiple versions of Gson on your classpath\r\n-- Or, the Gson version you compiled against is different from the one on your classpath\r\n-- Or, you are using a code shrinking tool such as ProGuard or R8 which removed methods from Gson\r\n-\r\n-**Solution:** First disable any code shrinking tools such as ProGuard or R8 and check if the issue persists. If not, you have to tweak the configuration of that tool to not modify Gson classes. Otherwise verify that the Gson JAR on your classpath is the same you are compiling against, and that there is only one Gson JAR on your classpath. See [this Stack Overflow question](https://stackoverflow.com/q/227486) to find out where a class is loaded from. For example, for debugging you could include the following code:\r\n-\r\n-```java\r\n-System.out.println(Gson.class.getProtectionDomain().getCodeSource().getLocation());\r\n-```\r\n-\r\n-If that fails with a `NullPointerException` you have to try one of the other ways to find out where a class is loaded from.\r\n-\r\n-## <a id=\"duplicate-fields\"></a> `IllegalArgumentException`: 'Class ... declares multiple JSON fields named '...''\r\n-\r\n-**Symptom:** An exception with the message 'Class ... declares multiple JSON fields named '...'' is thrown\r\n-\r\n-**Reason:**\r\n-\r\n-- The name you have specified with a [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation for a field collides with the name of another field\r\n-- The [`FieldNamingStrategy`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/FieldNamingStrategy.html) you have specified produces conflicting field names\r\n-- A field of your class has the same name as the field of a superclass\r\n-\r\n-Gson prevents multiple fields with the same name because during deserialization it would be ambiguous for which field the JSON data should be deserialized. For serialization it would cause the same field to appear multiple times in JSON. While the JSON specification permits this, it is likely that the application parsing the JSON data will not handle it correctly.\r\n-\r\n-**Solution:** First identify the fields with conflicting names based on the exception message. Then decide if you want to rename one of them using the [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation, or if you want to [exclude](UserGuide.md#excluding-fields-from-serialization-and-deserialization) one of them. When excluding one of the fields you have to include it for both serialization and deserialization (even if your application only performs one of these actions) because the duplicate field check cannot differentiate between these actions.\r\n-\r\n-## <a id=\"java-lang-class-unsupported\"></a> `UnsupportedOperationException` when serializing or deserializing `java.lang.Class`\r\n-\r\n-**Symptom:** An `UnsupportedOperationException` is thrown when trying to serialize or deserialize `java.lang.Class`\r\n-\r\n-**Reason:** Gson intentionally does not permit serializing and deserializing `java.lang.Class` for security reasons. Otherwise a malicious user could make your application load an arbitrary class from the classpath and, depending on what your application does with the `Class`, in the worst case perform a remote code execution attack.\r\n-\r\n-**Solution:** First check if you really need to serialize or deserialize a `Class`. Often it is possible to use string aliases and then map them to the known `Class`; you could write a custom [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) to do this. If the `Class` values are not known in advance, try to introduce a common base class or interface for all these classes and then verify that the deserialized class is a subclass. For example assuming the base class is called `MyBaseClass`, your custom `TypeAdapter` should load the class like this:\r\n-\r\n-```java\r\n-Class.forName(jsonString, false, getClass().getClassLoader()).asSubclass(MyBaseClass.class)\r\n-```\r\n-\r\n-This will not initialize arbitrary classes, and it will throw a `ClassCastException` if the loaded class is not the same as or a subclass of `MyBaseClass`.\r\n-\r\n-## <a id=\"type-token-raw\"></a> `IllegalStateException`: 'TypeToken must be created with a type argument' <br> `RuntimeException`: 'Missing type parameter'\r\n-\r\n-**Symptom:** An `IllegalStateException` with the message 'TypeToken must be created with a type argument' is thrown.  \r\n-For older Gson versions a `RuntimeException` with message 'Missing type parameter' is thrown.\r\n-\r\n-**Reason:**\r\n-\r\n-- You created a `TypeToken` without type argument, for example `new TypeToken() {}` (note the missing `<...>`). You always have to provide the type argument, for example like this: `new TypeToken<List<String>>() {}`. Normally the compiler will also emit a 'raw types' warning when you forget the `<...>`.\r\n-- You are using a code shrinking tool such as ProGuard or R8 (Android app builds normally have this enabled by default) but have not configured it correctly for usage with Gson.\r\n-\r\n-**Solution:** When you are using a code shrinking tool such as ProGuard or R8 you have to adjust your configuration to include the following rules:\r\n-\r\n-```\r\n-# Keep generic signatures; needed for correct type resolution\r\n--keepattributes Signature\r\n-\r\n-# Keep class TypeToken (respectively its generic signature)\r\n--keep class com.google.gson.reflect.TypeToken { *; }\r\n-\r\n-# Keep any (anonymous) classes extending TypeToken\r\n--keep class * extends com.google.gson.reflect.TypeToken\r\n-```\r\n-\r\n-See also the [Android example](examples/android-proguard-example/README.md) for more information.\r\n-\r\n-Note: For newer Gson versions these rules might be applied automatically; make sure you are using the latest Gson version and the latest version of the code shrinking tool.\r\n-\r\n-## <a id=\"r8-abstract-class\"></a> `JsonIOException`: 'Abstract classes can't be instantiated!' (R8)\r\n-\r\n-**Symptom:** A `JsonIOException` with the message 'Abstract classes can't be instantiated!' is thrown; the class mentioned in the exception message is not actually `abstract` in your source code, and you are using the code shrinking tool R8 (Android app builds normally have this configured by default).\r\n-\r\n-**Reason:** The code shrinking tool R8 performs optimizations where it removes the no-args constructor from a class and makes the class `abstract`. Due to this Gson cannot create an instance of the class.\r\n-\r\n-**Solution:** Make sure the class has a no-args constructor, then adjust your R8 configuration file to keep the constructor of the class. For example:\r\n-\r\n-```\r\n-# Keep the no-args constructor of the deserialized class\r\n--keepclassmembers class com.example.MyClass {\r\n-  <init>();\r\n-}\r\n-```\r\n-\r\n-For Android you can add this rule to the `proguard-rules.pro` file, see also the [Android documentation](https://developer.android.com/build/shrink-code#keep-code). In case the class name in the exception message is obfuscated, see the Android documentation about [retracing](https://developer.android.com/build/shrink-code#retracing).\r\n-\r\n-Note: If the class which you are trying to deserialize is actually abstract, then this exception is probably unrelated to R8 and you will have to implement a custom [`InstanceCreator`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/InstanceCreator.html) or [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) which creates an instance of a non-abstract subclass of the class.\r\n+# Troubleshooting Guide\n+\n+This guide describes how to troubleshoot common issues when using Gson.\n+\n+<!-- The '<a id=\"...\"></a>' anchors below are used to create stable links; don't remove or rename them -->\n+<!-- Use only lowercase IDs, GitHub seems to not support uppercase IDs, see also https://github.com/orgs/community/discussions/50962 -->\n+\n+## <a id=\"class-cast-exception\"></a> `ClassCastException` when using deserialized object\n+\n+**Symptom:** `ClassCastException` is thrown when accessing an object deserialized by Gson\n+\n+**Reason:** Your code is most likely not type-safe\n+\n+**Solution:** Make sure your code adheres to the following:\n+\n+- Avoid raw types: Instead of calling `fromJson(..., List.class)`, create for example a `TypeToken<List<MyClass>>`.\n+  See the [user guide](UserGuide.md#collections-examples) for more information.\n+- When using `TypeToken` prefer the `Gson.fromJson` overloads with `TypeToken` parameter such as [`fromJson(Reader, TypeToken)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#fromJson(java.io.Reader,com.google.gson.reflect.TypeToken)).\n+  The overloads with `Type` parameter do not provide any type-safety guarantees.\n+- When using `TypeToken` make sure you don't capture a type variable. For example avoid something like `new TypeToken<List<T>>()` (where `T` is a type variable). Due to Java type erasure the actual type of `T` is not available at runtime. Refactor your code to pass around `TypeToken` instances or use [`TypeToken.getParameterized(...)`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/reflect/TypeToken.html#getParameterized(java.lang.reflect.Type,java.lang.reflect.Type...)), for example `TypeToken.getParameterized(List.class, elementClass)`.\n+\n+## <a id=\"reflection-inaccessible\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to unnamed module'\n+\n+**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to unnamed module' is thrown\n+\n+**Reason:** You use Gson by accident to access internal fields of third-party classes\n+\n+**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data. If this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\n+\n+**Explanation:**\n+\n+When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are seeing this error because you (by accident) rely on the reflection-based adapter for third-party classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point. For the JDK it is also not possible anymore to access internal fields using reflection starting with JDK 17, see [JEP 403](https://openjdk.org/jeps/403).\n+\n+If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\n+\n+## <a id=\"reflection-inaccessible-to-module-gson\"></a> `InaccessibleObjectException`: 'module ... does not \"opens ...\" to module com.google.gson'\n+\n+**Symptom:** An exception with a message in the form 'module ... does not \"opens ...\" to module com.google.gson' is thrown\n+\n+**Reason:**\n+\n+- If the reported package is your own package then you have not configured the module declaration of your project to allow Gson to use reflection on your classes.\n+- If the reported package is from a third party library or the JDK see [this troubleshooting point](#inaccessibleobjectexception-module--does-not-opens--to-unnamed-module).\n+\n+**Solution:** Make sure the `module-info.java` file of your project allows Gson to use reflection on your classes, for example:\n+\n+```java\n+module mymodule {\n+    requires com.google.gson;\n+\n+    opens mypackage to com.google.gson;\n+}\n+```\n+\n+Or in case this occurs for a field in one of your classes which you did not actually want to serialize or deserialize in the first place, you can exclude that field, see the [user guide](UserGuide.md#excluding-fields-from-serialization-and-deserialization).\n+\n+## <a id=\"android-app-random-names\"></a> Android app not working in Release mode; random property names\n+\n+**Symptom:** Your Android app is working fine in Debug mode but fails in Release mode and the JSON properties have seemingly random names such as `a`, `b`, ...\n+\n+**Reason:** You probably have not configured ProGuard / R8 correctly\n+\n+**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+## <a id=\"android-app-broken-after-app-update\"></a> Android app unable to parse JSON after app update\n+\n+**Symptom:** You released a new version of your Android app and it fails to parse JSON data created by the previous version of your app\n+\n+**Reason:** You probably have not configured ProGuard / R8 correctly; probably the fields names are being obfuscated and their naming changed between the versions of your app\n+\n+**Solution:** Make sure you have configured ProGuard / R8 correctly to preserve the names of your fields. See the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+If you want to preserve backward compatibility for you app you can use [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) on the fields to specify the obfuscated name as alternate, for example: `@SerializedName(value = \"myprop\", alternate = \"a\")`\n+\n+Normally ProGuard and R8 produce a mapping file, this makes it easier to find out the obfuscated field names instead of having to find them out through trial and error or other means. See the [Android Studio user guide](https://developer.android.com/studio/build/shrink-code.html#retracing) for more information.\n+\n+## <a id=\"default-field-values-missing\"></a> Default field values not present after deserialization\n+\n+**Symptom:** You have assign default values to fields but after deserialization the fields have their standard value (such as `null` or `0`)\n+\n+**Reason:** Gson cannot invoke the constructor of your class and falls back to JDK `Unsafe` (or similar means)\n+\n+**Solution:** Make sure that the class:\n+\n+- is `static` (explicitly or implicitly when it is a top-level class)\n+- has a no-args constructor\n+\n+Otherwise Gson will by default try to use JDK `Unsafe` or similar means to create an instance of your class without invoking the constructor and without running any initializers. You can also disable that behavior through [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()) to notice such issues early on.\n+\n+## <a id=\"anonymous-local-null\"></a> `null` values for anonymous and local classes\n+\n+**Symptom:** Objects of a class are always serialized as JSON `null` / always deserialized as Java `null`\n+\n+**Reason:** The class you are serializing or deserializing is an anonymous or a local class (or you have specified a custom `ExclusionStrategy`)\n+\n+**Solution:** Convert the class to a `static` nested class. If the class is already `static` make sure you have not specified a Gson `ExclusionStrategy` which might exclude the class.\n+\n+Notes:\n+\n+- \"double brace-initialization\" also creates anonymous classes\n+- Local record classes (feature added in Java 16) are supported by Gson and are not affected by this\n+\n+## <a id=\"map-key-wrong-json\"></a> Map keys having unexpected format in JSON\n+\n+**Symptom:** JSON output for `Map` keys is unexpected / cannot be deserialized again\n+\n+**Reason:** The `Map` key type is 'complex' and you have not configured the `GsonBuilder` properly\n+\n+**Solution:** Use [`GsonBuilder.enableComplexMapKeySerialization()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#enableComplexMapKeySerialization()). See also the [user guide](UserGuide.md#maps-examples) for more information.\n+\n+## <a id=\"malformed-json\"></a> Parsing JSON fails with `MalformedJsonException`\n+\n+**Symptom:** JSON parsing fails with `MalformedJsonException`\n+\n+**Reason:** The JSON data is actually malformed\n+\n+**Solution:** During debugging, log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Sometimes APIs might return HTML error pages (instead of JSON data) when reaching rate limits or when other errors occur. Also read the location information of the `MalformedJsonException` exception message, it indicates where exactly in the document the malformed data was detected, including the [JSONPath](https://goessner.net/articles/JsonPath/).\n+\n+For example, let's assume you want to deserialize the following JSON data:\n+\n+```json\n+{\n+  \"languages\": [\n+    \"English\",\n+    \"French\",\n+  ]\n+}\n+```\n+\n+This will fail with an exception similar to this one: `MalformedJsonException: Use JsonReader.setLenient(true) to accept malformed JSON at line 5 column 4 path $.languages[2]`  \n+The problem here is the trailing comma (`,`) after `\"French\"`, trailing commas are not allowed by the JSON specification. The location information \"line 5 column 4\" points to the `]` in the JSON data (with some slight inaccuracies) because Gson expected another value after `,` instead of the closing `]`. The JSONPath `$.languages[2]` in the exception message also points there: `$.` refers to the root object, `languages` refers to its member of that name and `[2]` refers to the (missing) third value in the JSON array value of that member (numbering starts at 0, so it is `[2]` instead of `[3]`).  \n+The proper solution here is to fix the malformed JSON data.\n+\n+To spot syntax errors in the JSON data easily you can open it in an editor with support for JSON, for example Visual Studio Code. It will highlight within the JSON data the error location and show why the JSON data is considered invalid.\n+\n+## <a id=\"number-parsed-as-double\"></a> Integral JSON number is parsed as `double`\n+\n+**Symptom:** JSON data contains an integral number such as `45` but Gson returns it as `double`\n+\n+**Reason:** When parsing a JSON number as `Object`, Gson will by default create always return a `double`\n+\n+**Solution:** Use [`GsonBuilder.setObjectToNumberStrategy`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#setObjectToNumberStrategy(com.google.gson.ToNumberStrategy)) to specify what type of number should be returned\n+\n+## <a id=\"default-lenient\"></a> Malformed JSON not rejected\n+\n+**Symptom:** Gson parses malformed JSON without throwing any exceptions\n+\n+**Reason:** Due to legacy reasons Gson performs parsing by default in lenient mode\n+\n+**Solution:** See [`Gson` class documentation](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/Gson.html#default-lenient) section \"Lenient JSON handling\"\n+\n+Note: Even in non-lenient mode Gson deviates slightly from the JSON specification, see [`JsonReader.setLenient`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/stream/JsonReader.html#setLenient(boolean)) for more details.\n+\n+## <a id=\"unexpected-json-structure\"></a> `IllegalStateException`: \"Expected ... but was ...\"\n+\n+**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was ...\" is thrown\n+\n+**Reason:** The JSON data does not have the correct format\n+\n+**Solution:** Make sure that your classes correctly model the JSON data. Also during debugging log the JSON data right before calling Gson methods or set a breakpoint to inspect the data and make sure it has the expected format. Read the location information of the exception message, it indicates where exactly in the document the error occurred, including the [JSONPath](https://goessner.net/articles/JsonPath/).\n+\n+For example, let's assume you have the following Java class:\n+\n+```java\n+class WebPage {\n+    String languages;\n+}\n+```\n+\n+And you want to deserialize the following JSON data:\n+\n+```json\n+{\n+  \"languages\": [\"English\", \"French\"]\n+}\n+```\n+\n+This will fail with an exception similar to this one: `IllegalStateException: Expected a string but was BEGIN_ARRAY at line 2 column 17 path $.languages`  \n+This means Gson expected a JSON string value but found the beginning of a JSON array (`[`). The location information \"line 2 column 17\" points to the `[` in the JSON data (with some slight inaccuracies), so does the JSONPath `$.languages` in the exception message. It refers to the `languages` member of the root object (`$.`).  \n+The solution here is to change in the `WebPage` class the field `String languages` to `List<String> languages`.\n+\n+## <a id=\"adapter-not-null-safe\"></a> `IllegalStateException`: \"Expected ... but was NULL\"\n+\n+**Symptom:** An `IllegalStateException` with a message in the form \"Expected ... but was NULL\" is thrown\n+\n+**Reason:**\n+\n+- A built-in adapter does not support JSON null values\n+- You have written a custom `TypeAdapter` which does not properly handle JSON null values\n+\n+**Solution:** If this occurs for a custom adapter you wrote, add code similar to the following at the beginning of its `read` method:\n+\n+```java\n+@Override\n+public MyClass read(JsonReader in) throws IOException {\n+    if (in.peek() == JsonToken.NULL) {\n+        in.nextNull();\n+        return null;\n+    }\n+\n+    ...\n+}\n+```\n+\n+Alternatively you can call [`nullSafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html#nullSafe()) on the adapter instance you created.\n+\n+## <a id=\"serialize-nulls\"></a> Properties missing in JSON\n+\n+**Symptom:** Properties are missing in the JSON output\n+\n+**Reason:** Gson by default omits JSON null from the output (or: ProGuard / R8 is not configured correctly and removed unused fields)\n+\n+**Solution:** Use [`GsonBuilder.serializeNulls()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#serializeNulls())\n+\n+Note: Gson does not support anonymous and local classes and will serialize them as JSON null, see the [related troubleshooting point](#null-values-for-anonymous-and-local-classes).\n+\n+## <a id=\"android-internal-fields\"></a> JSON output changes for newer Android versions\n+\n+**Symptom:** The JSON output differs when running on newer Android versions\n+\n+**Reason:** You use Gson by accident to access internal fields of Android classes\n+\n+**Solution:** Write custom Gson [`TypeAdapter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) implementations for the affected classes or change the type of your data\n+\n+**Explanation:**\n+\n+When no built-in adapter for a type exists and no custom adapter has been registered, Gson falls back to using reflection to access the fields of a class (including `private` ones). Most likely you are experiencing this issue because you (by accident) rely on the reflection-based adapter for Android classes. That should be avoided because you make yourself dependent on the implementation details of these classes which could change at any point.\n+\n+If you want to prevent using reflection on third-party classes in the future you can write your own [`ReflectionAccessFilter`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/ReflectionAccessFilter.html) or use one of the predefined ones, such as `ReflectionAccessFilter.BLOCK_ALL_PLATFORM`.\n+\n+## <a id=\"json-static-fields\"></a> JSON output contains values of `static` fields\n+\n+**Symptom:** The JSON output contains values of `static` fields\n+\n+**Reason:** You used `GsonBuilder.excludeFieldsWithModifiers` to overwrite the default excluded modifiers\n+\n+**Solution:** When calling `GsonBuilder.excludeFieldsWithModifiers` you overwrite the default excluded modifiers. Therefore, you have to explicitly exclude `static` fields if desired. This can be done by adding `Modifier.STATIC` as additional argument.\n+\n+## <a id=\"no-such-method-error\"></a> `NoSuchMethodError` when calling Gson methods\n+\n+**Symptom:** A `java.lang.NoSuchMethodError` is thrown when trying to call certain Gson methods\n+\n+**Reason:**\n+\n+- You have multiple versions of Gson on your classpath\n+- Or, the Gson version you compiled against is different from the one on your classpath\n+- Or, you are using a code shrinking tool such as ProGuard or R8 which removed methods from Gson\n+\n+**Solution:** First disable any code shrinking tools such as ProGuard or R8 and check if the issue persists. If not, you have to tweak the configuration of that tool to not modify Gson classes. Otherwise verify that the Gson JAR on your classpath is the same you are compiling against, and that there is only one Gson JAR on your classpath. See [this Stack Overflow question](https://stackoverflow.com/q/227486) to find out where a class is loaded from. For example, for debugging you could include the following code:\n+\n+```java\n+System.out.println(Gson.class.getProtectionDomain().getCodeSource().getLocation());\n+```\n+\n+If that fails with a `NullPointerException` you have to try one of the other ways to find out where a class is loaded from.\n+\n+## <a id=\"duplicate-fields\"></a> `IllegalArgumentException`: 'Class ... declares multiple JSON fields named '...''\n+\n+**Symptom:** An exception with the message 'Class ... declares multiple JSON fields named '...'' is thrown\n+\n+**Reason:**\n+\n+- The name you have specified with a [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation for a field collides with the name of another field\n+- The [`FieldNamingStrategy`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/FieldNamingStrategy.html) you have specified produces conflicting field names\n+- A field of your class has the same name as the field of a superclass\n+\n+Gson prevents multiple fields with the same name because during deserialization it would be ambiguous for which field the JSON data should be deserialized. For serialization it would cause the same field to appear multiple times in JSON. While the JSON specification permits this, it is likely that the application parsing the JSON data will not handle it correctly.\n+\n+**Solution:** First identify the fields with conflicting names based on the exception message. Then decide if you want to rename one of them using the [`@SerializedName`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/annotations/SerializedName.html) annotation, or if you want to [exclude](UserGuide.md#excluding-fields-from-serialization-and-deserialization) one of them. When excluding one of the fields you have to include it for both serialization and deserialization (even if your application only performs one of these actions) because the duplicate field check cannot differentiate between these actions.\n+\n+## <a id=\"java-lang-class-unsupported\"></a> `UnsupportedOperationException` when serializing or deserializing `java.lang.Class`\n+\n+**Symptom:** An `UnsupportedOperationException` is thrown when trying to serialize or deserialize `java.lang.Class`\n+\n+**Reason:** Gson intentionally does not permit serializing and deserializing `java.lang.Class` for security reasons. Otherwise a malicious user could make your application load an arbitrary class from the classpath and, depending on what your application does with the `Class`, in the worst case perform a remote code execution attack.\n+\n+**Solution:** First check if you really need to serialize or deserialize a `Class`. Often it is possible to use string aliases and then map them to the known `Class`; you could write a custom [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) to do this. If the `Class` values are not known in advance, try to introduce a common base class or interface for all these classes and then verify that the deserialized class is a subclass. For example assuming the base class is called `MyBaseClass`, your custom `TypeAdapter` should load the class like this:\n+\n+```java\n+Class.forName(jsonString, false, getClass().getClassLoader()).asSubclass(MyBaseClass.class)\n+```\n+\n+This will not initialize arbitrary classes, and it will throw a `ClassCastException` if the loaded class is not the same as or a subclass of `MyBaseClass`.\n+\n+## <a id=\"type-token-raw\"></a> `IllegalStateException`: 'TypeToken must be created with a type argument' <br> `RuntimeException`: 'Missing type parameter'\n+\n+**Symptom:** An `IllegalStateException` with the message 'TypeToken must be created with a type argument' is thrown.  \n+For older Gson versions a `RuntimeException` with message 'Missing type parameter' is thrown.\n+\n+**Reason:**\n+\n+- You created a `TypeToken` without type argument, for example `new TypeToken() {}` (note the missing `<...>`). You always have to provide the type argument, for example like this: `new TypeToken<List<String>>() {}`. Normally the compiler will also emit a 'raw types' warning when you forget the `<...>`.\n+- You are using a code shrinking tool such as ProGuard or R8 (Android app builds normally have this enabled by default) but have not configured it correctly for usage with Gson.\n+\n+**Solution:** When you are using a code shrinking tool such as ProGuard or R8 you have to adjust your configuration to include the following rules:\n+\n+```\n+# Keep generic signatures; needed for correct type resolution\n+-keepattributes Signature\n+\n+# Keep class TypeToken (respectively its generic signature)\n+-keep class com.google.gson.reflect.TypeToken { *; }\n+\n+# Keep any (anonymous) classes extending TypeToken\n+-keep class * extends com.google.gson.reflect.TypeToken\n+```\n+\n+See also the [Android example](examples/android-proguard-example/README.md) for more information.\n+\n+Note: For newer Gson versions these rules might be applied automatically; make sure you are using the latest Gson version and the latest version of the code shrinking tool.\n+\n+## <a id=\"r8-abstract-class\"></a> `JsonIOException`: 'Abstract classes can't be instantiated!' (R8)\n+\n+**Symptom:** A `JsonIOException` with the message 'Abstract classes can't be instantiated!' is thrown; the class mentioned in the exception message is not actually `abstract` in your source code, and you are using the code shrinking tool R8 (Android app builds normally have this configured by default).\n+\n+**Reason:** R8 can remove constructors and, in some optimizations, make classes `abstract`. This prevents Gson from creating instances. In some builds, R8 may retain synthetic or additional constructors even after making a class abstract, but instantiation will still fail.\n+\n+**Solution:** Prefer keeping all constructors of the affected class so R8 neither removes constructors nor changes abstractness when the rule applies. For example:\n+\n+```\n+# Keep all constructors of the deserialized class and keep the class when the rule matches\n+-keepclasseswithmembers class com.example.MyClass {\n+  <init>(...);\n+}\n+```\n+\n+Notes and alternatives:\n+\n+- Kotlin classes commonly do not have a no-args constructor (for example `class MyClass(val s: String)`). Keeping all constructors avoids mismatches with rules that only keep `<init>()`. If you rely on constructor logic (initializers, default values), consider providing a no-args or secondary constructor that fits your deserialization needs.\n+- If no suitable constructor is available, Gson may fall back to JDK Unsafe to create instances without invoking constructors. To detect this early, use [`GsonBuilder.disableJdkUnsafe()`](https://www.javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/GsonBuilder.html#disableJdkUnsafe()).\n+- `-keepclasseswithmembers` keeps the class when the member pattern matches and retains the specified members. Compared to `-keepclassmembers`, it also prevents R8 from changing the class abstractness when the rule applies. If you want to unconditionally keep a class (and all its members), you can use `-keep class com.example.MyClass`.\n+- As an Android-friendly alternative, annotate your model class or its constructor with `@Keep` to prevent removal by the shrinker. See the [Android documentation](https://developer.android.com/studio/write/annotations#keep).\n+- Newer Gson versions ship default ProGuard/R8 rules that help retain constructors when Gson annotations are present on a class (see `gson/META-INF/proguard/gson.pro` in the JAR). If your class does not use Gson annotations, you may still need an explicit rule or `@Keep`.\n+\n+For Android you can add these rules to the `proguard-rules.pro` file, see also the [Android documentation](https://developer.android.com/build/shrink-code#keep-code). In case the class name in the exception message is obfuscated, see the Android documentation about [retracing](https://developer.android.com/build/shrink-code#retracing).\n+\n+Note: If the class which you are trying to deserialize is actually abstract, then this exception is unrelated to R8 and you will have to implement a custom [`InstanceCreator`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/InstanceCreator.html) or [`TypeAdapter`](https://javadoc.io/doc/com.google.code.gson/gson/latest/com.google.gson/com/google/gson/TypeAdapter.html) which creates an instance of a non-abstract subclass of the class.\ndiff --git a/examples/android-proguard-example/README.md b/examples/android-proguard-example/README.md\nindex 942477d7..51482166 100644\n--- a/examples/android-proguard-example/README.md\n+++ b/examples/android-proguard-example/README.md\n@@ -15,3 +15,18 @@ tools. Have a look at R8's Compatibility FAQ, and especially at the [Gson sectio\n Note that newer Gson versions apply some of the rules shown in `proguard.cfg` automatically by default,\n see the file [`gson/META-INF/proguard/gson.pro`](/gson/src/main/resources/META-INF/proguard/gson.pro) for\n the Gson version you are using.\n+\n+Additional guidance:\n+\n+- For classes that are deserialized by Gson, prefer keeping all constructors to avoid R8 removing them or making the class abstract. For example:\n+\n+```\n+-keepclasseswithmembers class com.example.MyClass {\n+  <init>(...);\n+}\n+```\n+\n+- If your model classes use Gson annotations (such as `@SerializedName`, `@Expose`, `@JsonAdapter`, `@Since`, `@Until`), newer Gson versions ship default rules that conditionally keep constructors when these annotations are present. This reduces the need for manual rules.\n+- Kotlin classes often do not have a no-args constructor. Keeping all constructors avoids issues with rules that only keep `<init>()`. If you rely on constructor logic or default property values, consider adding a suitable constructor for deserialization.\n+- As an alternative to shrinker rules, annotate classes or constructors with Android's `@Keep` to prevent removal by ProGuard/R8. See the [Android documentation](https://developer.android.com/studio/write/annotations#keep).\n+- Ensure generic signatures are preserved when using `TypeToken`, and retain runtime-visible annotations where they influence Gson behavior. The shipped `gson.pro` covers common cases, but project-specific rules may still be required.\ndiff --git a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\nindex 7d2dc9b6..942f585b 100644\n--- a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n+++ b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n@@ -75,15 +75,11 @@ public final class ConstructorConstructor {\n     }\n     if (Modifier.isAbstract(modifiers)) {\n       // R8 performs aggressive optimizations where it removes the default constructor of a class\n-      // and makes the class `abstract`; check for that here explicitly\n-      if (c.getDeclaredConstructors().length == 0) {\n-        return \"Abstract classes can't be instantiated! Adjust the R8 configuration or register\"\n-            + \" an InstanceCreator or a TypeAdapter for this type. Class name: \" + c.getName()\n-            + \"\\nSee \" + TroubleshootingGuide.createUrl(\"r8-abstract-class\");\n-      }\n-\n+      // and makes the class `abstract`; include troubleshooting guide link to help users.\n       return \"Abstract classes can't be instantiated! Register an InstanceCreator\"\n-          + \" or a TypeAdapter for this type. Class name: \" + c.getName();\n+          + \" or a TypeAdapter for this type, or adjust the R8 configuration if this class was made\"\n+          + \" abstract by R8. Class name: \" + c.getName()\n+          + \"\\nSee \" + TroubleshootingGuide.createUrl(\"r8-abstract-class\");\n     }\n     return null;\n   }\ndiff --git a/gson/src/main/resources/META-INF/proguard/gson.pro b/gson/src/main/resources/META-INF/proguard/gson.pro\nindex c9f235e9..cd5ce733 100644\n--- a/gson/src/main/resources/META-INF/proguard/gson.pro\n+++ b/gson/src/main/resources/META-INF/proguard/gson.pro\n@@ -56,3 +56,27 @@\n -keep class * implements com.google.gson.JsonDeserializer {\n   <init>();\n }\n+\n+# Keep all constructors of classes that are likely used with Gson based on annotations.\n+# Using -keepclasseswithmembers ensures the class is kept (so R8 won't make it abstract)\n+# and that its constructors are retained. allowobfuscation lets names still be obfuscated.\n+-keepclasseswithmembers,allowobfuscation class * {\n+  @com.google.gson.annotations.SerializedName <fields>;\n+  <init>(...);\n+}\n+-keepclasseswithmembers,allowobfuscation class * {\n+  @com.google.gson.annotations.Expose <fields>;\n+  <init>(...);\n+}\n+-keepclasseswithmembers,allowobfuscation class * {\n+  @com.google.gson.annotations.JsonAdapter <fields>;\n+  <init>(...);\n+}\n+-keepclasseswithmembers,allowobfuscation class * {\n+  @com.google.gson.annotations.Since <fields>;\n+  <init>(...);\n+}\n+-keepclasseswithmembers,allowobfuscation class * {\n+  @com.google.gson.annotations.Until <fields>;\n+  <init>(...);\n+}\n"}
{"instance_id": "apache__dubbo-4515", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/io/Bytes.java b/dubbo-common/src/main/java/org/apache/dubbo/common/io/Bytes.java\nindex 263e7b9f67..5112dcf73a 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/io/Bytes.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/io/Bytes.java\n@@ -730,8 +730,12 @@ public class Bytes {\n             char pc = code[64];\n             if (str.charAt(off + len - 2) == pc) {\n                 size -= 2;\n+                --num;\n+                rem = 2;\n             } else if (str.charAt(off + len - 1) == pc) {\n                 size--;\n+                --num;\n+                rem = 3;\n             }\n         } else {\n             if (rem == 2) {\n"}
{"instance_id": "apache__dubbo-8126", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/api/Connection.java b/dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/api/Connection.java\nindex 3f058292d0..eec4d79fb2 100644\n--- a/dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/api/Connection.java\n+++ b/dubbo-remoting/dubbo-remoting-api/src/main/java/org/apache/dubbo/remoting/api/Connection.java\n@@ -222,6 +222,7 @@ public class Connection extends AbstractReferenceCounted implements ReferenceCou\n         @Override\n         public void operationComplete(ChannelFuture future) {\n             if (future.isSuccess()) {\n+                onConnected(future.channel());\n                 return;\n             }\n             final Connection conn = Connection.this;\n"}
{"instance_id": "apache__dubbo-5356", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "apache__rocketmq-7964", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/ConsumerManageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/ConsumerManageProcessor.java\nindex e16a1e909..eef4ae4ac 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/ConsumerManageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/ConsumerManageProcessor.java\n@@ -194,6 +194,15 @@ public class ConsumerManageProcessor implements NettyRequestProcessor {\n             }\n         }\n \n+        // Check the existence of consumer group to prevent dirty offsets for deleted groups\n+        if (!this.brokerController.getSubscriptionGroupManager().containsSubscriptionGroup(group)) {\n+            response.setCode(ResponseCode.SUBSCRIPTION_GROUP_NOT_EXIST);\n+            response.setRemark(\"subscription group [\" + group + \"] does not exist\");\n+            LOGGER.warn(\"Update consumer offset refused because subscription group does not exist. ClientHost={}, Group={}, Topic={}, QueueId={}, Offset={}\",\n+                RemotingHelper.parseChannelRemoteAddr(ctx.channel()), group, topic, queueId, offset);\n+            return response;\n+        }\n+\n         this.brokerController.getConsumerOffsetManager().commitOffset(\n             RemotingHelper.parseChannelRemoteAddr(ctx.channel()), group, topic, queueId, offset);\n         response.setCode(ResponseCode.SUCCESS);\n"}
{"instance_id": "apache__rocketmq-5841", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/consumer/ReceiveMessageActivity.java b/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/consumer/ReceiveMessageActivity.java\nindex 31b841132..1c6b1c658 100644\n--- a/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/consumer/ReceiveMessageActivity.java\n+++ b/proxy/src/main/java/org/apache/rocketmq/proxy/grpc/v2/consumer/ReceiveMessageActivity.java\n@@ -85,7 +85,7 @@ public class ReceiveMessageActivity extends AbstractMessingActivity {\n                 if (timeRemaining >= config.getGrpcClientConsumerMinLongPollingTimeoutMillis()) {\n                     pollingTime = timeRemaining;\n                 } else {\n-                    writer.writeAndComplete(ctx, Code.ILLEGAL_POLLING_TIME, \"The deadline time remaining is not enough\" +\n+                    writer.writeAndComplete(ctx, Code.BAD_REQUEST, \"The deadline time remaining is not enough\" +\n                         \" for polling, please check network condition\");\n                     return;\n                 }\n"}
{"instance_id": "apache__rocketmq-7426", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/proxy/src/main/java/org/apache/rocketmq/proxy/service/sysmessage/HeartbeatSyncer.java b/proxy/src/main/java/org/apache/rocketmq/proxy/service/sysmessage/HeartbeatSyncer.java\nindex f70c06b8f..f5d8385ce 100644\n--- a/proxy/src/main/java/org/apache/rocketmq/proxy/service/sysmessage/HeartbeatSyncer.java\n+++ b/proxy/src/main/java/org/apache/rocketmq/proxy/service/sysmessage/HeartbeatSyncer.java\n@@ -80,7 +80,10 @@ public class HeartbeatSyncer extends AbstractSystemMessageSyncer {\n                     }\n                     if (args[0] instanceof ClientChannelInfo) {\n                         ClientChannelInfo clientChannelInfo = (ClientChannelInfo) args[0];\n-                        remoteChannelMap.remove(clientChannelInfo.getChannel().id().asLongText());\n+                        String clientId = clientChannelInfo.getClientId();\n+                        if (s != null && clientId != null) {\n+                            remoteChannelMap.remove(s + \"@\" + clientId);\n+                        }\n                     }\n                 }\n             }\n@@ -189,7 +192,7 @@ public class HeartbeatSyncer extends AbstractSystemMessageSyncer {\n                 }\n \n                 RemoteChannel decodedChannel = RemoteChannel.decode(data.getChannelData());\n-                RemoteChannel channel = remoteChannelMap.computeIfAbsent(data.getGroup() + \"@\" + decodedChannel.id().asLongText(), key -> decodedChannel);\n+                RemoteChannel channel = remoteChannelMap.computeIfAbsent(data.getGroup() + \"@\" + data.getClientId(), key -> decodedChannel);\n                 channel.setExtendAttribute(decodedChannel.getChannelExtendAttribute());\n                 ClientChannelInfo clientChannelInfo = new ClientChannelInfo(\n                     channel,\n@@ -214,6 +217,7 @@ public class HeartbeatSyncer extends AbstractSystemMessageSyncer {\n                         clientChannelInfo,\n                         false\n                     );\n+                    remoteChannelMap.remove(data.getGroup() + \"@\" + data.getClientId());\n                 }\n             } catch (Throwable t) {\n                 log.error(\"heartbeat consume message failed. msg:{}, data:{}\", msg, new String(msg.getBody(), StandardCharsets.UTF_8), t);\n"}
{"instance_id": "apache__dubbo-8414", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/reference/ReferenceCreator.java b/dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/reference/ReferenceCreator.java\nindex c2f0648442..7617d4300c 100644\n--- a/dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/reference/ReferenceCreator.java\n+++ b/dubbo-config/dubbo-config-spring/src/main/java/org/apache/dubbo/config/spring/reference/ReferenceCreator.java\n@@ -318,19 +318,37 @@ public class ReferenceCreator {\n     }\n \n     public static Map convertStringArrayToMap(String[] source) {\n-        String content = arrayToCommaDelimitedString(source);\n-        // Trim all whitespace\n-        content = StringUtils.trimAllWhitespace(content);\n-        if (!StringUtils.hasText(content)) { // No content , ignore directly\n+        if (source == null || source.length == 0) {\n             return null;\n         }\n-        // replace \"=\" to \",\"\n-        content = StringUtils.replace(content, \"=\", \",\");\n-        // replace \":\" to \",\"\n-        content = StringUtils.replace(content, \":\", \",\");\n-        // String[] to Map\n-        Map<String, String> parameters = CollectionUtils.toStringMap(commaDelimitedListToStringArray(content));\n-        return parameters;\n+        Map<String, String> parameters = new java.util.LinkedHashMap<>();\n+        java.util.List<String> tokens = new java.util.ArrayList<>();\n+        for (String item : source) {\n+            if (item == null) {\n+                continue;\n+            }\n+            String s = StringUtils.trimWhitespace(item);\n+            if (!StringUtils.hasText(s)) {\n+                continue;\n+            }\n+            int eqIdx = s.indexOf('=');\n+            if (eqIdx >= 0) {\n+                String key = StringUtils.trimWhitespace(s.substring(0, eqIdx));\n+                String value = s.substring(eqIdx + 1);\n+                // Do not treat ':' as delimiter; preserve it as part of the value\n+                parameters.put(key, value);\n+            } else {\n+                tokens.add(s);\n+            }\n+        }\n+        if (!tokens.isEmpty()) {\n+            for (int i = 0; i + 1 < tokens.size(); i += 2) {\n+                String key = StringUtils.trimWhitespace(tokens.get(i));\n+                String value = tokens.get(i + 1);\n+                parameters.put(key, value);\n+            }\n+        }\n+        return parameters.isEmpty() ? null : parameters;\n     }\n \n     public static ReferenceCreator create(Map<String, Object> attributes, ApplicationContext applicationContext) {\n"}
{"instance_id": "apache__rocketmq-5633", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java b/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\nindex 02ea9a6b6..eabb23eae 100644\n--- a/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\n+++ b/controller/src/main/java/org/apache/rocketmq/controller/impl/manager/ReplicasInfoManager.java\n@@ -221,7 +221,7 @@ public class ReplicasInfoManager {\n         final String brokerAddress = request.getBrokerAddress();\n         final ControllerResult<RegisterBrokerToControllerResponseHeader> result = new ControllerResult<>(new RegisterBrokerToControllerResponseHeader());\n         final RegisterBrokerToControllerResponseHeader response = result.getResponse();\n-        boolean canBeElectedAsMaster;\n+        boolean canBeElectedAsMaster;  // will be assigned in branches below\n         if (isContainsBroker(brokerName)) {\n             final SyncStateInfo syncStateInfo = this.syncStateSetInfoTable.get(brokerName);\n             final BrokerInfo brokerInfo = this.replicaInfoTable.get(brokerName);\n@@ -243,8 +243,13 @@ public class ReplicasInfoManager {\n             if (syncStateInfo.isMasterExist()) {\n                 // If the master is alive, just return master info.\n                 final String masterAddress = syncStateInfo.getMasterAddress();\n-                response.setMasterAddress(masterAddress);\n-                return result;\n+                // Only return master when it is the registering broker (alive now)\n+                if (StringUtils.equals(masterAddress, brokerAddress)) {\n+                    response.setMasterAddress(masterAddress);\n+                    return result;\n+                }\n+                // The recorded master is not alive (not the registering broker), go to election\n+                canBeElectedAsMaster = syncStateInfo.getSyncStateSet().contains(brokerAddress) || this.controllerConfig.isEnableElectUncleanMaster();\n             } else {\n                 // If the master is not alive, we should elect a new master:\n                 // Case1: This replicas was in sync state set list\n"}
{"instance_id": "apache__dubbo-6498", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/BootstrapListener.java b/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/BootstrapListener.java\nindex 8c2e6f267b..57628b1071 100644\n--- a/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/BootstrapListener.java\n+++ b/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/BootstrapListener.java\n@@ -28,6 +28,15 @@ public class BootstrapListener implements ServletContextListener {\n     @Override\n     public void contextInitialized(ServletContextEvent servletContextEvent) {\n         ServletManager.getInstance().addServletContext(ServletManager.EXTERNAL_SERVER_PORT, servletContextEvent.getServletContext());\n+        // store web application context path for building correct service URL in servlet mode\n+        try {\n+            String contextPath = servletContextEvent.getServletContext().getContextPath();\n+            if (contextPath != null) {\n+                servletContextEvent.getServletContext().setAttribute(\"dubbo.appContextPath\", contextPath);\n+            }\n+        } catch (Throwable ignored) {\n+            // ignore\n+        }\n     }\n \n     @Override\ndiff --git a/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/DispatcherServlet.java b/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/DispatcherServlet.java\nindex 6cc0c1e7f8..26dc8b2154 100644\n--- a/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/DispatcherServlet.java\n+++ b/dubbo-remoting/dubbo-remoting-http/src/main/java/org/apache/dubbo/remoting/http/servlet/DispatcherServlet.java\n@@ -1,65 +1,90 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.remoting.http.servlet;\r\n-\r\n-import org.apache.dubbo.remoting.http.HttpHandler;\r\n-\r\n-import javax.servlet.ServletException;\r\n-import javax.servlet.http.HttpServlet;\r\n-import javax.servlet.http.HttpServletRequest;\r\n-import javax.servlet.http.HttpServletResponse;\r\n-import java.io.IOException;\r\n-import java.util.Map;\r\n-import java.util.concurrent.ConcurrentHashMap;\r\n-\r\n-/**\r\n- * Service dispatcher Servlet.\r\n- */\r\n-public class DispatcherServlet extends HttpServlet {\r\n-\r\n-    private static final long serialVersionUID = 5766349180380479888L;\r\n-    private static final Map<Integer, HttpHandler> HANDLERS = new ConcurrentHashMap<Integer, HttpHandler>();\r\n-    private static DispatcherServlet INSTANCE;\r\n-\r\n-    public DispatcherServlet() {\r\n-        DispatcherServlet.INSTANCE = this;\r\n-    }\r\n-\r\n-    public static void addHttpHandler(int port, HttpHandler processor) {\r\n-        HANDLERS.put(port, processor);\r\n-    }\r\n-\r\n-    public static void removeHttpHandler(int port) {\r\n-        HANDLERS.remove(port);\r\n-    }\r\n-\r\n-    public static DispatcherServlet getInstance() {\r\n-        return INSTANCE;\r\n-    }\r\n-\r\n-    @Override\r\n-    protected void service(HttpServletRequest request, HttpServletResponse response)\r\n-            throws ServletException, IOException {\r\n-        HttpHandler handler = HANDLERS.get(request.getLocalPort());\r\n-        if (handler == null) {// service not found.\r\n-            response.sendError(HttpServletResponse.SC_NOT_FOUND, \"Service not found.\");\r\n-        } else {\r\n-            handler.handle(request, response);\r\n-        }\r\n-    }\r\n-\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.remoting.http.servlet;\n+\n+import org.apache.dubbo.remoting.http.HttpHandler;\n+\n+import javax.servlet.ServletException;\n+import javax.servlet.http.HttpServlet;\n+import javax.servlet.http.HttpServletRequest;\n+import javax.servlet.http.HttpServletResponse;\n+import java.io.IOException;\n+import java.util.Map;\n+import java.util.concurrent.ConcurrentHashMap;\n+\n+/**\n+ * Service dispatcher Servlet.\n+ */\n+public class DispatcherServlet extends HttpServlet {\n+\n+    private static final long serialVersionUID = 5766349180380479888L;\n+    private static final Map<Integer, HttpHandler> HANDLERS = new ConcurrentHashMap<Integer, HttpHandler>();\n+    private static DispatcherServlet INSTANCE;\n+\n+    public DispatcherServlet() {\n+        DispatcherServlet.INSTANCE = this;\n+    }\n+\n+    @Override\n+    public void init() throws ServletException {\n+        super.init();\n+        // Detect and store the servlet url-pattern for later usage by protocols\n+        if (getServletContext() != null) {\n+            try {\n+                javax.servlet.ServletRegistration registration = getServletContext().getServletRegistration(getServletName());\n+                if (registration != null) {\n+                    java.util.Collection<String> mappings = registration.getMappings();\n+                    // choose the first mapping if multiple\n+                    if (mappings != null && !mappings.isEmpty()) {\n+                        String mapping = mappings.iterator().next();\n+                        // normalize '/services/*' to '/services'\n+                        if (mapping.endsWith(\"/*\")) {\n+                            mapping = mapping.substring(0, mapping.length() - 2);\n+                        }\n+                        getServletContext().setAttribute(\"dubbo.servlet.urlPattern\", mapping);\n+                    }\n+                }\n+            } catch (Throwable ignored) {\n+                // ignore any error from container specifics\n+            }\n+        }\n+    }\n+\n+    public static void addHttpHandler(int port, HttpHandler processor) {\n+        HANDLERS.put(port, processor);\n+    }\n+\n+    public static void removeHttpHandler(int port) {\n+        HANDLERS.remove(port);\n+    }\n+\n+    public static DispatcherServlet getInstance() {\n+        return INSTANCE;\n+    }\n+\n+    @Override\n+    protected void service(HttpServletRequest request, HttpServletResponse response)\n+            throws ServletException, IOException {\n+        HttpHandler handler = HANDLERS.get(request.getLocalPort());\n+        if (handler == null) {// service not found.\n+            response.sendError(HttpServletResponse.SC_NOT_FOUND, \"Service not found.\");\n+        } else {\n+            handler.handle(request, response);\n+        }\n+    }\n+\n+}\ndiff --git a/dubbo-rpc/dubbo-rpc-webservice/src/main/java/org/apache/dubbo/rpc/protocol/webservice/WebServiceProtocol.java b/dubbo-rpc/dubbo-rpc-webservice/src/main/java/org/apache/dubbo/rpc/protocol/webservice/WebServiceProtocol.java\nindex dff3bd1e13..8fe562659d 100644\n--- a/dubbo-rpc/dubbo-rpc-webservice/src/main/java/org/apache/dubbo/rpc/protocol/webservice/WebServiceProtocol.java\n+++ b/dubbo-rpc/dubbo-rpc-webservice/src/main/java/org/apache/dubbo/rpc/protocol/webservice/WebServiceProtocol.java\n@@ -105,7 +105,16 @@ public class WebServiceProtocol extends AbstractProxyProtocol {\n             serverMap.put(addr, new ProxyProtocolServer(remotingServer));\n         }\n         serverFactoryBean = new ServerFactoryBean();\n-        serverFactoryBean.setAddress(url.getAbsolutePath());\n+        String serverParam = url.getParameter(Constants.SERVER_KEY);\n+        String exportedAddress;\n+        if (\"servlet\".equalsIgnoreCase(serverParam)) {\n+            // In servlet mode, let the container prepend contextPath and servlet mapping.\n+            // Use the service interface as the relative address to avoid duplicating path segments.\n+            exportedAddress = \"/\" + url.getServiceInterface();\n+        } else {\n+            exportedAddress = url.getAbsolutePath();\n+        }\n+        serverFactoryBean.setAddress(exportedAddress);\n         serverFactoryBean.setServiceClass(type);\n         serverFactoryBean.setServiceBean(impl);\n         serverFactoryBean.setBus(bus);\n@@ -134,7 +143,42 @@ public class WebServiceProtocol extends AbstractProxyProtocol {\n     @SuppressWarnings(\"unchecked\")\n     protected <T> T doRefer(final Class<T> serviceType, final URL url) throws RpcException {\n         ClientProxyFactoryBean proxyFactoryBean = new ClientProxyFactoryBean();\n-        proxyFactoryBean.setAddress(url.setProtocol(\"http\").toIdentityString());\n+        String targetAddress;\n+        boolean hasMeta = url.hasParameter(\"appContextPath\") || url.hasParameter(\"servletUrlPattern\") || url.hasParameter(\"serviceRelativePath\");\n+        if (hasMeta) {\n+            // Assemble target address with potential servlet url-pattern and context path info from provider.\n+            String appContextPath = url.getParameter(\"appContextPath\", \"\");\n+            String servletUrlPattern = url.getParameter(\"servletUrlPattern\", \"\");\n+            // normalize servlet pattern like '/services/*' -> '/services'\n+            if (servletUrlPattern.endsWith(\"/*\")) {\n+                servletUrlPattern = servletUrlPattern.substring(0, servletUrlPattern.length() - 2);\n+            }\n+            String base = url.setProtocol(\"http\").setPath(null).toIdentityString();\n+            // base contains protocol://host:port\n+            StringBuilder addrBuilder = new StringBuilder(base);\n+            if (!appContextPath.isEmpty()) {\n+                if (!appContextPath.startsWith(\"/\")) {\n+                    addrBuilder.append('/');\n+                }\n+                addrBuilder.append(appContextPath);\n+            }\n+            if (!servletUrlPattern.isEmpty()) {\n+                if (!servletUrlPattern.startsWith(\"/\")) {\n+                    addrBuilder.append('/');\n+                }\n+                addrBuilder.append(servletUrlPattern);\n+            }\n+            String serviceRelativePath = url.getParameter(\"serviceRelativePath\", \"/\" + url.getServiceInterface());\n+            if (!serviceRelativePath.startsWith(\"/\")) {\n+                addrBuilder.append('/');\n+            }\n+            addrBuilder.append(serviceRelativePath.startsWith(\"/\") ? serviceRelativePath.substring(1) : serviceRelativePath);\n+            targetAddress = addrBuilder.toString();\n+        } else {\n+            // Fallback to original behavior\n+            targetAddress = url.setProtocol(\"http\").toIdentityString();\n+        }\n+        proxyFactoryBean.setAddress(targetAddress);\n         proxyFactoryBean.setServiceClass(serviceType);\n         proxyFactoryBean.setBus(bus);\n         T ref = (T) proxyFactoryBean.create();\n"}
{"instance_id": "apache__rocketmq-7420", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicBlackListFilter.java b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicBlackListFilter.java\nindex 50adbb713..87150fe7b 100644\n--- a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicBlackListFilter.java\n+++ b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicBlackListFilter.java\n@@ -38,8 +38,17 @@ public class TieredStoreTopicBlackListFilter implements TieredStoreTopicFilter {\n         return TieredStoreUtil.isSystemTopic(topicName) || topicBlackSet.contains(topicName);\n     }\n \n+    /**\n+     * @deprecated use addTopicToBlackList instead.\n+     */\n+    @Deprecated\n     @Override\n     public void addTopicToWhiteList(String topicName) {\n+        addTopicToBlackList(topicName);\n+    }\n+\n+    @Override\n+    public void addTopicToBlackList(String topicName) {\n         this.topicBlackSet.add(topicName);\n     }\n }\ndiff --git a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicFilter.java b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicFilter.java\nindex 3f26b8b02..56b29d02c 100644\n--- a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicFilter.java\n+++ b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/provider/TieredStoreTopicFilter.java\n@@ -21,5 +21,17 @@ public interface TieredStoreTopicFilter {\n \n     boolean filterTopic(String topicName);\n \n+    /**\n+     * @deprecated use addTopicToBlackList instead.\n+     */\n+    @Deprecated\n     void addTopicToWhiteList(String topicName);\n+\n+    /**\n+     * Preferred API replacing addTopicToWhiteList for blacklist filters.\n+     * Default implementation delegates to addTopicToWhiteList for backward compatibility.\n+     */\n+    default void addTopicToBlackList(String topicName) {\n+        addTopicToWhiteList(topicName);\n+    }\n }\n"}
{"instance_id": "apache__rocketmq-5062", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/broker/src/main/java/org/apache/rocketmq/broker/BrokerController.java b/broker/src/main/java/org/apache/rocketmq/broker/BrokerController.java\nindex 6c79559c3..8c772e348 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/BrokerController.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/BrokerController.java\n@@ -1140,6 +1140,9 @@ public class BrokerController {\n     public Broker2Client getBroker2Client() {\n         return broker2Client;\n     }\n+    public EscapeBridge getEscapeBridge() {\n+        return escapeBridge;\n+    }\n \n     public ConsumerManager getConsumerManager() {\n         return consumerManager;\ndiff --git a/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageBridge.java b/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageBridge.java\nindex 30a2330dd..81b2e4944 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageBridge.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageBridge.java\n@@ -346,4 +346,31 @@ public class TransactionalMessageBridge {\n     public BrokerController getBrokerController() {\n         return brokerController;\n     }\n+\n+    public MessageExtBrokerInner restorePrepareMessageInner(MessageExt msgExt) {\n+        MessageExtBrokerInner msgInner = new MessageExtBrokerInner();\n+        // restore real topic and queueId from half message properties\n+        msgInner.setTopic(msgExt.getUserProperty(MessageConst.PROPERTY_REAL_TOPIC));\n+        String realQueueId = msgExt.getUserProperty(MessageConst.PROPERTY_REAL_QUEUE_ID);\n+        msgInner.setQueueId(realQueueId == null ? 0 : Integer.parseInt(realQueueId));\n+        msgInner.setBody(msgExt.getBody());\n+        msgInner.setFlag(msgExt.getFlag());\n+        msgInner.setBornTimestamp(msgExt.getBornTimestamp());\n+        msgInner.setBornHost(msgExt.getBornHost());\n+        msgInner.setStoreHost(msgExt.getStoreHost());\n+        msgInner.setReconsumeTimes(msgExt.getReconsumeTimes());\n+        msgInner.setWaitStoreMsgOK(false);\n+        msgInner.setSysFlag(msgExt.getSysFlag());\n+        msgInner.setTags(msgExt.getTags());\n+        msgInner.setTagsCode(MessageExtBrokerInner.tagsString2tagsCode(msgInner.getTags()));\n+        // copy properties from half message\n+        MessageAccessor.setProperties(msgInner, msgExt.getProperties());\n+        // mark as transactional prepare so that remote broker stores into half topic\n+        MessageAccessor.putProperty(msgInner, MessageConst.PROPERTY_TRANSACTION_PREPARED, String.valueOf(true));\n+        // clear local half-only properties\n+        MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_REAL_TOPIC);\n+        MessageAccessor.clearProperty(msgInner, MessageConst.PROPERTY_REAL_QUEUE_ID);\n+        msgInner.setPropertiesString(MessageDecoder.messageProperties2String(msgInner.getProperties()));\n+        return msgInner;\n+    }\n }\ndiff --git a/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java b/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java\nindex 63b188e64..fbf291a7a 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/transaction/queue/TransactionalMessageServiceImpl.java\n@@ -224,10 +224,29 @@ public class TransactionalMessageServiceImpl implements TransactionalMessageServ\n                             || valueOfCurrentMinusBorn <= -1;\n \n                         if (isNeedCheck) {\n-                            if (!putBackHalfMsgQueue(msgExt, i)) {\n-                                continue;\n+                            if (transactionalMessageBridge.getBrokerController().getBrokerConfig().isEnableSlaveActingMaster()) {\n+                                try {\n+                                    // In SAM mode, escape half messages to an available master\n+                                    if (transactionalMessageBridge.getBrokerController().peekMasterBroker() != null) {\n+                                        // local master available, append to half topic on local master directly\n+                                        MessageExtBrokerInner halfInner = transactionalMessageBridge.renewHalfMessageInner(msgExt);\n+                                        transactionalMessageBridge.getBrokerController().getEscapeBridge().putMessage(halfInner);\n+                                    } else {\n+                                        // remote master, restore to original prepare message and send via remoting\n+                                        MessageExtBrokerInner prepareInner = transactionalMessageBridge.restorePrepareMessageInner(msgExt);\n+                                        transactionalMessageBridge.getBrokerController().getEscapeBridge().putMessage(prepareInner);\n+                                    }\n+                                } catch (Throwable e) {\n+                                    log.error(\"Escape half message failed, msgId={}, will retry later\", msgExt.getMsgId(), e);\n+                                    continue;\n+                                }\n+                                // Do not create local half/op messages or send check requests in SAM mode\n+                            } else {\n+                                if (!putBackHalfMsgQueue(msgExt, i)) {\n+                                    continue;\n+                                }\n+                                listener.resolveHalfMsg(msgExt);\n                             }\n-                            listener.resolveHalfMsg(msgExt);\n                         } else {\n                             pullResult = fillOpRemoveMap(removeMap, opQueue, pullResult.getNextBeginOffset(), halfOffset, doneOpOffset);\n                             log.debug(\"The miss offset:{} in messageQueue:{} need to get more opMsg, result is:{}\", i,\ndiff --git a/common/src/main/java/org/apache/rocketmq/common/message/MessageConst.java b/common/src/main/java/org/apache/rocketmq/common/message/MessageConst.java\nindex 43f47efc4..b7f92c2d6 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/message/MessageConst.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/message/MessageConst.java\n@@ -97,6 +97,7 @@ public class MessageConst {\n     public static final String PROPERTY_TIMER_DEL_UNIQKEY = \"TIMER_DEL_UNIQKEY\";\n     public static final String PROPERTY_TIMER_DELAY_LEVEL = \"TIMER_DELAY_LEVEL\";\n     public static final String PROPERTY_TIMER_DELAY_MS = \"TIMER_DELAY_MS\";\n+    public static final String PROPERTY_TRANSACTION_ESCAPED = \"TRAN_ESCAPED\";\n \n     static {\n         STRING_HASH_SET.add(PROPERTY_TRACE_SWITCH);\n@@ -147,5 +148,6 @@ public class MessageConst {\n         STRING_HASH_SET.add(PROPERTY_TIMER_DELAY_LEVEL);\n         STRING_HASH_SET.add(PROPERTY_BORN_HOST);\n         STRING_HASH_SET.add(PROPERTY_BORN_TIMESTAMP);\n+        STRING_HASH_SET.add(PROPERTY_TRANSACTION_ESCAPED);\n     }\n }\n"}
{"instance_id": "apache__rocketmq-7745", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/client/src/main/java/org/apache/rocketmq/client/consumer/store/LocalFileOffsetStore.java b/client/src/main/java/org/apache/rocketmq/client/consumer/store/LocalFileOffsetStore.java\nindex f949b75a8..4b8bdc4ee 100644\n--- a/client/src/main/java/org/apache/rocketmq/client/consumer/store/LocalFileOffsetStore.java\n+++ b/client/src/main/java/org/apache/rocketmq/client/consumer/store/LocalFileOffsetStore.java\n@@ -154,6 +154,22 @@ public class LocalFileOffsetStore implements OffsetStore {\n \n     @Override\n     public void persist(MessageQueue mq) {\n+        if (mq == null) {\n+            return;\n+        }\n+        OffsetSerializeWrapper offsetSerializeWrapper = new OffsetSerializeWrapper();\n+        for (Map.Entry<MessageQueue, AtomicLong> entry : this.offsetTable.entrySet()) {\n+            // persist all current offsets to avoid losing others\n+            offsetSerializeWrapper.getOffsetTable().put(entry.getKey(), entry.getValue());\n+        }\n+        String jsonString = offsetSerializeWrapper.toJson(true);\n+        if (jsonString != null) {\n+            try {\n+                MixAll.string2File(jsonString, this.storePath);\n+            } catch (IOException e) {\n+                log.error(\"persist consumer offset Exception, \" + this.storePath, e);\n+            }\n+        }\n     }\n \n     @Override\ndiff --git a/client/src/main/java/org/apache/rocketmq/client/impl/consumer/DefaultMQPushConsumerImpl.java b/client/src/main/java/org/apache/rocketmq/client/impl/consumer/DefaultMQPushConsumerImpl.java\nindex bb40f855f..a66a9fb79 100644\n--- a/client/src/main/java/org/apache/rocketmq/client/impl/consumer/DefaultMQPushConsumerImpl.java\n+++ b/client/src/main/java/org/apache/rocketmq/client/impl/consumer/DefaultMQPushConsumerImpl.java\n@@ -372,26 +372,33 @@ public class DefaultMQPushConsumerImpl implements MQConsumerInner {\n                             log.warn(\"the pull request offset illegal, {} {}\",\n                                 pullRequest.toString(), pullResult.toString());\n                             pullRequest.setNextOffset(pullResult.getNextBeginOffset());\n-\n-                            pullRequest.getProcessQueue().setDropped(true);\n-                            DefaultMQPushConsumerImpl.this.executeTaskLater(new Runnable() {\n-\n-                                @Override\n-                                public void run() {\n-                                    try {\n-                                        DefaultMQPushConsumerImpl.this.offsetStore.updateOffset(pullRequest.getMessageQueue(),\n-                                            pullRequest.getNextOffset(), false);\n-\n-                                        DefaultMQPushConsumerImpl.this.offsetStore.persist(pullRequest.getMessageQueue());\n-\n-                                        DefaultMQPushConsumerImpl.this.rebalanceImpl.removeProcessQueue(pullRequest.getMessageQueue());\n-\n-                                        log.warn(\"fix the pull request offset, {}\", pullRequest);\n-                                    } catch (Throwable e) {\n-                                        log.error(\"executeTaskLater Exception\", e);\n+                            // Persist corrected offset immediately to avoid reading -1 from store\n+                            try {\n+                                DefaultMQPushConsumerImpl.this.offsetStore.updateOffset(pullRequest.getMessageQueue(),\n+                                    pullRequest.getNextOffset(), false);\n+                                DefaultMQPushConsumerImpl.this.offsetStore.persist(pullRequest.getMessageQueue());\n+                            } catch (Throwable e) {\n+                                log.error(\"persist corrected offset exception\", e);\n+                            }\n+                            if (DefaultMQPushConsumerImpl.this.defaultMQPushConsumer.getMessageModel() == MessageModel.BROADCASTING) {\n+                                // In broadcasting mode, do not drop PQ; continue pulling with corrected offset\n+                                DefaultMQPushConsumerImpl.this.executePullRequestImmediately(pullRequest);\n+                            } else {\n+                                // In clustering mode, drop PQ and remove it after a delay to trigger rebalance\n+                                pullRequest.getProcessQueue().setDropped(true);\n+                                DefaultMQPushConsumerImpl.this.executeTaskLater(new Runnable() {\n+\n+                                    @Override\n+                                    public void run() {\n+                                        try {\n+                                            DefaultMQPushConsumerImpl.this.rebalanceImpl.removeProcessQueue(pullRequest.getMessageQueue());\n+                                            log.warn(\"fix the pull request offset, {}\", pullRequest);\n+                                        } catch (Throwable e) {\n+                                            log.error(\"executeTaskLater Exception\", e);\n+                                        }\n                                     }\n-                                }\n-                            }, 10000);\n+                                }, 10000);\n+                            }\n                             break;\n                         default:\n                             break;\ndiff --git a/client/src/main/java/org/apache/rocketmq/client/impl/consumer/RebalancePushImpl.java b/client/src/main/java/org/apache/rocketmq/client/impl/consumer/RebalancePushImpl.java\nindex 666b696ff..7c942a552 100644\n--- a/client/src/main/java/org/apache/rocketmq/client/impl/consumer/RebalancePushImpl.java\n+++ b/client/src/main/java/org/apache/rocketmq/client/impl/consumer/RebalancePushImpl.java\n@@ -154,12 +154,14 @@ public class RebalancePushImpl extends RebalanceImpl {\n         long result = -1;\n         final ConsumeFromWhere consumeFromWhere = this.defaultMQPushConsumerImpl.getDefaultMQPushConsumer().getConsumeFromWhere();\n         final OffsetStore offsetStore = this.defaultMQPushConsumerImpl.getOffsetStore();\n+        final MessageModel messageModel = this.defaultMQPushConsumerImpl.getDefaultMQPushConsumer().getMessageModel();\n+        final ReadOffsetType readOffsetType = (messageModel == MessageModel.BROADCASTING) ? ReadOffsetType.MEMORY_FIRST_THEN_STORE : ReadOffsetType.READ_FROM_STORE;\n         switch (consumeFromWhere) {\n             case CONSUME_FROM_LAST_OFFSET_AND_FROM_MIN_WHEN_BOOT_FIRST:\n             case CONSUME_FROM_MIN_OFFSET:\n             case CONSUME_FROM_MAX_OFFSET:\n             case CONSUME_FROM_LAST_OFFSET: {\n-                long lastOffset = offsetStore.readOffset(mq, ReadOffsetType.READ_FROM_STORE);\n+                long lastOffset = offsetStore.readOffset(mq, readOffsetType);\n                 if (lastOffset >= 0) {\n                     result = lastOffset;\n                 }\n@@ -181,18 +183,27 @@ public class RebalancePushImpl extends RebalanceImpl {\n                 break;\n             }\n             case CONSUME_FROM_FIRST_OFFSET: {\n-                long lastOffset = offsetStore.readOffset(mq, ReadOffsetType.READ_FROM_STORE);\n+                long lastOffset = offsetStore.readOffset(mq, readOffsetType);\n                 if (lastOffset >= 0) {\n                     result = lastOffset;\n                 } else if (-1 == lastOffset) {\n-                    result = 0L;\n+                    if (messageModel == MessageModel.BROADCASTING) {\n+                        try {\n+                            result = this.mQClientFactory.getMQAdminImpl().minOffset(mq);\n+                        } catch (MQClientException e) {\n+                            log.warn(\"Compute consume offset from first offset(min) exception, mq={}, exception={}\", mq, e);\n+                            throw e;\n+                        }\n+                    } else {\n+                        result = 0L;\n+                    }\n                 } else {\n                     result = -1;\n                 }\n                 break;\n             }\n             case CONSUME_FROM_TIMESTAMP: {\n-                long lastOffset = offsetStore.readOffset(mq, ReadOffsetType.READ_FROM_STORE);\n+                long lastOffset = offsetStore.readOffset(mq, readOffsetType);\n                 if (lastOffset >= 0) {\n                     result = lastOffset;\n                 } else if (-1 == lastOffset) {\n"}
{"instance_id": "apache__rocketmq-516", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/common/src/main/java/org/apache/rocketmq/common/stats/MomentStatsItemSet.java b/common/src/main/java/org/apache/rocketmq/common/stats/MomentStatsItemSet.java\nindex d3b559661..5b73bbcb9 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/stats/MomentStatsItemSet.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/stats/MomentStatsItemSet.java\n@@ -77,13 +77,15 @@ public class MomentStatsItemSet {\n     public MomentStatsItem getAndCreateStatsItem(final String statsKey) {\n         MomentStatsItem statsItem = this.statsItemTable.get(statsKey);\n         if (null == statsItem) {\n-            statsItem =\n+            MomentStatsItem newItem =\n                 new MomentStatsItem(this.statsName, statsKey, this.scheduledExecutorService, this.log);\n-            MomentStatsItem prev = this.statsItemTable.put(statsKey, statsItem);\n+            MomentStatsItem prev = this.statsItemTable.putIfAbsent(statsKey, newItem);\n \n             if (null == prev) {\n-\n+                statsItem = newItem;\n                 // statsItem.init();\n+            } else {\n+                statsItem = prev;\n             }\n         }\n \ndiff --git a/common/src/main/java/org/apache/rocketmq/common/stats/StatsItemSet.java b/common/src/main/java/org/apache/rocketmq/common/stats/StatsItemSet.java\nindex 9a0caaa11..b2b2f0a6d 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/stats/StatsItemSet.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/stats/StatsItemSet.java\n@@ -161,12 +161,14 @@ public class StatsItemSet {\n     public StatsItem getAndCreateStatsItem(final String statsKey) {\n         StatsItem statsItem = this.statsItemTable.get(statsKey);\n         if (null == statsItem) {\n-            statsItem = new StatsItem(this.statsName, statsKey, this.scheduledExecutorService, this.log);\n-            StatsItem prev = this.statsItemTable.put(statsKey, statsItem);\n+            StatsItem newItem = new StatsItem(this.statsName, statsKey, this.scheduledExecutorService, this.log);\n+            StatsItem prev = this.statsItemTable.putIfAbsent(statsKey, newItem);\n \n             if (null == prev) {\n-\n+                statsItem = newItem;\n                 // statsItem.init();\n+            } else {\n+                statsItem = prev;\n             }\n         }\n \n"}
{"instance_id": "apache__rocketmq-4122", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/store/pom.xml b/store/pom.xml\nindex 888403170..4bf48044e 100644\n--- a/store/pom.xml\n+++ b/store/pom.xml\n@@ -31,7 +31,7 @@\n         <dependency>\n             <groupId>io.openmessaging.storage</groupId>\n             <artifactId>dledger</artifactId>\n-            <version>0.2.4</version>\n+            <version>0.2.5</version>\n             <exclusions>\n                 <exclusion>\n                     <groupId>org.apache.rocketmq</groupId>\ndiff --git a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\nindex 30cf36c50..52d533b71 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\n@@ -826,7 +826,12 @@ public class DefaultMessageStore implements MessageStore {\n     public String getStorePathPhysic() {\n         String storePathPhysic;\n         if (DefaultMessageStore.this.getMessageStoreConfig().isEnableDLegerCommitLog()) {\n-            storePathPhysic = ((DLedgerCommitLog)DefaultMessageStore.this.getCommitLog()).getdLedgerServer().getdLedgerConfig().getDataStorePath();\n+            String multiDirs = DefaultMessageStore.this.getMessageStoreConfig().getdLegerCommitLogStoreDirs();\n+            if (multiDirs != null && multiDirs.trim().length() > 0) {\n+                storePathPhysic = multiDirs;\n+            } else {\n+                storePathPhysic = ((DLedgerCommitLog)DefaultMessageStore.this.getCommitLog()).getdLedgerServer().getdLedgerConfig().getDataStorePath();\n+            }\n         } else {\n             storePathPhysic = DefaultMessageStore.this.getMessageStoreConfig().getStorePathCommitLog();\n         }\ndiff --git a/store/src/main/java/org/apache/rocketmq/store/config/MessageStoreConfig.java b/store/src/main/java/org/apache/rocketmq/store/config/MessageStoreConfig.java\nindex d7fd781da..e2fea1c0a 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/config/MessageStoreConfig.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/config/MessageStoreConfig.java\n@@ -152,6 +152,7 @@ public class MessageStoreConfig {\n     private String dLegerGroup;\n     private String dLegerPeers;\n     private String dLegerSelfId;\n+    private String dLegerCommitLogStoreDirs;\n \n     private String preferredLeaderId;\n \n@@ -732,6 +733,14 @@ public class MessageStoreConfig {\n         this.dLegerSelfId = dLegerSelfId;\n     }\n \n+    public String getdLegerCommitLogStoreDirs() {\n+        return dLegerCommitLogStoreDirs;\n+    }\n+\n+    public void setdLegerCommitLogStoreDirs(String dLegerCommitLogStoreDirs) {\n+        this.dLegerCommitLogStoreDirs = dLegerCommitLogStoreDirs;\n+    }\n+\n     public boolean isEnableDLegerCommitLog() {\n         return enableDLegerCommitLog;\n     }\ndiff --git a/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java b/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java\nindex 12b8ec7f8..47e487c61 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/dledger/DLedgerCommitLog.java\n@@ -93,6 +93,12 @@ public class DLedgerCommitLog extends CommitLog {\n         dLedgerConfig.setFileReservedHours(defaultMessageStore.getMessageStoreConfig().getFileReservedTime() + 1);\n         dLedgerConfig.setPreferredLeaderId(defaultMessageStore.getMessageStoreConfig().getPreferredLeaderId());\n         dLedgerConfig.setEnableBatchPush(defaultMessageStore.getMessageStoreConfig().isEnableBatchPush());\n+        dLedgerConfig.setMultiPathSplit(defaultMessageStore.getMessageStoreConfig().MULTI_PATH_SPLITTER);\n+        String multiDirs = defaultMessageStore.getMessageStoreConfig().getdLegerCommitLogStoreDirs();\n+        if (multiDirs != null && multiDirs.trim().length() > 0) {\n+            // pass multi-directory storage paths to DLedger\n+            dLedgerConfig.setDataStorePath(multiDirs);\n+        }\n \n         id = Integer.parseInt(dLedgerConfig.getSelfId().substring(1)) + 1;\n         dLedgerServer = new DLedgerServer(dLedgerConfig);\n"}
{"instance_id": "apache__rocketmq-7712", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/common/src/main/java/org/apache/rocketmq/common/UtilAll.java b/common/src/main/java/org/apache/rocketmq/common/UtilAll.java\nindex 19efa9aa9..1bd00bbb0 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/UtilAll.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/UtilAll.java\n@@ -681,8 +681,23 @@ public class UtilAll {\n             return null;\n         }\n \n-        String[] addrArray = str.split(splitter);\n-        return Arrays.asList(addrArray);\n+        String s = str.trim();\n+        if (s.isEmpty()) {\n+            return java.util.Collections.emptyList();\n+        }\n+\n+        String[] addrArray = s.split(splitter);\n+        java.util.ArrayList<String> result = new java.util.ArrayList<>();\n+        for (String token : addrArray) {\n+            if (token == null) {\n+                continue;\n+            }\n+            String t = token.trim();\n+            if (!t.isEmpty()) {\n+                result.add(t);\n+            }\n+        }\n+        return result;\n     }\n \n     public static void deleteEmptyDirectory(File file) {\n"}
{"instance_id": "apache__dubbo-4567", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/Version.java b/dubbo-common/src/main/java/org/apache/dubbo/common/Version.java\nindex a015b44e9e..bfd8027319 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/Version.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/Version.java\n@@ -115,10 +115,15 @@ public final class Version {\n     public static int getIntVersion(String version) {\n         Integer v = VERSION2INT.get(version);\n         if (v == null) {\n-            v = parseInt(version);\n-            // e.g., version number 2.6.3 will convert to 2060300\n-            if (version.split(\"\\\\.\").length == 3) {\n-                v = v * 100;\n+            try {\n+                v = parseInt(version);\n+                // e.g., version number 2.6.3 will convert to 2060300\n+                if (version.split(\"\\\\.\").length >= 3) {\n+                    v = v * 100;\n+                }\n+            } catch (Throwable t) {\n+                // default to 0 on malformed version strings\n+                v = 0;\n             }\n             VERSION2INT.put(version, v);\n         }\n@@ -128,9 +133,18 @@ public final class Version {\n     private static int parseInt(String version) {\n         int v = 0;\n         String[] vArr = version.split(\"\\\\.\");\n-        int len = vArr.length;\n+        int len = Math.min(3, vArr.length);\n         for (int i = 0; i < len; i++) {\n-            v += Integer.parseInt(getPrefixDigits(vArr[i])) * Math.pow(10, (len - i - 1) * 2);\n+            String digits = getPrefixDigits(vArr[i]);\n+            int part = 0;\n+            if (!StringUtils.isEmpty(digits)) {\n+                try {\n+                    part = Integer.parseInt(digits);\n+                } catch (NumberFormatException ignore) {\n+                    part = 0;\n+                }\n+            }\n+            v += part * Math.pow(10, (len - i - 1) * 2);\n         }\n         return v;\n     }\ndiff --git a/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/DubboCodec.java b/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/DubboCodec.java\nindex 3b8fe66901..bdeaed2eab 100644\n--- a/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/DubboCodec.java\n+++ b/dubbo-rpc/dubbo-rpc-dubbo/src/main/java/org/apache/dubbo/rpc/protocol/dubbo/DubboCodec.java\n@@ -166,7 +166,11 @@ public class DubboCodec extends ExchangeCodec {\n \n     @Override\n     protected void encodeResponseData(Channel channel, ObjectOutput out, Object data) throws IOException {\n-        encodeResponseData(channel, out, data, DUBBO_VERSION);\n+        String clientVersion = org.apache.dubbo.rpc.RpcContext.getContext().getAttachment(DUBBO_VERSION_KEY);\n+        if (StringUtils.isEmpty(clientVersion)) {\n+            clientVersion = null;\n+        }\n+        encodeResponseData(channel, out, data, clientVersion);\n     }\n \n     @Override\n"}
{"instance_id": "google__gson-2167", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/JsonObject.java b/gson/src/main/java/com/google/gson/JsonObject.java\nindex 285a8429..d160e25b 100644\n--- a/gson/src/main/java/com/google/gson/JsonObject.java\n+++ b/gson/src/main/java/com/google/gson/JsonObject.java\n@@ -31,6 +31,7 @@ import java.util.Set;\n  */\n public final class JsonObject extends JsonElement {\n   private final LinkedTreeMap<String, JsonElement> members = new LinkedTreeMap<>();\n+  private Set<Map.Entry<String, JsonElement>> entrySetView;\n \n   /**\n    * Creates a deep copy of this element and all its children\n@@ -119,7 +120,78 @@ public final class JsonObject extends JsonElement {\n    * @return a set of members of this object.\n    */\n   public Set<Map.Entry<String, JsonElement>> entrySet() {\n-    return members.entrySet();\n+    Set<Map.Entry<String, JsonElement>> result = entrySetView;\n+    if (result == null) {\n+      result = entrySetView = new NonNullEntrySet(members.entrySet());\n+    }\n+    return result;\n+  }\n+\n+  private static final class NonNullEntrySet extends java.util.AbstractSet<Map.Entry<String, JsonElement>> {\n+    private final Set<Map.Entry<String, JsonElement>> delegate;\n+\n+    NonNullEntrySet(Set<Map.Entry<String, JsonElement>> delegate) {\n+      this.delegate = delegate;\n+    }\n+\n+    @Override public int size() {\n+      return delegate.size();\n+    }\n+\n+    @Override public java.util.Iterator<Map.Entry<String, JsonElement>> iterator() {\n+      final java.util.Iterator<Map.Entry<String, JsonElement>> it = delegate.iterator();\n+      return new java.util.Iterator<Map.Entry<String, JsonElement>>() {\n+        @Override public boolean hasNext() {\n+          return it.hasNext();\n+        }\n+\n+        @Override public Map.Entry<String, JsonElement> next() {\n+          return new NonNullEntry(it.next());\n+        }\n+\n+        @Override public void remove() {\n+          it.remove();\n+        }\n+      };\n+    }\n+  }\n+\n+  private static final class NonNullEntry implements Map.Entry<String, JsonElement> {\n+    private final Map.Entry<String, JsonElement> delegate;\n+\n+    NonNullEntry(Map.Entry<String, JsonElement> delegate) {\n+      this.delegate = delegate;\n+    }\n+\n+    @Override public String getKey() {\n+      return delegate.getKey();\n+    }\n+\n+    @Override public JsonElement getValue() {\n+      return delegate.getValue();\n+    }\n+\n+    @Override public JsonElement setValue(JsonElement value) {\n+      if (value == null) {\n+        throw new NullPointerException(\"value == null\");\n+      }\n+      return delegate.setValue(value);\n+    }\n+\n+    @Override public boolean equals(Object o) {\n+      if (!(o instanceof Map.Entry)) return false;\n+      Map.Entry<?, ?> e = (Map.Entry<?, ?>) o;\n+      Object key = getKey();\n+      Object val = getValue();\n+      return (key == null ? e.getKey() == null : key.equals(e.getKey()))\n+          && (val == null ? e.getValue() == null : val.equals(e.getValue()));\n+    }\n+\n+    @Override public int hashCode() {\n+      Object key = getKey();\n+      Object val = getValue();\n+      return (key == null ? 0 : key.hashCode()) ^ (val == null ? 0 : val.hashCode());\n+    }\n   }\n \n   /**\n"}
{"instance_id": "google__gson-1904", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex ce4517a3..4545ee56 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -203,10 +203,28 @@ public final class Gson {\n       List<TypeAdapterFactory> builderHierarchyFactories,\n       List<TypeAdapterFactory> factoriesToBeAdded,\n           ToNumberStrategy objectToNumberStrategy, ToNumberStrategy numberToNumberStrategy) {\n+    this(excluder, fieldNamingStrategy, instanceCreators, serializeNulls,\n+        complexMapKeySerialization, generateNonExecutableGson, htmlSafe,\n+        prettyPrinting, lenient, serializeSpecialFloatingPointValues,\n+        longSerializationPolicy, datePattern, dateStyle, timeStyle,\n+        builderFactories, builderHierarchyFactories, factoriesToBeAdded,\n+        objectToNumberStrategy, numberToNumberStrategy, true);\n+  }\n+\n+  Gson(Excluder excluder, FieldNamingStrategy fieldNamingStrategy,\n+      Map<Type, InstanceCreator<?>> instanceCreators, boolean serializeNulls,\n+      boolean complexMapKeySerialization, boolean generateNonExecutableGson, boolean htmlSafe,\n+      boolean prettyPrinting, boolean lenient, boolean serializeSpecialFloatingPointValues,\n+      LongSerializationPolicy longSerializationPolicy, String datePattern, int dateStyle,\n+      int timeStyle, List<TypeAdapterFactory> builderFactories,\n+      List<TypeAdapterFactory> builderHierarchyFactories,\n+      List<TypeAdapterFactory> factoriesToBeAdded,\n+          ToNumberStrategy objectToNumberStrategy, ToNumberStrategy numberToNumberStrategy,\n+          boolean allowUnsafeAllocator) {\n     this.excluder = excluder;\n     this.fieldNamingStrategy = fieldNamingStrategy;\n     this.instanceCreators = instanceCreators;\n-    this.constructorConstructor = new ConstructorConstructor(instanceCreators);\n+    this.constructorConstructor = new ConstructorConstructor(instanceCreators, allowUnsafeAllocator);\n     this.serializeNulls = serializeNulls;\n     this.complexMapKeySerialization = complexMapKeySerialization;\n     this.generateNonExecutableJson = generateNonExecutableGson;\ndiff --git a/gson/src/main/java/com/google/gson/GsonBuilder.java b/gson/src/main/java/com/google/gson/GsonBuilder.java\nindex fa2bb926..687e75c4 100644\n--- a/gson/src/main/java/com/google/gson/GsonBuilder.java\n+++ b/gson/src/main/java/com/google/gson/GsonBuilder.java\n@@ -96,6 +96,7 @@ public final class GsonBuilder {\n   private boolean lenient = DEFAULT_LENIENT;\n   private ToNumberStrategy objectToNumberStrategy = ToNumberPolicy.DOUBLE;\n   private ToNumberStrategy numberToNumberStrategy = ToNumberPolicy.LAZILY_PARSED_NUMBER;\n+  private boolean allowUnsafeAllocator = true;\n \n   /**\n    * Creates a GsonBuilder instance that can be used to build Gson with various configuration\n@@ -429,6 +430,20 @@ public final class GsonBuilder {\n     return this;\n   }\n \n+  /**\n+   * Disables the Unsafe-based instantiation fallback used during deserialization for types\n+   * without accessible no-args constructors or registered InstanceCreators.\n+   * When disabled, Gson will not attempt to allocate objects without invoking their constructors\n+   * and will instead fail with a JsonIOException advising to register an InstanceCreator or\n+   * provide a no-args constructor.\n+   *\n+   * @return a reference to this {@code GsonBuilder} object to fulfill the \"Builder\" pattern\n+   */\n+  public GsonBuilder disableUnsafe() {\n+    this.allowUnsafeAllocator = false;\n+    return this;\n+  }\n+\n   /**\n    * By default, Gson escapes HTML characters such as &lt; &gt; etc. Use this option to configure\n    * Gson to pass-through HTML characters as is.\n@@ -628,7 +643,8 @@ public final class GsonBuilder {\n         generateNonExecutableJson, escapeHtmlChars, prettyPrinting, lenient,\n         serializeSpecialFloatingPointValues, longSerializationPolicy,\n         datePattern, dateStyle, timeStyle,\n-        this.factories, this.hierarchyFactories, factories, objectToNumberStrategy, numberToNumberStrategy);\n+        this.factories, this.hierarchyFactories, factories, objectToNumberStrategy, numberToNumberStrategy,\n+        allowUnsafeAllocator);\n   }\n \n   private void addTypeAdaptersForDate(String datePattern, int dateStyle, int timeStyle,\ndiff --git a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\nindex 9ef0d39a..8b4e1b2b 100644\n--- a/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n+++ b/gson/src/main/java/com/google/gson/internal/ConstructorConstructor.java\n@@ -48,9 +48,15 @@ import com.google.gson.reflect.TypeToken;\n  */\n public final class ConstructorConstructor {\n   private final Map<Type, InstanceCreator<?>> instanceCreators;\n+  private final boolean allowUnsafeAllocator;\n \n   public ConstructorConstructor(Map<Type, InstanceCreator<?>> instanceCreators) {\n+    this(instanceCreators, true);\n+  }\n+\n+  public ConstructorConstructor(Map<Type, InstanceCreator<?>> instanceCreators, boolean allowUnsafeAllocator) {\n     this.instanceCreators = instanceCreators;\n+    this.allowUnsafeAllocator = allowUnsafeAllocator;\n   }\n \n   public <T> ObjectConstructor<T> get(TypeToken<T> typeToken) {\n@@ -92,7 +98,10 @@ public final class ConstructorConstructor {\n     }\n \n     // finally try unsafe\n-    return newUnsafeAllocator(type, rawType);\n+    if (allowUnsafeAllocator) {\n+      return newUnsafeAllocator(type, rawType);\n+    }\n+    return newFailingConstructor(type);\n   }\n \n   private <T> ObjectConstructor<T> newDefaultConstructor(Class<? super T> rawType) {\n@@ -250,6 +259,16 @@ public final class ConstructorConstructor {\n     };\n   }\n \n+  private <T> ObjectConstructor<T> newFailingConstructor(final Type type) {\n+    return new ObjectConstructor<T>() {\n+      @Override\n+      public T construct() {\n+        throw new JsonIOException(\"Unable to create instance of \" + type + \" without calling its constructor. \"\n+            + \"Unsafe-based allocation is disabled. Register an InstanceCreator or ensure an accessible no-args constructor.\");\n+      }\n+    };\n+  }\n+\n   @Override public String toString() {\n     return instanceCreators.toString();\n   }\n"}
{"instance_id": "google__gson-2345", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/UserGuide.md b/UserGuide.md\nindex f5198654..c26dcb27 100644\n--- a/UserGuide.md\n+++ b/UserGuide.md\n@@ -517,15 +517,25 @@ In the above example, an instance of the Id class can not be created without act\n \n The default JSON output that is provided by Gson is a compact JSON format. This means that there will not be any whitespace in the output JSON structure. Therefore, there will be no whitespace between field names and its value, object fields, and objects within arrays in the JSON output. As well, \"null\" fields will be ignored in the output (NOTE: null values will still be included in collections/arrays of objects). See the [Null Object Support](#null-object-support) section for information on configure Gson to output all null values.\n \n-If you would like to use the Pretty Print feature, you must configure your `Gson` instance using the `GsonBuilder`. The `JsonFormatter` is not exposed through our public API, so the client is unable to configure the default print settings/margins for the JSON output. For now, we only provide a default `JsonPrintFormatter` that has default line length of 80 character, 2 character indentation, and 4 character right margin.\n+If you would like to use the Pretty Print feature, configure your `Gson` instance using the `GsonBuilder`. The formatting style can be customized with `FormattingStyle` to control the newline and indent, and whether to add spaces after separators.\n \n-The following is an example shows how to configure a `Gson` instance to use the default `JsonPrintFormatter` instead of the `JsonCompactFormatter`:\n+The following is an example which configures a `Gson` instance to use the default pretty printing formatting style:\n \n ```java\n Gson gson = new GsonBuilder().setPrettyPrinting().create();\n String jsonOutput = gson.toJson(someObject);\n ```\n \n+To produce single-line pretty-printed JSON with spaces after `:` and `,` without line breaks, use an empty newline and enable spacing after separators:\n+\n+```java\n+FormattingStyle style = FormattingStyle.DEFAULT.withNewline(\"\").withSpaceAfterSeparator(true);\n+Gson gson = new GsonBuilder().setPrettyPrinting(style).create();\n+String jsonOutput = gson.toJson(someObject);\n+```\n+\n+Note: When the newline is not empty, commas will still be followed by the newline and no space will be added after the comma, regardless of the spacing setting.\n+\n ### Null Object Support\n \n The default behaviour that is implemented in Gson is that `null` object fields are ignored. This allows for a more compact output format; however, the client must define a default value for these fields as the JSON format is converted back into its Java form.\ndiff --git a/gson/src/main/java/com/google/gson/FormattingStyle.java b/gson/src/main/java/com/google/gson/FormattingStyle.java\nindex ed9f86dd..499d5806 100644\n--- a/gson/src/main/java/com/google/gson/FormattingStyle.java\n+++ b/gson/src/main/java/com/google/gson/FormattingStyle.java\n@@ -22,8 +22,12 @@ import java.util.Objects;\n /**\n  * A class used to control what the serialization output looks like.\n  *\n- * <p>It currently defines the kind of newline to use, and the indent, but\n- * might add more in the future.</p>\n+ * <p>It currently defines the kind of newline to use, the indent and whether to add spaces\n+ * after separators. Additional formatting options might be added in the future.</p>\n+ *\n+ * <p>If {@link #isSpaceAfterSeparator()} is enabled a space will be added after ':' and, if the\n+ * newline value is empty, also after ','. If the newline value is not empty, commas will still\n+ * be followed by the newline and no space will be added after the comma.</p>\n  *\n  * @see GsonBuilder#setPrettyPrinting(FormattingStyle)\n  * @see JsonWriter#setFormattingStyle(FormattingStyle)\n@@ -34,15 +38,16 @@ import java.util.Objects;\n public class FormattingStyle {\n   private final String newline;\n   private final String indent;\n+  private final boolean spaceAfterSeparator;\n \n   /**\n    * The default pretty printing formatting style using {@code \"\\n\"} as\n    * newline and two spaces as indent.\n    */\n   public static final FormattingStyle DEFAULT =\n-      new FormattingStyle(\"\\n\", \"  \");\n+      new FormattingStyle(\"\\n\", \"  \", true);\n \n-  private FormattingStyle(String newline, String indent) {\n+  private FormattingStyle(String newline, String indent, boolean spaceAfterSeparator) {\n     Objects.requireNonNull(newline, \"newline == null\");\n     Objects.requireNonNull(indent, \"indent == null\");\n     if (!newline.matches(\"[\\r\\n]*\")) {\n@@ -55,6 +60,7 @@ public class FormattingStyle {\n     }\n     this.newline = newline;\n     this.indent = indent;\n+    this.spaceAfterSeparator = spaceAfterSeparator;\n   }\n \n   /**\n@@ -70,7 +76,7 @@ public class FormattingStyle {\n    * @return a newly created {@link FormattingStyle}\n    */\n   public FormattingStyle withNewline(String newline) {\n-    return new FormattingStyle(newline, this.indent);\n+    return new FormattingStyle(newline, this.indent, this.spaceAfterSeparator);\n   }\n \n   /**\n@@ -82,7 +88,20 @@ public class FormattingStyle {\n    * @return a newly created {@link FormattingStyle}\n    */\n   public FormattingStyle withIndent(String indent) {\n-    return new FormattingStyle(this.newline, indent);\n+    return new FormattingStyle(this.newline, indent, this.spaceAfterSeparator);\n+  }\n+\n+  /**\n+   * Creates a {@link FormattingStyle} with the specified space-after-separator setting.\n+   *\n+   * <p>When enabled, a space is always added after ':' and, if the newline value is empty,\n+   * also after ','. When disabled, no spaces are added after ':' and ','.</p>\n+   *\n+   * @param spaceAfterSeparator whether to add a space after separators\n+   * @return a newly created {@link FormattingStyle}\n+   */\n+  public FormattingStyle withSpaceAfterSeparator(boolean spaceAfterSeparator) {\n+    return new FormattingStyle(this.newline, this.indent, spaceAfterSeparator);\n   }\n \n   /**\n@@ -102,4 +121,13 @@ public class FormattingStyle {\n   public String getIndent() {\n     return this.indent;\n   }\n+\n+  /**\n+   * Whether a space should be added after separators.\n+   *\n+   * @return true if a space should be added after ':' and, for empty newline, after ','\n+   */\n+  public boolean isSpaceAfterSeparator() {\n+    return this.spaceAfterSeparator;\n+  }\n }\ndiff --git a/gson/src/main/java/com/google/gson/Gson.java b/gson/src/main/java/com/google/gson/Gson.java\nindex ec5f69f6..53a6daa3 100644\n--- a/gson/src/main/java/com/google/gson/Gson.java\n+++ b/gson/src/main/java/com/google/gson/Gson.java\n@@ -69,7 +69,7 @@ import java.util.concurrent.atomic.AtomicLongArray;\n  *\n  * <p>You can create a Gson instance by invoking {@code new Gson()} if the default configuration\n  * is all you need. You can also use {@link GsonBuilder} to build a Gson instance with various\n- * configuration options such as versioning support, pretty printing, custom newline, custom indent,\n+ * configuration options such as versioning support, pretty printing, custom newline, custom indent, separator spacing,\n  * custom {@link JsonSerializer}s, {@link JsonDeserializer}s, and {@link InstanceCreator}s.</p>\n  *\n  * <p>Here is an example of how Gson is used for a simple Class:\ndiff --git a/gson/src/main/java/com/google/gson/GsonBuilder.java b/gson/src/main/java/com/google/gson/GsonBuilder.java\nindex d1508cfa..4373f129 100644\n--- a/gson/src/main/java/com/google/gson/GsonBuilder.java\n+++ b/gson/src/main/java/com/google/gson/GsonBuilder.java\n@@ -511,7 +511,8 @@ public final class GsonBuilder {\n    * Configures Gson to output JSON that uses a certain kind of formatting style (for example newline and indent).\n    * This option only affects JSON serialization. By default Gson produces compact JSON output without any formatting.\n    *\n-   * <p>Has no effect if the serialized format is a single line.</p>\n+   * <p>If the formatting style uses an empty newline, pretty printing can still affect spacing\n+   * after separators depending on the style configuration.</p>\n    *\n    * @param formattingStyle the formatting style to use.\n    * @return a reference to this {@code GsonBuilder} object to fulfill the \"Builder\" pattern\ndiff --git a/gson/src/main/java/com/google/gson/stream/JsonWriter.java b/gson/src/main/java/com/google/gson/stream/JsonWriter.java\nindex 4a2424e6..ac51dfb4 100644\n--- a/gson/src/main/java/com/google/gson/stream/JsonWriter.java\n+++ b/gson/src/main/java/com/google/gson/stream/JsonWriter.java\n@@ -233,7 +233,8 @@ public class JsonWriter implements Closeable, Flushable {\n    * For example the indentation string to be repeated for each level of indentation.\n    * Or the newline style, to accommodate various OS styles.</p>\n    *\n-   * <p>Has no effect if the serialized format is a single line.</p>\n+   * <p>If the formatting style uses an empty newline, pretty printing can still affect spacing\n+   * after separators depending on the style configuration.</p>\n    *\n    * @param formattingStyle the style used for pretty printing, no pretty printing if {@code null}.\n    * @since $next-version$\n@@ -243,7 +244,7 @@ public class JsonWriter implements Closeable, Flushable {\n     if (formattingStyle == null) {\n       this.separator = \":\";\n     } else {\n-      this.separator = \": \";\n+      this.separator = formattingStyle.isSpaceAfterSeparator() ? \": \" : \":\";\n     }\n   }\n \n@@ -697,7 +698,13 @@ public class JsonWriter implements Closeable, Flushable {\n       return;\n     }\n \n-    out.write(formattingStyle.getNewline());\n+    String nl = formattingStyle.getNewline();\n+    if (nl.isEmpty()) {\n+      // Single-line output: Do not write indent or newline here\n+      return;\n+    }\n+\n+    out.write(nl);\n     for (int i = 1, size = stackSize; i < size; i++) {\n       out.write(formattingStyle.getIndent());\n     }\n@@ -711,10 +718,17 @@ public class JsonWriter implements Closeable, Flushable {\n     int context = peek();\n     if (context == NONEMPTY_OBJECT) { // first in object\n       out.write(',');\n+      if (formattingStyle != null && formattingStyle.getNewline().isEmpty() && formattingStyle.isSpaceAfterSeparator()) {\n+        out.write(' ');\n+      } else {\n+        newline();\n+      }\n     } else if (context != EMPTY_OBJECT) { // not in an object!\n       throw new IllegalStateException(\"Nesting problem.\");\n+    } else {\n+      // first in object\n+      newline();\n     }\n-    newline();\n     replaceTop(DANGLING_NAME);\n   }\n \n@@ -743,7 +757,11 @@ public class JsonWriter implements Closeable, Flushable {\n \n     case NONEMPTY_ARRAY: // another in array\n       out.append(',');\n-      newline();\n+      if (formattingStyle != null && formattingStyle.getNewline().isEmpty() && formattingStyle.isSpaceAfterSeparator()) {\n+        out.write(' ');\n+      } else {\n+        newline();\n+      }\n       break;\n \n     case DANGLING_NAME: // value for name\n"}
{"instance_id": "apache__rocketmq-7346", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/file/TieredFlatFile.java b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/file/TieredFlatFile.java\nindex 426c4e09d..d973179ee 100644\n--- a/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/file/TieredFlatFile.java\n+++ b/tieredstore/src/main/java/org/apache/rocketmq/tieredstore/file/TieredFlatFile.java\n@@ -365,7 +365,10 @@ public class TieredFlatFile {\n             if (!segmentList.isEmpty()) {\n                 return boundaryType == BoundaryType.UPPER ? segmentList.get(0) : segmentList.get(segmentList.size() - 1);\n             }\n-            return fileSegmentList.isEmpty() ? null : fileSegmentList.get(fileSegmentList.size() - 1);\n+            if (fileSegmentList.isEmpty()) {\n+                return null;\n+            }\n+            return boundaryType == BoundaryType.UPPER ? fileSegmentList.get(fileSegmentList.size() - 1) : fileSegmentList.get(0);\n         } finally {\n             fileSegmentLock.readLock().unlock();\n         }\n"}
{"instance_id": "apache__rocketmq-7823", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/common/src/main/java/org/apache/rocketmq/common/utils/NetworkUtil.java b/common/src/main/java/org/apache/rocketmq/common/utils/NetworkUtil.java\nindex 7dd83e617..09904278a 100644\n--- a/common/src/main/java/org/apache/rocketmq/common/utils/NetworkUtil.java\n+++ b/common/src/main/java/org/apache/rocketmq/common/utils/NetworkUtil.java\n@@ -146,10 +146,28 @@ public class NetworkUtil {\n     }\n \n     public static SocketAddress string2SocketAddress(final String addr) {\n-        int split = addr.lastIndexOf(\":\");\n-        String host = addr.substring(0, split);\n-        String port = addr.substring(split + 1);\n-        InetSocketAddress isa = new InetSocketAddress(host, Integer.parseInt(port));\n+        String host;\n+        String portStr;\n+        if (addr.startsWith(\"[\")) {\n+            int end = addr.indexOf(']');\n+            if (end == -1) {\n+                throw new IllegalArgumentException(\"Invalid IPv6 address: \" + addr);\n+            }\n+            host = addr.substring(1, end);\n+            int colon = addr.indexOf(':', end + 1);\n+            if (colon == -1) {\n+                throw new IllegalArgumentException(\"Missing port: \" + addr);\n+            }\n+            portStr = addr.substring(colon + 1);\n+        } else {\n+            int split = addr.lastIndexOf(\":\");\n+            if (split <= 0) {\n+                throw new IllegalArgumentException(\"Invalid address, expected host:port, got: \" + addr);\n+            }\n+            host = addr.substring(0, split);\n+            portStr = addr.substring(split + 1);\n+        }\n+        InetSocketAddress isa = new InetSocketAddress(host, Integer.parseInt(portStr));\n         return isa;\n     }\n \ndiff --git a/remoting/src/main/java/org/apache/rocketmq/remoting/common/RemotingHelper.java b/remoting/src/main/java/org/apache/rocketmq/remoting/common/RemotingHelper.java\nindex 363b22eac..4e79c198b 100644\n--- a/remoting/src/main/java/org/apache/rocketmq/remoting/common/RemotingHelper.java\n+++ b/remoting/src/main/java/org/apache/rocketmq/remoting/common/RemotingHelper.java\n@@ -95,10 +95,29 @@ public class RemotingHelper {\n     }\n \n     public static SocketAddress string2SocketAddress(final String addr) {\n-        int split = addr.lastIndexOf(\":\");\n-        String host = addr.substring(0, split);\n-        String port = addr.substring(split + 1);\n-        InetSocketAddress isa = new InetSocketAddress(host, Integer.parseInt(port));\n+        int splitHostEnd = -1;\n+        String host;\n+        String portStr;\n+        if (addr.startsWith(\"[\")) {\n+            splitHostEnd = addr.indexOf(']');\n+            if (splitHostEnd == -1) {\n+                throw new IllegalArgumentException(\"Invalid IPv6 address: \" + addr);\n+            }\n+            host = addr.substring(1, splitHostEnd);\n+            int colon = addr.indexOf(':', splitHostEnd + 1);\n+            if (colon == -1) {\n+                throw new IllegalArgumentException(\"Missing port: \" + addr);\n+            }\n+            portStr = addr.substring(colon + 1);\n+        } else {\n+            int split = addr.lastIndexOf(\":\");\n+            if (split <= 0) {\n+                throw new IllegalArgumentException(\"Invalid address, expected host:port, got: \" + addr);\n+            }\n+            host = addr.substring(0, split);\n+            portStr = addr.substring(split + 1);\n+        }\n+        InetSocketAddress isa = new InetSocketAddress(host, Integer.parseInt(portStr));\n         return isa;\n     }\n \ndiff --git a/remoting/src/main/java/org/apache/rocketmq/remoting/netty/NettyRemotingClient.java b/remoting/src/main/java/org/apache/rocketmq/remoting/netty/NettyRemotingClient.java\nindex 9f1519130..4ea32a9f3 100644\n--- a/remoting/src/main/java/org/apache/rocketmq/remoting/netty/NettyRemotingClient.java\n+++ b/remoting/src/main/java/org/apache/rocketmq/remoting/netty/NettyRemotingClient.java\n@@ -353,7 +353,31 @@ public class NettyRemotingClient extends NettyRemotingAbstract implements Remoti\n \n     // Do not use RemotingUtil, it will directly resolve the domain\n     private String[] getHostAndPort(String address) {\n-        return address.split(\":\");\n+        if (address == null) {\n+            throw new IllegalArgumentException(\"address is null\");\n+        }\n+        String host;\n+        String portStr;\n+        if (address.startsWith(\"[\")) {\n+            int end = address.indexOf(']');\n+            if (end == -1) {\n+                throw new IllegalArgumentException(\"Invalid IPv6 address: \" + address);\n+            }\n+            host = address.substring(1, end);\n+            int colon = address.indexOf(':', end + 1);\n+            if (colon == -1) {\n+                throw new IllegalArgumentException(\"Missing port: \" + address);\n+            }\n+            portStr = address.substring(colon + 1);\n+        } else {\n+            int split = address.lastIndexOf(':');\n+            if (split <= 0) {\n+                throw new IllegalArgumentException(\"Invalid address, expected host:port, got: \" + address);\n+            }\n+            host = address.substring(0, split);\n+            portStr = address.substring(split + 1);\n+        }\n+        return new String[] { host, portStr };\n     }\n \n     @Override\n"}
{"instance_id": "apache__rocketmq-5008", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetAssigner.java b/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetAssigner.java\nindex 55614ccba..0c36af02e 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetAssigner.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/queue/QueueOffsetAssigner.java\n@@ -35,7 +35,12 @@ public class QueueOffsetAssigner {\n     private ConcurrentMap<String/* topic-queueid */, Long/* offset */> lmqTopicQueueTable = new ConcurrentHashMap<>(1024);\n \n     public long assignQueueOffset(String topicQueueKey, short messageNum) {\n-        long queueOffset = this.topicQueueTable.computeIfAbsent(topicQueueKey, k -> 0L);\n+        Long queueOffsetObj = this.topicQueueTable.get(topicQueueKey);\n+        if (queueOffsetObj == null) {\n+            Long prev = this.topicQueueTable.putIfAbsent(topicQueueKey, 0L);\n+            queueOffsetObj = (prev == null ? 0L : prev);\n+        }\n+        long queueOffset = queueOffsetObj;\n         this.topicQueueTable.put(topicQueueKey, queueOffset + messageNum);\n         return queueOffset;\n     }\n@@ -45,13 +50,23 @@ public class QueueOffsetAssigner {\n     }\n \n     public long assignBatchQueueOffset(String topicQueueKey, short messageNum) {\n-        Long topicOffset = this.batchTopicQueueTable.computeIfAbsent(topicQueueKey, k -> 0L);\n+        Long topicOffsetObj = this.batchTopicQueueTable.get(topicQueueKey);\n+        if (topicOffsetObj == null) {\n+            Long prev = this.batchTopicQueueTable.putIfAbsent(topicQueueKey, 0L);\n+            topicOffsetObj = (prev == null ? 0L : prev);\n+        }\n+        long topicOffset = topicOffsetObj;\n         this.batchTopicQueueTable.put(topicQueueKey, topicOffset + messageNum);\n         return topicOffset;\n     }\n \n     public long assignLmqOffset(String topicQueueKey, short messageNum) {\n-        long topicOffset = this.lmqTopicQueueTable.computeIfAbsent(topicQueueKey, k -> 0L);\n+        Long topicOffsetObj = this.lmqTopicQueueTable.get(topicQueueKey);\n+        if (topicOffsetObj == null) {\n+            Long prev = this.lmqTopicQueueTable.putIfAbsent(topicQueueKey, 0L);\n+            topicOffsetObj = (prev == null ? 0L : prev);\n+        }\n+        long topicOffset = topicOffsetObj;\n         this.lmqTopicQueueTable.put(topicQueueKey, topicOffset + messageNum);\n         return topicOffset;\n     }\n"}
{"instance_id": "apache__rocketmq-5037", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "apache__dubbo-5708", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/legacy/SelectTelnetHandler.java b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/legacy/SelectTelnetHandler.java\nindex 700b6ae841..2db7f54da3 100644\n--- a/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/legacy/SelectTelnetHandler.java\n+++ b/dubbo-plugin/dubbo-qos/src/main/java/org/apache/dubbo/qos/legacy/SelectTelnetHandler.java\n@@ -51,7 +51,7 @@ public class SelectTelnetHandler implements TelnetHandler {\n         if (!StringUtils.isInteger(message) || Integer.parseInt(message) < 1 || Integer.parseInt(message) > methodList.size()) {\n             return \"Illegal index ,please input select 1~\" + methodList.size();\n         }\n-        Method method = methodList.get(Integer.parseInt(message));\n+        Method method = methodList.get(Integer.parseInt(message) - 1);\n         channel.setAttribute(SELECT_METHOD_KEY, method);\n         channel.setAttribute(SELECT_KEY, Boolean.TRUE);\n         String invokeMessage = (String) channel.getAttribute(InvokeTelnetHandler.INVOKE_MESSAGE_KEY);\n"}
{"instance_id": "apache__dubbo-4678", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java b/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java\nindex d557624a66..94bad26d9f 100644\n--- a/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java\n+++ b/dubbo-config/dubbo-config-api/src/main/java/org/apache/dubbo/config/AbstractConfig.java\n@@ -493,6 +493,20 @@ public abstract class AbstractConfig implements Serializable {\n             try {\n                 String name = method.getName();\n                 if (MethodUtils.isMetaMethod(method)) {\n+                    // Prefer getter 'getXxx' over boolean 'isXxx' for the same property to ensure determinism\n+                    if (name.startsWith(\"is\")) {\n+                        try {\n+                            Method getMethod = this.getClass().getMethod(\"get\" + name.substring(2));\n+                            if (MethodUtils.isMetaMethod(getMethod)) {\n+                                Parameter gp = getMethod.getAnnotation(Parameter.class);\n+                                if (gp == null || !gp.excluded()) {\n+                                    continue;\n+                                }\n+                            }\n+                        } catch (NoSuchMethodException e) {\n+                            // ignore, no corresponding get method\n+                        }\n+                    }\n                     String prop = calculateAttributeFromGetter(name);\n                     String key;\n                     Parameter parameter = method.getAnnotation(Parameter.class);\n@@ -501,6 +515,9 @@ public abstract class AbstractConfig implements Serializable {\n                     } else {\n                         key = prop;\n                     }\n+                    if (parameter != null && parameter.excluded()) {\n+                        continue;\n+                    }\n                     // treat url and configuration differently, the value should always present in configuration though it may not need to present in url.\n                     //if (method.getReturnType() == Object.class || parameter != null && parameter.excluded()) {\n                     if (method.getReturnType() == Object.class) {\n"}
{"instance_id": "trinodb__trino-2707", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-docs/src/main/sphinx/develop/functions.rst b/presto-docs/src/main/sphinx/develop/functions.rst\nindex a69c6d24671..1e316af3432 100644\n--- a/presto-docs/src/main/sphinx/develop/functions.rst\n+++ b/presto-docs/src/main/sphinx/develop/functions.rst\n@@ -42,12 +42,36 @@ The function framework uses annotations to indicate relevant information\n about functions, including name, description, return type and parameter\n types. Below is a sample function which implements ``is_null``:\n \n+Description annotation formatting\n+---------------------------------\n+\n+Use consistent formatting for all ``@Description`` values:\n+\n+- Start with a capital letter.\n+- End with a period.\n+- Use present tense to succinctly describe the function's behavior.\n+- Do not repeat the function name; describe what it does.\n+- Keep the description to a single sentence. Add further details to the user documentation under the functions section.\n+\n+Deprecated functions:\n+\n+- Prefix the description with ``(DEPRECATED) ``.\n+- Provide a replacement or action and end the sentence with a period.\n+\n+Examples:\n+\n+- ``@Description(\"Returns TRUE if the argument is NULL.\")``\n+- ``@Description(\"Converts the string to alternating case.\")``\n+- ``@Description(\"(DEPRECATED) Use good_function() instead.\")``\n+\n+Consistent ``@Description`` formatting helps ensure consistency between developer documentation, CLI help, and any auto-generated references.\n+\n .. code-block:: java\n \n     public class ExampleNullFunction\n     {\n         @ScalarFunction(\"is_null\")\n-        @Description(\"Returns TRUE if the argument is NULL\")\n+        @Description(\"Returns TRUE if the argument is NULL.\")\n         @SqlType(StandardTypes.BOOLEAN)\n         public static boolean isNull(@SqlNullable @SqlType(StandardTypes.VARCHAR) Slice string)\n         {\n@@ -84,7 +108,7 @@ To make our previous example work with any type we need the following:\n .. code-block:: java\n \n     @ScalarFunction(name = \"is_null\")\n-    @Description(\"Returns TRUE if the argument is NULL\")\n+    @Description(\"Returns TRUE if the argument is NULL.\")\n     public final class IsNullFunction\n     {\n         @TypeParameter(\"T\")\n@@ -157,7 +181,7 @@ The ``lowercaser`` function takes a single ``VARCHAR`` argument and returns a\n     public class ExampleStringFunction\n     {\n         @ScalarFunction(\"lowercaser\")\n-        @Description(\"converts the string to alternating case\")\n+        @Description(\"Converts the string to alternating case.\")\n         @SqlType(StandardTypes.VARCHAR)\n         public static Slice lowercaser(@SqlType(StandardTypes.VARCHAR) Slice slice)\n         {\n@@ -297,7 +321,7 @@ needs to be replaced with a note about the deprecation and the replacement funct\n     {\n         @Deprecated\n         @ScalarFunction(\"bad_function\")\n-        @Description(\"(DEPRECATED) Use good_function() instead\")\n+        @Description(\"(DEPRECATED) Use good_function() instead.\")\n         @SqlType(StandardTypes.BOOLEAN)\n         public static boolean bad_function()\n         {\n"}
{"instance_id": "apache__dubbo-4026", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/PojoUtils.java b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/PojoUtils.java\nindex 37aa5ddaa6..3943b39978 100644\n--- a/dubbo-common/src/main/java/org/apache/dubbo/common/utils/PojoUtils.java\n+++ b/dubbo-common/src/main/java/org/apache/dubbo/common/utils/PojoUtils.java\n@@ -1,610 +1,636 @@\n-/*\r\n- * Licensed to the Apache Software Foundation (ASF) under one or more\r\n- * contributor license agreements.  See the NOTICE file distributed with\r\n- * this work for additional information regarding copyright ownership.\r\n- * The ASF licenses this file to You under the Apache License, Version 2.0\r\n- * (the \"License\"); you may not use this file except in compliance with\r\n- * the License.  You may obtain a copy of the License at\r\n- *\r\n- *     http://www.apache.org/licenses/LICENSE-2.0\r\n- *\r\n- * Unless required by applicable law or agreed to in writing, software\r\n- * distributed under the License is distributed on an \"AS IS\" BASIS,\r\n- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n- * See the License for the specific language governing permissions and\r\n- * limitations under the License.\r\n- */\r\n-package org.apache.dubbo.common.utils;\r\n-\r\n-import org.apache.dubbo.common.logger.Logger;\r\n-import org.apache.dubbo.common.logger.LoggerFactory;\r\n-\r\n-import java.lang.reflect.Array;\r\n-import java.lang.reflect.Constructor;\r\n-import java.lang.reflect.Field;\r\n-import java.lang.reflect.InvocationHandler;\r\n-import java.lang.reflect.InvocationTargetException;\r\n-import java.lang.reflect.Method;\r\n-import java.lang.reflect.Modifier;\r\n-import java.lang.reflect.ParameterizedType;\r\n-import java.lang.reflect.Proxy;\r\n-import java.lang.reflect.Type;\r\n-import java.util.ArrayList;\r\n-import java.util.Collection;\r\n-import java.util.Collections;\r\n-import java.util.HashMap;\r\n-import java.util.HashSet;\r\n-import java.util.Hashtable;\r\n-import java.util.IdentityHashMap;\r\n-import java.util.LinkedHashMap;\r\n-import java.util.List;\r\n-import java.util.Map;\r\n-import java.util.Properties;\r\n-import java.util.TreeMap;\r\n-import java.util.WeakHashMap;\r\n-import java.util.concurrent.ConcurrentHashMap;\r\n-import java.util.concurrent.ConcurrentMap;\r\n-import java.util.concurrent.ConcurrentSkipListMap;\r\n-\r\n-/**\r\n- * PojoUtils. Travel object deeply, and convert complex type to simple type.\r\n- * <p/>\r\n- * Simple type below will be remained:\r\n- * <ul>\r\n- * <li> Primitive Type, also include <b>String</b>, <b>Number</b>(Integer, Long), <b>Date</b>\r\n- * <li> Array of Primitive Type\r\n- * <li> Collection, eg: List, Map, Set etc.\r\n- * </ul>\r\n- * <p/>\r\n- * Other type will be covert to a map which contains the attributes and value pair of object.\r\n- */\r\n-public class PojoUtils {\r\n-\r\n-    private static final Logger logger = LoggerFactory.getLogger(PojoUtils.class);\r\n-    private static final ConcurrentMap<String, Method> NAME_METHODS_CACHE = new ConcurrentHashMap<String, Method>();\r\n-    private static final ConcurrentMap<Class<?>, ConcurrentMap<String, Field>> CLASS_FIELD_CACHE = new ConcurrentHashMap<Class<?>, ConcurrentMap<String, Field>>();\r\n-\r\n-    public static Object[] generalize(Object[] objs) {\r\n-        Object[] dests = new Object[objs.length];\r\n-        for (int i = 0; i < objs.length; i++) {\r\n-            dests[i] = generalize(objs[i]);\r\n-        }\r\n-        return dests;\r\n-    }\r\n-\r\n-    public static Object[] realize(Object[] objs, Class<?>[] types) {\r\n-        if (objs.length != types.length) {\r\n-            throw new IllegalArgumentException(\"args.length != types.length\");\r\n-        }\r\n-\r\n-        Object[] dests = new Object[objs.length];\r\n-        for (int i = 0; i < objs.length; i++) {\r\n-            dests[i] = realize(objs[i], types[i]);\r\n-        }\r\n-\r\n-        return dests;\r\n-    }\r\n-\r\n-    public static Object[] realize(Object[] objs, Class<?>[] types, Type[] gtypes) {\r\n-        if (objs.length != types.length || objs.length != gtypes.length) {\r\n-            throw new IllegalArgumentException(\"args.length != types.length\");\r\n-        }\r\n-        Object[] dests = new Object[objs.length];\r\n-        for (int i = 0; i < objs.length; i++) {\r\n-            dests[i] = realize(objs[i], types[i], gtypes[i]);\r\n-        }\r\n-        return dests;\r\n-    }\r\n-\r\n-    public static Object generalize(Object pojo) {\r\n-        return generalize(pojo, new IdentityHashMap<Object, Object>());\r\n-    }\r\n-\r\n-    @SuppressWarnings(\"unchecked\")\r\n-    private static Object generalize(Object pojo, Map<Object, Object> history) {\r\n-        if (pojo == null) {\r\n-            return null;\r\n-        }\r\n-\r\n-        if (pojo instanceof Enum<?>) {\r\n-            return ((Enum<?>) pojo).name();\r\n-        }\r\n-        if (pojo.getClass().isArray() && Enum.class.isAssignableFrom(pojo.getClass().getComponentType())) {\r\n-            int len = Array.getLength(pojo);\r\n-            String[] values = new String[len];\r\n-            for (int i = 0; i < len; i++) {\r\n-                values[i] = ((Enum<?>) Array.get(pojo, i)).name();\r\n-            }\r\n-            return values;\r\n-        }\r\n-\r\n-        if (ReflectUtils.isPrimitives(pojo.getClass())) {\r\n-            return pojo;\r\n-        }\r\n-\r\n-        if (pojo instanceof Class) {\r\n-            return ((Class) pojo).getName();\r\n-        }\r\n-\r\n-        Object o = history.get(pojo);\r\n-        if (o != null) {\r\n-            return o;\r\n-        }\r\n-        history.put(pojo, pojo);\r\n-\r\n-        if (pojo.getClass().isArray()) {\r\n-            int len = Array.getLength(pojo);\r\n-            Object[] dest = new Object[len];\r\n-            history.put(pojo, dest);\r\n-            for (int i = 0; i < len; i++) {\r\n-                Object obj = Array.get(pojo, i);\r\n-                dest[i] = generalize(obj, history);\r\n-            }\r\n-            return dest;\r\n-        }\r\n-        if (pojo instanceof Collection<?>) {\r\n-            Collection<Object> src = (Collection<Object>) pojo;\r\n-            int len = src.size();\r\n-            Collection<Object> dest = (pojo instanceof List<?>) ? new ArrayList<Object>(len) : new HashSet<Object>(len);\r\n-            history.put(pojo, dest);\r\n-            for (Object obj : src) {\r\n-                dest.add(generalize(obj, history));\r\n-            }\r\n-            return dest;\r\n-        }\r\n-        if (pojo instanceof Map<?, ?>) {\r\n-            Map<Object, Object> src = (Map<Object, Object>) pojo;\r\n-            Map<Object, Object> dest = createMap(src);\r\n-            history.put(pojo, dest);\r\n-            for (Map.Entry<Object, Object> obj : src.entrySet()) {\r\n-                dest.put(generalize(obj.getKey(), history), generalize(obj.getValue(), history));\r\n-            }\r\n-            return dest;\r\n-        }\r\n-        Map<String, Object> map = new HashMap<String, Object>();\r\n-        history.put(pojo, map);\r\n-        map.put(\"class\", pojo.getClass().getName());\r\n-        for (Method method : pojo.getClass().getMethods()) {\r\n-            if (ReflectUtils.isBeanPropertyReadMethod(method)) {\r\n-                try {\r\n-                    map.put(ReflectUtils.getPropertyNameFromBeanReadMethod(method), generalize(method.invoke(pojo), history));\r\n-                } catch (Exception e) {\r\n-                    throw new RuntimeException(e.getMessage(), e);\r\n-                }\r\n-            }\r\n-        }\r\n-        // public field\r\n-        for (Field field : pojo.getClass().getFields()) {\r\n-            if (ReflectUtils.isPublicInstanceField(field)) {\r\n-                try {\r\n-                    Object fieldValue = field.get(pojo);\r\n-                    if (history.containsKey(pojo)) {\r\n-                        Object pojoGeneralizedValue = history.get(pojo);\r\n-                        if (pojoGeneralizedValue instanceof Map\r\n-                                && ((Map) pojoGeneralizedValue).containsKey(field.getName())) {\r\n-                            continue;\r\n-                        }\r\n-                    }\r\n-                    if (fieldValue != null) {\r\n-                        map.put(field.getName(), generalize(fieldValue, history));\r\n-                    }\r\n-                } catch (Exception e) {\r\n-                    throw new RuntimeException(e.getMessage(), e);\r\n-                }\r\n-            }\r\n-        }\r\n-        return map;\r\n-    }\r\n-\r\n-    public static Object realize(Object pojo, Class<?> type) {\r\n-        return realize0(pojo, type, null, new IdentityHashMap<Object, Object>());\r\n-    }\r\n-\r\n-    public static Object realize(Object pojo, Class<?> type, Type genericType) {\r\n-        return realize0(pojo, type, genericType, new IdentityHashMap<Object, Object>());\r\n-    }\r\n-\r\n-    private static class PojoInvocationHandler implements InvocationHandler {\r\n-\r\n-        private Map<Object, Object> map;\r\n-\r\n-        public PojoInvocationHandler(Map<Object, Object> map) {\r\n-            this.map = map;\r\n-        }\r\n-\r\n-        @Override\r\n-        @SuppressWarnings(\"unchecked\")\r\n-        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\r\n-            if (method.getDeclaringClass() == Object.class) {\r\n-                return method.invoke(map, args);\r\n-            }\r\n-            String methodName = method.getName();\r\n-            Object value = null;\r\n-            if (methodName.length() > 3 && methodName.startsWith(\"get\")) {\r\n-                value = map.get(methodName.substring(3, 4).toLowerCase() + methodName.substring(4));\r\n-            } else if (methodName.length() > 2 && methodName.startsWith(\"is\")) {\r\n-                value = map.get(methodName.substring(2, 3).toLowerCase() + methodName.substring(3));\r\n-            } else {\r\n-                value = map.get(methodName.substring(0, 1).toLowerCase() + methodName.substring(1));\r\n-            }\r\n-            if (value instanceof Map<?, ?> && !Map.class.isAssignableFrom(method.getReturnType())) {\r\n-                value = realize0((Map<String, Object>) value, method.getReturnType(), null, new IdentityHashMap<Object, Object>());\r\n-            }\r\n-            return value;\r\n-        }\r\n-    }\r\n-\r\n-    @SuppressWarnings(\"unchecked\")\r\n-    private static Collection<Object> createCollection(Class<?> type, int len) {\r\n-        if (type.isAssignableFrom(ArrayList.class)) {\r\n-            return new ArrayList<Object>(len);\r\n-        }\r\n-        if (type.isAssignableFrom(HashSet.class)) {\r\n-            return new HashSet<Object>(len);\r\n-        }\r\n-        if (!type.isInterface() && !Modifier.isAbstract(type.getModifiers())) {\r\n-            try {\r\n-                return (Collection<Object>) type.newInstance();\r\n-            } catch (Exception e) {\r\n-                // ignore\r\n-            }\r\n-        }\r\n-        return new ArrayList<Object>();\r\n-    }\r\n-\r\n-    private static Map createMap(Map src) {\r\n-        Class<? extends Map> cl = src.getClass();\r\n-        Map result = null;\r\n-        if (HashMap.class == cl) {\r\n-            result = new HashMap();\r\n-        } else if (Hashtable.class == cl) {\r\n-            result = new Hashtable();\r\n-        } else if (IdentityHashMap.class == cl) {\r\n-            result = new IdentityHashMap();\r\n-        } else if (LinkedHashMap.class == cl) {\r\n-            result = new LinkedHashMap();\r\n-        } else if (Properties.class == cl) {\r\n-            result = new Properties();\r\n-        } else if (TreeMap.class == cl) {\r\n-            result = new TreeMap();\r\n-        } else if (WeakHashMap.class == cl) {\r\n-            return new WeakHashMap();\r\n-        } else if (ConcurrentHashMap.class == cl) {\r\n-            result = new ConcurrentHashMap();\r\n-        } else if (ConcurrentSkipListMap.class == cl) {\r\n-            result = new ConcurrentSkipListMap();\r\n-        } else {\r\n-            try {\r\n-                result = cl.newInstance();\r\n-            } catch (Exception e) { /* ignore */ }\r\n-\r\n-            if (result == null) {\r\n-                try {\r\n-                    Constructor<?> constructor = cl.getConstructor(Map.class);\r\n-                    result = (Map) constructor.newInstance(Collections.EMPTY_MAP);\r\n-                } catch (Exception e) { /* ignore */ }\r\n-            }\r\n-        }\r\n-\r\n-        if (result == null) {\r\n-            result = new HashMap<Object, Object>();\r\n-        }\r\n-\r\n-        return result;\r\n-    }\r\n-\r\n-    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\r\n-    private static Object realize0(Object pojo, Class<?> type, Type genericType, final Map<Object, Object> history) {\r\n-        if (pojo == null) {\r\n-            return null;\r\n-        }\r\n-\r\n-        if (type != null && type.isEnum() && pojo.getClass() == String.class) {\r\n-            return Enum.valueOf((Class<Enum>) type, (String) pojo);\r\n-        }\r\n-\r\n-        if (ReflectUtils.isPrimitives(pojo.getClass())\r\n-                && !(type != null && type.isArray()\r\n-                && type.getComponentType().isEnum()\r\n-                && pojo.getClass() == String[].class)) {\r\n-            return CompatibleTypeUtils.compatibleTypeConvert(pojo, type);\r\n-        }\r\n-\r\n-        Object o = history.get(pojo);\r\n-\r\n-        if (o != null) {\r\n-            return o;\r\n-        }\r\n-\r\n-        history.put(pojo, pojo);\r\n-\r\n-        if (pojo.getClass().isArray()) {\r\n-            if (Collection.class.isAssignableFrom(type)) {\r\n-                Class<?> ctype = pojo.getClass().getComponentType();\r\n-                int len = Array.getLength(pojo);\r\n-                Collection dest = createCollection(type, len);\r\n-                history.put(pojo, dest);\r\n-                for (int i = 0; i < len; i++) {\r\n-                    Object obj = Array.get(pojo, i);\r\n-                    Object value = realize0(obj, ctype, null, history);\r\n-                    dest.add(value);\r\n-                }\r\n-                return dest;\r\n-            } else {\r\n-                Class<?> ctype = (type != null && type.isArray() ? type.getComponentType() : pojo.getClass().getComponentType());\r\n-                int len = Array.getLength(pojo);\r\n-                Object dest = Array.newInstance(ctype, len);\r\n-                history.put(pojo, dest);\r\n-                for (int i = 0; i < len; i++) {\r\n-                    Object obj = Array.get(pojo, i);\r\n-                    Object value = realize0(obj, ctype, null, history);\r\n-                    Array.set(dest, i, value);\r\n-                }\r\n-                return dest;\r\n-            }\r\n-        }\r\n-\r\n-        if (pojo instanceof Collection<?>) {\r\n-            if (type.isArray()) {\r\n-                Class<?> ctype = type.getComponentType();\r\n-                Collection<Object> src = (Collection<Object>) pojo;\r\n-                int len = src.size();\r\n-                Object dest = Array.newInstance(ctype, len);\r\n-                history.put(pojo, dest);\r\n-                int i = 0;\r\n-                for (Object obj : src) {\r\n-                    Object value = realize0(obj, ctype, null, history);\r\n-                    Array.set(dest, i, value);\r\n-                    i++;\r\n-                }\r\n-                return dest;\r\n-            } else {\r\n-                Collection<Object> src = (Collection<Object>) pojo;\r\n-                int len = src.size();\r\n-                Collection<Object> dest = createCollection(type, len);\r\n-                history.put(pojo, dest);\r\n-                for (Object obj : src) {\r\n-                    Type keyType = getGenericClassByIndex(genericType, 0);\r\n-                    Class<?> keyClazz = obj.getClass();\r\n-                    if (keyType instanceof Class) {\r\n-                        keyClazz = (Class<?>) keyType;\r\n-                    }\r\n-                    Object value = realize0(obj, keyClazz, keyType, history);\r\n-                    dest.add(value);\r\n-                }\r\n-                return dest;\r\n-            }\r\n-        }\r\n-\r\n-        if (pojo instanceof Map<?, ?> && type != null) {\r\n-            Object className = ((Map<Object, Object>) pojo).get(\"class\");\r\n-            if (className instanceof String) {\r\n-                try {\r\n-                    type = ClassUtils.forName((String) className);\r\n-                } catch (ClassNotFoundException e) {\r\n-                    // ignore\r\n-                }\r\n-            }\r\n-\r\n-            // special logic for enum\r\n-            if (type.isEnum()) {\r\n-                Object name = ((Map<Object, Object>) pojo).get(\"name\");\r\n-                if (name != null) {\r\n-                    return Enum.valueOf((Class<Enum>) type, name.toString());\r\n-                }\r\n-            }\r\n-            Map<Object, Object> map;\r\n-            // when return type is not the subclass of return type from the signature and not an interface\r\n-            if (!type.isInterface() && !type.isAssignableFrom(pojo.getClass())) {\r\n-                try {\r\n-                    map = (Map<Object, Object>) type.newInstance();\r\n-                    Map<Object, Object> mapPojo = (Map<Object, Object>) pojo;\r\n-                    map.putAll(mapPojo);\r\n-                    map.remove(\"class\");\r\n-                } catch (Exception e) {\r\n-                    //ignore error\r\n-                    map = (Map<Object, Object>) pojo;\r\n-                }\r\n-            } else {\r\n-                map = (Map<Object, Object>) pojo;\r\n-            }\r\n-\r\n-            if (Map.class.isAssignableFrom(type) || type == Object.class) {\r\n-                final Map<Object, Object> result = createMap(map);\r\n-                history.put(pojo, result);\r\n-                for (Map.Entry<Object, Object> entry : map.entrySet()) {\r\n-                    Type keyType = getGenericClassByIndex(genericType, 0);\r\n-                    Type valueType = getGenericClassByIndex(genericType, 1);\r\n-                    Class<?> keyClazz;\r\n-                    if (keyType instanceof Class) {\r\n-                        keyClazz = (Class<?>) keyType;\r\n-                    } else if (keyType instanceof ParameterizedType) {\r\n-                        keyClazz = (Class<?>) ((ParameterizedType) keyType).getRawType();\r\n-                    } else {\r\n-                        keyClazz = entry.getKey() == null ? null : entry.getKey().getClass();\r\n-                    }\r\n-                    Class<?> valueClazz;\r\n-                    if (valueType instanceof Class) {\r\n-                        valueClazz = (Class<?>) valueType;\r\n-                    } else if (valueType instanceof ParameterizedType) {\r\n-                        valueClazz = (Class<?>) ((ParameterizedType) valueType).getRawType();\r\n-                    } else {\r\n-                        valueClazz = entry.getValue() == null ? null : entry.getValue().getClass();\r\n-                    }\r\n-\r\n-                    Object key = keyClazz == null ? entry.getKey() : realize0(entry.getKey(), keyClazz, keyType, history);\r\n-                    Object value = valueClazz == null ? entry.getValue() : realize0(entry.getValue(), valueClazz, valueType, history);\r\n-                    result.put(key, value);\r\n-                }\r\n-                return result;\r\n-            } else if (type.isInterface()) {\r\n-                Object dest = Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), new Class<?>[]{type}, new PojoInvocationHandler(map));\r\n-                history.put(pojo, dest);\r\n-                return dest;\r\n-            } else {\r\n-                Object dest = newInstance(type);\r\n-                history.put(pojo, dest);\r\n-                for (Map.Entry<Object, Object> entry : map.entrySet()) {\r\n-                    Object key = entry.getKey();\r\n-                    if (key instanceof String) {\r\n-                        String name = (String) key;\r\n-                        Object value = entry.getValue();\r\n-                        if (value != null) {\r\n-                            Method method = getSetterMethod(dest.getClass(), name, value.getClass());\r\n-                            Field field = getField(dest.getClass(), name);\r\n-                            if (method != null) {\r\n-                                if (!method.isAccessible()) {\r\n-                                    method.setAccessible(true);\r\n-                                }\r\n-                                Type ptype = method.getGenericParameterTypes()[0];\r\n-                                value = realize0(value, method.getParameterTypes()[0], ptype, history);\r\n-                                try {\r\n-                                    method.invoke(dest, value);\r\n-                                } catch (Exception e) {\r\n-                                    String exceptionDescription = \"Failed to set pojo \" + dest.getClass().getSimpleName() + \" property \" + name\r\n-                                            + \" value \" + value + \"(\" + value.getClass() + \"), cause: \" + e.getMessage();\r\n-                                    logger.error(exceptionDescription, e);\r\n-                                    throw new RuntimeException(exceptionDescription, e);\r\n-                                }\r\n-                            } else if (field != null) {\r\n-                                value = realize0(value, field.getType(), field.getGenericType(), history);\r\n-                                try {\r\n-                                    field.set(dest, value);\r\n-                                } catch (IllegalAccessException e) {\r\n-                                    throw new RuntimeException(\"Failed to set field \" + name + \" of pojo \" + dest.getClass().getName() + \" : \" + e.getMessage(), e);\r\n-                                }\r\n-                            }\r\n-                        }\r\n-                    }\r\n-                }\r\n-                if (dest instanceof Throwable) {\r\n-                    Object message = map.get(\"message\");\r\n-                    if (message instanceof String) {\r\n-                        try {\r\n-                            Field field = Throwable.class.getDeclaredField(\"detailMessage\");\r\n-                            if (!field.isAccessible()) {\r\n-                                field.setAccessible(true);\r\n-                            }\r\n-                            field.set(dest, message);\r\n-                        } catch (Exception e) {\r\n-                        }\r\n-                    }\r\n-                }\r\n-                return dest;\r\n-            }\r\n-        }\r\n-        return pojo;\r\n-    }\r\n-\r\n-    /**\r\n-     * Get parameterized type\r\n-     *\r\n-     * @param genericType generic type\r\n-     * @param index       index of the target parameterized type\r\n-     * @return Return Person.class for List<Person>, return Person.class for Map<String, Person> when index=0\r\n-     */\r\n-    private static Type getGenericClassByIndex(Type genericType, int index) {\r\n-        Type clazz = null;\r\n-        // find parameterized type\r\n-        if (genericType instanceof ParameterizedType) {\r\n-            ParameterizedType t = (ParameterizedType) genericType;\r\n-            Type[] types = t.getActualTypeArguments();\r\n-            clazz = types[index];\r\n-        }\r\n-        return clazz;\r\n-    }\r\n-\r\n-    private static Object newInstance(Class<?> cls) {\r\n-        try {\r\n-            return cls.newInstance();\r\n-        } catch (Throwable t) {\r\n-            try {\r\n-                Constructor<?>[] constructors = cls.getDeclaredConstructors();\r\n-                /**\r\n-                 * From Javadoc java.lang.Class#getDeclaredConstructors\r\n-                 * This method returns an array of Constructor objects reflecting all the constructors\r\n-                 * declared by the class represented by this Class object.\r\n-                 * This method returns an array of length 0,\r\n-                 * if this Class object represents an interface, a primitive type, an array class, or void.\r\n-                 */\r\n-                if (constructors.length == 0) {\r\n-                    throw new RuntimeException(\"Illegal constructor: \" + cls.getName());\r\n-                }\r\n-                Constructor<?> constructor = constructors[0];\r\n-                if (constructor.getParameterTypes().length > 0) {\r\n-                    for (Constructor<?> c : constructors) {\r\n-                        if (c.getParameterTypes().length < constructor.getParameterTypes().length) {\r\n-                            constructor = c;\r\n-                            if (constructor.getParameterTypes().length == 0) {\r\n-                                break;\r\n-                            }\r\n-                        }\r\n-                    }\r\n-                }\r\n-                constructor.setAccessible(true);\r\n-                return constructor.newInstance(new Object[constructor.getParameterTypes().length]);\r\n-            } catch (InstantiationException e) {\r\n-                throw new RuntimeException(e.getMessage(), e);\r\n-            } catch (IllegalAccessException e) {\r\n-                throw new RuntimeException(e.getMessage(), e);\r\n-            } catch (InvocationTargetException e) {\r\n-                throw new RuntimeException(e.getMessage(), e);\r\n-            }\r\n-        }\r\n-    }\r\n-\r\n-    private static Method getSetterMethod(Class<?> cls, String property, Class<?> valueCls) {\r\n-        String name = \"set\" + property.substring(0, 1).toUpperCase() + property.substring(1);\r\n-        Method method = NAME_METHODS_CACHE.get(cls.getName() + \".\" + name + \"(\" + valueCls.getName() + \")\");\r\n-        if (method == null) {\r\n-            try {\r\n-                method = cls.getMethod(name, valueCls);\r\n-            } catch (NoSuchMethodException e) {\r\n-                for (Method m : cls.getMethods()) {\r\n-                    if (ReflectUtils.isBeanPropertyWriteMethod(m) && m.getName().equals(name)) {\r\n-                        method = m;\r\n-                    }\r\n-                }\r\n-            }\r\n-            if (method != null) {\r\n-                NAME_METHODS_CACHE.put(cls.getName() + \".\" + name + \"(\" + valueCls.getName() + \")\", method);\r\n-            }\r\n-        }\r\n-        return method;\r\n-    }\r\n-\r\n-    private static Field getField(Class<?> cls, String fieldName) {\r\n-        Field result = null;\r\n-        if (CLASS_FIELD_CACHE.containsKey(cls) && CLASS_FIELD_CACHE.get(cls).containsKey(fieldName)) {\r\n-            return CLASS_FIELD_CACHE.get(cls).get(fieldName);\r\n-        }\r\n-        try {\r\n-            result = cls.getDeclaredField(fieldName);\r\n-            result.setAccessible(true);\r\n-        } catch (NoSuchFieldException e) {\r\n-            for (Field field : cls.getFields()) {\r\n-                if (fieldName.equals(field.getName()) && ReflectUtils.isPublicInstanceField(field)) {\r\n-                    result = field;\r\n-                    break;\r\n-                }\r\n-            }\r\n-        }\r\n-        if (result != null) {\r\n-            ConcurrentMap<String, Field> fields = CLASS_FIELD_CACHE.get(cls);\r\n-            if (fields == null) {\r\n-                fields = new ConcurrentHashMap<String, Field>();\r\n-                CLASS_FIELD_CACHE.putIfAbsent(cls, fields);\r\n-            }\r\n-            fields = CLASS_FIELD_CACHE.get(cls);\r\n-            fields.putIfAbsent(fieldName, result);\r\n-        }\r\n-        return result;\r\n-    }\r\n-\r\n-    public static boolean isPojo(Class<?> cls) {\r\n-        return !ReflectUtils.isPrimitives(cls)\r\n-                && !Collection.class.isAssignableFrom(cls)\r\n-                && !Map.class.isAssignableFrom(cls);\r\n-    }\r\n-\r\n-}\r\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one or more\n+ * contributor license agreements.  See the NOTICE file distributed with\n+ * this work for additional information regarding copyright ownership.\n+ * The ASF licenses this file to You under the Apache License, Version 2.0\n+ * (the \"License\"); you may not use this file except in compliance with\n+ * the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.dubbo.common.utils;\n+\n+import org.apache.dubbo.common.logger.Logger;\n+import org.apache.dubbo.common.logger.LoggerFactory;\n+\n+import java.lang.reflect.Array;\n+import java.lang.reflect.Constructor;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.InvocationHandler;\n+import java.lang.reflect.InvocationTargetException;\n+import java.lang.reflect.Method;\n+import java.lang.reflect.Modifier;\n+import java.lang.reflect.ParameterizedType;\n+import java.lang.reflect.Proxy;\n+import java.lang.reflect.Type;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.Hashtable;\n+import java.util.IdentityHashMap;\n+import java.util.LinkedHashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Properties;\n+import java.util.TreeMap;\n+import java.util.WeakHashMap;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ConcurrentSkipListMap;\n+\n+/**\n+ * PojoUtils. Travel object deeply, and convert complex type to simple type.\n+ * <p/>\n+ * Simple type below will be remained:\n+ * <ul>\n+ * <li> Primitive Type, also include <b>String</b>, <b>Number</b>(Integer, Long), <b>Date</b>\n+ * <li> Array of Primitive Type\n+ * <li> Collection, eg: List, Map, Set etc.\n+ * </ul>\n+ * <p/>\n+ * Other type will be covert to a map which contains the attributes and value pair of object.\n+ */\n+public class PojoUtils {\n+\n+    private static final Logger logger = LoggerFactory.getLogger(PojoUtils.class);\n+    private static final ConcurrentMap<String, Method> NAME_METHODS_CACHE = new ConcurrentHashMap<String, Method>();\n+    private static final ConcurrentMap<Class<?>, ConcurrentMap<String, Field>> CLASS_FIELD_CACHE = new ConcurrentHashMap<Class<?>, ConcurrentMap<String, Field>>();\n+\n+    public static Object[] generalize(Object[] objs) {\n+        Object[] dests = new Object[objs.length];\n+        for (int i = 0; i < objs.length; i++) {\n+            dests[i] = generalize(objs[i]);\n+        }\n+        return dests;\n+    }\n+\n+    public static Object[] realize(Object[] objs, Class<?>[] types) {\n+        if (objs.length != types.length) {\n+            throw new IllegalArgumentException(\"args.length != types.length\");\n+        }\n+\n+        Object[] dests = new Object[objs.length];\n+        for (int i = 0; i < objs.length; i++) {\n+            dests[i] = realize(objs[i], types[i]);\n+        }\n+\n+        return dests;\n+    }\n+\n+    public static Object[] realize(Object[] objs, Class<?>[] types, Type[] gtypes) {\n+        if (objs.length != types.length || objs.length != gtypes.length) {\n+            throw new IllegalArgumentException(\"args.length != types.length\");\n+        }\n+        Object[] dests = new Object[objs.length];\n+        for (int i = 0; i < objs.length; i++) {\n+            dests[i] = realize(objs[i], types[i], gtypes[i]);\n+        }\n+        return dests;\n+    }\n+\n+    public static Object generalize(Object pojo) {\n+        return generalize(pojo, new IdentityHashMap<Object, Object>());\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static Object generalize(Object pojo, Map<Object, Object> history) {\n+        if (pojo == null) {\n+            return null;\n+        }\n+\n+        if (pojo instanceof Enum<?>) {\n+            return ((Enum<?>) pojo).name();\n+        }\n+        if (pojo.getClass().isArray() && Enum.class.isAssignableFrom(pojo.getClass().getComponentType())) {\n+            int len = Array.getLength(pojo);\n+            String[] values = new String[len];\n+            for (int i = 0; i < len; i++) {\n+                values[i] = ((Enum<?>) Array.get(pojo, i)).name();\n+            }\n+            return values;\n+        }\n+\n+        if (ReflectUtils.isPrimitives(pojo.getClass())) {\n+            return pojo;\n+        }\n+\n+        if (pojo instanceof Class) {\n+            return ((Class) pojo).getName();\n+        }\n+\n+        Object o = history.get(pojo);\n+        if (o != null) {\n+            return o;\n+        }\n+        history.put(pojo, pojo);\n+\n+        if (pojo.getClass().isArray()) {\n+            int len = Array.getLength(pojo);\n+            Object[] dest = new Object[len];\n+            history.put(pojo, dest);\n+            for (int i = 0; i < len; i++) {\n+                Object obj = Array.get(pojo, i);\n+                dest[i] = generalize(obj, history);\n+            }\n+            return dest;\n+        }\n+        if (pojo instanceof Collection<?>) {\n+            Collection<Object> src = (Collection<Object>) pojo;\n+            int len = src.size();\n+            Collection<Object> dest = (pojo instanceof List<?>) ? new ArrayList<Object>(len) : new HashSet<Object>(len);\n+            history.put(pojo, dest);\n+            for (Object obj : src) {\n+                dest.add(generalize(obj, history));\n+            }\n+            return dest;\n+        }\n+        if (pojo instanceof Map<?, ?>) {\n+            Map<Object, Object> src = (Map<Object, Object>) pojo;\n+            Map<Object, Object> dest = createMap(src);\n+            history.put(pojo, dest);\n+            for (Map.Entry<Object, Object> obj : src.entrySet()) {\n+                dest.put(generalize(obj.getKey(), history), generalize(obj.getValue(), history));\n+            }\n+            return dest;\n+        }\n+        Map<String, Object> map = new HashMap<String, Object>();\n+        history.put(pojo, map);\n+        map.put(\"class\", pojo.getClass().getName());\n+        for (Method method : pojo.getClass().getMethods()) {\n+            if (ReflectUtils.isBeanPropertyReadMethod(method)) {\n+                try {\n+                    map.put(ReflectUtils.getPropertyNameFromBeanReadMethod(method), generalize(method.invoke(pojo), history));\n+                } catch (Exception e) {\n+                    throw new RuntimeException(e.getMessage(), e);\n+                }\n+            }\n+        }\n+        // public field\n+        for (Field field : pojo.getClass().getFields()) {\n+            if (ReflectUtils.isPublicInstanceField(field)) {\n+                try {\n+                    Object fieldValue = field.get(pojo);\n+                    if (history.containsKey(pojo)) {\n+                        Object pojoGeneralizedValue = history.get(pojo);\n+                        if (pojoGeneralizedValue instanceof Map\n+                                && ((Map) pojoGeneralizedValue).containsKey(field.getName())) {\n+                            continue;\n+                        }\n+                    }\n+                    if (fieldValue != null) {\n+                        map.put(field.getName(), generalize(fieldValue, history));\n+                    }\n+                } catch (Exception e) {\n+                    throw new RuntimeException(e.getMessage(), e);\n+                }\n+            }\n+        }\n+        return map;\n+    }\n+\n+    public static Object realize(Object pojo, Class<?> type) {\n+        return realize0(pojo, type, null, new IdentityHashMap<Object, Object>());\n+    }\n+\n+    public static Object realize(Object pojo, Class<?> type, Type genericType) {\n+        return realize0(pojo, type, genericType, new IdentityHashMap<Object, Object>());\n+    }\n+\n+    private static class PojoInvocationHandler implements InvocationHandler {\n+\n+        private Map<Object, Object> map;\n+\n+        public PojoInvocationHandler(Map<Object, Object> map) {\n+            this.map = map;\n+        }\n+\n+        @Override\n+        @SuppressWarnings(\"unchecked\")\n+        public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n+            if (method.getDeclaringClass() == Object.class) {\n+                return method.invoke(map, args);\n+            }\n+            String methodName = method.getName();\n+            Object value = null;\n+            if (methodName.length() > 3 && methodName.startsWith(\"get\")) {\n+                value = map.get(methodName.substring(3, 4).toLowerCase() + methodName.substring(4));\n+            } else if (methodName.length() > 2 && methodName.startsWith(\"is\")) {\n+                value = map.get(methodName.substring(2, 3).toLowerCase() + methodName.substring(3));\n+            } else {\n+                value = map.get(methodName.substring(0, 1).toLowerCase() + methodName.substring(1));\n+            }\n+            if (value instanceof Map<?, ?> && !Map.class.isAssignableFrom(method.getReturnType())) {\n+                value = realize0((Map<String, Object>) value, method.getReturnType(), null, new IdentityHashMap<Object, Object>());\n+            }\n+            return value;\n+        }\n+    }\n+\n+    @SuppressWarnings(\"unchecked\")\n+    private static Collection<Object> createCollection(Class<?> type, int len) {\n+        if (type.isAssignableFrom(ArrayList.class)) {\n+            return new ArrayList<Object>(len);\n+        }\n+        if (type.isAssignableFrom(HashSet.class)) {\n+            return new HashSet<Object>(len);\n+        }\n+        if (!type.isInterface() && !Modifier.isAbstract(type.getModifiers())) {\n+            try {\n+                return (Collection<Object>) type.newInstance();\n+            } catch (Exception e) {\n+                // ignore\n+            }\n+        }\n+        return new ArrayList<Object>();\n+    }\n+\n+    private static Map createMap(Map src) {\n+        Class<? extends Map> cl = src.getClass();\n+        Map result = null;\n+        if (HashMap.class == cl) {\n+            result = new HashMap();\n+        } else if (Hashtable.class == cl) {\n+            result = new Hashtable();\n+        } else if (IdentityHashMap.class == cl) {\n+            result = new IdentityHashMap();\n+        } else if (LinkedHashMap.class == cl) {\n+            result = new LinkedHashMap();\n+        } else if (Properties.class == cl) {\n+            result = new Properties();\n+        } else if (TreeMap.class == cl) {\n+            result = new TreeMap();\n+        } else if (WeakHashMap.class == cl) {\n+            return new WeakHashMap();\n+        } else if (ConcurrentHashMap.class == cl) {\n+            result = new ConcurrentHashMap();\n+        } else if (ConcurrentSkipListMap.class == cl) {\n+            result = new ConcurrentSkipListMap();\n+        } else {\n+            try {\n+                result = cl.newInstance();\n+            } catch (Exception e) { /* ignore */ }\n+\n+            if (result == null) {\n+                try {\n+                    Constructor<?> constructor = cl.getConstructor(Map.class);\n+                    result = (Map) constructor.newInstance(Collections.EMPTY_MAP);\n+                } catch (Exception e) { /* ignore */ }\n+            }\n+        }\n+\n+        if (result == null) {\n+            result = new HashMap<Object, Object>();\n+        }\n+\n+        return result;\n+    }\n+\n+    @SuppressWarnings({\"unchecked\", \"rawtypes\"})\n+    private static Object realize0(Object pojo, Class<?> type, Type genericType, final Map<Object, Object> history) {\n+        if (pojo == null) {\n+            return null;\n+        }\n+\n+        if (type != null && type.isEnum() && pojo.getClass() == String.class) {\n+            return Enum.valueOf((Class<Enum>) type, (String) pojo);\n+        }\n+\n+        if (ReflectUtils.isPrimitives(pojo.getClass())\n+                && !(type != null && type.isArray()\n+                && type.getComponentType().isEnum()\n+                && pojo.getClass() == String[].class)) {\n+            return CompatibleTypeUtils.compatibleTypeConvert(pojo, type);\n+        }\n+\n+        Object o = history.get(pojo);\n+\n+        if (o != null) {\n+            return o;\n+        }\n+\n+        history.put(pojo, pojo);\n+\n+        if (pojo.getClass().isArray()) {\n+            if (Collection.class.isAssignableFrom(type)) {\n+                Class<?> ctype = pojo.getClass().getComponentType();\n+                int len = Array.getLength(pojo);\n+                Collection dest = createCollection(type, len);\n+                history.put(pojo, dest);\n+                for (int i = 0; i < len; i++) {\n+                    Object obj = Array.get(pojo, i);\n+                    Object value = realize0(obj, ctype, null, history);\n+                    dest.add(value);\n+                }\n+                return dest;\n+            } else {\n+                Class<?> ctype = (type != null && type.isArray() ? type.getComponentType() : pojo.getClass().getComponentType());\n+                int len = Array.getLength(pojo);\n+                Object dest = Array.newInstance(ctype, len);\n+                history.put(pojo, dest);\n+                for (int i = 0; i < len; i++) {\n+                    Object obj = Array.get(pojo, i);\n+                    Object value = realize0(obj, ctype, null, history);\n+                    Array.set(dest, i, value);\n+                }\n+                return dest;\n+            }\n+        }\n+\n+        if (pojo instanceof Collection<?>) {\n+            if (type.isArray()) {\n+                Class<?> ctype = type.getComponentType();\n+                Collection<Object> src = (Collection<Object>) pojo;\n+                int len = src.size();\n+                Object dest = Array.newInstance(ctype, len);\n+                history.put(pojo, dest);\n+                int i = 0;\n+                for (Object obj : src) {\n+                    Object value = realize0(obj, ctype, null, history);\n+                    Array.set(dest, i, value);\n+                    i++;\n+                }\n+                return dest;\n+            } else {\n+                Collection<Object> src = (Collection<Object>) pojo;\n+                int len = src.size();\n+                Collection<Object> dest = createCollection(type, len);\n+                history.put(pojo, dest);\n+                for (Object obj : src) {\n+                    Type keyType = getGenericClassByIndex(genericType, 0);\n+                    Class<?> keyClazz = obj.getClass();\n+                    if (keyType instanceof Class) {\n+                        keyClazz = (Class<?>) keyType;\n+                    }\n+                    Object value = realize0(obj, keyClazz, keyType, history);\n+                    dest.add(value);\n+                }\n+                return dest;\n+            }\n+        }\n+\n+        if (pojo instanceof Map<?, ?> && type != null) {\n+            Object className = ((Map<Object, Object>) pojo).get(\"class\");\n+            if (className instanceof String) {\n+                try {\n+                    type = ClassUtils.forName((String) className);\n+                } catch (ClassNotFoundException e) {\n+                    // ignore\n+                }\n+            }\n+\n+            // special logic for enum\n+            if (type.isEnum()) {\n+                Object name = ((Map<Object, Object>) pojo).get(\"name\");\n+                if (name != null) {\n+                    return Enum.valueOf((Class<Enum>) type, name.toString());\n+                }\n+            }\n+            Map<Object, Object> map;\n+            // when return type is not the subclass of return type from the signature and not an interface\n+            if (!type.isInterface() && !type.isAssignableFrom(pojo.getClass())) {\n+                try {\n+                    map = (Map<Object, Object>) type.newInstance();\n+                    Map<Object, Object> mapPojo = (Map<Object, Object>) pojo;\n+                    map.putAll(mapPojo);\n+                    map.remove(\"class\");\n+                } catch (Exception e) {\n+                    //ignore error\n+                    map = (Map<Object, Object>) pojo;\n+                }\n+            } else {\n+                map = (Map<Object, Object>) pojo;\n+            }\n+\n+            if (Map.class.isAssignableFrom(type) || type == Object.class) {\n+                final Map<Object, Object> result = createMap(map);\n+                history.put(pojo, result);\n+                for (Map.Entry<Object, Object> entry : map.entrySet()) {\n+                    Type keyType = getGenericClassByIndex(genericType, 0);\n+                    Type valueType = getGenericClassByIndex(genericType, 1);\n+                    Class<?> keyClazz;\n+                    if (keyType instanceof Class) {\n+                        keyClazz = (Class<?>) keyType;\n+                    } else if (keyType instanceof ParameterizedType) {\n+                        keyClazz = (Class<?>) ((ParameterizedType) keyType).getRawType();\n+                    } else {\n+                        keyClazz = entry.getKey() == null ? null : entry.getKey().getClass();\n+                    }\n+                    Class<?> valueClazz;\n+                    if (valueType instanceof Class) {\n+                        valueClazz = (Class<?>) valueType;\n+                    } else if (valueType instanceof ParameterizedType) {\n+                        valueClazz = (Class<?>) ((ParameterizedType) valueType).getRawType();\n+                    } else {\n+                        valueClazz = entry.getValue() == null ? null : entry.getValue().getClass();\n+                    }\n+\n+                    Object key = keyClazz == null ? entry.getKey() : realize0(entry.getKey(), keyClazz, keyType, history);\n+                    Object value = valueClazz == null ? entry.getValue() : realize0(entry.getValue(), valueClazz, valueType, history);\n+                    result.put(key, value);\n+                }\n+                return result;\n+            } else if (type.isInterface()) {\n+                Object dest = Proxy.newProxyInstance(Thread.currentThread().getContextClassLoader(), new Class<?>[]{type}, new PojoInvocationHandler(map));\n+                history.put(pojo, dest);\n+                return dest;\n+            } else {\n+                Object dest = newInstance(type);\n+                history.put(pojo, dest);\n+                for (Map.Entry<Object, Object> entry : map.entrySet()) {\n+                    Object key = entry.getKey();\n+                    if (key instanceof String) {\n+                        String name = (String) key;\n+                        Object value = entry.getValue();\n+                        if (value != null) {\n+                            Method method = getSetterMethod(dest.getClass(), name, value.getClass());\n+                            Field field = getField(dest.getClass(), name);\n+                            if (method != null) {\n+                                if (!method.isAccessible()) {\n+                                    method.setAccessible(true);\n+                                }\n+                                Type ptype = method.getGenericParameterTypes()[0];\n+                                value = realize0(value, method.getParameterTypes()[0], ptype, history);\n+                                try {\n+                                    method.invoke(dest, value);\n+                                } catch (Exception e) {\n+                                    String exceptionDescription = \"Failed to set pojo \" + dest.getClass().getSimpleName() + \" property \" + name\n+                                            + \" value \" + value + \"(\" + value.getClass() + \"), cause: \" + e.getMessage();\n+                                    logger.error(exceptionDescription, e);\n+                                    throw new RuntimeException(exceptionDescription, e);\n+                                }\n+                            } else if (field != null) {\n+                                value = realize0(value, field.getType(), field.getGenericType(), history);\n+                                try {\n+                                    field.set(dest, value);\n+                                } catch (IllegalAccessException e) {\n+                                    throw new RuntimeException(\"Failed to set field \" + name + \" of pojo \" + dest.getClass().getName() + \" : \" + e.getMessage(), e);\n+                                }\n+                            }\n+                        }\n+                    }\n+                }\n+                if (dest instanceof Throwable) {\n+                    Object message = map.get(\"message\");\n+                    if (message instanceof String) {\n+                        try {\n+                            Field field = Throwable.class.getDeclaredField(\"detailMessage\");\n+                            if (!field.isAccessible()) {\n+                                field.setAccessible(true);\n+                            }\n+                            field.set(dest, message);\n+                        } catch (Exception e) {\n+                        }\n+                    }\n+                }\n+                return dest;\n+            }\n+        }\n+        return pojo;\n+    }\n+\n+    /**\n+     * Get parameterized type\n+     *\n+     * @param genericType generic type\n+     * @param index       index of the target parameterized type\n+     * @return Return Person.class for List<Person>, return Person.class for Map<String, Person> when index=0\n+     */\n+    private static Type getGenericClassByIndex(Type genericType, int index) {\n+        Type clazz = null;\n+        // find parameterized type\n+        if (genericType instanceof ParameterizedType) {\n+            ParameterizedType t = (ParameterizedType) genericType;\n+            Type[] types = t.getActualTypeArguments();\n+            clazz = types[index];\n+        }\n+        return clazz;\n+    }\n+\n+    private static Object newInstance(Class<?> cls) {\n+        try {\n+            return cls.newInstance();\n+        } catch (Throwable t) {\n+            try {\n+                Constructor<?>[] constructors = cls.getDeclaredConstructors();\n+                /**\n+                 * From Javadoc java.lang.Class#getDeclaredConstructors\n+                 * This method returns an array of Constructor objects reflecting all the constructors\n+                 * declared by the class represented by this Class object.\n+                 * This method returns an array of length 0,\n+                 * if this Class object represents an interface, a primitive type, an array class, or void.\n+                 */\n+                if (constructors.length == 0) {\n+                    throw new RuntimeException(\"Illegal constructor: \" + cls.getName());\n+                }\n+                Constructor<?> constructor = constructors[0];\n+                if (constructor.getParameterTypes().length > 0) {\n+                    for (Constructor<?> c : constructors) {\n+                        if (c.getParameterTypes().length < constructor.getParameterTypes().length) {\n+                            constructor = c;\n+                            if (constructor.getParameterTypes().length == 0) {\n+                                break;\n+                            }\n+                        }\n+                    }\n+                }\n+                constructor.setAccessible(true);\n+                Class<?>[] paramTypes = constructor.getParameterTypes();\n+                Object[] params = new Object[paramTypes.length];\n+                for (int i = 0; i < paramTypes.length; i++) {\n+                    Class<?> p = paramTypes[i];\n+                    if (p.isPrimitive()) {\n+                        if (p == boolean.class) {\n+                            params[i] = false;\n+                        } else if (p == char.class) {\n+                            params[i] = '\\0';\n+                        } else if (p == byte.class) {\n+                            params[i] = (byte) 0;\n+                        } else if (p == short.class) {\n+                            params[i] = (short) 0;\n+                        } else if (p == int.class) {\n+                            params[i] = 0;\n+                        } else if (p == long.class) {\n+                            params[i] = 0L;\n+                        } else if (p == float.class) {\n+                            params[i] = 0F;\n+                        } else if (p == double.class) {\n+                            params[i] = 0D;\n+                        }\n+                    } else {\n+                        params[i] = null;\n+                    }\n+                }\n+                return constructor.newInstance(params);\n+            } catch (InstantiationException e) {\n+                throw new RuntimeException(e.getMessage(), e);\n+            } catch (IllegalAccessException e) {\n+                throw new RuntimeException(e.getMessage(), e);\n+            } catch (InvocationTargetException e) {\n+                throw new RuntimeException(e.getMessage(), e);\n+            }\n+        }\n+    }\n+\n+    private static Method getSetterMethod(Class<?> cls, String property, Class<?> valueCls) {\n+        String name = \"set\" + property.substring(0, 1).toUpperCase() + property.substring(1);\n+        Method method = NAME_METHODS_CACHE.get(cls.getName() + \".\" + name + \"(\" + valueCls.getName() + \")\");\n+        if (method == null) {\n+            try {\n+                method = cls.getMethod(name, valueCls);\n+            } catch (NoSuchMethodException e) {\n+                for (Method m : cls.getMethods()) {\n+                    if (ReflectUtils.isBeanPropertyWriteMethod(m) && m.getName().equals(name)) {\n+                        method = m;\n+                    }\n+                }\n+            }\n+            if (method != null) {\n+                NAME_METHODS_CACHE.put(cls.getName() + \".\" + name + \"(\" + valueCls.getName() + \")\", method);\n+            }\n+        }\n+        return method;\n+    }\n+\n+    private static Field getField(Class<?> cls, String fieldName) {\n+        Field result = null;\n+        if (CLASS_FIELD_CACHE.containsKey(cls) && CLASS_FIELD_CACHE.get(cls).containsKey(fieldName)) {\n+            return CLASS_FIELD_CACHE.get(cls).get(fieldName);\n+        }\n+        try {\n+            result = cls.getDeclaredField(fieldName);\n+            result.setAccessible(true);\n+        } catch (NoSuchFieldException e) {\n+            for (Field field : cls.getFields()) {\n+                if (fieldName.equals(field.getName()) && ReflectUtils.isPublicInstanceField(field)) {\n+                    result = field;\n+                    break;\n+                }\n+            }\n+        }\n+        if (result != null) {\n+            ConcurrentMap<String, Field> fields = CLASS_FIELD_CACHE.get(cls);\n+            if (fields == null) {\n+                fields = new ConcurrentHashMap<String, Field>();\n+                CLASS_FIELD_CACHE.putIfAbsent(cls, fields);\n+            }\n+            fields = CLASS_FIELD_CACHE.get(cls);\n+            fields.putIfAbsent(fieldName, result);\n+        }\n+        return result;\n+    }\n+\n+    public static boolean isPojo(Class<?> cls) {\n+        return !ReflectUtils.isPrimitives(cls)\n+                && !Collection.class.isAssignableFrom(cls)\n+                && !Map.class.isAssignableFrom(cls);\n+    }\n+\n+}\n"}
{"instance_id": "trinodb__trino-2081", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/metadata/FunctionRegistry.java b/presto-main/src/main/java/io/prestosql/metadata/FunctionRegistry.java\nindex e5ea57abd3c..c08ccafd826 100644\n--- a/presto-main/src/main/java/io/prestosql/metadata/FunctionRegistry.java\n+++ b/presto-main/src/main/java/io/prestosql/metadata/FunctionRegistry.java\n@@ -1152,7 +1152,16 @@ public class FunctionRegistry\n                     .putAll(map.functionsByName);\n             functions.stream()\n                     .map(SqlFunction::getFunctionMetadata)\n-                    .forEach(functionMetadata -> functionsByName.put(QualifiedName.of(functionMetadata.getSignature().getName()), functionMetadata));\n+                    .forEach(functionMetadata -> {\n+                        String name = functionMetadata.getSignature().getName();\n+                        functionsByName.put(QualifiedName.of(name), functionMetadata);\n+                        if (name.contains(\".\")) {\n+                            java.util.List<io.prestosql.sql.tree.Identifier> identifiers = java.util.Arrays.stream(name.split(\"\\\\.\"))\n+                                    .map(part -> new io.prestosql.sql.tree.Identifier(part))\n+                                    .collect(java.util.stream.Collectors.toList());\n+                            functionsByName.put(QualifiedName.of(identifiers), functionMetadata);\n+                        }\n+                    });\n             this.functionsByName = functionsByName.build();\n \n             // Make sure all functions with the same name are aggregations or none of them are\n"}
{"instance_id": "trinodb__trino-3859", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "mrdoob__three.js-14836", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/api/en/math/Plane.html b/docs/api/en/math/Plane.html\nindex c7a1f63e59..3c278f048f 100644\n--- a/docs/api/en/math/Plane.html\n+++ b/docs/api/en/math/Plane.html\n@@ -12,7 +12,7 @@\n \n \t\t<p class=\"desc\">\n \t\t\tA two dimensional surface that extends infinitely in 3d space, represented in [link:http://mathworld.wolfram.com/HessianNormalForm.html Hessian normal form]\n-\t\t\tby a unit length normal vector and a constant.\n+\t\t\tby a unit length normal vector and a constant. The plane equation used is nx + constant = 0.\n \t\t</p>\n \n \ndiff --git a/src/math/Box3.js b/src/math/Box3.js\nindex 8784d7b2ae..ef2c17cc93 100644\n--- a/src/math/Box3.js\n+++ b/src/math/Box3.js\n@@ -384,7 +384,7 @@ Object.assign( Box3.prototype, {\n \n \t\t}\n \n-\t\treturn ( min <= plane.constant && max >= plane.constant );\n+\t\treturn ( min <= - plane.constant && max >= - plane.constant );\n \n \t},\n \ndiff --git a/test/unit/src/math/Box3.tests.js b/test/unit/src/math/Box3.tests.js\nindex bd8a7a41bf..ddf5b1feed 100644\n--- a/test/unit/src/math/Box3.tests.js\n+++ b/test/unit/src/math/Box3.tests.js\n@@ -406,8 +406,8 @@ export default QUnit.module( 'Maths', () => {\n \t\tQUnit.test( \"intersectsPlane\", ( assert ) => {\n \n \t\t\tvar a = new Box3( zero3.clone(), one3.clone() );\n-\t\t\tvar b = new Plane( new Vector3( 0, 1, 0 ), 1 );\n-\t\t\tvar c = new Plane( new Vector3( 0, 1, 0 ), 1.25 );\n+\t\t\tvar b = new Plane( new Vector3( 0, 1, 0 ), - 1 );\n+\t\t\tvar c = new Plane( new Vector3( 0, 1, 0 ), - 1.25 );\n \t\t\tvar d = new Plane( new Vector3( 0, - 1, 0 ), 1.25 );\n \n \t\t\tassert.ok( a.intersectsPlane( b ), \"Passed!\" );\n"}
{"instance_id": "mrdoob__three.js-18648", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/api/en/core/Raycaster.html b/docs/api/en/core/Raycaster.html\nindex 3ba8d30a75..c661b89503 100644\n--- a/docs/api/en/core/Raycaster.html\n+++ b/docs/api/en/core/Raycaster.html\n@@ -93,10 +93,6 @@\n \t\tThis value shouldn't be negative and should be larger than the near property.\n \t\t</p>\n \n-\t\t<h3>[property:float linePrecision]</h3>\n-\t\t<p>\n-\t\tThe precision factor of the raycaster when intersecting [page:Line] objects.\n-\t\t</p>\n \n \t\t<h3>[property:float near]</h3>\n \t\t<p>\n@@ -119,7 +115,7 @@\n \t\t\t<code>\n {\n \tMesh: {},\n-\tLine: {},\n+\tLine: { threshold: 1 },\n \tLOD: {},\n \tPoints: { threshold: 1 },\n \tSprite: {}\ndiff --git a/src/core/Raycaster.js b/src/core/Raycaster.js\nindex 926884f245..bcad08b690 100644\n--- a/src/core/Raycaster.js\n+++ b/src/core/Raycaster.js\n@@ -17,7 +17,7 @@ function Raycaster( origin, direction, near, far ) {\n \n \tthis.params = {\n \t\tMesh: {},\n-\t\tLine: {},\n+\t\tLine: { threshold: 1 },\n \t\tLOD: {},\n \t\tPoints: { threshold: 1 },\n \t\tSprite: {}\n@@ -64,8 +64,6 @@ function intersectObject( object, raycaster, intersects, recursive ) {\n \n Object.assign( Raycaster.prototype, {\n \n-\tlinePrecision: 1,\n-\n \tset: function ( origin, direction ) {\n \n \t\t// direction is assumed to be normalized (for accurate distance calculations)\n@@ -134,4 +132,21 @@ Object.assign( Raycaster.prototype, {\n } );\n \n \n+Object.defineProperties( Raycaster.prototype, {\n+\tlinePrecision: {\n+\t\tget: function () {\n+\n+\t\t\tconsole.warn( 'THREE.Raycaster: linePrecision has been deprecated. Use raycaster.params.Line.threshold instead.' );\n+\t\t\treturn this.params.Line.threshold;\n+\n+\t\t},\n+\t\tset: function ( value ) {\n+\n+\t\t\tconsole.warn( 'THREE.Raycaster: linePrecision has been deprecated. Use raycaster.params.Line.threshold instead.' );\n+\t\t\tthis.params.Line.threshold = value;\n+\n+\t\t}\n+\t}\n+} );\n+\n export { Raycaster };\ndiff --git a/src/objects/Line.js b/src/objects/Line.js\nindex 3a8575d903..ceb63ec66a 100644\n--- a/src/objects/Line.js\n+++ b/src/objects/Line.js\n@@ -93,7 +93,7 @@ Line.prototype = Object.assign( Object.create( Object3D.prototype ), {\n \n \traycast: function ( raycaster, intersects ) {\n \n-\t\tvar precision = raycaster.linePrecision;\n+\t\tvar precision = raycaster.params.Line.threshold;\n \n \t\tvar geometry = this.geometry;\n \t\tvar matrixWorld = this.matrixWorld;\n"}
{"instance_id": "mrdoob__three.js-20991", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/api/en/math/Euler.html b/docs/api/en/math/Euler.html\nindex e8779d8be5..caf74083d0 100644\n--- a/docs/api/en/math/Euler.html\n+++ b/docs/api/en/math/Euler.html\n@@ -106,14 +106,17 @@\n \t\t\tSets the angles of this euler transform and optionally the [page:.order order].\n \t\t</p>\n \n-\t\t<h3>[method:Euler setFromRotationMatrix]( [param:Matrix4 m], [param:String order] )</h3>\n+\t\t<h3>[method:Euler setFromRotationMatrix]( [param:Matrix4|Matrix3 m], [param:String order] )</h3>\n \t\t<p>\n-\t\t[page:Matrix4 m] - a [page:Matrix4] of which the upper 3x3 of matrix is a pure\n-\t\t[link:https://en.wikipedia.org/wiki/Rotation_matrix rotation matrix] (i.e. unscaled).<br />\n+\t\t[page:Matrix4|Matrix3 m] - a pure [link:https://en.wikipedia.org/wiki/Rotation_matrix rotation matrix] (i.e. unscaled).<br />\n+\t\tIf a [page:Matrix4] is provided, the upper-left 3x3 is used. If a [page:Matrix3] is provided, the full 3x3 is used.<br />\n \t\t[page:.order order] - (optional) a string representing the order that the rotations are applied.<br />\n \n \t\tSets the angles of this euler transform from a pure rotation matrix based on the orientation\n-\t\tspecified by order.\n+\t\tspecified by order.<br /><br />\n+\t\tNote: Internally, matrices are stored in column-major order. When constructing matrices manually, prefer using helpers like\n+\t\t[page:Matrix4.makeRotationFromEuler] or [page:Matrix4.makeRotationFromQuaternion], or the [page:Matrix3] equivalents, to avoid\n+\t\trow-major/column-major confusion. No transpose is required when using these helpers.\n \t\t</p>\n \n \t\t<h3>[method:Euler setFromQuaternion]( [param:Quaternion q], [param:String order] )</h3>\ndiff --git a/docs/api/en/math/Quaternion.html b/docs/api/en/math/Quaternion.html\nindex eeb7bafe53..a49b2753e9 100644\n--- a/docs/api/en/math/Quaternion.html\n+++ b/docs/api/en/math/Quaternion.html\n@@ -176,12 +176,15 @@\n \t\t<h3>[method:Quaternion setFromEuler]( [param:Euler euler] )</h3>\n \t\t<p>Sets this quaternion from the rotation specified by [page:Euler] angle.</p>\n \n-\t\t<h3>[method:Quaternion setFromRotationMatrix]( [param:Matrix4 m] )</h3>\n+\t\t<h3>[method:Quaternion setFromRotationMatrix]( [param:Matrix4|Matrix3 m] )</h3>\n \t\t<p>\n-\t\t[page:Matrix4 m] - a [page:Matrix4] of which the upper 3x3 of matrix is a pure\n-\t\t[link:https://en.wikipedia.org/wiki/Rotation_matrix rotation matrix] (i.e. unscaled).<br />\n-\t\tSets this quaternion from rotation component of [page:Matrix4 m].<br />\n-\t\tAdapted from the method [link:http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/index.htm here].\n+\t\t[page:Matrix4|Matrix3 m] - a pure [link:https://en.wikipedia.org/wiki/Rotation_matrix rotation matrix] (i.e. unscaled).<br />\n+\t\tIf a [page:Matrix4] is provided, the upper-left 3x3 is used. If a [page:Matrix3] is provided, the full 3x3 is used.<br />\n+\t\tSets this quaternion from the rotation component of the given matrix.<br />\n+\t\tAdapted from the method [link:http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/index.htm here].<br /><br />\n+\t\tNote: Internally, matrices are stored in column-major order. When constructing matrices manually, prefer using helpers like\n+\t\t[page:Matrix4.makeRotationFromEuler] or [page:Matrix4.makeRotationFromQuaternion], or the [page:Matrix3] equivalents, to avoid\n+\t\trow-major/column-major confusion. No transpose is required when using these helpers.\n \t\t</p>\n \n \t\t<h3>[method:Quaternion setFromUnitVectors]( [param:Vector3 vFrom], [param:Vector3 vTo] )</h3>\ndiff --git a/src/math/Euler.js b/src/math/Euler.js\nindex 483f271542..a6efd09333 100644\n--- a/src/math/Euler.js\n+++ b/src/math/Euler.js\n@@ -107,9 +107,31 @@ class Euler {\n \t\t// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n \n \t\tconst te = m.elements;\n-\t\tconst m11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ];\n-\t\tconst m21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ];\n-\t\tconst m31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ];\n+\n+\t\tlet m11, m12, m13;\n+\t\tlet m21, m22, m23;\n+\t\tlet m31, m32, m33;\n+\n+\t\tif ( m.isMatrix3 === true ) {\n+\n+\t\t\t// Matrix3 uses 3x3 column-major storage\n+\t\t\tm11 = te[ 0 ]; m12 = te[ 3 ]; m13 = te[ 6 ];\n+\t\t\tm21 = te[ 1 ]; m22 = te[ 4 ]; m23 = te[ 7 ];\n+\t\t\tm31 = te[ 2 ]; m32 = te[ 5 ]; m33 = te[ 8 ];\n+\n+\t\t} else if ( m.isMatrix4 === true ) {\n+\n+\t\t\t// Matrix4 uses 4x4 column-major storage; use upper-left 3x3\n+\t\t\tm11 = te[ 0 ]; m12 = te[ 4 ]; m13 = te[ 8 ];\n+\t\t\tm21 = te[ 1 ]; m22 = te[ 5 ]; m23 = te[ 9 ];\n+\t\t\tm31 = te[ 2 ]; m32 = te[ 6 ]; m33 = te[ 10 ];\n+\n+\t\t} else {\n+\n+\t\t\tconsole.warn( 'THREE.Euler: .setFromRotationMatrix() expected Matrix3 or Matrix4.' );\n+\t\t\treturn this;\n+\n+\t\t}\n \n \t\torder = order || this._order;\n \ndiff --git a/src/math/Quaternion.js b/src/math/Quaternion.js\nindex bbf48af501..d8b8e1d51e 100644\n--- a/src/math/Quaternion.js\n+++ b/src/math/Quaternion.js\n@@ -289,13 +289,34 @@ class Quaternion {\n \n \t\t// assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n \n-\t\tconst te = m.elements,\n+\t\tconst te = m.elements;\n \n-\t\t\tm11 = te[ 0 ], m12 = te[ 4 ], m13 = te[ 8 ],\n-\t\t\tm21 = te[ 1 ], m22 = te[ 5 ], m23 = te[ 9 ],\n-\t\t\tm31 = te[ 2 ], m32 = te[ 6 ], m33 = te[ 10 ],\n+\t\tlet m11, m12, m13;\n+\t\tlet m21, m22, m23;\n+\t\tlet m31, m32, m33;\n \n-\t\t\ttrace = m11 + m22 + m33;\n+\t\tif ( m.isMatrix3 === true ) {\n+\n+\t\t\t// Matrix3 uses 3x3 column-major storage\n+\t\t\tm11 = te[ 0 ]; m12 = te[ 3 ]; m13 = te[ 6 ];\n+\t\t\tm21 = te[ 1 ]; m22 = te[ 4 ]; m23 = te[ 7 ];\n+\t\t\tm31 = te[ 2 ]; m32 = te[ 5 ]; m33 = te[ 8 ];\n+\n+\t\t} else if ( m.isMatrix4 === true ) {\n+\n+\t\t\t// Matrix4 uses 4x4 column-major storage; use upper-left 3x3\n+\t\t\tm11 = te[ 0 ]; m12 = te[ 4 ]; m13 = te[ 8 ];\n+\t\t\tm21 = te[ 1 ]; m22 = te[ 5 ]; m23 = te[ 9 ];\n+\t\t\tm31 = te[ 2 ]; m32 = te[ 6 ]; m33 = te[ 10 ];\n+\n+\t\t} else {\n+\n+\t\t\tconsole.warn( 'THREE.Quaternion: .setFromRotationMatrix() expected Matrix3 or Matrix4.' );\n+\t\t\treturn this;\n+\n+\t\t}\n+\n+\t\tconst trace = m11 + m22 + m33;\n \n \t\tif ( trace > 0 ) {\n \n"}
{"instance_id": "mrdoob__three.js-24461", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/api/en/math/Color.html b/docs/api/en/math/Color.html\nindex 6ef47bdc83..8d563185ad 100644\n--- a/docs/api/en/math/Color.html\n+++ b/docs/api/en/math/Color.html\n@@ -39,6 +39,8 @@ const color5 = new THREE.Color( 'skyblue' );\n \n //HSL string\n const color6 = new THREE.Color(\"hsl(0, 100%, 50%)\");\n+// HSL string with decimal percentages\n+const color6b = new THREE.Color(\"hsl(209, 95.0%, 90.1%)\");\n \n //Separate RGB values between 0 and 1\n const color7 = new THREE.Color( 1, 0, 0 );\n@@ -67,6 +69,7 @@ const color7 = new THREE.Color( 1, 0, 0 );\n \t\t\t\t\t<li>'rgb(250, 0,0)'</li>\n \t\t\t\t\t<li>'rgb(100%,0%,0%)'</li>\n \t\t\t\t\t<li>'hsl(0, 100%, 50%)'</li>\n+\t\t\t\t\t<li>'hsl(209, 95.0%, 90.1%)'</li>\n \t\t\t\t\t<li>'#ff0000'</li>\n \t\t\t\t\t<li>'#f00'</li>\n \t\t\t\t\t<li>'red'</li>\n@@ -281,6 +284,7 @@ const color7 = new THREE.Color( 1, 0, 0 );\n \t\t\"rgb(250, 0,0)\",\n \t\t\"rgb(100%, 0%, 0%)\",\n \t\t\"hsl(0, 100%, 50%)\",\n+\t\t\"hsl(209, 95.0%, 90.1%)\",\n \t\t\"#ff0000\",\n \t\t\"#f00\", or\n \t\t\"red\" ( or any [link:https://en.wikipedia.org/wiki/X11_color_names#Color_name_chart X11 color name]\ndiff --git a/src/math/Color.js b/src/math/Color.js\nindex e2c45f974f..b913958e1b 100644\n--- a/src/math/Color.js\n+++ b/src/math/Color.js\n@@ -222,12 +222,12 @@ class Color {\n \t\t\t\tcase 'hsl':\n \t\t\t\tcase 'hsla':\n \n-\t\t\t\t\tif ( color = /^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n+\t\t\t\t\tif ( color = /^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d*\\.?\\d+)\\%\\s*,\\s*(\\d*\\.?\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec( components ) ) {\n \n \t\t\t\t\t\t// hsl(120,50%,50%) hsla(120,50%,50%,0.5)\n \t\t\t\t\t\tconst h = parseFloat( color[ 1 ] ) / 360;\n-\t\t\t\t\t\tconst s = parseInt( color[ 2 ], 10 ) / 100;\n-\t\t\t\t\t\tconst l = parseInt( color[ 3 ], 10 ) / 100;\n+\t\t\t\t\t\tconst s = parseFloat( color[ 2 ] ) / 100;\n+\t\t\t\t\t\tconst l = parseFloat( color[ 3 ] ) / 100;\n \n \t\t\t\t\t\thandleAlpha( color[ 4 ] );\n \n"}
{"instance_id": "sveltejs__svelte-477", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/Generator.js b/src/generators/Generator.js\nindex 83f726cab..1ec9716d5 100644\n--- a/src/generators/Generator.js\n+++ b/src/generators/Generator.js\n@@ -148,7 +148,7 @@ export default class Generator {\n \t\t});\n \n \t\tdependencies.forEach( name => {\n-\t\t\tthis.expectedProperties.add( name );\n+\t\t\tif ( !globalWhitelist.has( name ) ) this.expectedProperties.add( name );\n \t\t});\n \n \t\treturn {\ndiff --git a/src/generators/dom/index.js b/src/generators/dom/index.js\nindex 385690d71..3e994e0b3 100644\n--- a/src/generators/dom/index.js\n+++ b/src/generators/dom/index.js\n@@ -218,7 +218,7 @@ export default function dom ( parsed, source, options ) {\n \tif ( options.dev ) {\n \t\tgenerator.expectedProperties.forEach( prop => {\n \t\t\tconstructorBlock.addLine(\n-\t\t\t\t`if ( !( '${prop}' in this._state ) ) throw new Error( \"Component was created without expected data property '${prop}'\" );`\n+\t\t\t\t`if ( !( '${prop}' in this._state ) ) console.warn( \"Component was created without expected data property '${prop}'\" );`\n \t\t\t);\n \t\t});\n \n"}
{"instance_id": "sveltejs__svelte-630", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "sveltejs__svelte-510", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/dom/visitors/EachBlock.js b/src/generators/dom/visitors/EachBlock.js\nindex dbb1d2c08..5a1a71d16 100644\n--- a/src/generators/dom/visitors/EachBlock.js\n+++ b/src/generators/dom/visitors/EachBlock.js\n@@ -66,12 +66,16 @@ export default function visitEachBlock ( generator, block, state, node ) {\n \t\t\t\t\t${each_block_else}.mount( ${anchor}.parentNode, ${anchor} );\n \t\t\t\t} else if ( ${each_block_else} ) {\n \t\t\t\t\t${each_block_else}.destroy( true );\n+\t\t\t\t\t${each_block_else} = null;\n \t\t\t\t}\n \t\t\t` );\n \t\t} else {\n \t\t\tblock.builders.update.addBlock( deindent`\n \t\t\t\tif ( ${each_block_value}.length ) {\n-\t\t\t\t\tif ( ${each_block_else} ) ${each_block_else}.destroy( true );\n+\t\t\t\t\tif ( ${each_block_else} ) {\n+\t\t\t\t\t\t${each_block_else}.destroy( true );\n+\t\t\t\t\t\t${each_block_else} = null;\n+\t\t\t\t\t}\n \t\t\t\t} else if ( !${each_block_else} ) {\n \t\t\t\t\t${each_block_else} = ${node.else._block.name}( ${params}, ${block.component} );\n \t\t\t\t\t${each_block_else}.mount( ${anchor}.parentNode, ${anchor} );\n"}
{"instance_id": "sveltejs__svelte-738", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "sveltejs__svelte-464", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/dom/visitors/Component/Component.js b/src/generators/dom/visitors/Component/Component.js\nindex 5446d5427..c8b56dd67 100644\n--- a/src/generators/dom/visitors/Component/Component.js\n+++ b/src/generators/dom/visitors/Component/Component.js\n@@ -38,7 +38,7 @@ const visitors = {\n \n export default function visitComponent ( generator, block, state, node ) {\n \tconst hasChildren = node.children.length > 0;\n-\tconst name = block.getUniqueName( capDown( node.name === ':Self' ? generator.name : node.name ) );\n+\tconst name = block.getUniqueName( node.name === ':Self' ? 'self' : capDown( node.name ) );\n \n \tconst childState = Object.assign( {}, state, {\n \t\tparentNode: null\n"}
{"instance_id": "sveltejs__svelte-728", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/dom/visitors/EachBlock.ts b/src/generators/dom/visitors/EachBlock.ts\nindex 7b232b6ef..ee527a50b 100644\n--- a/src/generators/dom/visitors/EachBlock.ts\n+++ b/src/generators/dom/visitors/EachBlock.ts\n@@ -163,19 +163,14 @@ function keyed(\n \tblock.addVariable(head);\n \tblock.addVariable(last);\n \n-\tif (node.children[0] && node.children[0].type === 'Element' && !generator.components.has(node.children[0].name)) {\n-\t\t// TODO or text/tag/raw\n-\t\tnode._block.first = node.children[0]._state.parentNode; // TODO this is highly confusing\n-\t} else {\n-\t\tnode._block.first = node._block.getUniqueName('first');\n-\t\tnode._block.addElement(\n-\t\t\tnode._block.first,\n-\t\t\t`@createComment()`,\n-\t\t\t`@createComment()`,\n-\t\t\tnull,\n-\t\t\ttrue\n-\t\t);\n-\t}\n+\tnode._block.first = node._block.getUniqueName('first');\n+\tnode._block.addElement(\n+\t\tnode._block.first,\n+\t\t`@createComment()`,\n+\t\t`@createComment()`,\n+\t\tnull,\n+\t\ttrue\n+\t);\n \n \tblock.builders.init.addBlock(deindent`\n \t\tfor ( var #i = 0; #i < ${each_block_value}.${length}; #i += 1 ) {\n@@ -301,7 +296,13 @@ function keyed(\n \t\t\t\t\t\t${iteration}.discard = false;\n \t\t\t\t\t\t${iteration}.last = ${last};\n \n-\t\t\t\t\t\tif (!${expected}) ${iteration}.mount( ${parentNode}, ${anchor} );\n+\t\t\t\t\t\tif ( ${expected} ) {\n+\t\t\t\t\t\t\t${iteration}.${mountOrIntro}( ${parentNode}, ${expected}.first );\n+\t\t\t\t\t\t\t${expected}.last = ${iteration};\n+\t\t\t\t\t\t\t${iteration}.next = ${expected};\n+\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t${iteration}.mount( ${parentNode}, ${anchor} );\n+\t\t\t\t\t\t}\n \t\t\t\t\t} else {\n \t\t\t\t\t\t// key is being inserted\n \t\t\t\t\t\t${iteration} = ${lookup}[${key}] = ${create_each_block}( ${params}, ${each_block_value}, ${each_block_value}[#i], #i, #component, ${key} );\n"}
{"instance_id": "sveltejs__svelte-907", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/Generator.ts b/src/generators/Generator.ts\nindex 5b7ec8f07..b449367a7 100644\n--- a/src/generators/Generator.ts\n+++ b/src/generators/Generator.ts\n@@ -510,6 +510,7 @@ export default class Generator {\n \n \t\t\t\tconst addArrowFunctionExpression = (name: string, node: Node) => {\n \t\t\t\t\tconst { body, params } = node;\n+\t\t\t\t\tconst asyncKeyword = (node as any).async ? 'async ' : '';\n \n \t\t\t\t\tconst paramString = params.length ?\n \t\t\t\t\t\t`[${params[0].start}-${params[params.length - 1].end}]` :\n@@ -517,11 +518,11 @@ export default class Generator {\n \n \t\t\t\t\tif (body.type === 'BlockStatement') {\n \t\t\t\t\t\tcomponentDefinition.addBlock(deindent`\n-\t\t\t\t\t\t\tfunction ${name}(${paramString}) [${body.start}-${body.end}]\n+\t\t\t\t\t\t\t${asyncKeyword}function ${name}(${paramString}) [${body.start}-${body.end}]\n \t\t\t\t\t\t`);\n \t\t\t\t\t} else {\n \t\t\t\t\t\tcomponentDefinition.addBlock(deindent`\n-\t\t\t\t\t\t\tfunction ${name}(${paramString}) {\n+\t\t\t\t\t\t\t${asyncKeyword}function ${name}(${paramString}) {\n \t\t\t\t\t\t\t\treturn [${body.start}-${body.end}];\n \t\t\t\t\t\t\t}\n \t\t\t\t\t\t`);\n@@ -531,8 +532,10 @@ export default class Generator {\n \t\t\t\tconst addFunctionExpression = (name: string, node: Node) => {\n \t\t\t\t\tlet c = node.start;\n \t\t\t\t\twhile (this.source[c] !== '(') c += 1;\n+\t\t\t\t\tconst asyncKeyword = (node as any).async ? 'async ' : '';\n+\t\t\t\t\tconst generatorMark = (node as any).generator ? '*' : '';\n \t\t\t\t\tcomponentDefinition.addBlock(deindent`\n-\t\t\t\t\t\tfunction ${name}[${c}-${node.end}];\n+\t\t\t\t\t\t${asyncKeyword}function${generatorMark} ${name}[${c}-${node.end}];\n \t\t\t\t\t`);\n \t\t\t\t};\n \n"}
{"instance_id": "sveltejs__svelte-906", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/css/Selector.ts b/src/css/Selector.ts\nindex 85922c017..220c68d90 100644\n--- a/src/css/Selector.ts\n+++ b/src/css/Selector.ts\n@@ -219,10 +219,12 @@ const operators = {\n \t'*=': (value: string, flags: string) => new RegExp(value, flags)\n };\n \n-function attributeMatches(node: Node, name: string, expectedValue: string, operator: string, caseInsensitive: boolean) {\n+function attributeMatches(node: Node, name: string, expectedValue: string, operator: string | null, caseInsensitive: boolean) {\n \tconst attr = node.attributes.find((attr: Node) => attr.name === name);\n \tif (!attr) return false;\n-\tif (attr.value === true) return operator === null;\n+\t// Presence-only selector [attr] matches if the attribute exists, regardless of value\n+\tif (operator === null) return true;\n+\tif (attr.value === true) return false; // boolean attributes only match presence selectors\n \tif (attr.value.length > 1) return true;\n \n \tconst pattern = operators[operator](expectedValue, caseInsensitive ? 'i' : '');\n"}
{"instance_id": "sveltejs__svelte-1049", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/nodes/Element.ts b/src/generators/nodes/Element.ts\nindex f3d87ab2b..5c0728310 100644\n--- a/src/generators/nodes/Element.ts\n+++ b/src/generators/nodes/Element.ts\n@@ -260,7 +260,8 @@ export default class Element extends Node {\n \t\t\t\tgenerator.addSourcemapLocations(attribute.expression);\n \n \t\t\t\tconst flattened = flattenReference(attribute.expression.callee);\n-\t\t\t\tif (!validCalleeObjects.has(flattened.name)) {\n+\t\t\t\tconst calleeBase = flattened.name;\n+\t\t\t\tif (!validCalleeObjects.has(calleeBase) && !block.contexts.has(calleeBase) && calleeBase !== 'state') {\n \t\t\t\t\t// allow event.stopPropagation(), this.select() etc\n \t\t\t\t\t// TODO verify that it's a valid callee (i.e. built-in or declared method)\n \t\t\t\t\tgenerator.code.prependRight(\n@@ -268,6 +269,12 @@ export default class Element extends Node {\n \t\t\t\t\t\t`${block.alias('component')}.`\n \t\t\t\t\t);\n \t\t\t\t\tif (shouldHoist) eventHandlerUsesComponent = true; // this feels a bit hacky but it works!\n+\t\t\t\t} else {\n+\t\t\t\t\t// if the callee base is a context or state, mark it as used\n+\t\t\t\t\tif (block.contexts.has(calleeBase) || calleeBase === 'state') {\n+\t\t\t\t\t\tif (!~usedContexts.indexOf(calleeBase)) usedContexts.push(calleeBase);\n+\t\t\t\t\t\tallUsedContexts.add(calleeBase);\n+\t\t\t\t\t}\n \t\t\t\t}\n \n \t\t\t\tattribute.expression.arguments.forEach((arg: Node) => {\n@@ -291,7 +298,11 @@ export default class Element extends Node {\n \t\t\t\tconst indexName = block.indexNames.get(name);\n \t\t\t\tconst contextName = block.contexts.get(name);\n \n-\t\t\t\treturn `var ${listName} = ${ctx}._svelte.${listName}, ${indexName} = ${ctx}._svelte.${indexName}, ${contextName} = ${listName}[${indexName}];`;\n+\t\t\t\tif (listName && indexName) {\n+\t\t\t\t\treturn `var ${listName} = ${ctx}._svelte.${listName}, ${indexName} = ${ctx}._svelte.${indexName}, ${contextName} = ${listName}[${indexName}];`;\n+\t\t\t\t}\n+\t\t\t\t// single-value context (e.g., await block)\n+\t\t\t\treturn `var ${contextName} = ${ctx}._svelte.${contextName};`;\n \t\t\t});\n \n \t\t\t// get a name for the event handler that is globally unique\n@@ -376,12 +387,22 @@ export default class Element extends Node {\n \t\t\t\tconst listName = block.listNames.get(contextName);\n \t\t\t\tconst indexName = block.indexNames.get(contextName);\n \n-\t\t\t\tinitialProps.push(\n-\t\t\t\t\t`${listName}: ${listName},\\n${indexName}: ${indexName}`\n-\t\t\t\t);\n-\t\t\t\tupdates.push(\n-\t\t\t\t\t`${name}._svelte.${listName} = ${listName};\\n${name}._svelte.${indexName} = ${indexName};`\n-\t\t\t\t);\n+\t\t\t\tif (listName && indexName) {\n+\t\t\t\t\tinitialProps.push(\n+\t\t\t\t\t\t`${listName}: ${listName},\\n${indexName}: ${indexName}`\n+\t\t\t\t\t);\n+\t\t\t\t\tupdates.push(\n+\t\t\t\t\t\t`${name}._svelte.${listName} = ${listName};\\n${name}._svelte.${indexName} = ${indexName};`\n+\t\t\t\t\t);\n+\t\t\t\t} else {\n+\t\t\t\t\tconst contextAlias = block.contexts.get(contextName);\n+\t\t\t\t\tinitialProps.push(\n+\t\t\t\t\t\t`${contextAlias}: ${contextAlias}`\n+\t\t\t\t\t);\n+\t\t\t\t\tupdates.push(\n+\t\t\t\t\t\t`${name}._svelte.${contextAlias} = ${contextAlias};`\n+\t\t\t\t\t);\n+\t\t\t\t}\n \t\t\t});\n \n \t\t\tif (initialProps.length) {\n"}
{"instance_id": "sveltejs__svelte-1137", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/shared/index.js b/src/shared/index.js\nindex 3adae010c..ef160ebf0 100644\n--- a/src/shared/index.js\n+++ b/src/shared/index.js\n@@ -177,7 +177,7 @@ export function setDev(newState) {\n }\n \n export function callAll(fns) {\n-\twhile (fns && fns.length) fns.pop()();\n+\twhile (fns && fns.length) fns.shift()();\n }\n \n export function _mount(target, anchor) {\n"}
{"instance_id": "sveltejs__svelte-1190", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/css/Stylesheet.ts b/src/css/Stylesheet.ts\nindex d16af0929..3b37ca526 100644\n--- a/src/css/Stylesheet.ts\n+++ b/src/css/Stylesheet.ts\n@@ -69,7 +69,7 @@ class Rule {\n \ttransform(code: MagicString, id: string, keyframes: Map<string, string>, cascade: boolean) {\n \t\tif (this.parent && this.parent.node.type === 'Atrule' && this.parent.node.name === 'keyframes') return true;\n \n-\t\tconst attr = `[${id}]`;\n+\t\tconst attr = `.${id}`;\n \n \t\tif (cascade) {\n \t\t\tthis.selectors.forEach(selector => {\ndiff --git a/src/generators/dom/index.ts b/src/generators/dom/index.ts\nindex ada015269..d14069070 100644\n--- a/src/generators/dom/index.ts\n+++ b/src/generators/dom/index.ts\n@@ -138,7 +138,7 @@ export default function dom(\n \tif (generator.needsEncapsulateHelper) {\n \t\tbuilder.addBlock(deindent`\n \t\t\tfunction @encapsulateStyles(node) {\n-\t\t\t\t@setAttribute(node, \"${generator.stylesheet.id}\", \"\");\n+\t\t\t\t@addClass(node, \"${generator.stylesheet.id}\");\n \t\t\t}\n \t\t`);\n \t}\ndiff --git a/src/generators/nodes/Attribute.ts b/src/generators/nodes/Attribute.ts\nindex 08075efee..a3b3ae733 100644\n--- a/src/generators/nodes/Attribute.ts\n+++ b/src/generators/nodes/Attribute.ts\n@@ -188,10 +188,17 @@ export default class Attribute {\n \n \t\t\t\tblock.builders.update.addLine(`${last} = ${value};`);\n \t\t\t} else if (propertyName) {\n-\t\t\t\tblock.builders.hydrate.addLine(\n-\t\t\t\t\t`${node.var}.${propertyName} = ${init};`\n-\t\t\t\t);\n-\t\t\t\tupdater = `${node.var}.${propertyName} = ${shouldCache || isSelectValueAttribute ? last : value};`;\n+\t\t\t\tif (propertyName === 'className' && node._needsCssAttribute && !this.generator.customElement) {\n+\t\t\t\t\tblock.builders.hydrate.addLine(\n+\t\t\t\t\t\t`@setClass(${node.var}, \"${this.generator.stylesheet.id}\", ${init});`\n+\t\t\t\t\t);\n+\t\t\t\t\tupdater = `@setClass(${node.var}, \"${this.generator.stylesheet.id}\", ${shouldCache || isSelectValueAttribute ? last : value});`;\n+\t\t\t\t} else {\n+\t\t\t\t\tblock.builders.hydrate.addLine(\n+\t\t\t\t\t\t`${node.var}.${propertyName} = ${init};`\n+\t\t\t\t\t);\n+\t\t\t\t\tupdater = `${node.var}.${propertyName} = ${shouldCache || isSelectValueAttribute ? last : value};`;\n+\t\t\t\t}\n \t\t\t} else if (isDataSet) {\n \t\t\t\tblock.builders.hydrate.addLine(\n \t\t\t\t\t`${node.var}.dataset.${camelCaseName} = ${init};`\n@@ -231,6 +238,7 @@ export default class Attribute {\n \n \t\t\tconst statement = (\n \t\t\t\tisLegacyInputType ? `@setInputType(${node.var}, ${value});` :\n+\t\t\t\t(propertyName === 'className' && node._needsCssAttribute && !this.generator.customElement) ? `@setClass(${node.var}, \"${this.generator.stylesheet.id}\", ${value});` :\n \t\t\t\tpropertyName ? `${node.var}.${propertyName} = ${value};` :\n \t\t\t\t\tisDataSet ? `${node.var}.dataset.${camelCaseName} = ${value};` :\n \t\t\t\t`${method}(${node.var}, \"${name}\", ${value});`\ndiff --git a/src/generators/nodes/Element.ts b/src/generators/nodes/Element.ts\nindex 2a75f1fc3..52a89895b 100644\n--- a/src/generators/nodes/Element.ts\n+++ b/src/generators/nodes/Element.ts\n@@ -429,18 +429,25 @@ export default class Element extends Node {\n \n \t\t\tlet open = `<${node.name}`;\n \n-\t\t\tif (node._needsCssAttribute) {\n-\t\t\t\topen += ` ${generator.stylesheet.id}`;\n-\t\t\t}\n+\t\t\tlet hasClass = false;\n \n \t\t\tif (node._cssRefAttribute) {\n \t\t\t\topen += ` svelte-ref-${node._cssRefAttribute}`;\n \t\t\t}\n \n \t\t\tnode.attributes.forEach((attr: Node) => {\n+\t\t\t\tif (attr.name === 'class') hasClass = true;\n \t\t\t\topen += ` ${fixAttributeCasing(attr.name)}${stringifyAttributeValue(attr.value)}`\n \t\t\t});\n \n+\t\t\tif (node._needsCssAttribute) {\n+\t\t\t\tif (hasClass) {\n+\t\t\t\t\topen = open.replace(/ class=\"/, ` class=\"${generator.stylesheet.id} `);\n+\t\t\t\t} else {\n+\t\t\t\t\topen += ` class=\"${generator.stylesheet.id}\"`;\n+\t\t\t\t}\n+\t\t\t}\n+\n \t\t\tif (isVoidElementName(node.name)) return open + '>';\n \n \t\t\treturn `${open}>${node.children.map(toHTML).join('')}</${node.name}>`;\ndiff --git a/src/generators/server-side-rendering/visitors/Element.ts b/src/generators/server-side-rendering/visitors/Element.ts\nindex 21ec923e3..6c2d3912e 100644\n--- a/src/generators/server-side-rendering/visitors/Element.ts\n+++ b/src/generators/server-side-rendering/visitors/Element.ts\n@@ -34,6 +34,8 @@ export default function visitElement(\n \t\tappendTarget.slots[slotName] = '';\n \t}\n \n+\tlet hasClass = false;\n+\n \tnode.attributes.forEach((attribute: Node) => {\n \t\tif (attribute.type !== 'Attribute') return;\n \n@@ -49,13 +51,22 @@ export default function visitElement(\n \t\t\t// a boolean attribute with one non-Text chunk\n \t\t\tblock.contextualise(attribute.value[0].expression);\n \t\t\topeningTag += '${' + attribute.value[0].metadata.snippet + ' ? \" ' + attribute.name + '\" : \"\" }';\n+\t\t} else if (attribute.name === 'class') {\n+\t\t\thasClass = true;\n+\t\t\tif (node._needsCssAttribute) {\n+\t\t\t\topeningTag += ` class=\"${generator.stylesheet.id} ${stringifyAttributeValue(block, attribute.value)}\"`;\n+\t\t\t} else {\n+\t\t\t\topeningTag += ` ${attribute.name}=\"${stringifyAttributeValue(block, attribute.value)}\"`;\n+\t\t\t}\n \t\t} else {\n \t\t\topeningTag += ` ${attribute.name}=\"${stringifyAttributeValue(block, attribute.value)}\"`;\n \t\t}\n \t});\n \n \tif (node._needsCssAttribute) {\n-\t\topeningTag += ` ${generator.stylesheet.id}`;\n+\t\tif (!hasClass) {\n+\t\t\topeningTag += ` class=\"${generator.stylesheet.id}\"`;\n+\t\t}\n \n \t\tif (node._cssRefAttribute) {\n \t\t\topeningTag += ` svelte-ref-${node._cssRefAttribute}`;\ndiff --git a/src/shared/dom.js b/src/shared/dom.js\nindex 9003faee3..0f15d6f54 100644\n--- a/src/shared/dom.js\n+++ b/src/shared/dom.js\n@@ -85,6 +85,24 @@ export function setAttribute(node, attribute, value) {\n \tnode.setAttribute(attribute, value);\n }\n \n+export function addClass(node, className) {\n+\tif (node.classList) {\n+\t\tnode.classList.add(className);\n+\t} else {\n+\t\tvar current = node.getAttribute('class') || '';\n+\t\tvar classes = current ? current.split(/\\s+/) : [];\n+\t\tif (classes.indexOf(className) === -1) classes.push(className);\n+\t\tnode.setAttribute('class', classes.join(' '));\n+\t}\n+}\n+\n+export function setClass(node, scopeClass, value) {\n+\tvar str = value == null ? '' : '' + value;\n+\tvar classes = str ? str.split(/\\s+/) : [];\n+\tif (classes.indexOf(scopeClass) === -1) classes.unshift(scopeClass);\n+\tnode.setAttribute('class', classes.join(' '));\n+}\n+\n export function setXlinkAttribute(node, attribute, value) {\n \tnode.setAttributeNS('http://www.w3.org/1999/xlink', attribute, value);\n }\n"}
{"instance_id": "sveltejs__svelte-1376", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compile/nodes/Element.ts b/src/compile/nodes/Element.ts\nindex a025eb7b0..f8cc67965 100644\n--- a/src/compile/nodes/Element.ts\n+++ b/src/compile/nodes/Element.ts\n@@ -614,7 +614,7 @@ export default class Element extends Node {\n \t\t\t\tblock.builders.hydrate.addBlock(deindent`\n \t\t\t\t\t${handlerName} = %events-${handler.name}.call(${component}, ${this.var}, function(event) {\n \t\t\t\t\t\t${handlerBody}\n-\t\t\t\t\t});\n+\t\t\t\t\t}.bind(${this.var}));\n \t\t\t\t`);\n \n \t\t\t\tblock.builders.destroy.addLine(deindent`\n"}
{"instance_id": "sveltejs__svelte-1310", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/css/Selector.ts b/src/css/Selector.ts\nindex fba0386f1..9c8d31bea 100644\n--- a/src/css/Selector.ts\n+++ b/src/css/Selector.ts\n@@ -224,7 +224,12 @@ const operators = {\n \n function attributeMatches(node: Node, name: string, expectedValue: string, operator: string, caseInsensitive: boolean) {\n \tconst attr = node.attributes.find((attr: Node) => attr.name === name);\n-\tif (!attr) return false;\n+\tif (!attr) {\n+\t\t// if the attribute isn't statically present but there is a spread,\n+\t\t// we must assume it could be provided at runtime\n+\t\tif (node.attributes.some((a: Node) => a.type === 'Spread')) return true;\n+\t\treturn false;\n+\t}\n \tif (attr.value === true) return operator === null;\n \tif (attr.value.length > 1) return true;\n \tif (!expectedValue) return true;\n"}
{"instance_id": "sveltejs__svelte-1231", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/Generator.ts b/src/generators/Generator.ts\nindex b53851cec..74b58dc19 100644\n--- a/src/generators/Generator.ts\n+++ b/src/generators/Generator.ts\n@@ -394,6 +394,7 @@ export default class Generator {\n \t\t\t\talias = `${name}_${i++}`\n \t\t\t);\n \t\t\tlocalUsedNames.add(alias);\n+\t\t\tthis.usedNames.add(alias);\n \t\t\treturn alias;\n \t\t};\n \t}\ndiff --git a/src/generators/dom/index.ts b/src/generators/dom/index.ts\nindex f02b013d0..14c32b729 100644\n--- a/src/generators/dom/index.ts\n+++ b/src/generators/dom/index.ts\n@@ -72,6 +72,7 @@ export class DomGenerator extends Generator {\n \t\t\t\talias = `${name}_${i++}`\n \t\t\t);\n \t\t\tlocalUsedNames.add(alias);\n+\t\t\tthis.usedNames.add(alias);\n \t\t\treturn alias;\n \t\t};\n \t}\n"}
{"instance_id": "sveltejs__svelte-1923", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compile/render-dom/wrappers/Element/index.ts b/src/compile/render-dom/wrappers/Element/index.ts\nindex 5f6f94f38..9b51799cd 100644\n--- a/src/compile/render-dom/wrappers/Element/index.ts\n+++ b/src/compile/render-dom/wrappers/Element/index.ts\n@@ -410,7 +410,7 @@ export default class ElementWrapper extends Wrapper {\n \t\t\t.filter(group => group.bindings.length);\n \n \t\tgroups.forEach(group => {\n-\t\t\tconst handler = block.getUniqueName(`${this.var}_${group.events.join('_')}_handler`);\n+\t\t\tconst handler = renderer.component.getUniqueName(`${this.var}_${group.events.join('_')}_handler`);\n \t\t\trenderer.component.declarations.push(handler);\n \t\t\trenderer.component.template_references.add(handler);\n \n"}
{"instance_id": "sveltejs__svelte-1932", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compile/Component.ts b/src/compile/Component.ts\nindex 647068fdf..9f3dc1af3 100644\n--- a/src/compile/Component.ts\n+++ b/src/compile/Component.ts\n@@ -673,7 +673,9 @@ export default class Component {\n \t\t\t});\n \n \t\t\tif (combining) {\n-\t\t\t\tcode.prependRight(c, ' } = $$props');\n+\t\t\t\tconst last = group[group.length - 1];\n+\t\t\t\tconst needs_semicolon = this.code.original[last.end - 1] !== ';';\n+\t\t\t\tcode.appendLeft(c, needs_semicolon ? ' } = $$props;' : ' } = $$props');\n \t\t\t}\n \t\t});\n \t}\n"}
{"instance_id": "sveltejs__svelte-3151", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/nodes/shared/Expression.ts b/src/compiler/compile/nodes/shared/Expression.ts\nindex e85c1de5e..78f049834 100644\n--- a/src/compiler/compile/nodes/shared/Expression.ts\n+++ b/src/compiler/compile/nodes/shared/Expression.ts\n@@ -402,7 +402,17 @@ export default class Expression {\n \t\t\t\t\tif (dependencies.size === 0 && contextual_dependencies.size === 0) {\n \t\t\t\t\t\t// we can hoist this out of the component completely\n \t\t\t\t\t\tcomponent.fully_hoisted.push(fn);\n-\t\t\t\t\t\tcode.overwrite(node.start, node.end, name);\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tconst is_method = parent && (parent as any).type === 'Property' && (parent as any).method;\n+\t\t\t\t\t\t\tconst replacement = name;\n+\t\t\t\t\t\t\tif (is_method) {\n+\t\t\t\t\t\t\t\tconst key_text = code.slice((parent as any).key.start, (parent as any).key.end);\n+\t\t\t\t\t\t\t\tconst prop = (parent as any).computed ? `[${key_text}]` : key_text;\n+\t\t\t\t\t\t\t\tcode.overwrite((parent as any).start, (parent as any).end, `${prop}: ${replacement}`);\n+\t\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t\tcode.overwrite(node.start, node.end, replacement);\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n \n \t\t\t\t\t\tcomponent.add_var({\n \t\t\t\t\t\t\tname,\n@@ -415,7 +425,17 @@ export default class Expression {\n \t\t\t\t\telse if (contextual_dependencies.size === 0) {\n \t\t\t\t\t\t// function can be hoisted inside the component init\n \t\t\t\t\t\tcomponent.partly_hoisted.push(fn);\n-\t\t\t\t\t\tcode.overwrite(node.start, node.end, `ctx.${name}`);\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tconst is_method = parent && (parent as any).type === 'Property' && (parent as any).method;\n+\t\t\t\t\t\t\tconst replacement = `ctx.${name}`;\n+\t\t\t\t\t\t\tif (is_method) {\n+\t\t\t\t\t\t\t\tconst key_text = code.slice((parent as any).key.start, (parent as any).key.end);\n+\t\t\t\t\t\t\t\tconst prop = (parent as any).computed ? `[${key_text}]` : key_text;\n+\t\t\t\t\t\t\t\tcode.overwrite((parent as any).start, (parent as any).end, `${prop}: ${replacement}`);\n+\t\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t\tcode.overwrite(node.start, node.end, replacement);\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n \n \t\t\t\t\t\tcomponent.add_var({\n \t\t\t\t\t\t\tname,\n@@ -427,7 +447,17 @@ export default class Expression {\n \t\t\t\t\telse {\n \t\t\t\t\t\t// we need a combo block/init recipe\n \t\t\t\t\t\tcomponent.partly_hoisted.push(fn);\n-\t\t\t\t\t\tcode.overwrite(node.start, node.end, name);\n+\t\t\t\t\t\t{\n+\t\t\t\t\t\t\tconst is_method = parent && (parent as any).type === 'Property' && (parent as any).method;\n+\t\t\t\t\t\t\tconst replacement = name;\n+\t\t\t\t\t\t\tif (is_method) {\n+\t\t\t\t\t\t\t\tconst key_text = code.slice((parent as any).key.start, (parent as any).key.end);\n+\t\t\t\t\t\t\t\tconst prop = (parent as any).computed ? `[${key_text}]` : key_text;\n+\t\t\t\t\t\t\t\tcode.overwrite((parent as any).start, (parent as any).end, `${prop}: ${replacement}`);\n+\t\t\t\t\t\t\t} else {\n+\t\t\t\t\t\t\t\tcode.overwrite(node.start, node.end, replacement);\n+\t\t\t\t\t\t\t}\n+\t\t\t\t\t\t}\n \n \t\t\t\t\t\tcomponent.add_var({\n \t\t\t\t\t\t\tname,\n"}
{"instance_id": "sveltejs__svelte-2185", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "sveltejs__svelte-3314", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_ssr/handlers/InlineComponent.ts b/src/compiler/compile/render_ssr/handlers/InlineComponent.ts\nindex 320bf5e6a..d25a096da 100644\n--- a/src/compiler/compile/render_ssr/handlers/InlineComponent.ts\n+++ b/src/compiler/compile/render_ssr/handlers/InlineComponent.ts\n@@ -43,8 +43,8 @@ export default function(node: InlineComponent, renderer: Renderer, options: Rend\n \t\t// TODO this probably won't work for contextual bindings\n \t\tconst snippet = snip(binding.expression);\n \n-\t\tbinding_props.push(`${binding.name}: ${snippet}`);\n-\t\tbinding_fns.push(`${binding.name}: $$value => { ${snippet} = $$value; $$settled = false }`);\n+\t\tbinding_props.push(`${quote_name_if_necessary(binding.name)}: ${snippet}`);\n+\t\tbinding_fns.push(`${quote_name_if_necessary(binding.name)}: $$value => { ${snippet} = $$value; $$settled = false }`);\n \t});\n \n \tconst uses_spread = node.attributes.find(attr => attr.is_spread);\n@@ -58,7 +58,7 @@ export default function(node: InlineComponent, renderer: Renderer, options: Rend\n \t\t\t\t\tif (attribute.is_spread) {\n \t\t\t\t\t\treturn snip(attribute.expression);\n \t\t\t\t\t} else {\n-\t\t\t\t\t\treturn `{ ${attribute.name}: ${get_attribute_value(attribute)} }`;\n+\t\t\t\t\t\treturn `{ ${quote_name_if_necessary(attribute.name)}: ${get_attribute_value(attribute)} }`;\n \t\t\t\t\t}\n \t\t\t\t})\n \t\t\t\t.concat(binding_props.map(p => `{ ${p} }`))\n@@ -67,7 +67,7 @@ export default function(node: InlineComponent, renderer: Renderer, options: Rend\n \t} else {\n \t\tprops = stringify_props(\n \t\t\tnode.attributes\n-\t\t\t\t.map(attribute => `${attribute.name}: ${get_attribute_value(attribute)}`)\n+\t\t\t\t.map(attribute => `${quote_name_if_necessary(attribute.name)}: ${get_attribute_value(attribute)}`)\n \t\t\t\t.concat(binding_props)\n \t\t);\n \t}\n"}
{"instance_id": "sveltejs__svelte-3305", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/runtime/internal/dom.ts b/src/runtime/internal/dom.ts\nindex 452347dc2..aee3d6025 100644\n--- a/src/runtime/internal/dom.ts\n+++ b/src/runtime/internal/dom.ts\n@@ -71,6 +71,11 @@ export function empty() {\n }\n \n export function listen(node: Node, event: string, handler: EventListenerOrEventListenerObject, options?: boolean | AddEventListenerOptions | EventListenerOptions) {\n+\t// Safari does not fire 'input' event for <input type=\"file\">; listen to 'change' instead\n+\tif (event === 'input' && node instanceof HTMLInputElement && node.type === 'file') {\n+\t\tnode.addEventListener('change', handler, options);\n+\t\treturn () => node.removeEventListener('change', handler, options);\n+\t}\n \tnode.addEventListener(event, handler, options);\n \treturn () => node.removeEventListener(event, handler, options);\n }\n"}
{"instance_id": "sveltejs__svelte-3403", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/nodes/Element.ts b/src/compiler/compile/nodes/Element.ts\nindex 62bc62059..c539a300a 100644\n--- a/src/compiler/compile/nodes/Element.ts\n+++ b/src/compiler/compile/nodes/Element.ts\n@@ -76,6 +76,16 @@ const passive_events = new Set([\n ]);\n \n function get_namespace(parent: Element, element: Element, explicit_namespace: string) {\n+\t// If the direct parent is an InlineComponent, we don't have a real DOM\n+\t// ancestor to derive the namespace from within this component. In that case,\n+\t// infer the namespace from the element name (e.g. SVG tags) or from any\n+\t// explicit namespace provided by the component.\n+\tif (parent && (parent as any).type === 'InlineComponent') {\n+\t\treturn explicit_namespace || (svg.test(element.name)\n+\t\t\t? namespaces.svg\n+\t\t\t: null);\n+\t}\n+\n \tconst parent_element = parent.find_nearest(/^Element/);\n \n \tif (!parent_element) {\n"}
{"instance_id": "sveltejs__svelte-3394", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "sveltejs__svelte-3435", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/runtime/internal/dom.ts b/src/runtime/internal/dom.ts\nindex 8b28a1f77..ccfd3d570 100644\n--- a/src/runtime/internal/dom.ts\n+++ b/src/runtime/internal/dom.ts\n@@ -184,7 +184,11 @@ export function set_input_type(input, type) {\n }\n \n export function set_style(node, key, value) {\n-\tnode.style.setProperty(key, value);\n+\tif (typeof value === 'string' && /\\s*!important\\s*$/i.test(value)) {\n+\t\tnode.style.setProperty(key, value.replace(/\\s*!important\\s*$/i, ''), 'important');\n+\t} else {\n+\t\tnode.style.setProperty(key, value);\n+\t}\n }\n \n export function select_option(select, value) {\n"}
{"instance_id": "sveltejs__svelte-3702", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/EachBlock.ts b/src/compiler/compile/render_dom/wrappers/EachBlock.ts\nindex fe56ac0fa..51436ed5c 100644\n--- a/src/compiler/compile/render_dom/wrappers/EachBlock.ts\n+++ b/src/compiler/compile/render_dom/wrappers/EachBlock.ts\n@@ -101,11 +101,7 @@ export default class EachBlockWrapper extends Wrapper {\n \t\t\t\t? node.expression.node.elements.length\n \t\t\t\t: null;\n \n-\t\t// hack the sourcemap, so that if data is missing the bug\n-\t\t// is easy to find\n-\t\tlet c = this.node.start + 2;\n-\t\twhile (renderer.component.source[c] !== 'e') c += 1;\n-\t\trenderer.component.code.overwrite(c, c + 4, 'length');\n+\t\t// use direct property access for length; removed brittle sourcemap hack\n \n \t\tconst each_block_value = renderer.component.get_unique_name(`${this.var}_value`);\n \t\tconst iterations = block.get_unique_name(`${this.var}_blocks`);\n@@ -115,12 +111,12 @@ export default class EachBlockWrapper extends Wrapper {\n \t\t\teach_block_value,\n \t\t\tget_each_context: renderer.component.get_unique_name(`get_${this.var}_context`),\n \t\t\titerations,\n-\t\t\tlength: `[${c}-${c+4}]`,\n+\t\t\tlength: `length`,\n \n \t\t\t// optimisation for array literal\n \t\t\tfixed_length,\n-\t\t\tdata_length: fixed_length === null ? `${each_block_value}.[${c}-${c+4}]` : fixed_length,\n-\t\t\tview_length: fixed_length === null ? `${iterations}.[${c}-${c+4}]` : fixed_length\n+\t\t\tdata_length: fixed_length === null ? `${each_block_value}.length` : fixed_length,\n+\t\t\tview_length: fixed_length === null ? `${iterations}.length` : fixed_length\n \t\t};\n \n \t\tconst store = \n"}
{"instance_id": "sveltejs__svelte-3749", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/IfBlock.ts b/src/compiler/compile/render_dom/wrappers/IfBlock.ts\nindex c54994a36..769f3db0d 100644\n--- a/src/compiler/compile/render_dom/wrappers/IfBlock.ts\n+++ b/src/compiler/compile/render_dom/wrappers/IfBlock.ts\n@@ -388,7 +388,11 @@ export default class IfBlockWrapper extends Wrapper {\n \t\t\t\t\tfunction ${select_block_type}(#changed, #ctx) {\n \t\t\t\t\t\t${this.branches.map(({ dependencies, condition, snippet }, i) => condition\n \t\t\t\t\t\t? b`\n-\t\t\t\t\t\t${snippet && b`if ((${condition} == null) || ${changed(dependencies)}) ${condition} = !!(${snippet})`}\n+\t\t\t\t\t\t${snippet && (\n+\t\t\t\t\t\t\tdependencies.length > 0\n+\t\t\t\t\t\t\t\t? b`if ((${condition} == null) || ${changed(dependencies)}) ${condition} = !!(${snippet})`\n+\t\t\t\t\t\t\t\t: b`if (${condition} == null) ${condition} = !!(${snippet})`\n+\t\t\t\t\t\t)}\n \t\t\t\t\t\tif (${condition}) return ${i};`\n \t\t\t\t\t\t: b`return ${i};`)}\n \t\t\t\t\t\t${!has_else && b`return -1;`}\ndiff --git a/src/compiler/compile/render_dom/wrappers/shared/changed.ts b/src/compiler/compile/render_dom/wrappers/shared/changed.ts\nindex b7dc12e53..d866ab40d 100644\n--- a/src/compiler/compile/render_dom/wrappers/shared/changed.ts\n+++ b/src/compiler/compile/render_dom/wrappers/shared/changed.ts\n@@ -3,5 +3,5 @@ import { x } from 'code-red';\n export function changed(dependencies: string[]) {\n \treturn dependencies\n \t\t.map(d => x`#changed.${d}`)\n-\t\t.reduce((lhs, rhs) => x`${lhs} || ${rhs}`);\n+\t\t.reduce((lhs, rhs) => x`${lhs} || ${rhs}`, x`false`);\n }\n\\ No newline at end of file\n"}
{"instance_id": "sveltejs__svelte-3949", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/runtime/internal/dom.ts b/src/runtime/internal/dom.ts\nindex e4db8c1e1..e578bde90 100644\n--- a/src/runtime/internal/dom.ts\n+++ b/src/runtime/internal/dom.ts\n@@ -239,6 +239,8 @@ export function add_resize_listener(element, fn) {\n \tobject.setAttribute('style', 'display: block; position: absolute; top: 0; left: 0; height: 100%; width: 100%; overflow: hidden; pointer-events: none; z-index: -1;');\n \tobject.type = 'text/html';\n \tobject.tabIndex = -1;\n+\tobject.setAttribute('aria-hidden', 'true');\n+\tobject.setAttribute('role', 'none');\n \n \tlet win;\n \n"}
{"instance_id": "sveltejs__svelte-3451", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/site/content/docs/01-component-format.md b/site/content/docs/01-component-format.md\nindex 3d349af51..9a23261a6 100644\n--- a/site/content/docs/01-component-format.md\n+++ b/site/content/docs/01-component-format.md\n@@ -111,7 +111,7 @@ Because Svelte's reactivity is based on assignments, using array methods like `.\n \n ---\n \n-Any top-level statement (i.e. not inside a block or a function) can be made reactive by prefixing it with the `$:` [JS label syntax](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/label). Reactive statements run immediately before the component updates, whenever the values that they depend on have changed.\n+Any top-level statement (i.e. not inside a block or a function) can be made reactive by prefixing it with the `$:` [JS label syntax](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/label). Reactive statements run immediately before the component updates, whenever the values that they depend on have changed. Identifiers declared via function statements are not const and may be reassigned  Svelte treats such reassignments as changes so reactive statements depending on them will re-run.\n \n ```html\n <script>\ndiff --git a/site/content/docs/04-compile-time.md b/site/content/docs/04-compile-time.md\nindex f47fe564a..13fefe3e4 100644\n--- a/site/content/docs/04-compile-time.md\n+++ b/site/content/docs/04-compile-time.md\n@@ -112,7 +112,7 @@ const {\n \t* `mutated` is `true` if the value's properties are assigned to inside the component\n \t* `reassigned` is `true` if the value is reassigned inside the component\n \t* `referenced` is `true` if the value is used outside the declaration\n-\t* `writable` is `true` if the value was declared with `let` or `var` (but not `const`, `class` or `function`)\n+\t* `writable` is `true` if the value was declared with `let` or `var` (but not `const`, `class` or `function`). Note: reactive dependencies include values that are writable, mutated or reassigned.\n * `stats` is an object used by the Svelte developer team for diagnosing the compiler. Avoid relying on it to stay the same!\n \n \ndiff --git a/src/compiler/compile/Component.ts b/src/compiler/compile/Component.ts\nindex 355ad0c42..756b2ce1c 100644\n--- a/src/compiler/compile/Component.ts\n+++ b/src/compiler/compile/Component.ts\n@@ -1158,7 +1158,7 @@ export default class Component {\n \t\t\t\t\t\t\t\tconst owner = scope.find_owner(name);\n \t\t\t\t\t\t\t\tconst variable = component.var_lookup.get(name);\n \t\t\t\t\t\t\t\tif (variable) variable.is_reactive_dependency = true;\n-\t\t\t\t\t\t\t\tconst is_writable_or_mutated = variable && (variable.writable || variable.mutated);\n+\t\t\t\t\t\t\t\tconst is_writable_or_mutated = variable && (variable.writable || variable.mutated || variable.reassigned);\n \t\t\t\t\t\t\t\tif (\n \t\t\t\t\t\t\t\t\t(!owner || owner === component.instance_scope) &&\n \t\t\t\t\t\t\t\t\t(name[0] === '$' || is_writable_or_mutated)\ndiff --git a/src/compiler/compile/render_dom/index.ts b/src/compiler/compile/render_dom/index.ts\nindex 52006e4d8..0af6f6cf0 100644\n--- a/src/compiler/compile/render_dom/index.ts\n+++ b/src/compiler/compile/render_dom/index.ts\n@@ -365,7 +365,7 @@ export default function dom(\n \t\t\t\tconst condition = !uses_props && dependencies\n \t\t\t\t\t.filter(n => {\n \t\t\t\t\t\tconst variable = component.var_lookup.get(n);\n-\t\t\t\t\t\treturn variable && (variable.writable || variable.mutated);\n+\t\t\t\t\t\treturn variable && (variable.writable || variable.mutated || variable.reassigned);\n \t\t\t\t\t})\n \t\t\t\t\t.map(n => `$$dirty.${n}`).join(' || ');\n \n"}
{"instance_id": "sveltejs__svelte-4288", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/runtime/internal/dom.ts b/src/runtime/internal/dom.ts\nindex f9e89f41b..c39cf93b6 100644\n--- a/src/runtime/internal/dom.ts\n+++ b/src/runtime/internal/dom.ts\n@@ -152,7 +152,7 @@ export function claim_element(nodes, name, attributes, svg) {\n \tfor (let i = 0; i < nodes.length; i += 1) {\n \t\tconst node = nodes[i];\n \t\tif (node.nodeName === name) {\n-\t\t\tfor (let j = 0; j < node.attributes.length; j += 1) {\n+\t\t\tfor (let j = node.attributes.length - 1; j >= 0; j -= 1) {\n \t\t\t\tconst attribute = node.attributes[j];\n \t\t\t\tif (!attributes[attribute.name]) node.removeAttribute(attribute.name);\n \t\t\t}\n"}
{"instance_id": "sveltejs__svelte-4454", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "sveltejs__svelte-4332", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/css/Selector.ts b/src/compiler/compile/css/Selector.ts\nindex 39bbc2e8d..ee96138a0 100644\n--- a/src/compiler/compile/css/Selector.ts\n+++ b/src/compiler/compile/css/Selector.ts\n@@ -36,6 +36,10 @@ export default class Selector {\n \t}\n \n \tapply(node: Element, stack: Element[]) {\n+\t\tif (this.blocks[0] && this.blocks[0].global) {\n+\t\t\treturn;\n+\t\t}\n+\n \t\tconst to_encapsulate: any[] = [];\n \n \t\tapply_selector(this.local_blocks.slice(), node, stack.slice(), to_encapsulate);\n"}
{"instance_id": "sveltejs__svelte-4146", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/css/Selector.ts b/src/compiler/compile/css/Selector.ts\nindex d99af7a11..1d547d1c2 100644\n--- a/src/compiler/compile/css/Selector.ts\n+++ b/src/compiler/compile/css/Selector.ts\n@@ -93,7 +93,13 @@ export default class Selector {\n \t\t\t\tcode.remove(selector.start, first.start).remove(last.end, selector.end);\n \t\t\t}\n \n-\t\t\tif (block.should_encapsulate) encapsulate_block(block);\n+\t\t\tif (block.should_encapsulate) {\n+\t\t\t\tencapsulate_block(block);\n+\t\t\t\t// increase specificity for single local-block selectors to preserve cascade\n+\t\t\t\tif (this.local_blocks.length === 1 && !block.global) {\n+\t\t\t\t\tencapsulate_block(block);\n+\t\t\t\t}\n+\t\t\t}\n \t\t});\n \t}\n \n"}
{"instance_id": "sveltejs__svelte-5875", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/site/content/docs/02-template-syntax.md b/site/content/docs/02-template-syntax.md\nindex 6f1a2da61..21f874ea0 100644\n--- a/site/content/docs/02-template-syntax.md\n+++ b/site/content/docs/02-template-syntax.md\n@@ -827,7 +827,7 @@ Actions are functions that are called when an element is created. They can retur\n \n ---\n \n-An action can have a parameter. If the returned value has an `update` method, it will be called whenever that parameter changes, immediately after Svelte has applied updates to the markup.\n+An action can have a parameter. If the returned value has an `update` method, it will be called whenever that parameter changes, immediately after Svelte has applied updates to the markup. Multiple actions can be applied to the same element and are run in the order they appear in the template. Using the same action more than once will attach multiple instances.\n \n > Don't worry about the fact that we're redeclaring the `foo` function for every component instance  Svelte will hoist any functions that don't depend on local state out of the component definition.\n \ndiff --git a/src/compiler/parse/state/tag.ts b/src/compiler/parse/state/tag.ts\nindex efeb9433b..696a47b64 100644\n--- a/src/compiler/parse/state/tag.ts\n+++ b/src/compiler/parse/state/tag.ts\n@@ -376,7 +376,7 @@ function read_attribute(parser: Parser, unique_names: Set<string>) {\n \n \t\tif (type === 'Binding' && directive_name !== 'this') {\n \t\t\tcheck_unique(directive_name);\n-\t\t} else if (type !== 'EventHandler') {\n+\t\t} else if (type !== 'EventHandler' && type !== 'Action') {\n \t\t\tcheck_unique(name);\n \t\t}\n \n"}
{"instance_id": "sveltejs__svelte-5850", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/runtime/internal/await_block.ts b/src/runtime/internal/await_block.ts\nindex 4b7ca6fd2..85c95437b 100644\n--- a/src/runtime/internal/await_block.ts\n+++ b/src/runtime/internal/await_block.ts\n@@ -33,6 +33,16 @@ export function handle_promise(promise, info) {\n \t\t\t\t\t\tcheck_outros();\n \t\t\t\t\t}\n \t\t\t\t});\n+\t\t\t\t// If we're switching to the same block type (e.g., then -> then),\n+\t\t\t\t// ensure we remove the existing block at this index before mounting a new one\n+\t\t\t\tconst previous = info.blocks[index];\n+\t\t\t\tif (previous) {\n+\t\t\t\t\tgroup_outros();\n+\t\t\t\t\ttransition_out(previous, 1, 1, () => {\n+\t\t\t\t\t\tinfo.blocks[index] = null;\n+\t\t\t\t\t});\n+\t\t\t\t\tcheck_outros();\n+\t\t\t\t}\n \t\t\t} else {\n \t\t\t\tinfo.block.d(1);\n \t\t\t}\n"}
{"instance_id": "sveltejs__svelte-5616", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/site/content/docs/02-template-syntax.md b/site/content/docs/02-template-syntax.md\nindex ac7ca7abf..9a51a5ed6 100644\n--- a/site/content/docs/02-template-syntax.md\n+++ b/site/content/docs/02-template-syntax.md\n@@ -97,9 +97,9 @@ As with elements, `name={name}` can be replaced with the `{name}` shorthand.\n \n ---\n \n-*Spread attributes* allow many attributes or properties to be passed to an element or component at once.\n+*Spread attributes* allow many attributes or properties to be passed to an element, component, or slot at once.\n \n-An element or component can have multiple spread attributes, interspersed with regular ones.\n+An element, component, or slot can have multiple spread attributes, interspersed with regular ones.\n \n ```sv\n <Widget {...things}/>\n@@ -1286,6 +1286,9 @@ Components also support `bind:this`, allowing you to interact with component ins\n ```sv\n <slot prop={value}></slot>\n ```\n+```sv\n+<slot {...$$props}></slot>\n+```\n \n ---\n \ndiff --git a/src/compiler/compile/nodes/Slot.ts b/src/compiler/compile/nodes/Slot.ts\nindex 87b6c1ea9..82e6a01d7 100644\n--- a/src/compiler/compile/nodes/Slot.ts\n+++ b/src/compiler/compile/nodes/Slot.ts\n@@ -10,19 +10,20 @@ export default class Slot extends Element {\n \tchildren: INode[];\n \tslot_name: string;\n \tvalues: Map<string, Attribute> = new Map();\n+\tattributes: Attribute[] = [];\n \n \tconstructor(component: Component, parent: INode, scope: TemplateScope, info: any) {\n \t\tsuper(component, parent, scope, info);\n \n \t\tinfo.attributes.forEach(attr => {\n-\t\t\tif (attr.type !== 'Attribute') {\n+\t\t\tif (attr.type !== 'Attribute' && attr.type !== 'Spread') {\n \t\t\t\tcomponent.error(attr, {\n \t\t\t\t\tcode: 'invalid-slot-directive',\n \t\t\t\t\tmessage: '<slot> cannot have directives'\n \t\t\t\t});\n \t\t\t}\n \n-\t\t\tif (attr.name === 'name') {\n+\t\t\tif (attr.type === 'Attribute' && attr.name === 'name') {\n \t\t\t\tif (attr.value.length !== 1 || attr.value[0].type !== 'Text') {\n \t\t\t\t\tcomponent.error(attr, {\n \t\t\t\t\t\tcode: 'dynamic-slot-name',\n@@ -39,7 +40,11 @@ export default class Slot extends Element {\n \t\t\t\t}\n \t\t\t}\n \n-\t\t\tthis.values.set(attr.name, new Attribute(component, this, scope, attr));\n+\t\t\tconst attribute_obj = new Attribute(component, this, scope, attr);\n+\t\t\tthis.attributes.push(attribute_obj);\n+\t\t\tif (attr.type === 'Attribute') {\n+\t\t\t\tthis.values.set(attr.name, attribute_obj);\n+\t\t\t}\n \t\t});\n \n \t\tif (!this.slot_name) this.slot_name = 'default';\n@@ -49,11 +54,14 @@ export default class Slot extends Element {\n \t\t\t// other slots (which inherit our slot values) that were\n \t\t\t// previously encountered\n \t\t\tcomponent.slots.forEach((slot) => {\n+\t\t\t\t// inherit explicit values if not present\n \t\t\t\tthis.values.forEach((attribute, name) => {\n \t\t\t\t\tif (!slot.values.has(name)) {\n \t\t\t\t\t\tslot.values.set(name, attribute);\n \t\t\t\t\t}\n \t\t\t\t});\n+\t\t\t\t// inherit ordered attributes (including spreads)\n+\t\t\t\tslot.attributes = [...this.attributes, ...slot.attributes];\n \t\t\t});\n \t\t} else if (component.slots.has('default')) {\n \t\t\t// otherwise, go the other way  inherit values from\n@@ -64,6 +72,8 @@ export default class Slot extends Element {\n \t\t\t\t\tthis.values.set(name, attribute);\n \t\t\t\t}\n \t\t\t});\n+\t\t\t// inherit ordered attributes (including spreads)\n+\t\t\tthis.attributes = [...default_slot.attributes, ...this.attributes];\n \t\t}\n \n \t\tcomponent.slots.set(this.slot_name, this);\ndiff --git a/src/compiler/compile/render_dom/wrappers/Slot.ts b/src/compiler/compile/render_dom/wrappers/Slot.ts\nindex 0746de323..25e7bc4b9 100644\n--- a/src/compiler/compile/render_dom/wrappers/Slot.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Slot.ts\n@@ -57,7 +57,7 @@ export default class SlotWrapper extends Wrapper {\n \t\t\tnext_sibling\n \t\t);\n \n-\t\tthis.node.values.forEach(attribute => {\n+\t\tthis.node.attributes.forEach(attribute => {\n \t\t\tadd_to_set(this.dependencies, attribute.dependencies);\n \t\t});\n \n@@ -84,7 +84,7 @@ export default class SlotWrapper extends Wrapper {\n \t\tlet get_slot_changes_fn;\n \t\tlet get_slot_context_fn;\n \n-\t\tif (this.node.values.size > 0) {\n+\t\tif (this.node.attributes.length > 0) {\n \t\t\tget_slot_changes_fn = renderer.component.get_unique_name(`get_${sanitize(slot_name)}_slot_changes`);\n \t\t\tget_slot_context_fn = renderer.component.get_unique_name(`get_${sanitize(slot_name)}_slot_context`);\n \n@@ -92,7 +92,13 @@ export default class SlotWrapper extends Wrapper {\n \n \t\t\tconst dependencies = new Set();\n \n-\t\t\tthis.node.values.forEach(attribute => {\n+\t\t\tlet has_spread = false;\n+\t\t\tthis.node.attributes.forEach(attribute => {\n+\t\t\t\tif (attribute.is_spread) {\n+\t\t\t\t\thas_spread = true;\n+\t\t\t\t\tadd_to_set(dependencies, attribute.dependencies);\n+\t\t\t\t\treturn;\n+\t\t\t\t}\n \t\t\t\tattribute.chunks.forEach(chunk => {\n \t\t\t\t\tif ((chunk as Expression).dependencies) {\n \t\t\t\t\t\tadd_to_set(dependencies, (chunk as Expression).contextual_dependencies);\n@@ -107,14 +113,15 @@ export default class SlotWrapper extends Wrapper {\n \n \t\t\t\tconst dynamic_dependencies = Array.from(attribute.dependencies).filter((name) => this.is_dependency_dynamic(name));\n \n-\t\t\t\tif (dynamic_dependencies.length > 0) {\n+\t\t\t\tif (dynamic_dependencies.length > 0 && attribute.name !== 'name') {\n \t\t\t\t\tchanges.properties.push(p`${attribute.name}: ${renderer.dirty(dynamic_dependencies)}`);\n \t\t\t\t}\n \t\t\t});\n \n+\t\t\tconst slot_changes_expr = has_spread ? x`#dirty` : changes;\n \t\t\trenderer.blocks.push(b`\n-\t\t\t\tconst ${get_slot_changes_fn} = #dirty => ${changes};\n-\t\t\t\tconst ${get_slot_context_fn} = #ctx => ${get_slot_data(this.node.values, block)};\n+\t\t\t\tconst ${get_slot_changes_fn} = #dirty => ${slot_changes_expr};\n+\t\t\t\tconst ${get_slot_context_fn} = #ctx => ${get_slot_data(this.node.attributes, block)};\n \t\t\t`);\n \t\t} else {\n \t\t\tget_slot_changes_fn = 'null';\ndiff --git a/src/compiler/compile/render_ssr/handlers/Slot.ts b/src/compiler/compile/render_ssr/handlers/Slot.ts\nindex f89b619c4..091ebe69b 100644\n--- a/src/compiler/compile/render_ssr/handlers/Slot.ts\n+++ b/src/compiler/compile/render_ssr/handlers/Slot.ts\n@@ -7,7 +7,7 @@ import { get_slot_scope } from './shared/get_slot_scope';\n export default function(node: Slot, renderer: Renderer, options: RenderOptions & {\n \tslot_scopes: Map<any, any>;\n }) {\n-\tconst slot_data = get_slot_data(node.values);\n+\tconst slot_data = get_slot_data(node.attributes);\n \tconst slot = node.get_static_attribute_value('slot');\n \tconst nearest_inline_component = node.find_nearest(/InlineComponent/);\n \ndiff --git a/src/compiler/compile/utils/get_slot_data.ts b/src/compiler/compile/utils/get_slot_data.ts\nindex c7f70aa48..46fa49bc3 100644\n--- a/src/compiler/compile/utils/get_slot_data.ts\n+++ b/src/compiler/compile/utils/get_slot_data.ts\n@@ -3,16 +3,45 @@ import { p, x } from 'code-red';\n import { string_literal } from './stringify';\n import Block from '../render_dom/Block';\n \n-export default function get_slot_data(values: Map<string, Attribute>, block: Block = null) {\n-\treturn {\n-\t\ttype: 'ObjectExpression',\n-\t\tproperties: Array.from(values.values())\n+export default function get_slot_data(values: any, block: Block = null) {\n+\t// values can be either Map<string, Attribute> (legacy) or Attribute[] (ordered including spreads)\n+\tconst list: Attribute[] = Array.isArray(values) ? values : Array.from(values.values());\n+\tconst has_spread = list.some(attr => attr.is_spread);\n+\tif (!has_spread) {\n+\t\treturn {\n+\t\t\ttype: 'ObjectExpression',\n+\t\t\tproperties: list\n+\t\t\t\t.filter(attribute => attribute.name !== 'name')\n+\t\t\t\t.map(attribute => {\n+\t\t\t\t\tconst value = get_value(block, attribute);\n+\t\t\t\t\treturn p`${attribute.name}: ${value}`;\n+\t\t\t\t})\n+\t\t};\n+\t}\n+\t// If spread is present, build merged object in order. Also ensure 'name' is not included in the final object.\n+\tif (block) {\n+\t\tlet merged = x`{}`;\n+\t\tlist\n+\t\t\t.filter(attribute => attribute.name !== 'name')\n+\t\t\t.forEach(attribute => {\n+\t\t\t\tconst src = attribute.is_spread\n+\t\t\t\t\t? x`@get_spread_object(${attribute.expression.manipulate(block)})`\n+\t\t\t\t\t: x`{ ${attribute.name}: ${get_value(block, attribute)} }`;\n+\t\t\t\tmerged = x`@assign(${merged}, ${src})`;\n+\t\t\t});\n+\t\treturn x`(() => { const $$slot_ctx = ${merged}; if ('name' in $$slot_ctx) delete $$slot_ctx.name; return $$slot_ctx; })()`;\n+\t} else {\n+\t\tlet merged = x`{}`;\n+\t\tlist\n \t\t\t.filter(attribute => attribute.name !== 'name')\n-\t\t\t.map(attribute => {\n-\t\t\t\tconst value = get_value(block, attribute);\n-\t\t\t\treturn p`${attribute.name}: ${value}`;\n-\t\t\t})\n-\t};\n+\t\t\t.forEach(attribute => {\n+\t\t\t\tconst src = attribute.is_spread\n+\t\t\t\t\t? attribute.expression.node\n+\t\t\t\t\t: x`{ ${attribute.name}: ${get_value(block, attribute)} }`;\n+\t\t\t\tmerged = x`@_Object.assign(${merged}, ${src})`;\n+\t\t\t});\n+\t\treturn x`(() => { const $$slot_ctx = ${merged}; if ('name' in $$slot_ctx) delete $$slot_ctx.name; return $$slot_ctx; })()`;\n+\t}\n }\n \n function get_value(block: Block, attribute: Attribute) {\n"}
{"instance_id": "sveltejs__svelte-6941", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/Element/Attribute.ts b/src/compiler/compile/render_dom/wrappers/Element/Attribute.ts\nindex 3f57d004b..fb081e295 100644\n--- a/src/compiler/compile/render_dom/wrappers/Element/Attribute.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Element/Attribute.ts\n@@ -204,7 +204,7 @@ export default class AttributeWrapper extends BaseAttributeWrapper {\n \t\tif (this.is_input_value) {\n \t\t\tconst type = element.node.get_static_attribute_value('type');\n \n-\t\t\tif (type === null || type === '' || type === 'text' || type === 'email' || type === 'password') {\n+\t\t\tif (type === null || type === '' || type === 'text' || type === 'email' || type === 'password' || type === 'search') {\n \t\t\t\tcondition = x`${condition} && ${element.var}.${property_name} !== ${should_cache ? last : value}`;\n \t\t\t}\n \t\t}\n"}
{"instance_id": "prettier__prettier-12930", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/language-js/print/typescript.js b/src/language-js/print/typescript.js\nindex 32942f2d7..bd7308d6f 100644\n--- a/src/language-js/print/typescript.js\n+++ b/src/language-js/print/typescript.js\n@@ -414,7 +414,7 @@ function printTypescript(path, options, print) {\n \n       return parts;\n     case \"TSEnumMember\":\n-      parts.push(print(\"id\"));\n+      parts.push(node.computed ? \"[\" : \"\", print(\"id\"), node.computed ? \"]\" : \"\");\n       if (node.initializer) {\n         parts.push(\" = \", print(\"initializer\"));\n       }\n"}
{"instance_id": "prettier__prettier-11000", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/cli/expand-patterns.js b/src/cli/expand-patterns.js\nindex 8e2e4d729..8e066babb 100644\n--- a/src/cli/expand-patterns.js\n+++ b/src/cli/expand-patterns.js\n@@ -76,10 +76,11 @@ async function* expandPatternsInternal(context) {\n           input: pattern,\n         });\n       } else if (stat.isDirectory()) {\n+        const dirPattern = removeTrailingSlash(fixWindowsSlashes(pattern));\n         entries.push({\n           type: \"dir\",\n           glob:\n-            escapePathForGlob(fixWindowsSlashes(pattern)) +\n+            escapePathForGlob(dirPattern) +\n             \"/\" +\n             getSupportedFilesGlob(),\n           input: pattern,\n@@ -211,6 +212,24 @@ function fixWindowsSlashes(pattern) {\n   return isWindows ? pattern.replace(/\\\\/g, \"/\") : pattern;\n }\n \n+/**\n+ * Remove a single trailing slash from POSIX-style paths, but keep root paths\n+ * like \"/\" and Windows drive roots like \"C:/\" intact.\n+ * @param {string} pattern\n+ */\n+function removeTrailingSlash(pattern) {\n+  if (pattern.length <= 1) {\n+    return pattern;\n+  }\n+  // Preserve Windows drive roots (e.g., \"C:/\") and UNC roots (e.g., \"//server\")\n+  const windowsDriveRoot = /^[A-Za-z]:\\/$/;\n+  if (windowsDriveRoot.test(pattern)) {\n+    return pattern;\n+  }\n+  // Remove a single trailing slash if present\n+  return pattern.endsWith(\"/\") ? pattern.slice(0, -1) : pattern;\n+}\n+\n module.exports = {\n   expandPatterns,\n   fixWindowsSlashes,\n"}
{"instance_id": "prettier__prettier-8777", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/main/ast-to-doc.js b/src/main/ast-to-doc.js\nindex 7d861c258..f53207518 100644\n--- a/src/main/ast-to-doc.js\n+++ b/src/main/ast-to-doc.js\n@@ -97,6 +97,57 @@ function callPluginPrintFunction(path, options, printPath, args) {\n \n   // Escape hatch\n   if (printer.hasPrettierIgnore && printer.hasPrettierIgnore(path)) {\n+    // Mark all comments within the ignored subtree as printed to avoid false positives\n+    (function markPrinted(value, seen) {\n+      if (!value || typeof value !== \"object\") {\n+        return;\n+      }\n+      if (seen.has(value)) {\n+        return;\n+      }\n+      seen.add(value);\n+\n+      // If this node has comments attached, mark them as printed\n+      if (Array.isArray(value.comments)) {\n+        for (const c of value.comments) {\n+          if (c && typeof c === \"object\") {\n+            c.printed = true;\n+          }\n+        }\n+      }\n+\n+      // Some parsers may store comments in leadingComments/trailingComments\n+      if (Array.isArray(value.leadingComments)) {\n+        for (const c of value.leadingComments) {\n+          if (c && typeof c === \"object\") {\n+            c.printed = true;\n+          }\n+        }\n+      }\n+      if (Array.isArray(value.trailingComments)) {\n+        for (const c of value.trailingComments) {\n+          if (c && typeof c === \"object\") {\n+            c.printed = true;\n+          }\n+        }\n+      }\n+\n+      // Recurse into child properties\n+      for (const key of Object.keys(value)) {\n+        if (key === \"parent\") {\n+          continue;\n+        }\n+        const child = value[key];\n+        if (Array.isArray(child)) {\n+          for (const item of child) {\n+            markPrinted(item, seen);\n+          }\n+        } else if (child && typeof child === \"object\") {\n+          markPrinted(child, seen);\n+        }\n+      }\n+    })(node, new Set());\n+\n     return options.originalText.slice(\n       options.locStart(node),\n       options.locEnd(node)\ndiff --git a/src/main/core.js b/src/main/core.js\nindex 3faeefc2a..2aa89de91 100644\n--- a/src/main/core.js\n+++ b/src/main/core.js\n@@ -32,13 +32,6 @@ function ensureAllCommentsPrinted(astComments) {\n     return;\n   }\n \n-  for (let i = 0; i < astComments.length; ++i) {\n-    if (isNodeIgnoreComment(astComments[i])) {\n-      // If there's a prettier-ignore, we're not printing that sub-tree so we\n-      // don't know if the comments was printed or not.\n-      return;\n-    }\n-  }\n \n   astComments.forEach((comment) => {\n     if (!comment.printed) {\n"}
{"instance_id": "prettier__prettier-14400", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/language-html/utils/index.js b/src/language-html/utils/index.js\nindex 943ae6595..abe37f1ba 100644\n--- a/src/language-html/utils/index.js\n+++ b/src/language-html/utils/index.js\n@@ -109,6 +109,7 @@ function isScriptLikeTag(node) {\n     (node.fullName === \"script\" ||\n       node.fullName === \"style\" ||\n       node.fullName === \"svg:style\" ||\n+      node.fullName === \"svg:script\" ||\n       (isUnknownNamespace(node) &&\n         (node.name === \"script\" || node.name === \"style\")))\n   );\n"}
{"instance_id": "prettier__prettier-9850", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "prettier__prettier-8046", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/language-js/parser-babel.js b/src/language-js/parser-babel.js\nindex 864bd3a38..ce890ab17 100644\n--- a/src/language-js/parser-babel.js\n+++ b/src/language-js/parser-babel.js\n@@ -98,6 +98,31 @@ function createParse(parseMethod, ...pluginCombinations) {\n         }\n       );\n     }\n+    // If Babel recovered from errors, surface the first error instead of printing\n+    if (ast && Array.isArray(ast.errors) && ast.errors.length > 0) {\n+      const error = ast.errors[0];\n+      throw createError(\n+        error.message.replace(/ \\(.*\\)/, \"\"),\n+        {\n+          start: {\n+            line: error.loc.line,\n+            column: error.loc.column + 1,\n+          },\n+        }\n+      );\n+    }\n+    if (ast && ast.program && Array.isArray(ast.program.errors) && ast.program.errors.length > 0) {\n+      const error = ast.program.errors[0];\n+      throw createError(\n+        error.message.replace(/ \\(.*\\)/, \"\"),\n+        {\n+          start: {\n+            line: error.loc.line,\n+            column: error.loc.column + 1,\n+          },\n+        }\n+      );\n+    }\n     delete ast.tokens;\n     return postprocess(ast, { ...opts, originalText: text });\n   };\n"}
{"instance_id": "prettier__prettier-5025", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/language-markdown/printer-markdown.js b/src/language-markdown/printer-markdown.js\nindex b6e66b2f8..7b560bcfb 100644\n--- a/src/language-markdown/printer-markdown.js\n+++ b/src/language-markdown/printer-markdown.js\n@@ -352,12 +352,24 @@ function genericPrint(path, options, print) {\n         group(\n           concat([\n             align(\n-              \" \".repeat(options.tabWidth),\n+              options.useTabs ? \"\\t\" : \"    \",\n               printChildren(path, options, print, {\n-                processor: (childPath, index) =>\n-                  index === 0\n-                    ? group(concat([softline, softline, childPath.call(print)]))\n-                    : childPath.call(print)\n+                processor: (childPath, index) => {\n+                  const childNode = childPath.getValue();\n+                  if (index === 0) {\n+                    if (childNode.type === \"paragraph\") {\n+                      return mapDoc(childPath.call(print), doc =>\n+                        doc && doc.type === \"line\" && !doc.hard\n+                          ? doc.soft ? \"\" : \" \"\n+                          : doc && doc.type === \"if-break\"\n+                            ? doc.flatContents || \"\"\n+                            : doc\n+                      );\n+                    }\n+                    return group(concat([softline, softline, childPath.call(print)]));\n+                  }\n+                  return childPath.call(print);\n+                }\n               })\n             ),\n             nextNode && nextNode.type === \"footnoteDefinition\" ? softline : \"\"\n"}
{"instance_id": "prettier__prettier-4667", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/api.md b/docs/api.md\nindex 29ec7d003..e8d5ddf0b 100644\n--- a/docs/api.md\n+++ b/docs/api.md\n@@ -85,7 +85,7 @@ As you repeatedly call `resolveConfig`, the file system structure will be cached\n \n Setting `options.ignorePath` (`string`) and `options.withNodeModules` (`boolean`) influence the value of `ignored` (`false` by default).\n \n-Providing [plugin](./plugins.md) paths in `options.plugins` (`string[]`) helps extract `inferredParser` for files that are not supported by Prettier core.\n+Providing [plugin](./plugins.md) paths in `options.plugins` (`string[]`) helps extract `inferredParser` for files that are not supported by Prettier core. If these options originate from a configuration file, relative paths are interpreted relative to that files location; when passed directly via the CLI/API they are interpreted relative to the current working directory.\n \n Use `prettier.getFileInfo.sync(filePath [, options])` if you'd like to use sync version.\n \ndiff --git a/docs/configuration.md b/docs/configuration.md\nindex 05703ae3d..9c20d3449 100644\n--- a/docs/configuration.md\n+++ b/docs/configuration.md\n@@ -11,7 +11,7 @@ Prettier uses [cosmiconfig](https://github.com/davidtheclark/cosmiconfig) for co\n \n The configuration file will be resolved starting from the location of the file being formatted, and searching up the file tree until a config file is (or isn't) found.\n \n-The options to the configuration file are the same as the [API options](options.md).\n+The options to the configuration file are the same as the [API options](options.md). Path-typed options such as `plugins` and `pluginSearchDirs` may use relative paths; these are resolved relative to the configuration files directory.\n \n ## Basic Configuration\n \ndiff --git a/docs/plugins.md b/docs/plugins.md\nindex a6a0c567b..205c801d4 100644\n--- a/docs/plugins.md\n+++ b/docs/plugins.md\n@@ -37,6 +37,8 @@ Prettier expects each of `pluginSearchDirs` to contain `node_modules` subdirecto\n \n Providing at least one path to `--plugin-search-dir`/`pluginSearchDirs` turns off plugin autoloading in the default directory (i.e. `node_modules` above `prettier` binary).\n \n+When specified in a configuration file, relative paths in `plugins` and `pluginSearchDirs` (strings beginning with `./` or `../`) are resolved relative to the configuration files directory. When provided via the CLI or API options directly, relative paths are resolved relative to the current working directory. Package names and absolute paths are unaffected.\n+\n ## Official Plugins\n \n - [`@prettier/plugin-python`](https://github.com/prettier/plugin-python)\ndiff --git a/src/cli/util.js b/src/cli/util.js\nindex 5ea6fba30..a09a66288 100644\n--- a/src/cli/util.js\n+++ b/src/cli/util.js\n@@ -236,7 +236,7 @@ function getOptionsForFile(context, filepath) {\n \n   const hasPlugins = options && options.plugins;\n   if (hasPlugins) {\n-    pushContextPlugins(context, options.plugins);\n+    pushContextPlugins(context, options.plugins, options.pluginSearchDirs);\n   }\n \n   const appliedOptions = Object.assign(\ndiff --git a/src/config/resolve-config.js b/src/config/resolve-config.js\nindex 229caf3d5..44d50eb63 100644\n--- a/src/config/resolve-config.js\n+++ b/src/config/resolve-config.js\n@@ -52,6 +52,22 @@ function _resolveConfig(filePath, opts, sync) {\n       return null;\n     }\n \n+    // Normalize relative plugin and pluginSearchDirs paths from config to be relative to the config file location\n+    if (result && result.filepath) {\n+      const configDir = path.dirname(result.filepath);\n+      const normalizeList = list =>\n+        Array.isArray(list)\n+          ? list.map(item =>\n+              typeof item === \"string\" && item[0] === \".\"\n+                ? path.resolve(configDir, item)\n+                : item\n+            )\n+          : list;\n+\n+      merged.plugins = normalizeList(merged.plugins);\n+      merged.pluginSearchDirs = normalizeList(merged.pluginSearchDirs);\n+    }\n+\n     return merged;\n   };\n \n"}
{"instance_id": "prettier__prettier-6604", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/language-js/clean.js b/src/language-js/clean.js\nindex b058c8cf7..084d8487a 100644\n--- a/src/language-js/clean.js\n+++ b/src/language-js/clean.js\n@@ -60,10 +60,6 @@ function clean(ast, newObj, parent) {\n     delete newObj.specifiers;\n   }\n \n-  // (TypeScript) bypass TSParenthesizedType\n-  if (ast.type === \"TSParenthesizedType\") {\n-    return newObj.typeAnnotation;\n-  }\n \n   // (TypeScript) Bypass `& foo` and `| foo` into `foo`\n   // https://github.com/microsoft/TypeScript/issues/30995\ndiff --git a/src/language-js/printer-estree.js b/src/language-js/printer-estree.js\nindex 47aafc252..438e3bb25 100644\n--- a/src/language-js/printer-estree.js\n+++ b/src/language-js/printer-estree.js\n@@ -3207,13 +3207,29 @@ function printPathNoParens(path, options, print, args) {\n       ]);\n     case \"TSLiteralType\":\n       return path.call(print, \"literal\");\n-    case \"TSIndexedAccessType\":\n+    case \"TSIndexedAccessType\": {\n+      // Parenthesize the objectType when necessary to preserve semantics\n+      const objectTypeNode = (() => {\n+        let t = n.objectType;\n+        while (t && t.type === \"TSParenthesizedType\") {\n+          t = t.typeAnnotation;\n+        }\n+        return t || n.objectType;\n+      })();\n+      const shouldParenObject =\n+        objectTypeNode.type === \"TSUnionType\" ||\n+        objectTypeNode.type === \"TSIntersectionType\" ||\n+        objectTypeNode.type === \"TSConditionalType\" ||\n+        objectTypeNode.type === \"TSTypeOperator\";\n+\n+      const printedObject = path.call(print, \"objectType\");\n       return concat([\n-        path.call(print, \"objectType\"),\n+        shouldParenObject ? concat([\"(\", printedObject, \")\"]) : printedObject,\n         \"[\",\n         path.call(print, \"indexType\"),\n         \"]\"\n       ]);\n+    }\n     case \"TSConstructSignatureDeclaration\":\n     case \"TSCallSignatureDeclaration\":\n     case \"TSConstructorType\": {\n@@ -3435,13 +3451,31 @@ function printPathNoParens(path, options, print, args) {\n \n     case \"TSConditionalType\":\n       return printTernaryOperator(path, options, print, {\n-        beforeParts: () => [\n-          path.call(print, \"checkType\"),\n-          \" \",\n-          \"extends\",\n-          \" \",\n-          path.call(print, \"extendsType\")\n-        ],\n+        beforeParts: () => {\n+          const checkTypeNode = n.checkType;\n+          const extendsTypeNode = n.extendsType;\n+\n+          const unwrap = node => {\n+            while (node && node.type === \"TSParenthesizedType\") {\n+              node = node.typeAnnotation;\n+            }\n+            return node;\n+          };\n+\n+          const needsParenCheck = unwrap(checkTypeNode).type === \"TSConditionalType\";\n+          const needsParenExtends = unwrap(extendsTypeNode).type === \"TSConditionalType\";\n+\n+          const printedCheck = path.call(print, \"checkType\");\n+          const printedExtends = path.call(print, \"extendsType\");\n+\n+          return [\n+            needsParenCheck ? concat([\"(\", printedCheck, \")\"]) : printedCheck,\n+            \" \",\n+            \"extends\",\n+            \" \",\n+            needsParenExtends ? concat([\"(\", printedExtends, \")\"]) : printedExtends\n+          ];\n+        },\n         afterParts: () => [],\n         shouldCheckJsx: false,\n         conditionalNodeType: \"TSConditionalType\",\n"}
{"instance_id": "prettier__prettier-3515", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/cli-util.js b/src/cli-util.js\nindex 27c0494d2..97a4ef943 100644\n--- a/src/cli-util.js\n+++ b/src/cli-util.js\n@@ -305,7 +305,7 @@ function eachFilename(argv, patterns, callback) {\n \n function formatFiles(argv) {\n   eachFilename(argv, argv.__filePatterns, (filename, options) => {\n-    if (argv[\"write\"] && process.stdout.isTTY) {\n+    if (argv[\"write\"] && process.stdout.isTTY && process.env[logger.ENV_LOG_LEVEL] !== \"silent\") {\n       // Don't use `console.log` here since we need to replace this line.\n       process.stdout.write(filename);\n     }\n@@ -346,7 +346,7 @@ function formatFiles(argv) {\n     }\n \n     if (argv[\"write\"]) {\n-      if (process.stdout.isTTY) {\n+      if (process.stdout.isTTY && process.env[logger.ENV_LOG_LEVEL] !== \"silent\") {\n         // Remove previously printed filename to log it with duration.\n         readline.clearLine(process.stdout, 0);\n         readline.cursorTo(process.stdout, 0, null);\n@@ -355,13 +355,13 @@ function formatFiles(argv) {\n       // Don't write the file if it won't change in order not to invalidate\n       // mtime based caches.\n       if (output === input) {\n-        if (!argv[\"list-different\"]) {\n+        if (!argv[\"list-different\"] && process.env[logger.ENV_LOG_LEVEL] !== \"silent\") {\n           console.log(`${chalk.grey(filename)} ${Date.now() - start}ms`);\n         }\n       } else {\n         if (argv[\"list-different\"]) {\n           console.log(filename);\n-        } else {\n+        } else if (process.env[logger.ENV_LOG_LEVEL] !== \"silent\") {\n           console.log(`${filename} ${Date.now() - start}ms`);\n         }\n \n"}
{"instance_id": "prettier__prettier-666", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/comments.js b/src/comments.js\nindex d97dae762..f8349fc6c 100644\n--- a/src/comments.js\n+++ b/src/comments.js\n@@ -140,6 +140,7 @@ function attach(comments, ast, text) {\n       // If a comment exists on its own line, prefer a leading comment.\n       // We also need to check if it's the first line of the file.\n       if (\n+        handleConditionalExpressionComments(enclosingNode, followingNode, comment) ||\n         handleMemberExpressionComment(enclosingNode, followingNode, comment) ||\n           handleIfStatementComments(enclosingNode, followingNode, comment) ||\n           handleTryStatementComments(enclosingNode, followingNode, comment)\n@@ -159,7 +160,9 @@ function attach(comments, ast, text) {\n     } else if (util.hasNewline(text, locEnd(comment))) {\n       // There is content before this comment on the same line, but\n       // none after it, so prefer a trailing comment of the previous node.\n-      if (precedingNode) {\n+      if (handleConditionalExpressionComments(enclosingNode, followingNode, comment)) {\n+        // We're good\n+      } else if (precedingNode) {\n         addTrailingComment(precedingNode, comment);\n       } else if (followingNode) {\n         addLeadingComment(followingNode, comment);\n@@ -176,14 +179,18 @@ function attach(comments, ast, text) {\n       // be attached to the next or previous node. In the last case,\n       // simply attach the right node;\n       if (precedingNode && followingNode) {\n-        const tieCount = tiesToBreak.length;\n-        if (tieCount > 0) {\n-          var lastTie = tiesToBreak[tieCount - 1];\n-          if (lastTie.followingNode !== comment.followingNode) {\n-            breakTies(tiesToBreak, text);\n+        if (handleConditionalExpressionComments(enclosingNode, followingNode, comment)) {\n+          // We're good\n+        } else {\n+          const tieCount = tiesToBreak.length;\n+          if (tieCount > 0) {\n+            var lastTie = tiesToBreak[tieCount - 1];\n+            if (lastTie.followingNode !== comment.followingNode) {\n+              breakTies(tiesToBreak, text);\n+            }\n           }\n+          tiesToBreak.push(comment);\n         }\n-        tiesToBreak.push(comment);\n       } else if (precedingNode) {\n         addTrailingComment(precedingNode, comment);\n       } else if (followingNode) {\n@@ -353,6 +360,21 @@ function handleTryStatementComments(enclosingNode, followingNode, comment) {\n   return false;\n }\n \n+function handleConditionalExpressionComments(enclosingNode, followingNode, comment) {\n+  if (\n+    !enclosingNode || enclosingNode.type !== \"ConditionalExpression\" || !followingNode\n+  ) {\n+    return false;\n+  }\n+\n+  if (followingNode === enclosingNode.consequent || followingNode === enclosingNode.alternate) {\n+    addLeadingComment(followingNode, comment);\n+    return true;\n+  }\n+\n+  return false;\n+}\n+\n function handleMemberExpressionComment(enclosingNode, followingNode, comment) {\n   if (\n     enclosingNode &&\n@@ -433,6 +455,9 @@ function printTrailingComment(commentPath, print, options, parentNode) {\n     return concat([\" \", contents]);\n   }\n \n+  if (parentNode && parentNode.type === \"ConditionalExpression\") {\n+    return concat([hardline, contents]);\n+  }\n   return concat([lineSuffix(\" \" + contents), !isBlock ? breakParent : \"\"]);\n }\n \n"}
{"instance_id": "prettier__prettier-661", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/README.md b/README.md\nindex 39fd19e3f..120962d67 100644\n--- a/README.md\n+++ b/README.md\n@@ -148,6 +148,9 @@ prettier.format(source, {\n   // Controls the printing of spaces inside object literals\n   bracketSpacing: true,\n \n+  // Place the > of a multi-line JSX element on the same line as the last prop\n+  jsxBracketSameLine: false,\n+\n   // Which parser to use. Valid options are 'flow' and 'babylon'\n   parser: 'babylon'\n });\ndiff --git a/src/options.js b/src/options.js\nindex e696e7eed..3d0551a22 100644\n--- a/src/options.js\n+++ b/src/options.js\n@@ -14,6 +14,8 @@ var defaults = {\n   trailingComma: false,\n   // Controls the printing of spaces inside array and objects\n   bracketSpacing: true,\n+  // Place the > of a multi-line JSX element on the same line as the last prop\n+  jsxBracketSameLine: false,\n   // Which parser to use. Valid options are 'flow' and 'babylon'\n   parser: \"babylon\"\n };\ndiff --git a/src/printer.js b/src/printer.js\nindex b99391c46..4e04eecd7 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -1219,7 +1219,9 @@ function genericPrintNoParens(path, options, print) {\n                 path.map(attr => concat([line, print(attr)]), \"attributes\")\n               )\n             ),\n-            n.selfClosing ? line : softline\n+            options.jsxBracketSameLine\n+              ? (n.selfClosing ? \" \" : ifBreak(\" \", \"\"))\n+              : (n.selfClosing ? line : softline)\n           ]),\n           n.selfClosing ? \"/>\" : \">\"\n         ])\n"}
{"instance_id": "prettier__prettier-361", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/printer.js b/src/printer.js\nindex 2468bbdba..9ca30953a 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -1841,24 +1841,52 @@ function printExportDeclaration(path, options, print) {\n       ) {\n         parts.push(\"*\");\n       } else {\n-        parts.push(\n-          decl.exportKind === \"type\" ? \"type \" : \"\",\n-          multilineGroup(\n-            concat([\n-              \"{\",\n-              indent(\n-                options.tabWidth,\n-                concat([\n-                  options.bracketSpacing ? line : softline,\n-                  join(concat([ \",\", line ]), path.map(print, \"specifiers\"))\n-                ])\n-              ),\n-              ifBreak(options.trailingComma ? \",\" : \"\"),\n-              options.bracketSpacing ? line : softline,\n-              \"}\"\n-            ])\n-          )\n+        var standaloneSpecifiers = [];\n+        var namedSpecifiers = [];\n+\n+        path.each(\n+          function(specifierPath) {\n+            var value = specifierPath.getValue();\n+            if (\n+              namedTypes.ExportDefaultSpecifier.check(value) ||\n+                namedTypes.ExportNamespaceSpecifier.check(value)\n+            ) {\n+              standaloneSpecifiers.push(print(specifierPath));\n+            } else {\n+              namedSpecifiers.push(print(specifierPath));\n+            }\n+          },\n+          \"specifiers\"\n         );\n+\n+        if (standaloneSpecifiers.length > 0) {\n+          parts.push(join(\", \", standaloneSpecifiers));\n+        }\n+\n+        if (standaloneSpecifiers.length > 0 && namedSpecifiers.length > 0) {\n+          parts.push(\", \");\n+        }\n+\n+        if (namedSpecifiers.length > 0) {\n+          parts.push(\n+            decl.exportKind === \"type\" ? \"type \" : \"\",\n+            multilineGroup(\n+              concat([\n+                \"{\",\n+                indent(\n+                  options.tabWidth,\n+                  concat([\n+                    options.bracketSpacing ? line : softline,\n+                    join(concat([ \",\", line ]), namedSpecifiers)\n+                  ])\n+                ),\n+                ifBreak(options.trailingComma ? \",\" : \"\"),\n+                options.bracketSpacing ? line : softline,\n+                \"}\"\n+              ])\n+            )\n+          );\n+        }\n       }\n     } else {\n       parts.push(\"{}\");\n"}
{"instance_id": "apolloconfig__apollo-4464", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "apolloconfig__apollo-4568", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "trinodb__trino-2768", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-docs/src/main/sphinx/sql/set-role.rst b/presto-docs/src/main/sphinx/sql/set-role.rst\nindex 9640d80769e..db6e868e380 100644\n--- a/presto-docs/src/main/sphinx/sql/set-role.rst\n+++ b/presto-docs/src/main/sphinx/sql/set-role.rst\n@@ -13,6 +13,7 @@ Description\n -----------\n \n ``SET ROLE`` sets the enabled role for the current session in the current catalog.\n+The statement operates on the current session catalog and fails if the current session catalog is not set or does not exist.\n \n ``SET ROLE role`` enables a single specified role for the current session.\n For the ``SET ROLE role`` statement to succeed, the user executing it should\ndiff --git a/presto-main/src/main/java/io/prestosql/Session.java b/presto-main/src/main/java/io/prestosql/Session.java\nindex f7a73e50da1..30967ad8e0e 100644\n--- a/presto-main/src/main/java/io/prestosql/Session.java\n+++ b/presto-main/src/main/java/io/prestosql/Session.java\n@@ -328,9 +328,13 @@ public final class Session\n         for (Entry<String, SelectedRole> entry : identity.getRoles().entrySet()) {\n             String catalogName = entry.getKey();\n             SelectedRole role = entry.getValue();\n-            CatalogName catalog = transactionManager.getOptionalCatalogMetadata(transactionId, catalogName)\n-                    .orElseThrow(() -> new PrestoException(NOT_FOUND, \"Catalog does not exist: \" + catalogName))\n-                    .getCatalogName();\n+            Optional<CatalogName> optionalCatalog = transactionManager.getOptionalCatalogMetadata(transactionId, catalogName)\n+                    .map(io.prestosql.metadata.CatalogMetadata::getCatalogName);\n+            if (!optionalCatalog.isPresent()) {\n+                // Ignore roles for catalogs that do not exist\n+                continue;\n+            }\n+            CatalogName catalog = optionalCatalog.get();\n             if (role.getType() == SelectedRole.Type.ROLE) {\n                 accessControl.checkCanSetRole(new SecurityContext(transactionId, identity), role.getRole().get(), catalogName);\n             }\ndiff --git a/presto-main/src/main/java/io/prestosql/execution/SetRoleTask.java b/presto-main/src/main/java/io/prestosql/execution/SetRoleTask.java\nindex 8b0319c8888..dbf2cca8837 100644\n--- a/presto-main/src/main/java/io/prestosql/execution/SetRoleTask.java\n+++ b/presto-main/src/main/java/io/prestosql/execution/SetRoleTask.java\n@@ -18,6 +18,7 @@ import io.prestosql.Session;\n import io.prestosql.metadata.Metadata;\n import io.prestosql.security.AccessControl;\n import io.prestosql.security.SecurityContext;\n+import io.prestosql.spi.PrestoException;\n import io.prestosql.spi.security.SelectedRole;\n import io.prestosql.sql.tree.Expression;\n import io.prestosql.sql.tree.SetRole;\n@@ -27,6 +28,7 @@ import java.util.List;\n \n import static com.google.common.util.concurrent.Futures.immediateFuture;\n import static io.prestosql.metadata.MetadataUtil.createCatalogName;\n+import static io.prestosql.spi.StandardErrorCode.NOT_FOUND;\n import static java.util.Locale.ENGLISH;\n \n public class SetRoleTask\n@@ -43,6 +45,9 @@ public class SetRoleTask\n     {\n         Session session = stateMachine.getSession();\n         String catalog = createCatalogName(session, statement);\n+        if (!metadata.getCatalogHandle(session, catalog).isPresent()) {\n+            throw new PrestoException(NOT_FOUND, \"Catalog does not exist: \" + catalog);\n+        }\n         if (statement.getType() == SetRole.Type.ROLE) {\n             accessControl.checkCanSetRole(\n                     SecurityContext.of(session),\n"}
{"instance_id": "sveltejs__svelte-1095", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/nodes/Attribute.ts b/src/generators/nodes/Attribute.ts\nindex 639870536..f4eabc843 100644\n--- a/src/generators/nodes/Attribute.ts\n+++ b/src/generators/nodes/Attribute.ts\n@@ -5,6 +5,7 @@ import { DomGenerator } from '../dom/index';\n import Node from './shared/Node';\n import Element from './Element';\n import Block from '../dom/Block';\n+import canonicalizeAttributeName from '../../utils/canonicalAttributeName';\n \n export interface StyleProp {\n \tkey: string;\n@@ -83,7 +84,7 @@ export default class Attribute {\n \t\tconst isDataSet = /^data-/.test(name) && !this.generator.legacy && !node.namespace;\n \t\tconst camelCaseName = isDataSet ? name.replace('data-', '').replace(/(-\\w)/g, function (m) {\n \t\t\treturn m[1].toUpperCase();\n-\t\t}) : name;\n+\t\t}) : (node.namespace ? canonicalizeAttributeName(node.namespace, node.name, name) : name);\n \n \t\tif (isDynamic) {\n \t\t\tlet value;\n@@ -198,9 +199,9 @@ export default class Attribute {\n \t\t\t\tupdater = `${node.var}.dataset.${camelCaseName} = ${shouldCache || isSelectValueAttribute ? last : value};`;\n \t\t\t} else {\n \t\t\t\tblock.builders.hydrate.addLine(\n-\t\t\t\t\t`${method}(${node.var}, \"${name}\", ${init});`\n+\t\t\t\t\t`${method}(${node.var}, \"${node.namespace ? canonicalizeAttributeName(node.namespace, node.name, name) : name}\", ${init});`\n \t\t\t\t);\n-\t\t\t\tupdater = `${method}(${node.var}, \"${name}\", ${shouldCache || isSelectValueAttribute ? last : value});`;\n+\t\t\t\tupdater = `${method}(${node.var}, \"${node.namespace ? canonicalizeAttributeName(node.namespace, node.name, name) : name}\", ${shouldCache || isSelectValueAttribute ? last : value});`;\n \t\t\t}\n \n \t\t\tif (allDependencies.size || hasChangeableIndex || isSelectValueAttribute) {\n@@ -232,7 +233,7 @@ export default class Attribute {\n \t\t\t\tisLegacyInputType ? `@setInputType(${node.var}, ${value});` :\n \t\t\t\tpropertyName ? `${node.var}.${propertyName} = ${value};` :\n \t\t\t\t\tisDataSet ? `${node.var}.dataset.${camelCaseName} = ${value};` :\n-\t\t\t\t`${method}(${node.var}, \"${name}\", ${value});`\n+\t\t\t\t`${method}(${node.var}, \"${node.namespace ? canonicalizeAttributeName(node.namespace, node.name, name) : name}\", ${value});`\n \t\t\t);\n \n \t\t\tblock.builders.hydrate.addLine(statement);\ndiff --git a/src/generators/nodes/Element.ts b/src/generators/nodes/Element.ts\nindex ab9c5b8dc..a583605e4 100644\n--- a/src/generators/nodes/Element.ts\n+++ b/src/generators/nodes/Element.ts\n@@ -13,6 +13,7 @@ import Ref from './Ref';\n import Transition from './Transition';\n import Text from './Text';\n import * as namespaces from '../../utils/namespaces';\n+import canonicalizeAttributeName from '../../utils/canonicalAttributeName';\n \n export default class Element extends Node {\n \ttype: 'Element';\n@@ -690,7 +691,7 @@ function getClaimStatement(\n ) {\n \tconst attributes = node.attributes\n \t\t.filter((attr: Node) => attr.type === 'Attribute')\n-\t\t.map((attr: Node) => `${quoteProp(attr.name, generator.legacy)}: true`)\n+\t\t.map((attr: Node) => `${quoteProp(namespace === namespaces.svg ? canonicalizeAttributeName(namespace, node.name, attr.name) : attr.name, generator.legacy)}: true`)\n \t\t.join(', ');\n \n \tconst name = namespace ? node.name : node.name.toUpperCase();\ndiff --git a/src/generators/server-side-rendering/visitors/Element.ts b/src/generators/server-side-rendering/visitors/Element.ts\nindex db728d6e8..f4885e0b7 100644\n--- a/src/generators/server-side-rendering/visitors/Element.ts\n+++ b/src/generators/server-side-rendering/visitors/Element.ts\n@@ -7,6 +7,8 @@ import Element from '../../nodes/Element';\n import Block from '../Block';\n import { Node } from '../../../interfaces';\n import stringifyAttributeValue from './shared/stringifyAttributeValue';\n+import canonicalizeAttributeName from '../../../utils/canonicalAttributeName';\n+import * as namespaces from '../../../utils/namespaces';\n \n export default function visitElement(\n \tgenerator: SsrGenerator,\n@@ -36,7 +38,8 @@ export default function visitElement(\n \t\tif (attribute.name === 'value' && node.name === 'textarea') {\n \t\t\ttextareaContents = stringifyAttributeValue(block, attribute.value);\n \t\t} else {\n-\t\t\tlet str = ` ${attribute.name}`;\n+\t\t\tconst renderedName = node.namespace === namespaces.svg ? canonicalizeAttributeName(node.namespace, node.name, attribute.name) : attribute.name;\n+\t\t\tlet str = ` ${renderedName}`;\n \n \t\t\tif (attribute.value !== true) {\n \t\t\t\tstr += `=\"${stringifyAttributeValue(block, attribute.value)}\"`;\ndiff --git a/src/utils/canonicalAttributeName.ts b/src/utils/canonicalAttributeName.ts\nnew file mode 100644\nindex 000000000..baa779bb9\n--- /dev/null\n+++ b/src/utils/canonicalAttributeName.ts\n@@ -0,0 +1,9 @@\n+import { svg } from './namespaces';\n+\n+export default function canonicalizeAttributeName(namespace: string, elementName: string, attributeName: string) {\n+\t// Currently only normalize known case-sensitive SVG attribute variants\n+\tif (namespace === svg) {\n+\t\tif (attributeName && attributeName.toLowerCase() === 'viewbox') return 'viewBox';\n+\t}\n+\treturn attributeName;\n+}\ndiff --git a/src/validate/html/validateElement.ts b/src/validate/html/validateElement.ts\nindex 2572fd29d..b2b9a2027 100644\n--- a/src/validate/html/validateElement.ts\n+++ b/src/validate/html/validateElement.ts\n@@ -218,6 +218,11 @@ export default function validateElement(\n \t\t\tif (attribute.name === 'slot' && !isComponent) {\n \t\t\t\tcheckSlotAttribute(validator, node, attribute, stack);\n \t\t\t}\n+\n+\t\t\t// Warn for common case-sensitive SVG attribute mistakes\n+\t\t\tif (node.namespace === namespaces.svg && attribute.name && attribute.name.toLowerCase() === 'viewbox' && attribute.name !== 'viewBox') {\n+\t\t\t\tvalidator.warn(`SVG attribute 'viewBox' is case-sensitive; did you mean 'viewBox' instead of '${attribute.name}'?`, attribute.start);\n+\t\t\t}\n \t\t}\n \t});\n }\n"}
{"instance_id": "sveltejs__svelte-1116", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/server-side-rendering/index.ts b/src/generators/server-side-rendering/index.ts\nindex 37bf859da..32dfc2d01 100644\n--- a/src/generators/server-side-rendering/index.ts\n+++ b/src/generators/server-side-rendering/index.ts\n@@ -81,9 +81,7 @@ export default function ssr(\n \n \tif (storeProps.length > 0) {\n \t\tconst initialize = `_init([${storeProps.map(prop => `\"${prop.slice(1)}\"`)}])`\n-\t\tif (options.store || templateProperties.store) {\n-\t\t\tinitialState.push(`options.store.${initialize}`);\n-\t\t}\n+\t\tinitialState.push(`options.store ? options.store.${initialize} : {}`);\n \t}\n \n \tif (templateProperties.data) {\ndiff --git a/src/generators/server-side-rendering/visitors/Component.ts b/src/generators/server-side-rendering/visitors/Component.ts\nindex 4843010fc..9126b8c3b 100644\n--- a/src/generators/server-side-rendering/visitors/Component.ts\n+++ b/src/generators/server-side-rendering/visitors/Component.ts\n@@ -88,7 +88,7 @@ export default function visitComponent(\n \n \tconst options = [];\n \tif (generator.options.store) {\n-\t\toptions.push(`store: options.store`);\n+\t\toptions.push(`store: (options.store || (${expression}.store && ${expression}.store()))`);\n \t}\n \n \tif (node.children.length) {\n"}
{"instance_id": "sveltejs__svelte-5452", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_dom/invalidate.ts b/src/compiler/compile/render_dom/invalidate.ts\nindex b045db079..676374d41 100644\n--- a/src/compiler/compile/render_dom/invalidate.ts\n+++ b/src/compiler/compile/render_dom/invalidate.ts\n@@ -54,7 +54,7 @@ export function invalidate(renderer: Renderer, scope: Scope, node: Node, names:\n \t\t\t\t)\n \t\t\t);\n \n-\t\t\tif (pass_value) {\n+\t\t\tif (pass_value && !is_store_value) {\n \t\t\t\textra_args.unshift({\n \t\t\t\t\ttype: 'Identifier',\n \t\t\t\t\tname: head.name\n@@ -74,6 +74,10 @@ export function invalidate(renderer: Renderer, scope: Scope, node: Node, names:\n \t\t\t\tinvalidate = x`${subscribe}(${invalidate})`;\n \t\t\t}\n \n+\t\t\tif (is_store_value && extra_args.length) {\n+\t\t\t\treturn [invalidate, ...extra_args];\n+\t\t\t}\n+\n \t\t\treturn invalidate;\n \t\t}\n \t}\n"}
{"instance_id": "sveltejs__svelte-4558", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/EachBlock.ts b/src/compiler/compile/render_dom/wrappers/EachBlock.ts\nindex f0dfa5fbc..488f31dae 100644\n--- a/src/compiler/compile/render_dom/wrappers/EachBlock.ts\n+++ b/src/compiler/compile/render_dom/wrappers/EachBlock.ts\n@@ -423,7 +423,7 @@ export default class EachBlockWrapper extends Wrapper {\n \t\tif (all_dependencies.size) {\n \t\t\tblock.chunks.update.push(b`\n \t\t\t\tif (${block.renderer.dirty(Array.from(all_dependencies))}) {\n-\t\t\t\t\tconst ${this.vars.each_block_value} = ${snippet};\n+\t\t\t\t\t${this.vars.each_block_value} = ${snippet};\n \t\t\t\t\t${this.renderer.options.dev && b`@validate_each_argument(${this.vars.each_block_value});`}\n \n \t\t\t\t\t${this.block.has_outros && b`@group_outros();`}\n"}
{"instance_id": "sveltejs__svelte-1227", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/nodes/Element.ts b/src/generators/nodes/Element.ts\nindex 69997e077..db9c5f568 100644\n--- a/src/generators/nodes/Element.ts\n+++ b/src/generators/nodes/Element.ts\n@@ -735,7 +735,10 @@ function stringifyAttributeValue(value: Node | true) {\n \tif (value === true) return '';\n \tif (value.length === 0) return `=\"\"`;\n \n-\tconst data = value[0].data;\n+\tlet data = '';\n+\tfor (let i = 0; i < value.length; i += 1) {\n+\t\tdata += value[i].data;\n+\t}\n \treturn `=${JSON.stringify(data)}`;\n }\n \n"}
{"instance_id": "sveltejs__svelte-6564", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/site/content/docs/02-template-syntax.md b/site/content/docs/02-template-syntax.md\nindex ca0c1d499..b50041029 100644\n--- a/site/content/docs/02-template-syntax.md\n+++ b/site/content/docs/02-template-syntax.md\n@@ -304,6 +304,9 @@ An each block can also have an `{:else}` clause, which is rendered if the list i\n {#await expression then name}...{/await}\n ```\n ```sv\n+{#await expression then}...{/await}\n+```\n+```sv\n {#await expression catch name}...{/await}\n ```\n \n@@ -348,6 +351,14 @@ If you don't care about the pending state, you can also omit the initial block.\n {/await}\n ```\n \n+You can also omit the resolved value variable if you don't need it:\n+\n+```sv\n+{#await promise then}\n+\t<p>resolved</p>\n+{/await}\n+```\n+\n ---\n \n If conversely you only want to show the error state, you can omit the `then` block.\ndiff --git a/src/compiler/parse/state/mustache.ts b/src/compiler/parse/state/mustache.ts\nindex cc3c24349..374d2751e 100644\n--- a/src/compiler/parse/state/mustache.ts\n+++ b/src/compiler/parse/state/mustache.ts\n@@ -290,9 +290,13 @@ export default function mustache(parser: Parser) {\n \n \t\tconst await_block_shorthand = type === 'AwaitBlock' && parser.eat('then');\n \t\tif (await_block_shorthand) {\n-\t\t\tparser.require_whitespace();\n-\t\t\tblock.value = read_context(parser);\n+\t\t\t// allow omission of the resolved value variable in shorthand\n \t\t\tparser.allow_whitespace();\n+\t\t\tif (!parser.match('}')) {\n+\t\t\t\tparser.require_whitespace();\n+\t\t\t\tblock.value = read_context(parser);\n+\t\t\t\tparser.allow_whitespace();\n+\t\t\t}\n \t\t}\n \n \t\tconst await_block_catch_shorthand = !await_block_shorthand && type === 'AwaitBlock' && parser.eat('catch');\ndiff --git a/src/runtime/internal/await_block.ts b/src/runtime/internal/await_block.ts\nindex ea6e8a187..539c61d67 100644\n--- a/src/runtime/internal/await_block.ts\n+++ b/src/runtime/internal/await_block.ts\n@@ -88,10 +88,10 @@ export function update_await_block_branch(info, ctx, dirty) {\n \tconst child_ctx = ctx.slice();\n \tconst { resolved } = info;\n \n-\tif (info.current === info.then) {\n+\tif (info.current === info.then && info.value !== undefined) {\n \t\tchild_ctx[info.value] = resolved;\n \t}\n-\tif (info.current === info.catch) {\n+\tif (info.current === info.catch && info.error !== undefined) {\n \t\tchild_ctx[info.error] = resolved;\n \t}\n \n"}
{"instance_id": "sveltejs__svelte-6525", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "sveltejs__svelte-6458", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_ssr/handlers/Element.ts b/src/compiler/compile/render_ssr/handlers/Element.ts\nindex 03838039a..02ed9d1a3 100644\n--- a/src/compiler/compile/render_ssr/handlers/Element.ts\n+++ b/src/compiler/compile/render_ssr/handlers/Element.ts\n@@ -121,7 +121,7 @@ export default function(node: Element, renderer: Renderer, options: RenderOption\n \t\t\tnode_contents = x`${snippet} || \"\"`;\n \t\t} else {\n \t\t\tconst snippet = expression.node;\n-\t\t\trenderer.add_expression(x`@add_attribute(\"${name}\", ${snippet}, 1)`);\n+\t\t\trenderer.add_expression(x`@add_attribute(\"${name}\", ${snippet}, ${boolean_attributes.has(name.toLowerCase()) ? 1 : 0})`);\n \t\t}\n \t});\n \n"}
{"instance_id": "trinodb__trino-1512", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/HashGenerationOptimizer.java b/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/HashGenerationOptimizer.java\nindex 9b77a314183..ec708d73203 100644\n--- a/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/HashGenerationOptimizer.java\n+++ b/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/HashGenerationOptimizer.java\n@@ -803,12 +803,12 @@ public class HashGenerationOptimizer\n \n         public HashComputationSet translate(Function<Symbol, Optional<Symbol>> translator)\n         {\n-            ImmutableMap.Builder<HashComputation, HashComputation> builder = ImmutableMap.builder();\n+            Map<HashComputation, HashComputation> result = new HashMap<>();\n             for (HashComputation hashComputation : hashes.keySet()) {\n                 hashComputation.translate(translator)\n-                        .ifPresent(hash -> builder.put(hash, hashComputation));\n+                        .ifPresent(hash -> result.putIfAbsent(hash, hashComputation));\n             }\n-            return new HashComputationSet(builder.build());\n+            return new HashComputationSet(result);\n         }\n \n         public HashComputation lookup(HashComputation hashComputation)\n"}
{"instance_id": "trinodb__trino-3392", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "sveltejs__svelte-6759", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/runtime/internal/Component.ts b/src/runtime/internal/Component.ts\nindex e706928af..93ba42e37 100644\n--- a/src/runtime/internal/Component.ts\n+++ b/src/runtime/internal/Component.ts\n@@ -124,7 +124,7 @@ export function init(component, options, instance, create_fragment, not_equal, p\n \t\ton_disconnect: [],\n \t\tbefore_update: [],\n \t\tafter_update: [],\n-\t\tcontext: new Map(parent_component ? parent_component.$$.context : options.context || []),\n+\t\tcontext: new Map(options.context || (parent_component ? parent_component.$$.context : [])),\n \n \t\t// everything else\n \t\tcallbacks: blank_object(),\n"}
{"instance_id": "sveltejs__svelte-6414", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/Slot.ts b/src/compiler/compile/render_dom/wrappers/Slot.ts\nindex d4629550b..10c4ffa8d 100644\n--- a/src/compiler/compile/render_dom/wrappers/Slot.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Slot.ts\n@@ -169,13 +169,35 @@ export default class SlotWrapper extends Wrapper {\n \t\t\tcondition = x`!#current || ${condition}`;\n \t\t}\n \n+\t\t// determine forced dirty mask when slot is in outro\n+\t\tlet forced_dirty;\n+\t\tif (this.renderer.context_overflow) {\n+\t\t\tconst groups = new Set<number>();\n+\t\t\tthis.node.values.forEach(attribute => {\n+\t\t\t\tconst deps = Array.from(attribute.dependencies).filter((name) => this.is_dependency_dynamic(name));\n+\t\t\t\tdeps.forEach((name) => {\n+\t\t\t\t\tconst idx = this.renderer.context_lookup.get(name).index.value as number;\n+\t\t\t\t\tconst g = (idx / 31) | 0;\n+\t\t\t\t\tgroups.add(g);\n+\t\t\t\t});\n+\t\t\t});\n+\t\t\tconst max_group = Math.max(-1, ...Array.from(groups.values()));\n+\t\t\tconst elements = [];\n+\t\t\tfor (let i = 0; i <= max_group; i += 1) {\n+\t\t\t\telements.push(groups.has(i) ? x`-1` : x`0`);\n+\t\t\t}\n+\t\t\tforced_dirty = x`#current ? #dirty : [${elements}]`;\n+\t\t} else {\n+\t\t\tforced_dirty = x`#current ? #dirty : -1`;\n+\t\t}\n+\n \t\tconst slot_update = get_slot_spread_changes_fn ? b`\n \t\t\tif (${slot}.p && ${condition}) {\n-\t\t\t\t@update_slot_spread(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, #dirty, ${get_slot_changes_fn}, ${get_slot_spread_changes_fn}, ${get_slot_context_fn});\n+\t\t\t\t@update_slot_spread(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, ${forced_dirty}, ${get_slot_changes_fn}, ${get_slot_spread_changes_fn}, ${get_slot_context_fn});\n \t\t\t}\n \t\t` : b`\n \t\t\tif (${slot}.p && ${condition}) {\n-\t\t\t\t@update_slot(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, #dirty, ${get_slot_changes_fn}, ${get_slot_context_fn});\n+\t\t\t\t@update_slot(${slot}, ${slot_definition}, #ctx, ${renderer.reference('$$scope')}, ${forced_dirty}, ${get_slot_changes_fn}, ${get_slot_context_fn});\n \t\t\t}\n \t\t`;\n \t\tconst fallback_update = has_fallback && fallback_dynamic_dependencies.length > 0 && b`\n"}
{"instance_id": "sveltejs__svelte-7422", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/compiler/compile/render_dom/wrappers/Slot.ts b/src/compiler/compile/render_dom/wrappers/Slot.ts\nindex 5a778ba5f..91e1d29ae 100644\n--- a/src/compiler/compile/render_dom/wrappers/Slot.ts\n+++ b/src/compiler/compile/render_dom/wrappers/Slot.ts\n@@ -164,7 +164,12 @@ export default class SlotWrapper extends Wrapper {\n \t\t\t? Array.from(this.fallback.dependencies).filter((name) => this.is_dependency_dynamic(name))\n \t\t\t: [];\n \n-\t\tlet condition = renderer.dirty(dynamic_dependencies);\n+\t\tlet condition;\n+\t\tif (this.node.values.size > 0) {\n+\t\t\tcondition = renderer.dirty(dynamic_dependencies);\n+\t\t} else {\n+\t\t\tcondition = x`#dirty`;\n+\t\t}\n \t\tif (block.has_outros) {\n \t\t\tcondition = x`!#current || ${condition}`;\n \t\t}\n"}
{"instance_id": "prettier__prettier-459", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/printer.js b/src/printer.js\nindex 28990dde8..e0385e76f 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -51,12 +51,16 @@ function genericPrint(path, options, printPath) {\n       // responsible for printing node.decorators.\n       !util.getParentExportDeclaration(path)\n   ) {\n-    path.each(\n-      function(decoratorPath) {\n-        parts.push(printPath(decoratorPath), line);\n-      },\n-      \"decorators\"\n-    );\n+    if (util.isClassMember(node)) {\n+      parts.push(join(\" \", path.map(printPath, \"decorators\")), \" \");\n+    } else {\n+      path.each(\n+        function(decoratorPath) {\n+          parts.push(printPath(decoratorPath), line);\n+        },\n+        \"decorators\"\n+      );\n+    }\n   } else if (\n     util.isExportDeclaration(node) &&\n       node.declaration &&\ndiff --git a/src/util.js b/src/util.js\nindex d7cf2a903..35c83a485 100644\n--- a/src/util.js\n+++ b/src/util.js\n@@ -77,6 +77,20 @@ function getParentExportDeclaration(path) {\n   return null;\n }\n \n+function isClassMember(node) {\n+  if (!node) {\n+    return false;\n+  }\n+  switch (node.type) {\n+    case \"MethodDefinition\":\n+    case \"ClassMethod\":\n+    case \"ClassProperty\":\n+    case \"ClassPropertyDefinition\":\n+      return true;\n+  }\n+  return false;\n+}\n+\n function getLast(arr) {\n   if (arr.length > 0) {\n     return arr[arr.length - 1];\n@@ -221,6 +235,7 @@ module.exports = {\n   fixFaultyLocations,\n   isExportDeclaration,\n   getParentExportDeclaration,\n+  isClassMember,\n   getLast,\n   newlineExistsBefore,\n   newlineExistsAfter,\n"}
{"instance_id": "prettier__prettier-11637", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/language-css/printer-postcss.js b/src/language-css/printer-postcss.js\nindex 0c326d6d2..365c5796d 100644\n--- a/src/language-css/printer-postcss.js\n+++ b/src/language-css/printer-postcss.js\n@@ -807,6 +807,12 @@ function genericPrint(path, options, print) {\n           continue;\n         }\n \n+        // Keep \"with (\" on the same line in SCSS module at-rules (@use/@forward)\n+        if ((insideAtRuleNode(path, \"use\") || insideAtRuleNode(path, \"forward\")) && iNode.type === \"value-word\" && iNode.value === \"with\" && iNextNode && iNextNode.type === \"value-paren_group\") {\n+          parts.push(\" \");\n+          continue;\n+        }\n+\n         // Be default all values go through `line`\n         parts.push(line);\n       }\n"}
{"instance_id": "serverless__serverless-7587", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/info/display.js b/lib/plugins/aws/info/display.js\nindex 3a244f6d8..ec645302b 100644\n--- a/lib/plugins/aws/info/display.js\n+++ b/lib/plugins/aws/info/display.js\n@@ -13,7 +13,7 @@ module.exports = {\n     message += `${chalk.yellow('stage:')} ${info.stage}\\n`;\n     message += `${chalk.yellow('region:')} ${info.region}\\n`;\n     message += `${chalk.yellow('stack:')} ${info.stack}\\n`;\n-    message += `${chalk.yellow('resources:')} ${info.resourceCount}`;\n+    message += `${chalk.yellow('resources:')} ${_.isNumber(info.resourceCount) ? info.resourceCount : 0}`;\n \n     if (_.has(info, 'resourceCount') && info.resourceCount >= 150) {\n       message += `\\n${chalk.red('WARNING:')}\\n`;\ndiff --git a/lib/plugins/aws/info/getResourceCount.js b/lib/plugins/aws/info/getResourceCount.js\nindex abe00ac4c..81704ebcf 100644\n--- a/lib/plugins/aws/info/getResourceCount.js\n+++ b/lib/plugins/aws/info/getResourceCount.js\n@@ -5,14 +5,10 @@ const _ = require('lodash');\n \n module.exports = {\n   getResourceCount() {\n-    const stackName = this.provider.naming.getStackName();\n-\n     return this.provider\n-      .request('CloudFormation', 'listStackResources', { StackName: stackName })\n-      .then(result => {\n-        if (!_.isEmpty(result)) {\n-          this.gatheredData.info.resourceCount = result.StackResourceSummaries.length;\n-        }\n+      .getStackResources()\n+      .then(resources => {\n+        this.gatheredData.info.resourceCount = Array.isArray(resources) ? resources.length : 0;\n         return BbPromise.resolve();\n       });\n   },\n"}
{"instance_id": "serverless__serverless-8159", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/events/apigateway.md b/docs/providers/aws/events/apigateway.md\nindex 77c99fa11..9e6c7c5a4 100644\n--- a/docs/providers/aws/events/apigateway.md\n+++ b/docs/providers/aws/events/apigateway.md\n@@ -932,11 +932,35 @@ This method is more complicated and involves a lot more configuration of the `ht\n \n #### Default Request Templates\n \n-Serverless ships with the following default request templates you can use out of the box:\n+Serverless ships with the following default request templates you can use out of the box (for the `lambda`/`AWS` integration):\n \n 1. `application/json`\n 2. `application/x-www-form-urlencoded`\n \n+You can control which of these defaults are applied per endpoint with the `request.defaultContentTypes` setting:\n+\n+- Omit `request.defaultContentTypes` to keep the current defaults (both will be added)\n+- Set `request.defaultContentTypes: [application/json]` to include only the JSON default\n+- Set `request.defaultContentTypes: []` to disable all defaults (you may want to define your own templates via `request.template`)\n+\n+Example:\n+\n+```yml\n+functions:\n+  create:\n+    handler: posts.create\n+    events:\n+      - http:\n+          method: post\n+          path: posts/create\n+          integration: lambda\n+          request:\n+            defaultContentTypes:\n+              - application/json\n+            template:\n+              text/xml: '{ \"foo\": \"bar\" }'\n+```\n+\n Both templates give you access to the following properties you can access with the help of the `event` object:\n \n - body\n@@ -953,7 +977,7 @@ Both templates give you access to the following properties you can access with t\n #### Custom Request Templates\n \n However you can define and use your own request templates as follows (you can even overwrite the default request templates\n-by defining a new request template for an existing content type):\n+by defining a new request template for an existing content type). If you prefer not to include any defaults, set `request.defaultContentTypes: []`.\n \n ```yml\n functions:\n@@ -965,6 +989,7 @@ functions:\n           path: whatever\n           integration: lambda\n           request:\n+            defaultContentTypes: []\n             template:\n               text/xhtml: '{ \"stage\" : \"$context.stage\" }'\n               application/json: '{ \"httpMethod\" : \"$context.httpMethod\" }'\n@@ -998,7 +1023,7 @@ If you want to spread a string into multiple lines, you can use the `>` or `|` s\n \n [API Gateway](https://serverless.com/amazon-api-gateway/) provides multiple ways to handle requests where the Content-Type header does not match any of the specified mapping templates. When this happens, the request payload will either be passed through the integration request _without transformation_ or rejected with a `415 - Unsupported Media Type`, depending on the configuration.\n \n-You can define this behaviour as follows (if not specified, a value of **NEVER** will be used):\n+You can define this behaviour as follows (if not specified, a value of **NEVER** will be used for the `lambda`/`AWS` integration). Note: If you disable all default request templates via `request.defaultContentTypes: []` and do not provide any custom templates, requests with unmatched Content-Type will be rejected with `415 - Unsupported Media Type` when passThrough is `NEVER`.\n \n ```yml\n functions:\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\nindex 3be224959..38fd4ea7c 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n@@ -201,10 +201,24 @@ module.exports = {\n \n     // Only set defaults for AWS (lambda) integration\n     if (useDefaults) {\n-      Object.assign(integrationRequestTemplates, {\n-        'application/json': this.DEFAULT_JSON_REQUEST_TEMPLATE,\n-        'application/x-www-form-urlencoded': this.DEFAULT_FORM_URL_ENCODED_REQUEST_TEMPLATE,\n-      });\n+      const defaultsConfig =\n+        http.request && Array.isArray(http.request.defaultContentTypes)\n+          ? http.request.defaultContentTypes\n+          : null;\n+      if (defaultsConfig === null) {\n+        Object.assign(integrationRequestTemplates, {\n+          'application/json': this.DEFAULT_JSON_REQUEST_TEMPLATE,\n+          'application/x-www-form-urlencoded': this.DEFAULT_FORM_URL_ENCODED_REQUEST_TEMPLATE,\n+        });\n+      } else {\n+        if (defaultsConfig.includes('application/json')) {\n+          integrationRequestTemplates['application/json'] = this.DEFAULT_JSON_REQUEST_TEMPLATE;\n+        }\n+        if (defaultsConfig.includes('application/x-www-form-urlencoded')) {\n+          integrationRequestTemplates['application/x-www-form-urlencoded'] =\n+            this.DEFAULT_FORM_URL_ENCODED_REQUEST_TEMPLATE;\n+        }\n+      }\n     }\n \n     // set custom request templates if provided\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\nindex 027ec480b..e6008e2ef 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\n@@ -506,6 +506,31 @@ module.exports = {\n         ].join('');\n         throw new this.serverless.classes.Error(errorMessage);\n       }\n+      if (http.request.defaultContentTypes) {\n+        if (!Array.isArray(http.request.defaultContentTypes)) {\n+          const errorMessage = [\n+            'defaultContentTypes config must be provided as an array of strings.',\n+            ' Please check the docs for more info.',\n+          ].join('');\n+          throw new this.serverless.classes.Error(errorMessage);\n+        }\n+        const allowedDefaults = [\n+          'application/json',\n+          'application/x-www-form-urlencoded',\n+        ];\n+        for (const ct of http.request.defaultContentTypes) {\n+          if (typeof ct !== 'string' || allowedDefaults.indexOf(ct) === -1) {\n+            const errorMessage = [\n+              'defaultContentTypes entries must be one of: ',\n+              allowedDefaults.join(', '),\n+              '.',\n+            ].join('');\n+            throw new this.serverless.classes.Error(errorMessage);\n+          }\n+        }\n+        // remove duplicates if any\n+        http.request.defaultContentTypes = Array.from(new Set(http.request.defaultContentTypes));\n+      }\n \n       if (request.parameters) {\n         request.parameters = this.getRequestParameters(request);\n"}
{"instance_id": "serverless__serverless-7277", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/events/sns.md b/docs/providers/aws/events/sns.md\nindex 556153b77..ab9a2f180 100644\n--- a/docs/providers/aws/events/sns.md\n+++ b/docs/providers/aws/events/sns.md\n@@ -159,7 +159,7 @@ functions:\n       - sns:\n           topicName: dispatcher\n           redrivePolicy:\n-            deadLetterTargetArn: !Ref myDLQ\n+            deadLetterTargetArn: !GetAtt myDLQ.Arn\n \n resources:\n   Resources:\n@@ -168,3 +168,5 @@ resources:\n       Properties:\n         QueueName: myDLQ\n ```\n+\n+Note: When the DLQ is defined in the same stack, the framework will also attach a policy to that queue allowing SNS to send messages to it. If you reference a DLQ from another stack or account (by providing a raw ARN), ensure that the external queue has an appropriate policy permitting sns:SendMessage from your SNS topic.\ndiff --git a/lib/plugins/aws/package/compile/events/sns/index.js b/lib/plugins/aws/package/compile/events/sns/index.js\nindex 3b62dc379..109ab42f1 100644\n--- a/lib/plugins/aws/package/compile/events/sns/index.js\n+++ b/lib/plugins/aws/package/compile/events/sns/index.js\n@@ -122,6 +122,25 @@ class AwsCompileSNSEvents {\n               throw new this.serverless.classes.Error(errorMessage);\n             }\n \n+            let normalizedRedrivePolicy = event.sns.redrivePolicy;\n+            let dlqLogicalId;\n+            if (event.sns.redrivePolicy && event.sns.redrivePolicy.deadLetterTargetArn) {\n+              const dlqTarget = event.sns.redrivePolicy.deadLetterTargetArn;\n+              if (typeof dlqTarget === 'object') {\n+                if (_.has(dlqTarget, 'Ref')) {\n+                  dlqLogicalId = dlqTarget.Ref;\n+                  normalizedRedrivePolicy = _.assign({}, event.sns.redrivePolicy, {\n+                    deadLetterTargetArn: { 'Fn::GetAtt': [dlqLogicalId, 'Arn'] },\n+                  });\n+                } else if (_.has(dlqTarget, 'Fn::GetAtt')) {\n+                  const getAtt = dlqTarget['Fn::GetAtt'];\n+                  if (Array.isArray(getAtt) && getAtt[1] === 'Arn') {\n+                    dlqLogicalId = getAtt[0];\n+                  }\n+                }\n+              }\n+            }\n+\n             const lambdaLogicalId = this.provider.naming.getLambdaLogicalId(functionName);\n \n             const endpoint = {\n@@ -142,7 +161,7 @@ class AwsCompileSNSEvents {\n                     Protocol: 'lambda',\n                     Endpoint: endpoint,\n                     FilterPolicy: event.sns.filterPolicy,\n-                    RedrivePolicy: event.sns.redrivePolicy,\n+                    RedrivePolicy: normalizedRedrivePolicy,\n                     Region: region,\n                   },\n                 },\n@@ -195,7 +214,7 @@ class AwsCompileSNSEvents {\n                         Ref: topicLogicalId,\n                       },\n                       FilterPolicy: event.sns.filterPolicy,\n-                      RedrivePolicy: event.sns.redrivePolicy,\n+                      RedrivePolicy: normalizedRedrivePolicy,\n                     }),\n                   },\n                 });\n@@ -224,7 +243,7 @@ class AwsCompileSNSEvents {\n               },\n             });\n \n-            if (event.sns.redrivePolicy && event.sns.redrivePolicy.deadLetterTargetArn) {\n+            if (normalizedRedrivePolicy && normalizedRedrivePolicy.deadLetterTargetArn && dlqLogicalId) {\n               const queuePolicyLogicalId = this.provider.naming.getQueueLogicalId(\n                 functionName,\n                 `${topicName}DLQ`\n@@ -243,7 +262,7 @@ class AwsCompileSNSEvents {\n                             Service: 'sns.amazonaws.com',\n                           },\n                           Action: 'sqs:SendMessage',\n-                          Resource: event.sns.redrivePolicy.deadLetterTargetArn,\n+                          Resource: { 'Fn::GetAtt': [dlqLogicalId, 'Arn'] },\n                           Condition: {\n                             ArnEquals: {\n                               'aws:SourceArn': topicArn,\n@@ -252,7 +271,7 @@ class AwsCompileSNSEvents {\n                         },\n                       ],\n                     },\n-                    Queues: [event.sns.redrivePolicy.deadLetterTargetArn],\n+                    Queues: [{ Ref: dlqLogicalId }],\n                   },\n                 },\n               });\n"}
{"instance_id": "serverless__serverless-6842", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/guide/iam.md b/docs/providers/aws/guide/iam.md\nindex f08eef33c..fe9808d21 100644\n--- a/docs/providers/aws/guide/iam.md\n+++ b/docs/providers/aws/guide/iam.md\n@@ -20,7 +20,7 @@ Every AWS Lambda function needs permission to interact with other AWS infrastruc\n \n By default, one IAM Role is shared by all of the Lambda functions in your service. Also by default, your Lambda functions have permission to create and write to CloudWatch logs. When VPC configuration is provided the default AWS `AWSLambdaVPCAccessExecutionRole` will be associated in order to communicate with your VPC resources.\n \n-To add specific rights to this service-wide Role, define statements in `provider.iamRoleStatements` which will be merged into the generated policy. As those statements will be merged into the CloudFormation template, you can use `Join`, `Ref` or any other CloudFormation method or feature.\n+To add specific rights to this service-wide Role, define statements in `provider.iamRoleStatements` which will be merged into the generated policy. As those statements will be merged into the CloudFormation template, you can use `Join`, `Ref` or any other CloudFormation method or feature. You may use either `Action` or `NotAction`, and either `Resource` or `NotResource` within a single statement (but not both of each).\n \n ```yml\n service: new-service\n@@ -45,6 +45,10 @@ provider:\n           - - 'arn:aws:s3:::'\n             - Ref: ServerlessDeploymentBucket\n             - '/*'\n+    # Example using NotResource to allow a lambda to send text messages, but not publish to any SNS topics\n+    - Effect: 'Allow'\n+      Action: 'sns:Publish'\n+      NotResource: 'arn:aws:sns:*:*:*'\n ```\n \n Alongside `provider.iamRoleStatements` managed policies can also be added to this service-wide Role, define managed policies in `provider.iamManagedPolicies`. These will also be merged into the generated IAM Role so you can use `Join`, `Ref` or any other CloudFormation method or feature here too.\ndiff --git a/lib/plugins/aws/customResources/index.js b/lib/plugins/aws/customResources/index.js\nindex b3b9b4f99..d5f959f36 100644\n--- a/lib/plugins/aws/customResources/index.js\n+++ b/lib/plugins/aws/customResources/index.js\n@@ -154,7 +154,21 @@ function addCustomResourceToService(awsProvider, resourceName, iamRoleStatements\n       }\n       const { Statement } = customResourceRole.Properties.Policies[0].PolicyDocument;\n       iamRoleStatements.forEach(newStmt => {\n-        if (!Statement.find(existingStmt => existingStmt.Resource === newStmt.Resource)) {\n+        const isDuplicate = Statement.find(existingStmt => {\n+          const newHasResource = newStmt.Resource !== undefined;\n+          const existingHasResource = existingStmt.Resource !== undefined;\n+          const newHasNotResource = newStmt.NotResource !== undefined;\n+          const existingHasNotResource = existingStmt.NotResource !== undefined;\n+\n+          if (newHasResource && existingHasResource) {\n+            return existingStmt.Resource === newStmt.Resource;\n+          }\n+          if (newHasNotResource && existingHasNotResource) {\n+            return existingStmt.NotResource === newStmt.NotResource;\n+          }\n+          return false;\n+        });\n+        if (!isDuplicate) {\n           Statement.push(newStmt);\n         }\n       });\ndiff --git a/lib/plugins/aws/package/lib/mergeIamTemplates.js b/lib/plugins/aws/package/lib/mergeIamTemplates.js\nindex 2d97671ad..2a879155b 100644\n--- a/lib/plugins/aws/package/lib/mergeIamTemplates.js\n+++ b/lib/plugins/aws/package/lib/mergeIamTemplates.js\n@@ -182,8 +182,8 @@ module.exports = {\n   },\n \n   validateStatements(statements) {\n-    // Verify that iamRoleStatements (if present) is an array of { Effect: ...,\n-    // Action: ..., Resource: ... } objects.\n+    // Verify that iamRoleStatements (if present) is an array of valid policy statement objects,\n+    // each having Effect and exactly one of Action/NotAction and exactly one of Resource/NotResource.\n     if (!statements) {\n       return;\n     }\n@@ -192,12 +192,31 @@ module.exports = {\n       violationsFound = 'it is not an array';\n     } else {\n       const descriptions = statements.map((statement, i) => {\n-        const missing = ['Effect', 'Action', 'Resource'].filter(\n-          prop => statement[prop] === undefined\n-        );\n-        return missing.length === 0\n+        const issues = [];\n+\n+        if (statement.Effect === undefined) {\n+          issues.push('missing property: Effect');\n+        }\n+\n+        const hasAction = statement.Action !== undefined;\n+        const hasNotAction = statement.NotAction !== undefined;\n+        if (hasAction && hasNotAction) {\n+          issues.push('has mutually exclusive properties: Action and NotAction');\n+        } else if (!hasAction && !hasNotAction) {\n+          issues.push('missing one of required properties: Action or NotAction');\n+        }\n+\n+        const hasResource = statement.Resource !== undefined;\n+        const hasNotResource = statement.NotResource !== undefined;\n+        if (hasResource && hasNotResource) {\n+          issues.push('has mutually exclusive properties: Resource and NotResource');\n+        } else if (!hasResource && !hasNotResource) {\n+          issues.push('missing one of required properties: Resource or NotResource');\n+        }\n+\n+        return issues.length === 0\n           ? null\n-          : `statement ${i} is missing the following properties: ${missing.join(', ')}`;\n+          : `statement ${i} ${issues.join('; ')}`;\n       });\n       const flawed = descriptions.filter(curr => curr);\n       if (flawed.length) {\n@@ -208,7 +227,7 @@ module.exports = {\n     if (violationsFound) {\n       const errorMessage = [\n         'iamRoleStatements should be an array of objects,',\n-        ' where each object has Effect, Action, Resource fields.',\n+        ' where each object has Effect and exactly one of Action/NotAction, and exactly one of Resource/NotResource.',\n         ` Specifically, ${violationsFound}`,\n       ].join('');\n       throw new this.serverless.classes.Error(errorMessage);\n"}
{"instance_id": "serverless__serverless-7374", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/utils/config/index.js b/lib/utils/config/index.js\nindex 0ba706cfe..6e8e42753 100644\n--- a/lib/utils/config/index.js\n+++ b/lib/utils/config/index.js\n@@ -3,6 +3,7 @@\n /* Config util */\n const p = require('path');\n const os = require('os');\n+const fs = require('fs');\n const _ = require('lodash');\n const rc = require('rc');\n const chalk = require('chalk');\n@@ -21,7 +22,19 @@ if (process.env.SERVERLESS_PLATFORM_STAGE && process.env.SERVERLESS_PLATFORM_STA\n \n function storeConfig(config) {\n   try {\n-    writeFileAtomic.sync(serverlessrcPath, JSON.stringify(config, null, 2));\n+    let writePath = serverlessrcPath;\n+    try {\n+      const stat = fs.lstatSync(serverlessrcPath);\n+      if (stat.isSymbolicLink()) {\n+        const linkTarget = fs.readlinkSync(serverlessrcPath);\n+        writePath = p.isAbsolute(linkTarget)\n+          ? linkTarget\n+          : p.resolve(p.dirname(serverlessrcPath), linkTarget);\n+      }\n+    } catch (e) {\n+      // If lstat/readlink fails (e.g., file doesn't exist yet), default to serverlessrcPath\n+    }\n+    writeFileAtomic.sync(writePath, JSON.stringify(config, null, 2));\n   } catch (error) {\n     if (process.env.SLS_DEBUG) {\n       process.stdout.write(`${chalk.red(error.stack)}\\n`);\ndiff --git a/lib/utils/fs/fileExistsSync.js b/lib/utils/fs/fileExistsSync.js\nindex 147300e7b..e11066ef2 100644\n--- a/lib/utils/fs/fileExistsSync.js\n+++ b/lib/utils/fs/fileExistsSync.js\n@@ -4,7 +4,7 @@ const fse = require('./fse');\n \n function fileExistsSync(filePath) {\n   try {\n-    const stats = fse.lstatSync(filePath);\n+    const stats = fse.statSync(filePath);\n     return stats.isFile();\n   } catch (e) {\n     return false;\n"}
{"instance_id": "serverless__serverless-6869", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/hack/updateStage.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/hack/updateStage.js\nindex a4c5da743..3d958bdca 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/hack/updateStage.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/hack/updateStage.js\n@@ -212,7 +212,11 @@ function handleLogs() {\n       logFormat = logs.format;\n     }\n \n-    const executionLogging = logs.executionLogging == null ? true : logs.executionLogging;\n+    const executionLoggingRaw = logs.executionLogging == null ? true : logs.executionLogging;\n+    const executionLogging =\n+      typeof executionLoggingRaw === 'string'\n+        ? executionLoggingRaw.trim().toLowerCase() === 'true'\n+        : Boolean(executionLoggingRaw);\n \n     let level = defaultApiGatewayLogLevel;\n     if (!executionLogging) {\n@@ -228,7 +232,11 @@ function handleLogs() {\n       }\n     }\n \n-    const accessLogging = logs.accessLogging == null ? true : logs.accessLogging;\n+    const accessLoggingRaw = logs.accessLogging == null ? true : logs.accessLogging;\n+    const accessLogging =\n+      typeof accessLoggingRaw === 'string'\n+        ? accessLoggingRaw.trim().toLowerCase() === 'true'\n+        : Boolean(accessLoggingRaw);\n \n     if (accessLogging) {\n       let resourceArn;\n@@ -257,11 +265,16 @@ function handleLogs() {\n       });\n     }\n \n-    const fullExecutionData = logs.fullExecutionData == null ? true : logs.fullExecutionData;\n+    const fullExecutionDataRaw =\n+      logs.fullExecutionData == null ? true : logs.fullExecutionData;\n+    const fullExecutionData =\n+      typeof fullExecutionDataRaw === 'string'\n+        ? fullExecutionDataRaw.trim().toLowerCase() === 'true'\n+        : Boolean(fullExecutionDataRaw);\n     operations.push({\n       op: 'replace',\n       path: '/*/*/logging/dataTrace',\n-      value: String(Boolean(fullExecutionData)),\n+      value: String(fullExecutionData),\n     });\n \n     operations.push({ op: 'replace', path: '/*/*/logging/loglevel', value: level });\n@@ -342,7 +355,12 @@ function removeAccessLoggingLogGroup() {\n   let accessLogging = provider.logs && provider.logs.restApi;\n \n   if (accessLogging) {\n-    accessLogging = accessLogging.accessLogging == null ? true : accessLogging.accessLogging;\n+    const accessLoggingRaw =\n+      accessLogging.accessLogging == null ? true : accessLogging.accessLogging;\n+    accessLogging =\n+      typeof accessLoggingRaw === 'string'\n+        ? accessLoggingRaw.trim().toLowerCase() === 'true'\n+        : Boolean(accessLoggingRaw);\n   }\n \n   // if there are no logs setup (or the user has disabled them) we need to\n"}
{"instance_id": "serverless__serverless-6447", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/package/index.js b/lib/plugins/aws/package/index.js\nindex 5ed9b0e5d..3de36dde8 100644\n--- a/lib/plugins/aws/package/index.js\n+++ b/lib/plugins/aws/package/index.js\n@@ -52,7 +52,16 @@ class AwsPackage {\n        */\n       'package:cleanup': () =>\n         BbPromise.bind(this)\n-          .then(() => this.serverless.pluginManager.spawn('aws:common:validate'))\n+          .then(() => {\n+            if (!this.serverless.config.servicePath) {\n+              const error = new this.serverless.classes.Error(\n+                'This command can only be run inside a service directory'\n+              );\n+              return BbPromise.reject(error);\n+            }\n+            this.options.stage = this.provider.getStage();\n+            this.options.region = this.provider.getRegion();\n+          })\n           .then(() => this.serverless.pluginManager.spawn('aws:common:cleanupTempDir')),\n \n       'package:initialize': () => BbPromise.bind(this).then(this.generateCoreTemplate),\n"}
{"instance_id": "serverless__serverless-6534", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/package/lib/mergeIamTemplates.js b/lib/plugins/aws/package/lib/mergeIamTemplates.js\nindex 945312b69..85a265422 100644\n--- a/lib/plugins/aws/package/lib/mergeIamTemplates.js\n+++ b/lib/plugins/aws/package/lib/mergeIamTemplates.js\n@@ -91,17 +91,29 @@ module.exports = {\n       .Statement;\n \n     // Ensure general polices for functions with default name resolution\n-    policyDocumentStatements[0].Resource.push({\n-      'Fn::Sub':\n-        'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}' +\n-        `:log-group:${logGroupsPrefix}*:*`,\n-    });\n+    const hasDefaultNamedFunctions = this.serverless.service\n+      .getAllFunctions()\n+      .some(functionName => {\n+        const { name: resolvedFunctionName } = this.serverless.service.getFunction(functionName);\n+        return (\n+          resolvedFunctionName &&\n+          resolvedFunctionName.startsWith(canonicalFunctionNamePrefix)\n+        );\n+      });\n \n-    policyDocumentStatements[1].Resource.push({\n-      'Fn::Sub':\n-        'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}' +\n-        `:log-group:${logGroupsPrefix}*:*:*`,\n-    });\n+    if (hasDefaultNamedFunctions) {\n+      policyDocumentStatements[0].Resource.push({\n+        'Fn::Sub':\n+          'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}' +\n+          `:log-group:${logGroupsPrefix}*:*`,\n+      });\n+\n+      policyDocumentStatements[1].Resource.push({\n+        'Fn::Sub':\n+          'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}' +\n+          `:log-group:${logGroupsPrefix}*:*:*`,\n+      });\n+    }\n \n     // Ensure policies for functions with custom name resolution\n     this.serverless.service.getAllFunctions().forEach(functionName => {\ndiff --git a/lib/plugins/aws/package/lib/mergeIamTemplates.test.js b/lib/plugins/aws/package/lib/mergeIamTemplates.test.js\nindex 09447f641..e28f2a17a 100644\n--- a/lib/plugins/aws/package/lib/mergeIamTemplates.test.js\n+++ b/lib/plugins/aws/package/lib/mergeIamTemplates.test.js\n@@ -178,11 +178,6 @@ describe('#mergeIamTemplates()', () => {\n                     Effect: 'Allow',\n                     Action: ['logs:CreateLogStream'],\n                     Resource: [\n-                      {\n-                        'Fn::Sub':\n-                          'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:' +\n-                          `log-group:/aws/lambda/${canonicalFunctionsPrefix}*:*`,\n-                      },\n                       {\n                         'Fn::Sub':\n                           'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:' +\n@@ -194,11 +189,6 @@ describe('#mergeIamTemplates()', () => {\n                     Effect: 'Allow',\n                     Action: ['logs:PutLogEvents'],\n                     Resource: [\n-                      {\n-                        'Fn::Sub':\n-                          'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:' +\n-                          `log-group:/aws/lambda/${canonicalFunctionsPrefix}*:*:*`,\n-                      },\n                       {\n                         'Fn::Sub':\n                           'arn:${AWS::Partition}:logs:${AWS::Region}:${AWS::AccountId}:' +\n"}
{"instance_id": "serverless__serverless-6261", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/guide/plugins.md b/docs/providers/aws/guide/plugins.md\nindex fc52aafb2..e6a5cebc9 100644\n--- a/docs/providers/aws/guide/plugins.md\n+++ b/docs/providers/aws/guide/plugins.md\n@@ -40,6 +40,7 @@ Array object:\n plugins:\n   - plugin1\n   - plugin2\n+  - ./src/foo/bar/plugin3\n ```\n \n Enhanced plugins object:\ndiff --git a/lib/classes/PluginManager.js b/lib/classes/PluginManager.js\nindex 1e6c063b1..09147bc5e 100644\n--- a/lib/classes/PluginManager.js\n+++ b/lib/classes/PluginManager.js\n@@ -151,8 +151,22 @@ class PluginManager {\n     if (pluginsObject.localPath) {\n       module.paths.unshift(pluginsObject.localPath);\n     }\n-    this.loadPlugins(pluginsObject.modules\n-      .filter(name => name !== '@serverless/enterprise-plugin'));\n+    const servicePath = (this.serverless && this.serverless.config && this.serverless.config.servicePath)\n+      || process.cwd();\n+    const resolvedModules = pluginsObject.modules\n+      .filter(name => name !== '@serverless/enterprise-plugin')\n+      .map((name) => {\n+        if (_.isString(name)) {\n+          if (path.isAbsolute(name)) {\n+            return name;\n+          }\n+          if (name.startsWith('./') || name.startsWith('../')) {\n+            return path.resolve(servicePath, name);\n+          }\n+        }\n+        return name;\n+      });\n+    this.loadPlugins(resolvedModules);\n   }\n \n   loadEnterprisePlugin() {\n"}
{"instance_id": "serverless__serverless-6366", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/events/sns.md b/docs/providers/aws/events/sns.md\nindex 738f5e9b4..44157e399 100644\n--- a/docs/providers/aws/events/sns.md\n+++ b/docs/providers/aws/events/sns.md\n@@ -81,6 +81,24 @@ functions:\n \n **Note:** If an `arn` string is specified but not a `topicName`, the last substring starting with `:` will be extracted as the `topicName`. If an `arn` object is specified, `topicName` must be specified as a string, used only to name the underlying Cloudformation mapping resources.\n \n+Cross-region topics:\n+- If the topic is specified via a string ARN and it points to a different region than the stack, the framework will automatically determine the topic's region from the ARN and set it on the subscription.\n+- If the topic ARN is provided via intrinsic functions or as an object, you must specify a `region` property with the topics region to enable cross-region subscription.\n+\n+Example with an intrinsic ARN for a cross-region topic:\n+\n+```yml\n+functions:\n+  dispatcher:\n+    handler: dispatcher.dispatch\n+    events:\n+      - sns:\n+          arn:\n+            Fn::ImportValue: MyCrossRegionTopicArn\n+          region: eu-west-1\n+          topicName: MyCrossRegionTopic\n+```\n+\n ## Setting a display name\n \n This event definition ensures that the `aggregator` function gets called every time a message is sent to the\ndiff --git a/lib/plugins/aws/package/compile/events/sns/index.js b/lib/plugins/aws/package/compile/events/sns/index.js\nindex 4d065c677..73c9b1a86 100644\n--- a/lib/plugins/aws/package/compile/events/sns/index.js\n+++ b/lib/plugins/aws/package/compile/events/sns/index.js\n@@ -50,10 +50,15 @@ class AwsCompileSNSEvents {\n             let topicArn;\n             let topicName;\n             let displayName = '';\n+            let topicRegion;\n \n             if (typeof event.sns === 'object') {\n               if (event.sns.arn) {\n                 topicArn = event.sns.arn;\n+                // Optional region override for cross-region topics when arn is provided as an object\n+                if (typeof event.sns.region === 'string') {\n+                  topicRegion = event.sns.region;\n+                }\n                 if (typeof topicArn === 'object') {\n                   if (!this.isValidStackImport(topicArn)) {\n                     throw new this.serverless.classes.Error(\n@@ -63,6 +68,8 @@ class AwsCompileSNSEvents {\n                 } else if (typeof topicArn === 'string') {\n                   if (topicArn.indexOf('arn:') === 0) {\n                     const splitArn = topicArn.split(':');\n+                    // arn:partition:service:region:account-id:resource\n+                    topicRegion = splitArn[3];\n                     topicName = splitArn[splitArn.length - 1];\n                   } else {\n                     throw new this.serverless.classes.Error(\n@@ -96,6 +103,8 @@ class AwsCompileSNSEvents {\n               if (event.sns.indexOf('arn:') === 0) {\n                 topicArn = event.sns;\n                 const splitArn = topicArn.split(':');\n+                // arn:partition:service:region:account-id:resource\n+                topicRegion = splitArn[3];\n                 topicName = splitArn[splitArn.length - 1];\n               } else {\n                 topicName = event.sns;\n@@ -124,15 +133,19 @@ class AwsCompileSNSEvents {\n             );\n \n             if (topicArn) {\n+              const subscriptionProperties = {\n+                TopicArn: topicArn,\n+                Protocol: 'lambda',\n+                Endpoint: endpoint,\n+                FilterPolicy: event.sns.filterPolicy,\n+              };\n+              if (topicRegion && typeof topicRegion === 'string') {\n+                subscriptionProperties.Region = topicRegion;\n+              }\n               _.merge(template.Resources, {\n                 [subscriptionLogicalId]: {\n                   Type: 'AWS::SNS::Subscription',\n-                  Properties: {\n-                    TopicArn: topicArn,\n-                    Protocol: 'lambda',\n-                    Endpoint: endpoint,\n-                    FilterPolicy: event.sns.filterPolicy,\n-                  },\n+                  Properties: subscriptionProperties,\n                 },\n               });\n             } else {\n"}
{"instance_id": "serverless__serverless-5775", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/guide/variables.md b/docs/providers/aws/guide/variables.md\nindex 6f52cda22..d27f9b201 100644\n--- a/docs/providers/aws/guide/variables.md\n+++ b/docs/providers/aws/guide/variables.md\n@@ -463,6 +463,8 @@ In the above example, if you pass `dev` as a stage option, the framework will lo\n ## Overwriting Variables\n The Serverless framework gives you an intuitive way to reference multiple variables as a fallback strategy in case one of the variables is missing. This way you'll be able to use a default value from a certain source, if the variable from another source is missing.\n \n+Note: When providing default values, you can use single or double quotes and any whitespace inside the quotes will be preserved. For example: `${env:SCHEDULE, 'rate(2 hours)'}` or `${env:SCHEDULE, \"rate(2 hours)\"}` will both result in `rate(2 hours)` when SCHEDULE is not set.\n+\n For example, if you want to reference the stage you're deploying to, but you don't want to keep on providing the `stage` option in the CLI. What you can do in `serverless.yml` is:\n \n ```yml\ndiff --git a/lib/classes/Variables.js b/lib/classes/Variables.js\nindex b5f6f406f..8948bfc1d 100644\n--- a/lib/classes/Variables.js\n+++ b/lib/classes/Variables.js\n@@ -294,7 +294,7 @@ class Variables {\n       this.variableSyntax,\n       (context, contents) => contents.trim()\n     );\n-    if (!cleaned.match(/\".*\"/)) {\n+    if (!cleaned.match(this.stringRefSyntax)) {\n       cleaned = cleaned.replace(/\\s/g, '');\n     }\n     return cleaned;\n@@ -787,7 +787,6 @@ class Variables {\n     const variableContainer = variable.match(this.variableSyntax)[0];\n     const variableString = this.cleanVariable(variableContainer);\n     return variableContainer\n-      .replace(/\\s/g, '')\n       .replace(variableString, `deep:${index}`);\n   }\n   appendDeepVariable(variable, subProperty) {\n"}
{"instance_id": "serverless__serverless-5842", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/guide/variables.md b/docs/providers/aws/guide/variables.md\nindex 677e6c681..c7a5a35ee 100644\n--- a/docs/providers/aws/guide/variables.md\n+++ b/docs/providers/aws/guide/variables.md\n@@ -274,6 +274,36 @@ custom:\n \n In this example, the serverless variable will contain the decrypted value of the secret.\n \n+### Access JSON keys from a secret\n+If your secret value is a JSON object, you can reference a specific key by appending a colon and the dot path to the SSM reference. For example, given a secret in Secrets Manager with value:\n+\n+```json\n+{\n+  \"db\": {\n+    \"username\": \"admin\",\n+    \"password\": \"s3cr3t\"\n+  }\n+}\n+```\n+\n+You can reference individual keys like:\n+\n+```yml\n+provider:\n+  environment:\n+    DB_USER: ${ssm:/aws/reference/secretsmanager/secret_ID_in_Secrets_Manager~true:db.username}\n+    DB_PASS: ${ssm:/aws/reference/secretsmanager/secret_ID_in_Secrets_Manager~true:db.password}\n+```\n+\n+- If the secret value is not valid JSON or the requested key path does not exist, the result resolves to undefined, allowing you to use overwrite fallback, e.g.:\n+\n+```yml\n+custom:\n+  dbUser: ${ssm:/aws/reference/secretsmanager/secret_ID_in_Secrets_Manager~true:db.username, env:DB_USER}\n+```\n+\n+- Only string/JSON Secrets Manager values are supported with this mechanism. Binary secrets are not supported via SSM reference.\n+\n ## Reference Variables in Other Files\n You can reference variables in other YAML or JSON files.  To reference variables in other YAML files use the `${file(./myFile.yml):someProperty}` syntax in your `serverless.yml` configuration file. To reference variables in other JSON files use the `${file(./myFile.json):someProperty}` syntax. It is important that the file you are referencing has the correct suffix, or file extension, for its file type (`.yml` for YAML or `.json` for JSON) in order for it to be interpreted correctly. Here's an example:\n \ndiff --git a/lib/classes/Variables.js b/lib/classes/Variables.js\nindex ef1b4f829..c92889131 100644\n--- a/lib/classes/Variables.js\n+++ b/lib/classes/Variables.js\n@@ -736,6 +736,13 @@ class Variables {\n     const groups = variableString.match(this.ssmRefSyntax);\n     const param = groups[1];\n     const decrypt = (groups[2] === 'true');\n+    // Detect optional sub-property selector (e.g. :db.username)\n+    const matchedPrefix = groups[0];\n+    let deepProperties;\n+    if (variableString.length > matchedPrefix.length && variableString.substring(matchedPrefix.length, matchedPrefix.length + 1) === ':') {\n+      const subSelector = variableString.slice(matchedPrefix.length + 1);\n+      deepProperties = subSelector.split('.');\n+    }\n     return this.serverless.getProvider('aws').request(\n       'SSM',\n       'getParameter',\n@@ -744,7 +751,20 @@ class Variables {\n         WithDecryption: decrypt,\n       },\n       { useCache: true }) // Use request cache\n-      .then(response => BbPromise.resolve(response.Parameter.Value))\n+      .then((response) => {\n+        const value = response.Parameter.Value;\n+        if (deepProperties) {\n+          let json;\n+          try {\n+            json = JSON.parse(value);\n+          } catch (e) {\n+            // If secret is not valid JSON and sub-property was requested, resolve undefined\n+            return BbPromise.resolve(undefined);\n+          }\n+          return this.getDeeperValue(deepProperties, json);\n+        }\n+        return BbPromise.resolve(value);\n+      })\n       .catch((err) => {\n         if (err.statusCode !== 400) {\n           return BbPromise.reject(new this.serverless.classes.Error(err.message));\n"}
{"instance_id": "serverless__serverless-5860", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/guide/functions.md b/docs/providers/aws/guide/functions.md\nindex 9a3ae2266..2132c9721 100644\n--- a/docs/providers/aws/guide/functions.md\n+++ b/docs/providers/aws/guide/functions.md\n@@ -38,6 +38,7 @@ functions:\n     memorySize: 512 # optional, in MB, default is 1024\n     timeout: 10 # optional, in seconds, default is 6\n     reservedConcurrency: 5 # optional, reserved concurrency limit for this function. By default, AWS uses account concurrency limit\n+    tracing: true # optional, enables AWS X-Ray Active tracing for this function\n ```\n \n The `handler` property points to the file and module containing the code you want to run in your function.\n@@ -352,6 +353,17 @@ AWS Lambda.\n \n To publish Lambda Layers, check out the [Layers](./layers.md) documentation.\n \n+## X-Ray Tracing\n+\n+You can enable AWS X-Ray Active tracing for your functions.\n+\n+- Per function: set `tracing: true` under the function definition to enable Active tracing for that function.\n+- Provider-wide: set `provider.tracing.lambda: true` to enable Active tracing for all functions (a function can override by setting `tracing: false`).\n+\n+When enabled, the framework configures your Lambda with `TracingConfig` set to `Mode: Active`.\n+\n+Note: When using the default IAM role generated by the framework and tracing is enabled, the AWS managed policy `AWSXRayDaemonWriteAccess` will be attached to allow publishing trace segments and telemetry. If you use custom IAM roles, add the necessary X-Ray permissions yourself.\n+\n ## Log Group Resources\n \n By default, the framework will create LogGroups for your Lambdas. This makes it easy to clean up your log groups in the case you remove your service, and make the lambda IAM permissions much more specific and secure.\ndiff --git a/docs/providers/aws/guide/iam.md b/docs/providers/aws/guide/iam.md\nindex ca982db00..7d6666d05 100644\n--- a/docs/providers/aws/guide/iam.md\n+++ b/docs/providers/aws/guide/iam.md\n@@ -18,6 +18,8 @@ Every AWS Lambda function needs permission to interact with other AWS infrastruc\n \n By default, one IAM Role is shared by all of the Lambda functions in your service. Also by default, your Lambda functions have permission to create and write to CloudWatch logs. When VPC configuration is provided the default AWS `AWSLambdaVPCAccessExecutionRole` will be associated in order to communicate with your VPC resources.\n \n+If AWS X-Ray tracing is enabled (per-function via `tracing: true` or provider-wide via `provider.tracing.lambda: true`) and the default role is used, the AWS managed policy `AWSXRayDaemonWriteAccess` will be attached automatically to allow writing X-Ray trace segments and telemetry. For custom roles, ensure you add equivalent X-Ray permissions.\n+\n To add specific rights to this service-wide Role, define statements in `provider.iamRoleStatements` which will be merged into the generated policy.  As those statements will be merged into the CloudFormation template, you can use `Join`, `Ref` or any other CloudFormation method or feature.\n \n ```yml\ndiff --git a/lib/plugins/aws/package/compile/functions/index.js b/lib/plugins/aws/package/compile/functions/index.js\nindex 8a130d1c9..46af4f060 100644\n--- a/lib/plugins/aws/package/compile/functions/index.js\n+++ b/lib/plugins/aws/package/compile/functions/index.js\n@@ -123,6 +123,16 @@ class AwsCompileFunctions {\n     newFunction.Properties.Timeout = Timeout;\n     newFunction.Properties.Runtime = Runtime;\n \n+    const isLambdaTracingEnabled = (functionObject.tracing === true)\n+      || (functionObject.tracing === undefined\n+        && _.get(this.serverless.service.provider, ['tracing', 'lambda']) === true);\n+\n+    if (isLambdaTracingEnabled) {\n+      newFunction.Properties.TracingConfig = {\n+        Mode: 'Active',\n+      };\n+    }\n+\n     // publish these properties to the platform\n     this.serverless.service.functions[functionName].memory = MemorySize;\n     this.serverless.service.functions[functionName].timeout = Timeout;\ndiff --git a/lib/plugins/aws/package/lib/mergeIamTemplates.js b/lib/plugins/aws/package/lib/mergeIamTemplates.js\nindex cb74e820d..741dac37b 100644\n--- a/lib/plugins/aws/package/lib/mergeIamTemplates.js\n+++ b/lib/plugins/aws/package/lib/mergeIamTemplates.js\n@@ -156,6 +156,29 @@ module.exports = {\n       }]);\n     }\n \n+    // add AWS X-Ray permissions if tracing is enabled\n+    const isProviderTracingEnabled = _.get(this.serverless.service.provider, ['tracing', 'lambda']) === true;\n+    let isAnyFunctionTracingEnabled = false;\n+    this.serverless.service.getAllFunctions().forEach((functionName) => {\n+      const functionObject = this.serverless.service.getFunction(functionName);\n+      if (functionObject.tracing === true || (functionObject.tracing === undefined && isProviderTracingEnabled)) {\n+        isAnyFunctionTracingEnabled = true;\n+      }\n+    });\n+\n+    if (isAnyFunctionTracingEnabled) {\n+      // Attach AWS managed policy that allows putting trace segments/telemetry\n+      this.mergeManagedPolicies([{\n+        'Fn::Join': ['',\n+          [\n+            'arn:',\n+            { Ref: 'AWS::Partition' },\n+            ':iam::aws:policy/AWSXRayDaemonWriteAccess',\n+          ],\n+        ],\n+      }]);\n+    }\n+\n     return BbPromise.resolve();\n   },\n \n"}
{"instance_id": "serverless__serverless-5640", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/guide/variables.md b/docs/providers/aws/guide/variables.md\nindex 71a846240..952cf24a4 100644\n--- a/docs/providers/aws/guide/variables.md\n+++ b/docs/providers/aws/guide/variables.md\n@@ -541,8 +541,8 @@ service: new-service\n provider:\n   name: aws\n   runtime: nodejs6.10\n-  variableSyntax: \"\\\\${{([ ~:a-zA-Z0-9._@\\\\'\\\",\\\\-\\\\/\\\\(\\\\)]+?)}}\" # notice the double quotes for yaml to ignore the escape characters!\n-#  variableSyntax: \"\\\\${((?!AWS)[ ~:a-zA-Z0-9._@'\\\",\\\\-\\\\/\\\\(\\\\)]+?)}\" # Use this for allowing CloudFormation Pseudo-Parameters in your serverless.yml -- e.g. ${AWS::Region}. All other Serverless variables work as usual.\n+  variableSyntax: \"\\\\${{([ ~:a-zA-Z0-9._@\\\\'\\\",\\\\-\\\\/\\\\(\\\\)\\\\*]+?)}}\" # notice the double quotes for yaml to ignore the escape characters!\n+#  variableSyntax: \"\\\\${((?!AWS)[ ~:a-zA-Z0-9._@'\\\",\\\\-\\\\/\\\\(\\\\)\\\\*]+?)}\" # Use this for allowing CloudFormation Pseudo-Parameters in your serverless.yml -- e.g. ${AWS::Region}. All other Serverless variables work as usual.\n \n custom:\n   myStage: ${{opt:stage}}\ndiff --git a/lib/classes/Service.js b/lib/classes/Service.js\nindex f508aa038..f03df6f80 100644\n--- a/lib/classes/Service.js\n+++ b/lib/classes/Service.js\n@@ -21,7 +21,7 @@ class Service {\n     this.provider = {\n       stage: 'dev',\n       region: 'us-east-1',\n-      variableSyntax: '\\\\${([ ~:a-zA-Z0-9._@\\'\",\\\\-\\\\/\\\\(\\\\)]+?)}',\n+      variableSyntax: '\\\\${([ ~:a-zA-Z0-9._@\\'\",\\\\-\\\\/\\\\(\\\\)\\\\*]+?)}',\n     };\n     this.custom = {};\n     this.plugins = [];\ndiff --git a/lib/plugins/print/print.js b/lib/plugins/print/print.js\nindex 65b137927..3020561e7 100644\n--- a/lib/plugins/print/print.js\n+++ b/lib/plugins/print/print.js\n@@ -56,7 +56,7 @@ class Print {\n     service.provider = _.merge({\n       stage: 'dev',\n       region: 'us-east-1',\n-      variableSyntax: '\\\\${([ ~:a-zA-Z0-9._@\\'\",\\\\-\\\\/\\\\(\\\\)]+?)}',\n+      variableSyntax: '\\\\${([ ~:a-zA-Z0-9._@\\'\",\\\\-\\\\/\\\\(\\\\)\\\\*]+?)}',\n     }, service.provider);\n   }\n   strip(svc) {\n"}
{"instance_id": "serverless__serverless-5571", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/classes/Variables.js b/lib/classes/Variables.js\nindex 6411f043f..f12e6a1cd 100644\n--- a/lib/classes/Variables.js\n+++ b/lib/classes/Variables.js\n@@ -268,7 +268,7 @@ class Variables {\n     return match.replace(\n       this.variableSyntax,\n       (context, contents) => contents.trim()\n-    ).replace(/\\s/g, '');\n+    );\n   }\n   /**\n    * @typedef {Object} MatchResult\n@@ -748,7 +748,6 @@ class Variables {\n     const variableContainer = variable.match(this.variableSyntax)[0];\n     const variableString = this.cleanVariable(variableContainer);\n     return variableContainer\n-      .replace(/\\s/g, '')\n       .replace(variableString, `deep:${index}`);\n   }\n   appendDeepVariable(variable, subProperty) {\n"}
{"instance_id": "serverless__serverless-3804", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "serverless__serverless-4192", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/cli-reference/deploy-function.md b/docs/providers/aws/cli-reference/deploy-function.md\nindex 3397c7631..d57f2c1c9 100644\n--- a/docs/providers/aws/cli-reference/deploy-function.md\n+++ b/docs/providers/aws/cli-reference/deploy-function.md\n@@ -16,6 +16,8 @@ The `sls deploy function` command deploys an individual function without AWS Clo\n \n ```bash\n serverless deploy function -f functionName\n+# Alias:\n+serverless deploy -f functionName\n ```\n \n **Note:** Because this command is only deploying the function code, function\ndiff --git a/docs/providers/aws/cli-reference/deploy.md b/docs/providers/aws/cli-reference/deploy.md\nindex bf05e94d0..09fe48226 100644\n--- a/docs/providers/aws/cli-reference/deploy.md\n+++ b/docs/providers/aws/cli-reference/deploy.md\n@@ -12,7 +12,7 @@ layout: Doc\n \n # AWS - deploy\n \n-The `sls deploy` command deploys your entire service via CloudFormation.  Run this command when you have made infrastructure changes (i.e., you edited `serverless.yml`).  Use `serverless deploy function -f myFunction` when you have made code changes and you want to quickly upload your updated code to AWS Lambda.\n+The `sls deploy` command deploys your entire service via CloudFormation.  Run this command when you have made infrastructure changes (i.e., you edited `serverless.yml`).  Use `serverless deploy function -f myFunction` when you have made code changes and you want to quickly upload your updated code to AWS Lambda. As a convenience alias, `serverless deploy -f myFunction` is equivalent to `serverless deploy function -f myFunction` and will deploy only the specified function's code.\n \n ```bash\n serverless deploy\ndiff --git a/lib/classes/CLI.js b/lib/classes/CLI.js\nindex 4a186a1a5..315fa4c65 100644\n--- a/lib/classes/CLI.js\n+++ b/lib/classes/CLI.js\n@@ -38,6 +38,15 @@ class CLI {\n     const commands = [].concat(argv._);\n     const options = _.omit(argv, ['_']);\n \n+    // Alias: If top-level \"deploy\" is invoked with --function or -f, route to \"deploy function\"\n+    if (commands.length === 1 && commands[0] === 'deploy') {\n+      const hasFunctionLong = Object.prototype.hasOwnProperty.call(options, 'function');\n+      const hasFunctionShort = Object.prototype.hasOwnProperty.call(options, 'f');\n+      if (hasFunctionLong || hasFunctionShort) {\n+        commands.push('function');\n+      }\n+    }\n+\n     return { commands, options };\n   }\n \n"}
{"instance_id": "serverless__serverless-3095", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/deploy/compile/events/iot/index.js b/lib/plugins/aws/deploy/compile/events/iot/index.js\nindex 0d6b01f07..f97987cbf 100644\n--- a/lib/plugins/aws/deploy/compile/events/iot/index.js\n+++ b/lib/plugins/aws/deploy/compile/events/iot/index.js\n@@ -51,55 +51,61 @@ class AwsCompileIoTEvents {\n               .getIotLogicalId(functionName, iotNumberInFunction);\n             const lambdaPermissionLogicalId = this.provider.naming\n               .getLambdaIotPermissionLogicalId(functionName, iotNumberInFunction);\n-            const iotTemplate = `\n-              {\n-                \"Type\": \"AWS::IoT::TopicRule\",\n-                \"Properties\": {\n-                  ${RuleName ? `\"RuleName\": \"${RuleName}\",` : ''}\n-                  \"TopicRulePayload\": {\n-                    ${AwsIotSqlVersion ? `\"AwsIotSqlVersion\": \"${AwsIotSqlVersion}\",` : ''}\n-                    ${Description ? `\"Description\": \"${Description}\",` : ''}\n-                    \"RuleDisabled\": \"${RuleDisabled}\",\n-                    \"Sql\": \"${Sql}\",\n-                    \"Actions\": [\n-                      {\n-                        \"Lambda\": {\n-                          \"FunctionArn\": { \"Fn::GetAtt\": [\"${lambdaLogicalId}\", \"Arn\"] }\n-                        }\n+            const trimmedDescription = (typeof Description === 'string') ? Description.trim() : undefined;\n+            const trimmedSql = (typeof Sql === 'string') ? Sql.trim() : undefined;\n+\n+            const iotRuleResource = {\n+              Type: 'AWS::IoT::TopicRule',\n+              Properties: {\n+                TopicRulePayload: {\n+                  RuleDisabled: String(RuleDisabled),\n+                  Sql: trimmedSql,\n+                  Actions: [\n+                    {\n+                      Lambda: {\n+                        FunctionArn: { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] }\n                       }\n-                    ]\n-                  }\n+                    }\n+                  ]\n                 }\n               }\n-            `;\n+            };\n \n-            const permissionTemplate = `\n-              {\n-                \"Type\": \"AWS::Lambda::Permission\",\n-                \"Properties\": {\n-                  \"FunctionName\": { \"Fn::GetAtt\": [\"${lambdaLogicalId}\", \"Arn\"] },\n-                  \"Action\": \"lambda:InvokeFunction\",\n-                  \"Principal\": \"iot.amazonaws.com\",\n-                  \"SourceArn\": { \"Fn::Join\": [\"\",\n-                    [\n-                      \"arn:aws:iot:\",\n-                      { \"Ref\": \"AWS::Region\" },\n-                      \":\",\n-                      { \"Ref\": \"AWS::AccountId\" },\n-                      \":rule/\",\n-                      { \"Ref\": \"${iotLogicalId}\"}\n-                    ]\n-                  ] }\n-                }\n+            if (RuleName) {\n+              iotRuleResource.Properties.RuleName = RuleName;\n+            }\n+            if (AwsIotSqlVersion) {\n+              iotRuleResource.Properties.TopicRulePayload.AwsIotSqlVersion = AwsIotSqlVersion;\n+            }\n+            if (trimmedDescription) {\n+              iotRuleResource.Properties.TopicRulePayload.Description = trimmedDescription;\n+            }\n+\n+            const permissionResource = {\n+              Type: 'AWS::Lambda::Permission',\n+              Properties: {\n+                FunctionName: { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] },\n+                Action: 'lambda:InvokeFunction',\n+                Principal: 'iot.amazonaws.com',\n+                SourceArn: { 'Fn::Join': ['',\n+                  [\n+                    'arn:aws:iot:',\n+                    { Ref: 'AWS::Region' },\n+                    ':',\n+                    { Ref: 'AWS::AccountId' },\n+                    ':rule/',\n+                    { Ref: iotLogicalId }\n+                  ]\n+                ] }\n               }\n-            `;\n+            };\n \n             const newIotObject = {\n-              [iotLogicalId]: JSON.parse(iotTemplate),\n+              [iotLogicalId]: iotRuleResource,\n             };\n \n             const newPermissionObject = {\n-              [lambdaPermissionLogicalId]: JSON.parse(permissionTemplate),\n+              [lambdaPermissionLogicalId]: permissionResource,\n             };\n \n             _.merge(this.serverless.service.provider.compiledCloudFormationTemplate.Resources,\n"}
{"instance_id": "serverless__serverless-3799", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/events/cognito-user-pool.md b/docs/providers/aws/events/cognito-user-pool.md\nindex 2af34ca39..eabab8c92 100644\n--- a/docs/providers/aws/events/cognito-user-pool.md\n+++ b/docs/providers/aws/events/cognito-user-pool.md\n@@ -37,6 +37,14 @@ functions:\n           trigger: CustomMessage\n ```\n \n+## Working with existing User Pools\n+\n+Note: The pool property must be a User Pool name, not a User Pool ID or ARN. The configuration shown above will create and manage a Cognito User Pool in the same CloudFormation stack using that name. If you provide a pool ID (e.g. us-east-1_ABC123) or an ARN, deployment will fail validation.\n+\n+If you need to customize the generated User Pool, define it in the resources section using the logical id CognitoUserPool<NormalizedPoolName> and use the same pool name in your event configuration so the triggers are attached to that pool.\n+\n+Attaching triggers to an already existing User Pool that is not managed by this stack is not supported via this event configuration.\n+\n ## Multiple pools event definitions\n \n This will create multiple Cognito User Pools with their specified names:\ndiff --git a/lib/plugins/aws/package/compile/events/cognitoUserPool/index.js b/lib/plugins/aws/package/compile/events/cognitoUserPool/index.js\nindex d94063701..26f8e3076 100644\n--- a/lib/plugins/aws/package/compile/events/cognitoUserPool/index.js\n+++ b/lib/plugins/aws/package/compile/events/cognitoUserPool/index.js\n@@ -56,6 +56,21 @@ class AwsCompileCognitoUserPoolEvents {\n                   ].join(' '));\n               }\n \n+              // Validate that \"pool\" is a pool name, not an ID or ARN\n+              const poolValue = event.cognitoUserPool.pool;\n+              const isArn = typeof poolValue === 'string' && poolValue.indexOf('arn:') === 0;\n+              // Cognito User Pool ID looks like: <region>_<id> e.g. us-east-1_abcdEFG12\n+              const isIdLike = typeof poolValue === 'string' && /[a-z]{2}-[a-z]+-\\d+_.+/i.test(poolValue);\n+              if (isArn || isIdLike) {\n+                throw new this.serverless.classes\n+                  .Error([\n+                    `Cognito User Pool \"pool\" value for function \"${functionName}\" must be a User Pool name, not an ID or ARN.`,\n+                    'This configuration creates or manages a User Pool within the same stack using the provided name.',\n+                    'To work with an already existing User Pool, define that pool in the \"resources\" section using the logical id',\n+                    '\"CognitoUserPool<NormalizedPoolName>\" and reference the same pool name here. See the docs for more info.',\n+                  ].join(' '));\n+              }\n+\n               // Save trigger functions so we can use them to generate\n               // IAM permissions later\n               cognitoUserPoolTriggerFunctions.push({\n"}
{"instance_id": "serverless__serverless-2945", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/classes/Service.js b/lib/classes/Service.js\nindex 9516492e8..63d9a4291 100644\n--- a/lib/classes/Service.js\n+++ b/lib/classes/Service.js\n@@ -99,6 +99,22 @@ class Service {\n         that.resources = serverlessFile.resources;\n         that.functions = serverlessFile.functions || {};\n \n+        // Validate iamRoleStatements format for AWS provider\n+        if (\n+          serverlessFile.provider\n+          && serverlessFile.provider.name === 'aws'\n+          && typeof serverlessFile.provider.iamRoleStatements !== 'undefined'\n+          && !(serverlessFile.provider.iamRoleStatements instanceof Array)\n+        ) {\n+          const warningMessage = [\n+            'Warning: \"provider.iamRoleStatements\" should be an array of IAM policy statements.',\n+            ` Detected type ${typeof serverlessFile.provider.iamRoleStatements}.`,\n+            ' If you are referencing a file via $ref or ${file(...)} ensure it resolves to an array.',\n+            ' The provided statements will be ignored.'\n+          ].join('');\n+          this.serverless.cli.warn(warningMessage);\n+        }\n+\n         if (serverlessFile.package) {\n           that.package.individually = serverlessFile.package.individually;\n           that.package.artifact = serverlessFile.package.artifact;\ndiff --git a/lib/plugins/aws/deploy/lib/mergeIamTemplates.js b/lib/plugins/aws/deploy/lib/mergeIamTemplates.js\nindex a85c8518b..04fef6087 100644\n--- a/lib/plugins/aws/deploy/lib/mergeIamTemplates.js\n+++ b/lib/plugins/aws/deploy/lib/mergeIamTemplates.js\n@@ -131,6 +131,14 @@ module.exports = {\n           .Properties\n           .PolicyDocument\n           .Statement.concat(this.serverless.service.provider.iamRoleStatements);\n+      } else if (typeof this.serverless.service.provider.iamRoleStatements !== 'undefined' &&\n+        !(this.serverless.service.provider.iamRoleStatements instanceof Array)) {\n+        const warningMessage = [\n+          'Warning: \"provider.iamRoleStatements\" must be an array of IAM policy statements.',\n+          ' The provided value is not an array and will not be included in the generated policy.',\n+          ' Ensure your $ref or ${file(...)} resolves to an array.'\n+        ].join('');\n+        this.serverless.cli.warn(warningMessage);\n       }\n     }\n \n"}
{"instance_id": "serverless__serverless-3457", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/stream/index.js b/lib/plugins/aws/package/compile/events/stream/index.js\nindex a0bb4ab36..0130a1fbe 100644\n--- a/lib/plugins/aws/package/compile/events/stream/index.js\n+++ b/lib/plugins/aws/package/compile/events/stream/index.js\n@@ -119,14 +119,17 @@ class AwsCompileStreamEvents {\n               .getStreamLogicalId(functionName, streamType, streamName);\n \n             const funcRole = functionObj.role || this.serverless.service.provider.role;\n-            let dependsOn = '\"IamRoleLambdaExecution\"';\n+            let dependsOn = `\"${this.provider.naming.getRoleLogicalId()}\"`;\n             if (funcRole) {\n-              if ( // check whether the custom role is an ARN\n-                typeof funcRole === 'string' &&\n-                funcRole.indexOf(':') !== -1\n-              ) {\n-                dependsOn = '[]';\n-              } else if ( // otherwise, check if we have an in-service reference to a role ARN\n+              if (typeof funcRole === 'string') {\n+                if (funcRole.indexOf(':') !== -1) {\n+                  // role is an ARN, no in-stack dependency\n+                  dependsOn = '[]';\n+                } else {\n+                  // role is a logical id of a role defined in this stack\n+                  dependsOn = `\"${funcRole}\"`;\n+                }\n+              } else if (\n                 typeof funcRole === 'object' &&\n                 'Fn::GetAtt' in funcRole &&\n                 Array.isArray(funcRole['Fn::GetAtt']) &&\n@@ -186,10 +189,9 @@ class AwsCompileStreamEvents {\n \n         // update the PolicyDocument statements (if default policy is used)\n         if (this.serverless.service.provider.compiledCloudFormationTemplate\n-          .Resources.IamRoleLambdaExecution) {\n+          .Resources[this.provider.naming.getRoleLogicalId()]) {\n           const statement = this.serverless.service.provider.compiledCloudFormationTemplate\n-            .Resources\n-            .IamRoleLambdaExecution\n+            .Resources[this.provider.naming.getRoleLogicalId()]\n             .Properties\n             .Policies[0]\n             .PolicyDocument\n"}
{"instance_id": "serverless__serverless-2952", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "serverless__serverless-2576", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/lib/monitorStack.js b/lib/plugins/aws/lib/monitorStack.js\nindex 3c3e49e8c..309713689 100644\n--- a/lib/plugins/aws/lib/monitorStack.js\n+++ b/lib/plugins/aws/lib/monitorStack.js\n@@ -42,29 +42,31 @@ module.exports = {\n               this.options.region)\n               .then((data) => {\n                 // Loop through stack events\n-                data.StackEvents.reverse().forEach((event) => {\n+                const stackEvents = Array.isArray(data.StackEvents) ? data.StackEvents : [];\n+                stackEvents.reverse().forEach((event) => {\n                   const eventInRange = (monitoredSince < event.Timestamp);\n                   const eventNotLogged = (loggedEvents.indexOf(event.EventId) === -1);\n                   let eventStatus = event.ResourceStatus;\n                   if (eventInRange && eventNotLogged) {\n+                    const hasEventStatus = typeof eventStatus === 'string' && eventStatus.length > 0;\n                     // Keep track of stack status\n-                    if (event.ResourceType === 'AWS::CloudFormation::Stack') {\n+                    if (event.ResourceType === 'AWS::CloudFormation::Stack' && hasEventStatus) {\n                       stackStatus = eventStatus;\n                     }\n                     // Keep track of first failed event\n-                    if (eventStatus.endsWith('FAILED') && stackLatestError === null) {\n+                    if (hasEventStatus && eventStatus.endsWith('FAILED') && stackLatestError === null) {\n                       stackLatestError = event;\n                     }\n                     // Log stack events\n                     if (this.options.verbose) {\n-                      if (eventStatus.endsWith('FAILED')) {\n+                      if (hasEventStatus && eventStatus.endsWith('FAILED')) {\n                         eventStatus = chalk.red(eventStatus);\n-                      } else if (eventStatus.endsWith('PROGRESS')) {\n+                      } else if (hasEventStatus && eventStatus.endsWith('PROGRESS')) {\n                         eventStatus = chalk.yellow(eventStatus);\n-                      } else if (eventStatus.endsWith('COMPLETE')) {\n+                      } else if (hasEventStatus && eventStatus.endsWith('COMPLETE')) {\n                         eventStatus = chalk.green(eventStatus);\n                       }\n-                      let eventLog = `CloudFormation - ${eventStatus} - `;\n+                      let eventLog = `CloudFormation - ${hasEventStatus ? eventStatus : 'UNKNOWN'} - `;\n                       eventLog += `${event.ResourceType} - `;\n                       eventLog += `${event.LogicalResourceId}`;\n                       this.serverless.cli.consoleLog(eventLog);\n@@ -77,18 +79,22 @@ module.exports = {\n                 });\n                 // Handle stack create/update/delete failures\n                 if ((stackLatestError && !this.options.verbose)\n-                || (stackStatus.endsWith('ROLLBACK_COMPLETE') && this.options.verbose)) {\n+                || ((typeof stackStatus === 'string' && stackStatus.endsWith('ROLLBACK_COMPLETE')) && this.options.verbose)) {\n                   this.serverless.cli.log('Deployment failed!');\n                   let errorMessage = 'An error occurred while provisioning your stack: ';\n-                  errorMessage += `${stackLatestError.LogicalResourceId} - `;\n-                  errorMessage += `${stackLatestError.ResourceStatusReason}.`;\n+                  if (stackLatestError) {\n+                    errorMessage += `${stackLatestError.LogicalResourceId} - `;\n+                    errorMessage += `${stackLatestError.ResourceStatusReason}.`;\n+                  } else {\n+                    errorMessage += 'Stack rolled back to previous state.';\n+                  }\n                   return reject(new this.serverless.classes.Error(errorMessage));\n                 }\n                 // Trigger next monitoring action\n                 return callback();\n               })\n               .catch((e) => {\n-                if (action === 'removal' && e.message.endsWith('does not exist')) {\n+                if (action === 'removal' && typeof e.message === 'string' && e.message.endsWith('does not exist')) {\n                   // empty console.log for a prettier output\n                   if (!this.options.verbose) this.serverless.cli.consoleLog('');\n                   this.serverless.cli.log(`Stack ${action} finished`);\n"}
{"instance_id": "serverless__serverless-2842", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/guide/resources.md b/docs/providers/aws/guide/resources.md\nindex f8d37aa09..9eca6c3e2 100644\n--- a/docs/providers/aws/guide/resources.md\n+++ b/docs/providers/aws/guide/resources.md\n@@ -48,6 +48,19 @@ resources:  // CloudFormation template syntax\n \n You can overwrite/attach any kind of resource to your CloudFormation stack. You can add `Resources`, `Outputs` or even overwrite the `Description`. You can also use [Serverless Variables](./variables.md) for sensitive data or reusable configuration in your resources templates.  Please be cautious as overwriting existing parts of your CloudFormation stack might introduce unexpected behavior.\n \n+### Include Multiple Resource Files\n+\n+For larger services, you can split CloudFormation resources across multiple files and include them as an array under the `Resources` section. Each file should define a map of CloudFormation resources (logical IDs as keys). Definitions are merged left-to-right, so later entries override earlier ones on key collisions:\n+\n+```yml\n+resources:\n+  Resources:\n+    - ${file(resources/first-cf-resources.yml)}\n+    - ${file(resources/second-cf-resources.yml)}\n+```\n+\n+Non-object entries are invalid and will result in an error.\n+\n ## AWS CloudFormation Resource Reference\n \n To have consistent naming in the Cloudformation Templates that get deployed we use a standard pattern:\ndiff --git a/docs/providers/aws/guide/variables.md b/docs/providers/aws/guide/variables.md\nindex 72785c6d3..6f8d1fdca 100644\n--- a/docs/providers/aws/guide/variables.md\n+++ b/docs/providers/aws/guide/variables.md\n@@ -159,8 +159,16 @@ resources:\n   Resources: ${file(cloudformation-resources.json)}\n ```\n \n-The corresponding resources which are defined inside the `cloudformation-resources.json` file will be resolved and loaded into the `Resources` section.\n+You can also include multiple resource files by providing an array of file references. Each referenced file must resolve to an object map of CloudFormation resources (logical IDs as keys). Items are merged left-to-right; later entries override earlier keys on collisions:\n \n+```yml\n+resources:\n+  Resources:\n+    - ${file(resources/first-cf-resources.yml)}\n+    - ${file(resources/second-cf-resources.yml)}\n+```\n+\n+The corresponding resources which are defined inside the referenced files will be resolved, merged, and loaded into the `Resources` section. Non-object entries are invalid and will result in an error.\n ## Nesting Variable References\n The Serverless variable system allows you to nest variable references within each other for ultimate flexibility. So you can reference certain variables based on other variables. Here's an example:\n \ndiff --git a/lib/plugins/aws/deploy/lib/mergeCustomProviderResources.js b/lib/plugins/aws/deploy/lib/mergeCustomProviderResources.js\nindex 414b098f4..8756233a1 100644\n--- a/lib/plugins/aws/deploy/lib/mergeCustomProviderResources.js\n+++ b/lib/plugins/aws/deploy/lib/mergeCustomProviderResources.js\n@@ -5,6 +5,37 @@ const BbPromise = require('bluebird');\n \n module.exports = {\n   mergeCustomProviderResources() {\n+    // Normalize resources.Resources if provided as an array of file references/objects\n+    if (this.serverless.service.resources\n+      && Array.isArray(this.serverless.service.resources.Resources)) {\n+      const mergedResources = {};\n+      this.serverless.service.resources.Resources.forEach((item, index) => {\n+        if (typeof item === 'undefined') {\n+          const errorMessage = [\n+            'Invalid \"resources.Resources\" entry at index ',\n+            String(index),\n+            '. Expected an object but received \"undefined\".',\n+            ' Check that file references resolve correctly.'\n+          ].join('');\n+          throw new this.serverless.classes.Error(errorMessage);\n+        }\n+        // Only plain objects are supported in Resources array\n+        if (Object.prototype.toString.call(item) !== '[object Object]') {\n+          const type = Array.isArray(item) ? 'array' : typeof item;\n+          const errorMessage = [\n+            'Invalid \"resources.Resources\" entry at index ',\n+            String(index),\n+            '. Expected an object map of CloudFormation resources but received ',\n+            type,\n+            '.'\n+          ].join('');\n+          throw new this.serverless.classes.Error(errorMessage);\n+        }\n+        _.merge(mergedResources, item);\n+      });\n+      this.serverless.service.resources.Resources = mergedResources;\n+    }\n+\n     if (this.serverless.service.resources && !this.serverless.service.resources.Resources) {\n       this.serverless.service.resources.Resources = {};\n     }\n"}
{"instance_id": "serverless__serverless-2434", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/classes/Service.js b/lib/classes/Service.js\nindex 9cff995f2..031e60182 100644\n--- a/lib/classes/Service.js\n+++ b/lib/classes/Service.js\n@@ -152,9 +152,21 @@ class Service {\n           if (!functionObj.events) {\n             that.functions[functionName].events = [];\n           }\n-          if (!_.isArray(functionObj.events)) {\n+\n+          // resolve events if it's expressed as a variable string (e.g., ${file(...):events})\n+          if (typeof that.functions[functionName].events === 'string') {\n+            // ensure variable syntax is prepared\n+            that.serverless.variables.loadVariableSyntax();\n+            const ev = that.functions[functionName].events;\n+            if (ev.match(that.serverless.variables.variableSyntax)) {\n+              that.functions[functionName].events =\n+                that.serverless.variables.populateProperty(ev);\n+            }\n+          }\n+\n+          if (!_.isArray(that.functions[functionName].events)) {\n             throw new SError(`Events for \"${functionName}\" must be an array,` +\n-                             ` not an ${typeof functionObj.events}`);\n+                             ` not an ${typeof that.functions[functionName].events}`);\n           }\n \n           if (!functionObj.name) {\n"}
{"instance_id": "serverless__serverless-1910", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/03-cli-reference/01-create.md b/docs/03-cli-reference/01-create.md\nindex 389d928aa..096408bcc 100644\n--- a/docs/03-cli-reference/01-create.md\n+++ b/docs/03-cli-reference/01-create.md\n@@ -14,8 +14,9 @@ serverless create --template aws-nodejs\n ```\n \n ## Options\n-- `--template` or `-t` The name of your new service. **Required**.\n+- `--template` or `-t` The template to use for your new service. **Required**.\n - `--path` or `-p` The path where the service should be created.\n+- `--name` or `-n` The name of the service to set in serverless.yml.\n \n ## Provided lifecycle events\n - `create:create`\n@@ -57,3 +58,13 @@ will use the already present directory.\n \n Additionally Serverless will rename the service according to the path you provide. In this example the service will be\n renamed to `my-new-service`.\n+\n+### Setting a custom service name\n+\n+```\n+serverless create --template aws-nodejs --name my-service\n+```\n+\n+This example will generate scaffolding in the current working directory and set the service name in serverless.yml to `my-service`.\n+\n+If both `--name` and `--path` are provided, `--name` takes precedence for the service name, while `--path` controls the destination directory.\ndiff --git a/lib/plugins/create/create.js b/lib/plugins/create/create.js\nindex 4d77a7c3c..39b471b2a 100644\n--- a/lib/plugins/create/create.js\n+++ b/lib/plugins/create/create.js\n@@ -36,6 +36,10 @@ class Create {\n             usage: 'The path where the service should be created (e.g. --path my-service)',\n             shortcut: 'p',\n           },\n+          name: {\n+            usage: 'The name of the service to create (e.g. --name my-service)',\n+            shortcut: 'n',\n+          },\n         },\n       },\n     };\n@@ -77,9 +81,12 @@ class Create {\n     this.serverless.utils.copyDirContentsSync(path.join(this.serverless.config.serverlessPath,\n       'plugins', 'create', 'templates', this.options.template), this.serverless.config.servicePath);\n \n-    // rename the service if the user has provided a path via options\n-    if (servicePath) {\n-      const serviceName = servicePath.split(path.sep).pop();\n+    // rename the service if the user has provided a name or a path via options\n+    const serviceNameOverride = (this.options.name && this.options.name.length)\n+      ? this.options.name\n+      : (servicePath ? servicePath.split(path.sep).pop() : null);\n+\n+    if (serviceNameOverride) {\n       const serverlessYmlFilePath = path\n         .join(this.serverless.config.servicePath, 'serverless.yml');\n \n@@ -87,7 +94,7 @@ class Create {\n         .readFileSync(serverlessYmlFilePath).toString();\n \n       serverlessYmlFileContent = serverlessYmlFileContent\n-        .replace(/service: .+/, `service: ${serviceName}`);\n+        .replace(/service: .+/, `service: ${serviceNameOverride}`);\n \n       fse.writeFileSync(serverlessYmlFilePath, serverlessYmlFileContent);\n     }\n@@ -96,7 +103,7 @@ class Create {\n     this.serverless.cli\n       .log(`Successfully created service with template: \"${this.options.template}\"`);\n \n-    if (!servicePath) {\n+    if (!serviceNameOverride) {\n       this.serverless.cli\n         .log('NOTE: Please update the \"service\" property in serverless.yml with your service name');\n     }\n"}
{"instance_id": "microsoft__vscode-108964", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/contrib/snippet/snippetSession.ts b/src/vs/editor/contrib/snippet/snippetSession.ts\nindex 7f91f835c4c..fd46e8c62e9 100644\n--- a/src/vs/editor/contrib/snippet/snippetSession.ts\n+++ b/src/vs/editor/contrib/snippet/snippetSession.ts\n@@ -114,7 +114,7 @@ export class OneSnippet {\n \t\t\t\t\tconst range = this._editor.getModel().getDecorationRange(id)!;\n \t\t\t\t\tconst currentValue = this._editor.getModel().getValueInRange(range);\n \n-\t\t\t\t\toperations.push(EditOperation.replaceMove(range, placeholder.transform.resolve(currentValue)));\n+\t\t\t\t\toperations.push(EditOperation.replace(range, placeholder.transform.resolve(currentValue)));\n \t\t\t\t}\n \t\t\t}\n \t\t\tif (operations.length > 0) {\n"}
{"instance_id": "microsoft__vscode-113837", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/base/browser/ui/highlightedlabel/highlightedLabel.ts b/src/vs/base/browser/ui/highlightedlabel/highlightedLabel.ts\nindex 552f1e57d18..23b487de4af 100644\n--- a/src/vs/base/browser/ui/highlightedlabel/highlightedLabel.ts\n+++ b/src/vs/base/browser/ui/highlightedlabel/highlightedLabel.ts\n@@ -62,7 +62,7 @@ export class HighlightedLabel {\n \t\t\tif (pos < highlight.start) {\n \t\t\t\tconst substring = this.text.substring(pos, highlight.start);\n \t\t\t\tchildren.push(dom.$('span', undefined, ...this.supportIcons ? renderLabelWithIcons(substring) : [substring]));\n-\t\t\t\tpos = highlight.end;\n+\t\t\t\tpos = highlight.start;\n \t\t\t}\n \n \t\t\tconst substring = this.text.substring(highlight.start, highlight.end);\n"}
{"instance_id": "microsoft__vscode-109750", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/contrib/suggest/suggestController.ts b/src/vs/editor/contrib/suggest/suggestController.ts\nindex 8bd4d44079e..07ce4c41609 100644\n--- a/src/vs/editor/contrib/suggest/suggestController.ts\n+++ b/src/vs/editor/contrib/suggest/suggestController.ts\n@@ -363,6 +363,20 @@ export class SuggestController implements IEditorContribution {\n \t\t\tinsertText = SnippetParser.escape(insertText);\n \t\t}\n \n+\t\t// Adjust overwriteAfter to consume an auto-inserted closing quote when the suggestion text itself is quoted\n+\t\t{\n+\t\t\tconst position = this.editor.getPosition()!;\n+\t\t\tconst lineText = model.getLineContent(position.lineNumber);\n+\t\t\tconst rightChar = lineText.charAt(position.column - 1);\n+\t\t\tif ((rightChar === '\"' || rightChar === '\\'')) {\n+\t\t\t\tconst firstChar = insertText.charAt(0);\n+\t\t\t\tconst lastChar = insertText.charAt(insertText.length - 1);\n+\t\t\t\tif (firstChar === rightChar && lastChar === rightChar) {\n+\t\t\t\t\tinfo.overwriteAfter += 1;\n+\t\t\t\t}\n+\t\t\t}\n+\t\t}\n+\n \t\tSnippetController2.get(this.editor).insert(insertText, {\n \t\t\toverwriteBefore: info.overwriteBefore,\n \t\t\toverwriteAfter: info.overwriteAfter,\n"}
{"instance_id": "microsoft__vscode-123294", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/base/common/charCode.ts b/src/vs/base/common/charCode.ts\nindex 23b840b2942..58df6beba47 100644\n--- a/src/vs/base/common/charCode.ts\n+++ b/src/vs/base/common/charCode.ts\n@@ -426,6 +426,10 @@ export const enum CharCode {\n \n \tU_OVERLINE = 0x203E, // Unicode Character 'OVERLINE'\n \n+\t// Unicode full-width/CJK brackets used for enclosing text in East Asian typography\n+\tU_Left_Black_Lenticular_Bracket = 0x3010, // U+3010 LEFT BLACK LENTICULAR BRACKET\n+\tU_Right_Black_Lenticular_Bracket = 0x3011, // U+3011 RIGHT BLACK LENTICULAR BRACKET\n+\n \t/**\n \t * UTF-8 BOM\n \t * Unicode Character 'ZERO WIDTH NO-BREAK SPACE' (U+FEFF)\ndiff --git a/src/vs/editor/common/modes/linkComputer.ts b/src/vs/editor/common/modes/linkComputer.ts\nindex c0ca979fb9b..8e89a828a09 100644\n--- a/src/vs/editor/common/modes/linkComputer.ts\n+++ b/src/vs/editor/common/modes/linkComputer.ts\n@@ -154,7 +154,7 @@ function getClassifier(): CharacterClassifier<CharacterClass> {\n \tif (_classifier === null) {\n \t\t_classifier = new CharacterClassifier<CharacterClass>(CharacterClass.None);\n \n-\t\tconst FORCE_TERMINATION_CHARACTERS = ' \\t<>\\'\\\"';\n+\t\tconst FORCE_TERMINATION_CHARACTERS = ' \\t<>\\'\\\"';\n \t\tfor (let i = 0; i < FORCE_TERMINATION_CHARACTERS.length; i++) {\n \t\t\t_classifier.set(FORCE_TERMINATION_CHARACTERS.charCodeAt(i), CharacterClass.ForceTermination);\n \t\t}\n@@ -181,7 +181,7 @@ export class LinkComputer {\n \t\t\tlastIncludedCharIndex--;\n \t\t} while (lastIncludedCharIndex > linkBeginIndex);\n \n-\t\t// Handle links enclosed in parens, square brackets and curlys.\n+\t\t// Handle links enclosed in parens, square brackets, curlys, and CJK lenticular brackets.\n \t\tif (linkBeginIndex > 0) {\n \t\t\tconst charCodeBeforeLink = line.charCodeAt(linkBeginIndex - 1);\n \t\t\tconst lastCharCodeInLink = line.charCodeAt(lastIncludedCharIndex);\n@@ -190,10 +190,12 @@ export class LinkComputer {\n \t\t\t\t(charCodeBeforeLink === CharCode.OpenParen && lastCharCodeInLink === CharCode.CloseParen)\n \t\t\t\t|| (charCodeBeforeLink === CharCode.OpenSquareBracket && lastCharCodeInLink === CharCode.CloseSquareBracket)\n \t\t\t\t|| (charCodeBeforeLink === CharCode.OpenCurlyBrace && lastCharCodeInLink === CharCode.CloseCurlyBrace)\n+\t\t\t\t|| (charCodeBeforeLink === CharCode.U_Left_Black_Lenticular_Bracket && lastCharCodeInLink === CharCode.U_Right_Black_Lenticular_Bracket)\n \t\t\t) {\n \t\t\t\t// Do not end in ) if ( is before the link start\n \t\t\t\t// Do not end in ] if [ is before the link start\n \t\t\t\t// Do not end in } if { is before the link start\n+\t\t\t\t// Do not end in  if  is before the link start\n \t\t\t\tlastIncludedCharIndex--;\n \t\t\t}\n \t\t}\n"}
{"instance_id": "microsoft__vscode-135197", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/common/modes/supports/characterPair.ts b/src/vs/editor/common/modes/supports/characterPair.ts\nindex e1f8d13dcd8..f2fc342d9de 100644\n--- a/src/vs/editor/common/modes/supports/characterPair.ts\n+++ b/src/vs/editor/common/modes/supports/characterPair.ts\n@@ -5,6 +5,7 @@\n \n import { IAutoClosingPair, StandardAutoClosingPairConditional, LanguageConfiguration, CharacterPair } from 'vs/editor/common/modes/languageConfiguration';\n import { ScopedLineTokens } from 'vs/editor/common/modes/supports';\n+import { StandardTokenType } from 'vs/editor/common/modes';\n \n export class CharacterPairSupport {\n \n@@ -66,6 +67,12 @@ export class CharacterPairSupport {\n \n \t\tconst tokenIndex = context.findTokenIndexAtOffset(column - 2);\n \t\tconst standardTokenType = context.getStandardTokenType(tokenIndex);\n+\n+\t\t// Special-case: Avoid auto-closing backticks inside strings (e.g., inside template literals)\n+\t\tif (standardTokenType === StandardTokenType.String && autoClosingPair.open === '`' && autoClosingPair.close === '`') {\n+\t\t\treturn false;\n+\t\t}\n+\n \t\treturn autoClosingPair.isOK(standardTokenType);\n \t}\n \n"}
{"instance_id": "microsoft__vscode-127071", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/base/browser/ui/tree/asyncDataTree.ts b/src/vs/base/browser/ui/tree/asyncDataTree.ts\nindex 4740d2c7c7d..1c77824109f 100644\n--- a/src/vs/base/browser/ui/tree/asyncDataTree.ts\n+++ b/src/vs/base/browser/ui/tree/asyncDataTree.ts\n@@ -582,7 +582,7 @@ export class AsyncDataTree<TInput, T, TFilterData = void> implements IDisposable\n \t\t}\n \n \t\tif (node.refreshPromise) {\n-\t\t\tawait this.root.refreshPromise;\n+\t\t\tawait node.refreshPromise;\n \t\t\tawait Event.toPromise(this._onDidRender.event);\n \t\t}\n \n@@ -593,7 +593,7 @@ export class AsyncDataTree<TInput, T, TFilterData = void> implements IDisposable\n \t\tconst result = this.tree.expand(node === this.root ? null : node, recursive);\n \n \t\tif (node.refreshPromise) {\n-\t\t\tawait this.root.refreshPromise;\n+\t\t\tawait node.refreshPromise;\n \t\t\tawait Event.toPromise(this._onDidRender.event);\n \t\t}\n \ndiff --git a/src/vs/workbench/browser/parts/views/treeView.ts b/src/vs/workbench/browser/parts/views/treeView.ts\nindex 29cb607489a..3adf9fd09b1 100644\n--- a/src/vs/workbench/browser/parts/views/treeView.ts\n+++ b/src/vs/workbench/browser/parts/views/treeView.ts\n@@ -734,6 +734,8 @@ export class TreeView extends Disposable implements ITreeView {\n \t\tif (tree && this.visible) {\n \t\t\tthis.refreshing = true;\n \t\t\tawait Promise.all(elements.map(element => tree.updateChildren(element, true, true)));\n+\t\t\t// Ensure items marked as Expanded are expanded after refresh\n+\t\t\tawait Promise.all(elements.filter(element => element.collapsibleState === TreeItemCollapsibleState.Expanded).map(element => tree.expand(element, false)));\n \t\t\tthis.refreshing = false;\n \t\t\tthis._onDidCompleteRefresh.fire();\n \t\t\tthis.updateContentAreas();\n"}
{"instance_id": "microsoft__vscode-149380", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/workbench/contrib/debug/node/terminals.ts b/src/vs/workbench/contrib/debug/node/terminals.ts\nindex 5390b15a8ec..e7065343e66 100644\n--- a/src/vs/workbench/contrib/debug/node/terminals.ts\n+++ b/src/vs/workbench/contrib/debug/node/terminals.ts\n@@ -157,8 +157,8 @@ export function prepareCommand(shell: string, args: string[], cwd?: string, env?\n \t\tcase ShellType.bash: {\n \n \t\t\tquote = (s: string) => {\n-\t\t\t\ts = s.replace(/([\"'\\\\\\$!><#()\\[\\]*&^|])/g, '\\\\$1');\n-\t\t\t\treturn (' ;'.split('').some(char => s.includes(char)) || s.length === 0) ? `\"${s}\"` : s;\n+\t\t\t\ts = s.replace(/([\"'\\\\\\$!#()\\[\\]*&^|])/g, '\\\\$1');\n+\t\t\t\treturn ([' ', ';', '<', '>'].some(char => s.includes(char)) || s.length === 0) ? `\"${s}\"` : s;\n \t\t\t};\n \n \t\t\tconst hardQuote = (s: string) => {\n"}
{"instance_id": "microsoft__vscode-153121", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts b/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\nindex f61919b4ceb..8647457b4b6 100644\n--- a/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\n+++ b/src/vs/editor/common/viewModel/monospaceLineBreaksComputer.ts\n@@ -489,7 +489,7 @@ function canBreak(prevCharCode: number, prevCharCodeClass: CharacterClass, charC\n \treturn (\n \t\tcharCode !== CharCode.Space\n \t\t&& (\n-\t\t\t(prevCharCodeClass === CharacterClass.BREAK_AFTER)\n+\t\t\t(prevCharCodeClass === CharacterClass.BREAK_AFTER && charCodeClass !== CharacterClass.BREAK_AFTER)\n \t\t\t|| (prevCharCodeClass === CharacterClass.BREAK_IDEOGRAPHIC && charCodeClass !== CharacterClass.BREAK_AFTER)\n \t\t\t|| (charCodeClass === CharacterClass.BREAK_BEFORE)\n \t\t\t|| (charCodeClass === CharacterClass.BREAK_IDEOGRAPHIC && prevCharCodeClass !== CharacterClass.BREAK_BEFORE)\n"}
{"instance_id": "microsoft__vscode-153857", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/common/languages/linkComputer.ts b/src/vs/editor/common/languages/linkComputer.ts\nindex 0ee39a20229..dad64e8a5e8 100644\n--- a/src/vs/editor/common/languages/linkComputer.ts\n+++ b/src/vs/editor/common/languages/linkComputer.ts\n@@ -160,7 +160,7 @@ function getClassifier(): CharacterClassifier<CharacterClass> {\n \t\t\t_classifier.set(FORCE_TERMINATION_CHARACTERS.charCodeAt(i), CharacterClass.ForceTermination);\n \t\t}\n \n-\t\tconst CANNOT_END_WITH_CHARACTERS = '.,;:';\n+\t\tconst CANNOT_END_WITH_CHARACTERS = '.,;:\\'\"`';\n \t\tfor (let i = 0; i < CANNOT_END_WITH_CHARACTERS.length; i++) {\n \t\t\t_classifier.set(CANNOT_END_WITH_CHARACTERS.charCodeAt(i), CharacterClass.CannotEndIn);\n \t\t}\n@@ -258,15 +258,15 @@ export class LinkComputer {\n \t\t\t\t\t\tcase CharCode.CloseCurlyBrace:\n \t\t\t\t\t\t\tchClass = (hasOpenCurlyBracket ? CharacterClass.None : CharacterClass.ForceTermination);\n \t\t\t\t\t\t\tbreak;\n-\t\t\t\t\t\t/* The following three rules make it that ' or \" or ` are allowed inside links if the link began with a different one */\n+\t\t\t\t\t\t/* The following three rules allow quotes inside links, but terminate when matching the opening quote */\n \t\t\t\t\t\tcase CharCode.SingleQuote:\n-\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.DoubleQuote || linkBeginChCode === CharCode.BackTick) ? CharacterClass.None : CharacterClass.ForceTermination;\n+\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.SingleQuote) ? CharacterClass.ForceTermination : CharacterClass.None;\n \t\t\t\t\t\t\tbreak;\n \t\t\t\t\t\tcase CharCode.DoubleQuote:\n-\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.SingleQuote || linkBeginChCode === CharCode.BackTick) ? CharacterClass.None : CharacterClass.ForceTermination;\n+\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.DoubleQuote) ? CharacterClass.ForceTermination : CharacterClass.None;\n \t\t\t\t\t\t\tbreak;\n \t\t\t\t\t\tcase CharCode.BackTick:\n-\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.SingleQuote || linkBeginChCode === CharCode.DoubleQuote) ? CharacterClass.None : CharacterClass.ForceTermination;\n+\t\t\t\t\t\t\tchClass = (linkBeginChCode === CharCode.BackTick) ? CharacterClass.ForceTermination : CharacterClass.None;\n \t\t\t\t\t\t\tbreak;\n \t\t\t\t\t\tcase CharCode.Asterisk:\n \t\t\t\t\t\t\t// `*` terminates a link if the link began with `*`\n"}
{"instance_id": "microsoft__vscode-160342", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/base/browser/ui/list/listWidget.ts b/src/vs/base/browser/ui/list/listWidget.ts\nindex 8ed5f2d8602..4894d52161a 100644\n--- a/src/vs/base/browser/ui/list/listWidget.ts\n+++ b/src/vs/base/browser/ui/list/listWidget.ts\n@@ -753,15 +753,39 @@ export class MouseController<T> implements IDisposable {\n \n \t\t} else if (this.isSelectionSingleChangeEvent(e)) {\n \t\t\tconst selection = this.list.getSelection();\n-\t\t\tconst newSelection = selection.filter(i => i !== focus);\n+\t\t\tconst wasSelected = selection.indexOf(focus) >= 0;\n \n-\t\t\tthis.list.setFocus([focus]);\n-\t\t\tthis.list.setAnchor(focus);\n-\n-\t\t\tif (selection.length === newSelection.length) {\n-\t\t\t\tthis.list.setSelection([...newSelection, focus], e.browserEvent);\n+\t\t\tif (!wasSelected) {\n+\t\t\t\t// Toggle on: add to selection and move focus/anchor to clicked\n+\t\t\t\tthis.list.setFocus([focus]);\n+\t\t\t\tthis.list.setAnchor(focus);\n+\t\t\t\tthis.list.setSelection([...selection, focus], e.browserEvent);\n \t\t\t} else {\n-\t\t\t\tthis.list.setSelection(newSelection, e.browserEvent);\n+\t\t\t\t// Toggle off: remove from selection, keep focus/anchor within remaining selection if any\n+\t\t\t\tconst newSelection = selection.filter(i => i !== focus);\n+\n+\t\t\t\tif (newSelection.length === 0) {\n+\t\t\t\t\t// No selection remains: focus/anchor can go to clicked item\n+\t\t\t\t\tthis.list.setFocus([focus]);\n+\t\t\t\t\tthis.list.setAnchor(focus);\n+\t\t\t\t\tthis.list.setSelection(newSelection, e.browserEvent);\n+\t\t\t\t} else {\n+\t\t\t\t\t// Prefer to keep previous focus if it remains selected\n+\t\t\t\t\tconst previousFocus = this.list.getFocus()[0];\n+\t\t\t\t\tlet newFocus = (typeof previousFocus !== 'undefined' && newSelection.indexOf(previousFocus) >= 0) ? previousFocus : newSelection[0];\n+\n+\t\t\t\t\t// Preserve anchor if it remains selected; otherwise use newFocus\n+\t\t\t\t\tlet currentAnchor = this.list.getAnchor();\n+\t\t\t\t\tlet newAnchor = (typeof currentAnchor !== 'undefined' && newSelection.indexOf(currentAnchor) >= 0) ? currentAnchor : newFocus;\n+\n+\t\t\t\t\tthis.list.setFocus([newFocus]);\n+\t\t\t\t\tif (typeof newAnchor !== 'undefined') {\n+\t\t\t\t\t\tthis.list.setAnchor(newAnchor);\n+\t\t\t\t\t} else {\n+\t\t\t\t\t\tthis.list.setAnchor(undefined);\n+\t\t\t\t\t}\n+\t\t\t\t\tthis.list.setSelection(newSelection, e.browserEvent);\n+\t\t\t\t}\n \t\t\t}\n \t\t}\n \t}\n"}
{"instance_id": "microsoft__vscode-157682", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/extensions/typescript-language-features/src/languageFeatures/organizeImports.ts b/extensions/typescript-language-features/src/languageFeatures/organizeImports.ts\nindex cd1aeffa823..be1a736dc22 100644\n--- a/extensions/typescript-language-features/src/languageFeatures/organizeImports.ts\n+++ b/extensions/typescript-language-features/src/languageFeatures/organizeImports.ts\n@@ -115,6 +115,9 @@ class ImportsCodeActionProvider implements vscode.CodeActionProvider {\n \t\tthis.fileConfigManager.ensureConfigurationForDocument(document, token);\n \n \t\tconst action = new vscode.CodeAction(this.title, this.kind);\n+\t\tif (!this.sortOnly) {\n+\t\t\taction.isPreferred = true;\n+\t\t}\n \t\taction.command = { title: '', command: OrganizeImportsCommand.Id, arguments: [file, this.sortOnly] };\n \t\treturn [action];\n \t}\ndiff --git a/extensions/typescript-language-features/src/languageFeatures/quickFix.ts b/extensions/typescript-language-features/src/languageFeatures/quickFix.ts\nindex 9ea0780a446..87b1e58ae0d 100644\n--- a/extensions/typescript-language-features/src/languageFeatures/quickFix.ts\n+++ b/extensions/typescript-language-features/src/languageFeatures/quickFix.ts\n@@ -385,7 +385,7 @@ const preferredFixes = new Map<string, { readonly priority: number; readonly the\n \t[fixNames.spelling, { priority: 0 }],\n \t[fixNames.addMissingAwait, { priority: 2 }],\n \t[fixNames.addMissingOverride, { priority: 2 }],\n-\t[fixNames.fixImport, { priority: 1, thereCanOnlyBeOne: true }],\n+\t[fixNames.fixImport, { priority: 4, thereCanOnlyBeOne: true }],\n ]);\n \n function isPreferredFix(\n"}
{"instance_id": "microsoft__vscode-177084", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkOpeners.ts b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkOpeners.ts\nindex 1349a799103..abef9edcd1d 100644\n--- a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkOpeners.ts\n+++ b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkOpeners.ts\n@@ -207,14 +207,16 @@ export class TerminalSearchLinkOpener implements ITerminalLinkOpener {\n \t}\n \n \tprivate async _tryOpenExactLink(text: string, link: ITerminalSimpleLink): Promise<boolean> {\n-\t\tconst sanitizedLink = text.replace(/:\\d+(:\\d+)?$/, '');\n+\t\t// Remove line/column suffix using parsed info when available or allow common delimiters after suffix\n+\t\tconst sanitizedLink = (link.parsedLink?.path?.text ?? text).replace(/:\\d+(:\\d+)?(?=$|\\s|\\||\\]|\\)|[\"'])/, '');\n \t\ttry {\n \t\t\tconst result = await this._getExactMatch(sanitizedLink);\n \t\t\tif (result) {\n \t\t\t\tconst { uri, isDirectory } = result;\n+\t\t\t\tconst lineColMatch = text.match(/:\\d+(:\\d+)?(?=$|\\s|\\||\\]|\\)|[\"'])/);\n \t\t\t\tconst linkToOpen = {\n \t\t\t\t\t// Use the absolute URI's path here so the optional line/col get detected\n-\t\t\t\t\ttext: result.uri.path + (text.match(/:\\d+(:\\d+)?$/)?.[0] || ''),\n+\t\t\t\t\ttext: result.uri.path + (lineColMatch?.[0] || ''),\n \t\t\t\t\turi,\n \t\t\t\t\tbufferRange: link.bufferRange,\n \t\t\t\t\ttype: link.type\ndiff --git a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\nindex 57dcd68c78a..38ca68d8262 100644\n--- a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\n+++ b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\n@@ -56,7 +56,7 @@ const linkSuffixRegexEol = new Lazy<RegExp>(() => {\n \t\t// foo 339:12                    [#140780]\n \t\t// \"foo\",339\n \t\t// \"foo\",339:12\n-\t\t`(?::| |['\"],)${l()}(:${c()})?$`,\n+\t\t`(?::| |['\"],)${l()}(:${c()})?(?=$|\\\\s|\\\\||\\\\]|\\\\)|[\"'])`,\n \t\t// The quotes below are optional [#171652]\n \t\t// \"foo\", line 339                [#40468]\n \t\t// \"foo\", line 339, col 12\n@@ -71,7 +71,7 @@ const linkSuffixRegexEol = new Lazy<RegExp>(() => {\n \t\t// \"foo\" on line 339, col 12\n \t\t// \"foo\" on line 339, column 12\n \t\t// \"foo\" line 339 column 12\n-\t\t`['\"]?(?:,? |: ?| on )line ${l()}(,? col(?:umn)? ${c()})?$`,\n+\t\t`['\"]?(?:,? |: ?| on )line ${l()}(,? col(?:umn)? ${c()})?(?=$|\\\\s|\\\\||\\\\]|\\\\)|[\"'])`,\n \t\t// foo(339)\n \t\t// foo(339,12)\n \t\t// foo(339, 12)\n@@ -79,7 +79,7 @@ const linkSuffixRegexEol = new Lazy<RegExp>(() => {\n \t\t//   ...\n \t\t// foo: (339)\n \t\t//   ...\n-\t\t`:? ?[\\\\[\\\\(]${l()}(?:, ?${c()})?[\\\\]\\\\)]$`,\n+\t\t`:? ?[\\\\[\\\\(]${l()}(?:, ?${c()})?[\\\\]\\\\)](?=$|\\\\s|\\\\||\\\\]|\\\\)|[\"'])`,\n \t];\n \n \tconst suffixClause = lineAndColumnRegexClauses\n@@ -205,7 +205,8 @@ export function toLinkSuffix(match: RegExpExecArray | null): ILinkSuffix | null\n }\n \n // Paths cannot start with opening brackets\n-const linkWithSuffixPathCharacters = /(?<path>[^\\s\\[\\({][^\\s]*)$/;\n+// Treat pipe '|' as a delimiter to avoid capturing it as part of the path\n+const linkWithSuffixPathCharacters = /(?<path>[^\\s\\|\\[\\({][^\\s\\|]*)$/;\n \n export function detectLinks(line: string, os: OperatingSystem) {\n \t// 1: Detect all links on line via suffixes first\ndiff --git a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalUriLinkDetector.ts b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalUriLinkDetector.ts\nindex 6af4b9a9f52..0ee90d45816 100644\n--- a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalUriLinkDetector.ts\n+++ b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalUriLinkDetector.ts\n@@ -134,7 +134,8 @@ export class TerminalUriLinkDetector implements ITerminalLinkDetector {\n \t}\n \n \tprivate _excludeLineAndColSuffix(path: string): string {\n-\t\treturn path.replace(/:\\d+(:\\d+)?$/, '');\n+\t\t// Also handle common delimiters following the suffix like pipe, space, bracket or quotes\n+\t\treturn path.replace(/:\\d+(:\\d+)?(?=$|\\s|\\||\\]|\\)|[\"'])/, '');\n \t}\n }\n \n"}
{"instance_id": "microsoft__vscode-168752", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/common/languages/linkComputer.ts b/src/vs/editor/common/languages/linkComputer.ts\nindex 52f4eaee2fb..98772d4d0f3 100644\n--- a/src/vs/editor/common/languages/linkComputer.ts\n+++ b/src/vs/editor/common/languages/linkComputer.ts\n@@ -155,7 +155,7 @@ function getClassifier(): CharacterClassifier<CharacterClass> {\n \t\t_classifier = new CharacterClassifier<CharacterClass>(CharacterClass.None);\n \n \t\t// allow-any-unicode-next-line\n-\t\tconst FORCE_TERMINATION_CHARACTERS = ' \\t<>\\'\\\"';\n+\t\tconst FORCE_TERMINATION_CHARACTERS = ' \\t,<>\\'\\\"';\n \t\tfor (let i = 0; i < FORCE_TERMINATION_CHARACTERS.length; i++) {\n \t\t\t_classifier.set(FORCE_TERMINATION_CHARACTERS.charCodeAt(i), CharacterClass.ForceTermination);\n \t\t}\n"}
{"instance_id": "microsoft__vscode-189223", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/workbench/contrib/terminal/common/terminalConfiguration.ts b/src/vs/workbench/contrib/terminal/common/terminalConfiguration.ts\nindex 1ca34b88c2e..671be6f128d 100644\n--- a/src/vs/workbench/contrib/terminal/common/terminalConfiguration.ts\n+++ b/src/vs/workbench/contrib/terminal/common/terminalConfiguration.ts\n@@ -451,7 +451,7 @@ const terminalConfiguration: IConfigurationNode = {\n \t\t\tmarkdownDescription: localize('terminal.integrated.wordSeparators', \"A string containing all characters to be considered word separators when double-clicking to select word and in the fallback 'word' link detection. Since this is used for link detection, including characters such as `:` that are used when detecting links will cause the line and column part of links like `file:10:5` to be ignored.\"),\n \t\t\ttype: 'string',\n \t\t\t// allow-any-unicode-next-line\n-\t\t\tdefault: ' ()[]{}\\',\"`|'\n+\t\t\tdefault: ' ()[]{}\\',\"`|'\n \t\t},\n \t\t[TerminalSettingId.EnableFileLinks]: {\n \t\t\tdescription: localize('terminal.integrated.enableFileLinks', \"Whether to enable file links in terminals. Links can be slow when working on a network drive in particular because each file link is verified against the file system. Changing this will take effect only in new terminals.\"),\ndiff --git a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\nindex a94483ab0e3..9b649364efb 100644\n--- a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\n+++ b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalLinkParsing.ts\n@@ -300,13 +300,13 @@ enum RegexPathConstants {\n \tPathSeparatorClause = '\\\\/',\n \t// '\":; are allowed in paths but they are often separators so ignore them\n \t// Also disallow \\\\ to prevent a catastropic backtracking case #24795\n-\tExcludedPathCharactersClause = '[^\\\\0<>\\\\?\\\\s!`&*()\\'\":;\\\\\\\\]',\n-\tExcludedStartPathCharactersClause = '[^\\\\0<>\\\\s!`&*()\\\\[\\\\]\\'\":;\\\\\\\\]',\n+\tExcludedPathCharactersClause = '[^\\\\0<>\\\\?\\\\s!`&*()\\'\":;\\\\\\\\\\uE000-\\uF8FF]',\n+\tExcludedStartPathCharactersClause = '[^\\\\0<>\\\\s!`&*()\\\\[\\\\]\\'\":;\\\\\\\\\\uE000-\\uF8FF]',\n \n \tWinOtherPathPrefix = '\\\\.\\\\.?|\\\\~',\n \tWinPathSeparatorClause = '(?:\\\\\\\\|\\\\/)',\n-\tWinExcludedPathCharactersClause = '[^\\\\0<>\\\\?\\\\|\\\\/\\\\s!`&*()\\'\":;]',\n-\tWinExcludedStartPathCharactersClause = '[^\\\\0<>\\\\?\\\\|\\\\/\\\\s!`&*()\\\\[\\\\]\\'\":;]',\n+\tWinExcludedPathCharactersClause = '[^\\\\0<>\\\\?\\\\|\\\\/\\\\s!`&*()\\'\":;\\uE000-\\uF8FF]',\n+\tWinExcludedStartPathCharactersClause = '[^\\\\0<>\\\\?\\\\|\\\\/\\\\s!`&*()\\\\[\\\\]\\'\":;\\uE000-\\uF8FF]',\n }\n \n /**\ndiff --git a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalWordLinkDetector.ts b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalWordLinkDetector.ts\nindex 1991ba84eac..38d6069c38d 100644\n--- a/src/vs/workbench/contrib/terminalContrib/links/browser/terminalWordLinkDetector.ts\n+++ b/src/vs/workbench/contrib/terminalContrib/links/browser/terminalWordLinkDetector.ts\n@@ -73,6 +73,10 @@ export class TerminalWordLinkDetector extends Disposable implements ITerminalLin\n \t\t\t\tword.text = word.text.slice(0, -1);\n \t\t\t\tword.endIndex--;\n \t\t\t}\n+\t\t\t// Skip words that consist entirely of Private Use Area (PUA) glyphs (eg. powerline symbols)\n+\t\t\tif (/^[\\uE000-\\uF8FF]+$/.test(word.text)) {\n+\t\t\t\tcontinue;\n+\t\t\t}\n \t\t\tconst bufferRange = convertLinkRangeToBuffer(\n \t\t\t\tlines,\n \t\t\t\tthis.xterm.cols,\n"}
{"instance_id": "mui__material-ui-12303", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "mui__material-ui-12968", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/src/pages/demos/text-fields/ComposedFilledTextField.js b/docs/src/pages/demos/text-fields/ComposedFilledTextField.js\nnew file mode 100644\nindex 0000000000..e69b77c591\n--- /dev/null\n+++ b/docs/src/pages/demos/text-fields/ComposedFilledTextField.js\n@@ -0,0 +1,17 @@\n+import React from 'react';\n+import FormControl from '@material-ui/core/FormControl';\n+import InputLabel from '@material-ui/core/InputLabel';\n+import FilledInput from '@material-ui/core/FilledInput';\n+import FormHelperText from '@material-ui/core/FormHelperText';\n+\n+function ComposedFilledTextField() {\n+  return (\n+    <FormControl variant=\"filled\">\n+      <InputLabel htmlFor=\"component-filled\">Name</InputLabel>\n+      <FilledInput id=\"component-filled\" />\n+      <FormHelperText>Helper text</FormHelperText>\n+    </FormControl>\n+  );\n+}\n+\n+export default ComposedFilledTextField;\ndiff --git a/docs/src/pages/demos/text-fields/ComposedOutlinedTextField.js b/docs/src/pages/demos/text-fields/ComposedOutlinedTextField.js\nnew file mode 100644\nindex 0000000000..cabbcc6705\n--- /dev/null\n+++ b/docs/src/pages/demos/text-fields/ComposedOutlinedTextField.js\n@@ -0,0 +1,17 @@\n+import React from 'react';\n+import FormControl from '@material-ui/core/FormControl';\n+import InputLabel from '@material-ui/core/InputLabel';\n+import OutlinedInput from '@material-ui/core/OutlinedInput';\n+import FormHelperText from '@material-ui/core/FormHelperText';\n+\n+function ComposedOutlinedTextField() {\n+  return (\n+    <FormControl variant=\"outlined\">\n+      <InputLabel htmlFor=\"component-outlined\">Name</InputLabel>\n+      <OutlinedInput id=\"component-outlined\" labelWidth={60} />\n+      <FormHelperText>Helper text</FormHelperText>\n+    </FormControl>\n+  );\n+}\n+\n+export default ComposedOutlinedTextField;\ndiff --git a/docs/src/pages/demos/text-fields/text-fields.md b/docs/src/pages/demos/text-fields/text-fields.md\nindex 2809b8953e..dcf9225436 100644\n--- a/docs/src/pages/demos/text-fields/text-fields.md\n+++ b/docs/src/pages/demos/text-fields/text-fields.md\n@@ -19,24 +19,42 @@ The `TextField` wrapper component is a complete form control including a label,\n \n `TextField` supports outlined styling.\n \n+If you compose inputs directly (instead of using TextField), use FilledInput/OutlinedInput to apply the filled/outlined styles.\n+\n {{\"demo\": \"pages/demos/text-fields/OutlinedTextFields.js\"}}\n \n ## Filled\n \n `TextField` supports filled styling.\n \n+If you compose inputs directly (instead of using TextField), use FilledInput/OutlinedInput to apply the filled/outlined styles.\n+\n {{\"demo\": \"pages/demos/text-fields/FilledTextFields.js\"}}\n \n ## Components\n \n-`TextField` is composed of smaller components ([`FormControl`](/api/form-control), [`InputLabel`](/api/input-label), [`Input`](/api/input), and [`FormHelperText`](/api/form-helper-text)) that you can leverage directly to significantly customize your form inputs.\n+`TextField` is composed of smaller components ([`FormControl`](/api/form-control), [`InputLabel`](/api/input-label), [`Input`](/api/input), [`FilledInput`](/api/filled-input), [`OutlinedInput`](/api/outlined-input), and [`FormHelperText`](/api/form-helper-text)) that you can leverage directly to significantly customize your form inputs.\n \n You might also have noticed that some native HTML input properties are missing from the `TextField` component.\n This is on purpose.\n The component takes care of the most used properties, then it's up to the user to use the underlying component shown in the following demo. Still, you can use `inputProps` (and `InputProps`, `InputLabelProps` properties) if you want to avoid some boilerplate.\n \n+When composing your own inputs with FormControl, the variant prop does not automatically change the styling of the standard Input component. To achieve filled or outlined appearances, use [`FilledInput`](/api/filled-input) for variant=\"filled\" and [`OutlinedInput`](/api/outlined-input) for variant=\"outlined\". The TextField component selects the correct input component for you internally based on the variant.\n+\n {{\"demo\": \"pages/demos/text-fields/ComposedTextField.js\"}}\n \n+## Composed filled\n+\n+This example composes a filled text field using FormControl, InputLabel, and FilledInput.\n+\n+{{\"demo\": \"pages/demos/text-fields/ComposedFilledTextField.js\"}}\n+\n+## Composed outlined\n+\n+This example composes an outlined text field using FormControl, InputLabel, and OutlinedInput. Note that OutlinedInput requires a labelWidth.\n+\n+{{\"demo\": \"pages/demos/text-fields/ComposedOutlinedTextField.js\"}}\n+\n ## Inputs\n \n {{\"demo\": \"pages/demos/text-fields/Inputs.js\"}}\n"}
{"instance_id": "mui__material-ui-12236", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/withWidth/withWidth.js b/packages/material-ui/src/withWidth/withWidth.js\nindex 670c3d36c2..700322e52f 100644\n--- a/packages/material-ui/src/withWidth/withWidth.js\n+++ b/packages/material-ui/src/withWidth/withWidth.js\n@@ -98,7 +98,7 @@ const withWidth = (options = {}) => Component => {\n     }\n \n     render() {\n-      const { initialWidth, theme, width, ...other } = this.props;\n+      const { initialWidth, theme, width, innerRef, ...other } = this.props;\n \n       const props = {\n         width:\n@@ -127,7 +127,7 @@ const withWidth = (options = {}) => Component => {\n \n       return (\n         <EventListener target=\"window\" onResize={this.handleResize}>\n-          <Component {...more} {...props} />\n+          <Component {...more} {...props} ref={innerRef} />\n         </EventListener>\n       );\n     }\n@@ -152,6 +152,10 @@ const withWidth = (options = {}) => Component => {\n      * Bypass the width calculation logic.\n      */\n     width: PropTypes.oneOf(['xs', 'sm', 'md', 'lg', 'xl']),\n+    /**\n+     * Use that property to pass a ref callback to the decorated component.\n+     */\n+    innerRef: PropTypes.oneOfType([PropTypes.func, PropTypes.object]),\n   };\n \n   if (process.env.NODE_ENV !== 'production') {\n"}
{"instance_id": "mui__material-ui-14638", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Tab/Tab.js b/packages/material-ui/src/Tab/Tab.js\nindex 225674eb58..1b59bbd043 100644\n--- a/packages/material-ui/src/Tab/Tab.js\n+++ b/packages/material-ui/src/Tab/Tab.js\n@@ -97,9 +97,9 @@ export const styles = theme => ({\n     },\n   },\n   /* Styles applied to the label wrapper element if `label` is provided. */\n-  label: {},\n+  label: { lineHeight: 1.5 },\n   /* Deprecated, the styles will be removed in v4. */\n-  labelWrapped: {},\n+  labelWrapped: { lineHeight: 1.5 },\n });\n \n class Tab extends React.Component {\n"}
{"instance_id": "mui__material-ui-14391", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/styles/colorManipulator.js b/packages/material-ui/src/styles/colorManipulator.js\nindex 694f3f638b..f5c5cfe94e 100644\n--- a/packages/material-ui/src/styles/colorManipulator.js\n+++ b/packages/material-ui/src/styles/colorManipulator.js\n@@ -164,14 +164,47 @@ export function getLuminance(color) {\n   if (decomposedColor.type.indexOf('rgb') !== -1) {\n     const rgb = decomposedColor.values.map(val => {\n       val /= 255; // normalized\n-      return val <= 0.03928 ? val / 12.92 : ((val + 0.055) / 1.055) ** 2.4;\n+      return val < 0.04045 ? val / 12.92 : ((val + 0.055) / 1.055) ** 2.4;\n     });\n     // Truncate at 3 digits\n     return Number((0.2126 * rgb[0] + 0.7152 * rgb[1] + 0.0722 * rgb[2]).toFixed(3));\n   }\n \n-  // else if (decomposedColor.type.indexOf('hsl') !== -1)\n-  return decomposedColor.values[2] / 100;\n+  // Convert HSL/HSLA to sRGB and compute luminance\n+  const values = decomposedColor.values;\n+  const h = values[0];\n+  let s = values[1];\n+  let l = values[2];\n+\n+  s /= 100;\n+  l /= 100;\n+\n+  const hue2rgb = (p, q, t) => {\n+    if (t < 0) t += 1;\n+    if (t > 1) t -= 1;\n+    if (t < 1 / 6) return p + (q - p) * 6 * t;\n+    if (t < 1 / 2) return q;\n+    if (t < 2 / 3) return p + (q - p) * (2 / 3 - t) * 6;\n+    return p;\n+  };\n+\n+  let r;\n+  let g;\n+  let b;\n+\n+  if (s === 0) {\n+    r = g = b = l; // achromatic\n+  } else {\n+    const q = l < 0.5 ? l * (1 + s) : l + s - l * s;\n+    const p = 2 * l - q;\n+    const hk = (h % 360) / 360;\n+    r = hue2rgb(p, q, hk + 1 / 3);\n+    g = hue2rgb(p, q, hk);\n+    b = hue2rgb(p, q, hk - 1 / 3);\n+  }\n+\n+  const rgb = [r, g, b].map(val => (val < 0.04045 ? val / 12.92 : ((val + 0.055) / 1.055) ** 2.4));\n+  return Number((0.2126 * rgb[0] + 0.7152 * rgb[1] + 0.0722 * rgb[2]).toFixed(3));\n }\n \n /**\n"}
{"instance_id": "mui__material-ui-18257", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/NativeSelect/NativeSelect.js b/packages/material-ui/src/NativeSelect/NativeSelect.js\nindex 6c94a71a98..f791f208d7 100644\n--- a/packages/material-ui/src/NativeSelect/NativeSelect.js\n+++ b/packages/material-ui/src/NativeSelect/NativeSelect.js\n@@ -115,6 +115,8 @@ const NativeSelect = React.forwardRef(function NativeSelect(props, ref) {\n       ...inputProps,\n       ...(input ? input.props.inputProps : {}),\n     },\n+    // Ensure id is forwarded to the underlying input/select.\n+    id: other.id,\n     ref,\n     ...other,\n   });\ndiff --git a/packages/material-ui/src/Select/Select.js b/packages/material-ui/src/Select/Select.js\nindex 0fec819d6f..6296447495 100644\n--- a/packages/material-ui/src/Select/Select.js\n+++ b/packages/material-ui/src/Select/Select.js\n@@ -91,6 +91,7 @@ const Select = React.forwardRef(function Select(props, ref) {\n         : classes,\n       ...(input ? input.props.inputProps : {}),\n     },\n+    ...(native ? { id } : {}),\n     ref,\n     ...other,\n   });\n"}
{"instance_id": "mui__material-ui-19849", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.js b/packages/material-ui-lab/src/TreeItem/TreeItem.js\nindex 1b3c568b7c..378e3bb618 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.js\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.js\n@@ -135,7 +135,8 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n \n   let icon = iconProp;\n \n-  const expandable = Boolean(Array.isArray(children) ? children.length : children);\n+  const validChildItems = React.Children.toArray(children).filter(child => React.isValidElement(child));\n+  const expandable = validChildItems.length > 0;\n   const expanded = isExpanded ? isExpanded(nodeId) : false;\n   const focused = isFocused ? isFocused(nodeId) : false;\n   const tabbable = isTabbable ? isTabbable(nodeId) : false;\n@@ -338,7 +339,9 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n   };\n \n   React.useEffect(() => {\n-    const childIds = React.Children.map(children, child => child.props.nodeId) || [];\n+    const childIds = React.Children.toArray(children)\n+      .filter(child => React.isValidElement(child) && child.props && typeof child.props.nodeId === 'string')\n+      .map(child => child.props.nodeId);\n     if (addNodeToNodeMap) {\n       addNodeToNodeMap(nodeId, childIds);\n     }\n@@ -391,7 +394,7 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n           {label}\n         </Typography>\n       </div>\n-      {children && (\n+      {validChildItems.length > 0 && (\n         <TransitionComponent\n           unmountOnExit\n           className={classes.group}\n@@ -400,7 +403,7 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n           role=\"group\"\n           {...TransitionProps}\n         >\n-          {children}\n+          {validChildItems}\n         </TransitionComponent>\n       )}\n     </li>\ndiff --git a/packages/material-ui-lab/src/TreeView/TreeView.js b/packages/material-ui-lab/src/TreeView/TreeView.js\nindex ef214967de..4306f486bc 100644\n--- a/packages/material-ui-lab/src/TreeView/TreeView.js\n+++ b/packages/material-ui-lab/src/TreeView/TreeView.js\n@@ -386,10 +386,13 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n    */\n \n   const addNodeToNodeMap = (id, childrenIds) => {\n+    const filtered = Array.isArray(childrenIds)\n+      ? childrenIds.filter(childId => typeof childId === 'string')\n+      : [];\n     const currentMap = nodeMap.current[id];\n-    nodeMap.current[id] = { ...currentMap, children: childrenIds, id };\n+    nodeMap.current[id] = { ...currentMap, children: filtered, id };\n \n-    childrenIds.forEach(childId => {\n+    filtered.forEach(childId => {\n       const currentChildMap = nodeMap.current[childId];\n       nodeMap.current[childId] = { ...currentChildMap, parent: id, id: childId };\n     });\n@@ -417,7 +420,9 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n   const prevChildIds = React.useRef([]);\n   const [childrenCalculated, setChildrenCalculated] = React.useState(false);\n   React.useEffect(() => {\n-    const childIds = React.Children.map(children, child => child.props.nodeId) || [];\n+    const childIds = React.Children.toArray(children)\n+      .filter(child => React.isValidElement(child) && child.props && typeof child.props.nodeId === 'string')\n+      .map(child => child.props.nodeId);\n     if (arrayDiff(prevChildIds.current, childIds)) {\n       nodeMap.current[-1] = { parent: null, children: childIds };\n \n"}
{"instance_id": "mui__material-ui-19511", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 632fb2bf45..6974541d9f 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -274,6 +274,12 @@ export default function useAutocomplete(props) {\n \n   popupOpen = freeSolo && filteredOptions.length === 0 ? false : popupOpen;\n \n+  // Reset indices when there are no options to prevent stale selection\n+  if (filteredOptions.length === 0) {\n+    highlightedIndexRef.current = -1;\n+    selectedIndexRef.current = -1;\n+  }\n+\n   const focusTag = useEventCallback(tagToFocus => {\n     if (tagToFocus === -1) {\n       inputRef.current.focus();\n@@ -656,7 +662,11 @@ export default function useAutocomplete(props) {\n       return;\n     }\n \n-    if (autoSelect && selectedIndexRef.current !== -1) {\n+    if (\n+      autoSelect &&\n+      selectedIndexRef.current !== -1 &&\n+      filteredOptions[selectedIndexRef.current] !== undefined\n+    ) {\n       selectNewValue(event, filteredOptions[selectedIndexRef.current]);\n     } else if (autoSelect && freeSolo && inputValue !== '') {\n       selectNewValue(event, inputValue, 'freeSolo');\n"}
{"instance_id": "mui__material-ui-19794", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 9957ed76d7..5130f0b3b2 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -760,9 +760,31 @@ export default function useAutocomplete(props) {\n     }\n   };\n \n-  // Prevent input blur when interacting with the combobox\n+  // Prevent input blur only when interacting with interactive sub-elements of the combobox\n   const handleMouseDown = event => {\n-    if (event.target.getAttribute('id') !== id) {\n+    // Allow default when clicking the input itself so it can blur naturally.\n+    if (event.target.getAttribute('id') === id) {\n+      return;\n+    }\n+\n+    // Walk up from the target to the root to determine if the click was on an interactive element.\n+    let el = event.target;\n+    let prevent = false;\n+    while (el && el !== event.currentTarget) {\n+      const getAttr = name => (el.getAttribute ? el.getAttribute(name) : null);\n+      const role = getAttr('role');\n+      const isButton = el.nodeName === 'BUTTON';\n+      const isTag = getAttr('data-tag-index') !== null;\n+      const isOption = role === 'option' || role === 'listbox';\n+\n+      if (isButton || isTag || isOption) {\n+        prevent = true;\n+        break;\n+      }\n+      el = el.parentElement;\n+    }\n+\n+    if (prevent) {\n       event.preventDefault();\n     }\n   };\n"}
{"instance_id": "mui__material-ui-20252", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Tooltip/Tooltip.js b/packages/material-ui/src/Tooltip/Tooltip.js\nindex 1d8154194b..62517243aa 100644\n--- a/packages/material-ui/src/Tooltip/Tooltip.js\n+++ b/packages/material-ui/src/Tooltip/Tooltip.js\n@@ -340,7 +340,7 @@ const Tooltip = React.forwardRef(function Tooltip(props, ref) {\n     }\n \n     const childrenProps = children.props;\n-    if (childrenProps.onFocus && event.currentTarget === childNode) {\n+    if (childrenProps.onFocus) {\n       childrenProps.onFocus(event);\n     }\n   };\n@@ -366,7 +366,7 @@ const Tooltip = React.forwardRef(function Tooltip(props, ref) {\n     const childrenProps = children.props;\n \n     if (event.type === 'blur') {\n-      if (childrenProps.onBlur && event.currentTarget === childNode) {\n+      if (childrenProps.onBlur) {\n         childrenProps.onBlur(event);\n       }\n       handleBlur(event);\n"}
{"instance_id": "mui__material-ui-20356", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Select/SelectInput.js b/packages/material-ui/src/Select/SelectInput.js\nindex 4bc58297fa..082b1ca0cc 100644\n--- a/packages/material-ui/src/Select/SelectInput.js\n+++ b/packages/material-ui/src/Select/SelectInput.js\n@@ -324,7 +324,7 @@ const SelectInput = React.forwardRef(function SelectInput(props, ref) {\n         tabIndex={tabIndex}\n         role=\"button\"\n         aria-expanded={open ? 'true' : undefined}\n-        aria-labelledby={`${labelId || ''} ${buttonId || ''}`}\n+        aria-labelledby={[labelId, buttonId].filter(Boolean).join(' ') || undefined}\n         aria-haspopup=\"listbox\"\n         onKeyDown={handleKeyDown}\n         onMouseDown={disabled || readOnly ? null : handleMouseDown}\n@@ -363,7 +363,7 @@ const SelectInput = React.forwardRef(function SelectInput(props, ref) {\n         onClose={handleClose}\n         {...MenuProps}\n         MenuListProps={{\n-          'aria-labelledby': labelId,\n+          'aria-labelledby': [labelId, buttonId].filter(Boolean).join(' ') || undefined,\n           role: 'listbox',\n           disableListWrap: true,\n           ...MenuProps.MenuListProps,\ndiff --git a/packages/material-ui/src/TablePagination/TablePagination.js b/packages/material-ui/src/TablePagination/TablePagination.js\nindex 019ce8d0bf..731281d4e0 100644\n--- a/packages/material-ui/src/TablePagination/TablePagination.js\n+++ b/packages/material-ui/src/TablePagination/TablePagination.js\n@@ -104,17 +104,20 @@ const TablePagination = React.forwardRef(function TablePagination(props, ref) {\n \n   const MenuItemComponent = SelectProps.native ? 'option' : MenuItem;\n \n+  const labelId = rowsPerPageOptions.length > 1 ? 'mui-table-pagination-label' : undefined;\n+  const selectLabelId = (SelectProps && SelectProps.labelId) || labelId;\n+\n   return (\n     <Component className={clsx(classes.root, className)} colSpan={colSpan} ref={ref} {...other}>\n       <Toolbar className={classes.toolbar}>\n         <div className={classes.spacer} />\n         {rowsPerPageOptions.length > 1 && (\n-          <Typography color=\"inherit\" variant=\"body2\" className={classes.caption}>\n+          <Typography id={selectLabelId} color=\"inherit\" variant=\"body2\" className={classes.caption}>\n             {labelRowsPerPage}\n           </Typography>\n         )}\n         {rowsPerPageOptions.length > 1 && (\n-          <Select\n+          <Select labelId={selectLabelId}\n             classes={{\n               select: classes.select,\n               icon: classes.selectIcon,\n"}
{"instance_id": "mui__material-ui-20377", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/pages/api-docs/menu-item.md b/docs/pages/api-docs/menu-item.md\nindex 1fbf2421d3..a5ef0c50f2 100644\n--- a/docs/pages/api-docs/menu-item.md\n+++ b/docs/pages/api-docs/menu-item.md\n@@ -44,6 +44,7 @@ Any other props supplied will be provided to the root element ([ListItem](/api/l\n | <span class=\"prop-name\">root</span> | <span class=\"prop-name\">.MuiMenuItem-root</span> | Styles applied to the root element.\n | <span class=\"prop-name\">gutters</span> | <span class=\"prop-name\">.MuiMenuItem-gutters</span> | Styles applied to the root element if `disableGutters={false}`.\n | <span class=\"prop-name\">selected</span> | <span class=\"prop-name\">.Mui-selected</span> | Styles applied to the root element if `selected={true}`.\n+| <span class=\"prop-name\">disabled</span> | <span class=\"prop-name\">.Mui-disabled</span> | Pseudo-class applied to the inner `component` element if `disabled={true}`.\n | <span class=\"prop-name\">dense</span> | <span class=\"prop-name\">.MuiMenuItem-dense</span> | Styles applied to the root element if dense.\n \n You can override the style of the component thanks to one of these customization points:\ndiff --git a/packages/material-ui/src/MenuItem/MenuItem.js b/packages/material-ui/src/MenuItem/MenuItem.js\nindex fa0eee22a6..d946b16718 100644\n--- a/packages/material-ui/src/MenuItem/MenuItem.js\n+++ b/packages/material-ui/src/MenuItem/MenuItem.js\n@@ -24,6 +24,8 @@ export const styles = (theme) => ({\n   gutters: {},\n   /* Styles applied to the root element if `selected={true}`. */\n   selected: {},\n+  /* Pseudo-class applied to the inner `component` element if `disabled={true}`. */\n+  disabled: {},\n   /* Styles applied to the root element if dense. */\n   dense: {\n     ...theme.typography.body2,\n@@ -55,7 +57,7 @@ const MenuItem = React.forwardRef(function MenuItem(props, ref) {\n       component={component}\n       selected={selected}\n       disableGutters={disableGutters}\n-      classes={{ dense: classes.dense }}\n+      classes={{ dense: classes.dense, disabled: classes.disabled }}\n       className={clsx(\n         classes.root,\n         {\n"}
{"instance_id": "mui__material-ui-20368", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Chip/Chip.js b/packages/material-ui/src/Chip/Chip.js\nindex f80d27599e..0cdbe0bce5 100644\n--- a/packages/material-ui/src/Chip/Chip.js\n+++ b/packages/material-ui/src/Chip/Chip.js\n@@ -302,7 +302,12 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n     if (isDeleteKeyboardEvent(event)) {\n       // will be handled in keyUp, otherwise some browsers\n       // might init navigation\n-      event.preventDefault();\n+      const target = event.target;\n+      const isEditable =\n+        target && (target.isContentEditable === true || target.tagName === 'INPUT' || target.tagName === 'TEXTAREA');\n+      if (!isEditable) {\n+        event.preventDefault();\n+      }\n     }\n \n     if (onKeyDown) {\n"}
{"instance_id": "mui__material-ui-20657", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/pages/api-docs/tree-view.md b/docs/pages/api-docs/tree-view.md\nindex ef55ae30b2..587570ecb3 100644\n--- a/docs/pages/api-docs/tree-view.md\n+++ b/docs/pages/api-docs/tree-view.md\n@@ -39,6 +39,7 @@ The `MuiTreeView` name can be used for providing [default props](/customization/\n | <span class=\"prop-name\">disableSelection</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true` selection is disabled. |\n | <span class=\"prop-name\">expanded</span> | <span class=\"prop-type\">Array&lt;string&gt;</span> |  | Expanded node ids. (Controlled) |\n | <span class=\"prop-name\">multiSelect</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If true `ctrl` and `shift` will trigger multiselect. |\n+| <span class=\"prop-name\">expandOnClick</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">true</span> | If `true`, clicking a tree item's content (including label) will toggle its expansion. If `false`, expansion/collapse is only triggered via the expand/collapse icon or keyboard interactions. |\n | <span class=\"prop-name\">onNodeSelect</span> | <span class=\"prop-type\">func</span> |  | Callback fired when tree items are selected/unselected.<br><br>**Signature:**<br>`function(event: object, value: array \\| string) => void`<br>*event:* The event source of the callback<br>*value:* of the selected nodes. When `multiSelect` is true this is an array of strings; when false (default) a string. |\n | <span class=\"prop-name\">onNodeToggle</span> | <span class=\"prop-type\">func</span> |  | Callback fired when tree items are expanded/collapsed.<br><br>**Signature:**<br>`function(event: object, nodeIds: array) => void`<br>*event:* The event source of the callback.<br>*nodeIds:* The ids of the expanded nodes. |\n | <span class=\"prop-name\">selected</span> | <span class=\"prop-type\">Array&lt;string&gt;<br>&#124;&nbsp;string</span> |  | Selected node ids. (Controlled) When `multiSelect` is true this takes an array of strings; when false (default) a string. |\ndiff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.js b/packages/material-ui-lab/src/TreeItem/TreeItem.js\nindex 6b29a4c902..446bdb700b 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.js\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.js\n@@ -126,6 +126,7 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n     mapFirstChar,\n     addNodeToNodeMap,\n     removeNodeFromNodeMap,\n+    expandOnClick,\n   } = React.useContext(TreeViewContext);\n \n   const nodeRef = React.useRef(null);\n@@ -166,7 +167,7 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n     const multiple = multiSelect && (event.shiftKey || event.ctrlKey || event.metaKey);\n \n     // If already expanded and trying to toggle selection don't close\n-    if (expandable && !(multiple && isExpanded(nodeId))) {\n+    if (expandOnClick && expandable && !(multiple && isExpanded(nodeId))) {\n       toggleExpansion(event, nodeId);\n     }\n \n@@ -386,7 +387,20 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n         onMouseDown={handleMouseDown}\n         ref={contentRef}\n       >\n-        <div className={classes.iconContainer}>{icon}</div>\n+        <div\n+          className={classes.iconContainer}\n+          onClick={expandOnClick === false && expandable ? (event) => {\n+            if (!focused) {\n+              focus(nodeId);\n+            }\n+            // Toggle expansion via icon click without affecting selection\n+            toggleExpansion(event, nodeId);\n+            // Prevent the click from bubbling to content which might select the node\n+            event.stopPropagation();\n+          } : undefined}\n+        >\n+          {icon}\n+        </div>\n         <Typography component=\"div\" className={classes.label}>\n           {label}\n         </Typography>\ndiff --git a/packages/material-ui-lab/src/TreeView/TreeView.js b/packages/material-ui-lab/src/TreeView/TreeView.js\nindex 9d9b6449fb..2060a726f3 100644\n--- a/packages/material-ui-lab/src/TreeView/TreeView.js\n+++ b/packages/material-ui-lab/src/TreeView/TreeView.js\n@@ -49,6 +49,7 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n     defaultSelected = defaultSelectedDefault,\n     disableSelection = false,\n     multiSelect = false,\n+    expandOnClick = true,\n     expanded: expandedProp,\n     onNodeSelect,\n     onNodeToggle,\n@@ -528,6 +529,7 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n         mapFirstChar,\n         addNodeToNodeMap,\n         removeNodeFromNodeMap,\n+        expandOnClick,\n       }}\n     >\n       <ul\n@@ -600,6 +602,11 @@ TreeView.propTypes = {\n    * If true `ctrl` and `shift` will trigger multiselect.\n    */\n   multiSelect: PropTypes.bool,\n+  /**\n+   * If `true`, clicking a tree item's content (including label) will toggle its expansion.\n+   * If `false`, expansion/collapse is only triggered via the expand/collapse icon or keyboard interactions.\n+   */\n+  expandOnClick: PropTypes.bool,\n   /**\n    * Callback fired when tree items are selected/unselected.\n    *\n"}
{"instance_id": "mui__material-ui-20732", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 76a1fb32dc..cd3ef10670 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -862,6 +862,10 @@ export default function useAutocomplete(props) {\n   const handleInputMouseDown = (event) => {\n     if (inputValue === '') {\n       handlePopupIndicator(event);\n+    } else if (inputValueIsSelectedValue) {\n+      if (!open) {\n+        handleOpen(event);\n+      }\n     }\n   };\n \n"}
{"instance_id": "mui__material-ui-23701", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/src/pages/components/date-range-picker/date-range-picker.md b/docs/src/pages/components/date-range-picker/date-range-picker.md\nindex 593f7629f2..a641707341 100644\n--- a/docs/src/pages/components/date-range-picker/date-range-picker.md\n+++ b/docs/src/pages/components/date-range-picker/date-range-picker.md\n@@ -44,6 +44,11 @@ Note that you can pass almost any prop from [DatePicker]('/api/date-picker/').\n \n {{\"demo\": \"pages/components/date-range-picker/BasicDateRangePicker.js\"}}\n \n+### Allow same date selection\n+\n+When `allowSameDateSelection` is set to `true`, the range can have the same start and end date, which is useful for selecting a single-day range.\n+\n+\n ## Responsiveness\n \n The date range picker component is designed to be optimized for the device it runs on.\ndiff --git a/packages/material-ui-lab/src/DateRangePicker/DateRangePickerView.tsx b/packages/material-ui-lab/src/DateRangePicker/DateRangePickerView.tsx\nindex 2a73bedbee..a6883379da 100644\n--- a/packages/material-ui-lab/src/DateRangePicker/DateRangePickerView.tsx\n+++ b/packages/material-ui-lab/src/DateRangePicker/DateRangePickerView.tsx\n@@ -31,6 +31,11 @@ export interface ExportedDateRangePickerViewProps<TDate>\n    * @default false\n    */\n   disableAutoMonthSwitching?: boolean;\n+  /**\n+   * If `true`, allows selecting the same date for start and end of the range.\n+   * @default false\n+   */\n+  allowSameDateSelection?: boolean;\n }\n \n interface DateRangePickerViewProps<TDate>\n@@ -149,8 +154,14 @@ export function DateRangePickerView<TDate>(props: DateRangePickerViewProps<TDate\n \n       setCurrentlySelectingRangeEnd(nextSelection);\n \n+      const allowSame = Boolean(props.allowSameDateSelection);\n+      const isValidSelected =\n+        Boolean(newRange[0] && newRange[1]) &&\n+        (allowSame\n+          ? utils.isBefore(newRange[0]!, newRange[1]!) || utils.isEqual(newRange[0]!, newRange[1]!)\n+          : utils.isBefore(newRange[0]!, newRange[1]!));\n       const isFullRangeSelected =\n-        currentlySelectingRangeEnd === 'end' && isRangeValid(utils, newRange);\n+        currentlySelectingRangeEnd === 'end' && isValidSelected;\n \n       onDateChange(\n         newRange as DateRange<TDate>,\ndiff --git a/packages/material-ui-lab/src/internal/pickers/date-utils.ts b/packages/material-ui-lab/src/internal/pickers/date-utils.ts\nindex c3d17b5703..6125cc5981 100644\n--- a/packages/material-ui-lab/src/internal/pickers/date-utils.ts\n+++ b/packages/material-ui-lab/src/internal/pickers/date-utils.ts\n@@ -180,6 +180,11 @@ export interface DateValidationProps<TDate> {\n    * @default false\n    */\n   disableFuture?: boolean;\n+  /**\n+   * If `true`, allows selecting the same date for start and end of the range.\n+   * @default false\n+   */\n+  allowSameDateSelection?: boolean;\n }\n \n export const validateDate = <TDate>(\n@@ -243,7 +248,16 @@ export const validateDateRange = <TDate>(\n     return dateValidations;\n   }\n \n-  if (!isRangeValid(utils, [utils.date(start), utils.date(end)])) {\n+  const startDate = utils.date(start);\n+  const endDate = utils.date(end);\n+  const allowSame = Boolean(dateValidationProps && dateValidationProps.allowSameDateSelection);\n+  const isValidRange =\n+    Boolean(startDate && endDate) &&\n+    (allowSame\n+      ? utils.isBefore(startDate, endDate) || utils.isEqual(startDate, endDate)\n+      : utils.isBefore(startDate, endDate));\n+\n+  if (!isValidRange) {\n     return ['invalidRange', 'invalidRange'];\n   }\n \n"}
{"instance_id": "mui__material-ui-23229", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/useAutocomplete/useAutocomplete.js b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\nindex 52d5598729..5ae540f97b 100644\n--- a/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n@@ -880,7 +880,7 @@ export default function useAutocomplete(props) {\n   };\n \n   // Focus the input when interacting with the combobox\n-  const handleClick = () => {\n+  const handleClick = (event) => {\n     inputRef.current.focus();\n \n     if (\n@@ -892,6 +892,17 @@ export default function useAutocomplete(props) {\n     }\n \n     firstFocus.current = false;\n+\n+    // Open the popup when clicking on the combobox container (deadzone) similar to input mousedown.\n+    // Avoid double toggling when clicking on interactive elements like the popup or clear buttons.\n+    const isInputClick = event && event.target && event.target.getAttribute('id') === id;\n+    const isButtonClick =\n+      event && event.target && typeof event.target.closest === 'function'\n+        ? event.target.closest('button') != null\n+        : false;\n+    if (!isInputClick && !isButtonClick && (inputValue === '' || !open)) {\n+      handlePopupIndicator(event);\n+    }\n   };\n \n   const handleInputMouseDown = (event) => {\n"}
{"instance_id": "mui__material-ui-22696", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/pages/api-docs/autocomplete.md b/docs/pages/api-docs/autocomplete.md\nindex 93cc13d2a6..19c453817b 100644\n--- a/docs/pages/api-docs/autocomplete.md\n+++ b/docs/pages/api-docs/autocomplete.md\n@@ -42,7 +42,7 @@ The `MuiAutocomplete` name can be used for providing [default props](/customizat\n | <span class=\"prop-name\">debug</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, the popup will ignore the blur event if the input is filled. You can inspect the popup markup with your browser tools. Consider this option when you need to customize the component. |\n | <span class=\"prop-name\">defaultValue</span> | <span class=\"prop-type\">any</span> | <span class=\"prop-default\">props.multiple ? [] : null</span> | The default input value. Use when the component is not controlled. |\n | <span class=\"prop-name\">disableClearable</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, the input can't be cleared. |\n-| <span class=\"prop-name\">disableCloseOnSelect</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, the popup won't close when a value is selected. |\n+| <span class=\"prop-name\">disableCloseOnSelect</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, the popup won't close when a value is selected. When `multiple` is `true`, holding Ctrl (or Cmd on macOS) or Shift while clicking an option will keep the popup open for that selection even if `disableCloseOnSelect` is `false`. |\n | <span class=\"prop-name\">disabled</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, the input will be disabled. |\n | <span class=\"prop-name\">disabledItemsFocusable</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, will allow focus on disabled items. |\n | <span class=\"prop-name\">disableListWrap</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, the list box in the popup will not wrap focus. |\ndiff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex a9d8d48de3..ce7dddf85a 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -563,14 +563,20 @@ export default function useAutocomplete(props) {\n     resetInputValue(event, newValue);\n \n     handleValue(event, newValue, reason, { option });\n-    if (!disableCloseOnSelect) {\n+    const keepOpenModifier =\n+      multiple &&\n+      event &&\n+      event.type === 'click' &&\n+      (event.ctrlKey || event.shiftKey || event.metaKey);\n+    if (!disableCloseOnSelect && !keepOpenModifier) {\n       handleClose(event, reason);\n     }\n \n     if (\n-      blurOnSelect === true ||\n-      (blurOnSelect === 'touch' && isTouch.current) ||\n-      (blurOnSelect === 'mouse' && !isTouch.current)\n+      !keepOpenModifier &&\n+      (blurOnSelect === true ||\n+        (blurOnSelect === 'touch' && isTouch.current) ||\n+        (blurOnSelect === 'mouse' && !isTouch.current))\n     ) {\n       inputRef.current.blur();\n     }\n"}
{"instance_id": "mui__material-ui-24213", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/useAutocomplete/useAutocomplete.js b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\nindex a47295e97d..d631c89aec 100644\n--- a/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n@@ -285,7 +285,12 @@ export default function useAutocomplete(props) {\n     if (index === -1) {\n       inputRef.current.removeAttribute('aria-activedescendant');\n     } else {\n-      inputRef.current.setAttribute('aria-activedescendant', `${id}-option-${index}`);\n+      const option = filteredOptions[index];\n+      const stableIndex = findIndex(options, (opt) => getOptionSelected(opt, option));\n+      inputRef.current.setAttribute(\n+        'aria-activedescendant',\n+        `${id}-option-${stableIndex === -1 ? index : stableIndex}`,\n+      );\n     }\n \n     if (onHighlightChange) {\n@@ -1004,8 +1009,10 @@ export default function useAutocomplete(props) {\n       );\n       const disabled = getOptionDisabled ? getOptionDisabled(option) : false;\n \n+      const stableIndex = findIndex(options, (opt) => getOptionSelected(opt, option));\n+\n       return {\n-        key: index,\n+        key: stableIndex === -1 ? index : stableIndex,\n         tabIndex: -1,\n         role: 'option',\n         id: `${id}-option-${index}`,\n"}
{"instance_id": "mui__material-ui-24105", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.js b/packages/material-ui-lab/src/TreeItem/TreeItem.js\nindex 742f6663e5..e1b4040473 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.js\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.js\n@@ -223,7 +223,17 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n   function handleFocus(event) {\n     // DOM focus stays on the tree which manages focus with aria-activedescendant\n     if (event.target === event.currentTarget) {\n-      ownerDocument(event.target).getElementById(treeId).focus();\n+      const doc = ownerDocument(event.target);\n+      const tree = doc.getElementById(treeId);\n+      if (tree && doc.activeElement !== tree) {\n+        // Avoid scrolling when programmatically focusing the tree root\n+        try {\n+          tree.focus({ preventScroll: true });\n+        } catch (e) {\n+          // Fallback for browsers that don't support preventScroll option\n+          tree.focus();\n+        }\n+      }\n     }\n \n     const unfocusable = !disabledItemsFocusable && disabled;\n"}
{"instance_id": "mui__material-ui-24742", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/InputAdornment/InputAdornment.js b/packages/material-ui/src/InputAdornment/InputAdornment.js\nindex 4d04077933..109985e5ef 100644\n--- a/packages/material-ui/src/InputAdornment/InputAdornment.js\n+++ b/packages/material-ui/src/InputAdornment/InputAdornment.js\n@@ -8,7 +8,7 @@ import FormControlContext, { useFormControl } from '../FormControl/FormControlCo\n export const styles = {\n   /* Styles applied to the root element. */\n   root: {\n-    display: 'flex',\n+    display: 'inline-flex',\n     height: '0.01em', // Fix IE11 flexbox alignment. To remove at some point.\n     maxHeight: '2em',\n     alignItems: 'center',\n@@ -23,6 +23,7 @@ export const styles = {\n   /* Styles applied to the root element if `position=\"start\"`. */\n   positionStart: {\n     marginRight: 8,\n+    order: 2,\n   },\n   /* Styles applied to the root element if `position=\"end\"`. */\n   positionEnd: {\n"}
{"instance_id": "apache__rocketmq-1636", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/AbstractSendMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/AbstractSendMessageProcessor.java\nindex b0668d49f..0bf28dc19 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/AbstractSendMessageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/AbstractSendMessageProcessor.java\n@@ -142,7 +142,7 @@ public abstract class AbstractSendMessageProcessor implements NettyRequestProces\n     protected RemotingCommand msgContentCheck(final ChannelHandlerContext ctx,\n         final SendMessageRequestHeader requestHeader, RemotingCommand request,\n         final RemotingCommand response) {\n-        if (requestHeader.getTopic().length() > Byte.MAX_VALUE) {\n+        if (requestHeader.getTopic().length() > 255) {\n             log.warn(\"putMessage message topic length too long {}\", requestHeader.getTopic().length());\n             response.setCode(ResponseCode.MESSAGE_ILLEGAL);\n             return response;\ndiff --git a/broker/src/main/java/org/apache/rocketmq/broker/processor/SendMessageProcessor.java b/broker/src/main/java/org/apache/rocketmq/broker/processor/SendMessageProcessor.java\nindex 2589a7547..14ec2f2a9 100644\n--- a/broker/src/main/java/org/apache/rocketmq/broker/processor/SendMessageProcessor.java\n+++ b/broker/src/main/java/org/apache/rocketmq/broker/processor/SendMessageProcessor.java\n@@ -510,7 +510,7 @@ public class SendMessageProcessor extends AbstractSendMessageProcessor implement\n             queueIdInt = Math.abs(this.random.nextInt() % 99999999) % topicConfig.getWriteQueueNums();\n         }\n \n-        if (requestHeader.getTopic().length() > Byte.MAX_VALUE) {\n+        if (requestHeader.getTopic().length() > 255) {\n             response.setCode(ResponseCode.MESSAGE_ILLEGAL);\n             response.setRemark(\"message topic length too long \" + requestHeader.getTopic().length());\n             return response;\ndiff --git a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\nindex d5ba5692a..ddf31dec2 100644\n--- a/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\n+++ b/store/src/main/java/org/apache/rocketmq/store/DefaultMessageStore.java\n@@ -377,7 +377,7 @@ public class DefaultMessageStore implements MessageStore {\n             this.printTimes.set(0);\n         }\n \n-        if (msg.getTopic().length() > Byte.MAX_VALUE) {\n+        if (msg.getTopic().length() > 255) {\n             log.warn(\"putMessage message topic length too long \" + msg.getTopic().length());\n             return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);\n         }\n@@ -433,7 +433,7 @@ public class DefaultMessageStore implements MessageStore {\n             this.printTimes.set(0);\n         }\n \n-        if (messageExtBatch.getTopic().length() > Byte.MAX_VALUE) {\n+        if (messageExtBatch.getTopic().length() > 255) {\n             log.warn(\"PutMessages topic length too long \" + messageExtBatch.getTopic().length());\n             return new PutMessageResult(PutMessageStatus.MESSAGE_ILLEGAL, null);\n         }\n"}
{"instance_id": "trinodb__trino-3208", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/connector/system/jdbc/TableJdbcTable.java b/presto-main/src/main/java/io/prestosql/connector/system/jdbc/TableJdbcTable.java\nindex 7e85dd22a73..002ab34ccdf 100644\n--- a/presto-main/src/main/java/io/prestosql/connector/system/jdbc/TableJdbcTable.java\n+++ b/presto-main/src/main/java/io/prestosql/connector/system/jdbc/TableJdbcTable.java\n@@ -98,10 +98,19 @@ public class TableJdbcTable\n             QualifiedTablePrefix prefix = tablePrefix(catalog, schemaFilter, tableFilter);\n \n             Set<SchemaTableName> views = listViews(session, metadata, accessControl, prefix);\n-            for (SchemaTableName name : listTables(session, metadata, accessControl, prefix)) {\n-                boolean isView = views.contains(name);\n-                if ((includeTables && !isView) || (includeViews && isView)) {\n-                    table.addRow(tableRow(catalog, name, isView ? \"VIEW\" : \"TABLE\"));\n+            Set<SchemaTableName> tables = listTables(session, metadata, accessControl, prefix);\n+\n+            if (includeTables) {\n+                for (SchemaTableName name : tables) {\n+                    if (!views.contains(name)) {\n+                        table.addRow(tableRow(catalog, name, \"TABLE\"));\n+                    }\n+                }\n+            }\n+\n+            if (includeViews) {\n+                for (SchemaTableName name : views) {\n+                    table.addRow(tableRow(catalog, name, \"VIEW\"));\n                 }\n             }\n         }\n"}
{"instance_id": "trinodb__trino-3603", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/AddLocalExchanges.java b/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/AddLocalExchanges.java\nindex 25c568303bf..40f492bae0c 100644\n--- a/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/AddLocalExchanges.java\n+++ b/presto-main/src/main/java/io/prestosql/sql/planner/optimizations/AddLocalExchanges.java\n@@ -56,6 +56,7 @@ import io.prestosql.sql.planner.plan.TopNNode;\n import io.prestosql.sql.planner.plan.TopNRowNumberNode;\n import io.prestosql.sql.planner.plan.UnionNode;\n import io.prestosql.sql.planner.plan.WindowNode;\n+import io.prestosql.sql.planner.plan.ProjectNode;\n \n import java.util.ArrayList;\n import java.util.Iterator;\n@@ -222,11 +223,13 @@ public class AddLocalExchanges\n             }\n \n             // final topN requires that all data be in one stream\n-            // also, a final changes the input organization completely, so we do not pass through parent preferences\n+            // also, a final changes the input organization completely, so we do not pass through parent preferences for input\n+            // However, we should respect parent's post-topN stream preference to avoid redundant exchanges\n+            StreamPreferredProperties requiredAfterTopN = parentPreferences.isSingleStreamPreferred() ? singleStream() : defaultParallelism(session);\n             return planAndEnforceChildren(\n                     node,\n                     singleStream(),\n-                    defaultParallelism(session));\n+                    requiredAfterTopN);\n         }\n \n         @Override\n@@ -336,7 +339,9 @@ public class AddLocalExchanges\n         @Override\n         public PlanWithProperties visitWindow(WindowNode node, StreamPreferredProperties parentPreferences)\n         {\n-            StreamPreferredProperties childRequirements = parentPreferences\n+            // Preserve single-stream if preferred by parent to avoid unnecessary round-robin below trivial projections\n+            StreamPreferredProperties basePreferences = parentPreferences;\n+            StreamPreferredProperties childRequirements = basePreferences\n                     .constrainTo(node.getSource().getOutputSymbols())\n                     .withDefaultParallelism(session)\n                     .withPartitioning(node.getPartitionBy());\n@@ -482,6 +487,27 @@ public class AddLocalExchanges\n             return planAndEnforceChildren(node, requiredProperties, requiredProperties);\n         }\n \n+        @Override\n+        public PlanWithProperties visitProject(ProjectNode node, StreamPreferredProperties parentPreferences)\n+        {\n+            // Detect trivial projection (identity/pruning): all output symbols are produced by the source\n+            List<Symbol> sourceOutputs = node.getSource().getOutputSymbols();\n+            boolean trivial = node.getOutputSymbols().stream().allMatch(sourceOutputs::contains);\n+\n+            if (trivial) {\n+                // Preserve parent stream preferences through trivial projections to avoid redundant local exchanges\n+                StreamPreferredProperties childRequirements = parentPreferences.constrainTo(sourceOutputs);\n+                PlanWithProperties child = planAndEnforce(node.getSource(), childRequirements, childRequirements);\n+                return rebaseAndDeriveProperties(node, ImmutableList.of(child));\n+            }\n+\n+            // Non-trivial projection: fall back to default behavior and allow default parallelism\n+            return planAndEnforceChildren(\n+                    node,\n+                    parentPreferences.withoutPreference().withDefaultParallelism(session),\n+                    parentPreferences.withDefaultParallelism(session));\n+        }\n+\n         //\n         // Table Writer\n         //\n"}
{"instance_id": "trinodb__trino-3599", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-docs/src/main/sphinx/functions/string.rst b/presto-docs/src/main/sphinx/functions/string.rst\nindex c7460e73fcb..a6fd0dbf439 100644\n--- a/presto-docs/src/main/sphinx/functions/string.rst\n+++ b/presto-docs/src/main/sphinx/functions/string.rst\n@@ -154,12 +154,18 @@ String Functions\n     Positions start with ``1``. A negative starting position is interpreted\n     as being relative to the end of the string.\n \n+    When ``string`` is of type ``CHAR(n)``, this function returns a ``VARCHAR(n)``\n+    and does not pad the result to the fixed length.\n+\n .. function:: substr(string, start, length) -> varchar\n \n     Returns a substring from ``string`` of length ``length`` from the starting\n     position ``start``. Positions start with ``1``. A negative starting\n     position is interpreted as being relative to the end of the string.\n \n+    When ``string`` is of type ``CHAR(n)``, this function returns a ``VARCHAR(n)``\n+    and does not pad the result to the fixed length.\n+\n .. function:: trim(string) -> varchar\n \n     Removes leading and trailing whitespace from ``string``.\ndiff --git a/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java b/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\nindex 2fb86d047f8..989146a4911 100644\n--- a/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\n+++ b/presto-main/src/main/java/io/prestosql/operator/scalar/StringFunctions.java\n@@ -309,7 +309,7 @@ public final class StringFunctions\n     @Description(\"Suffix starting at given index\")\n     @ScalarFunction(\"substr\")\n     @LiteralParameters(\"x\")\n-    @SqlType(\"char(x)\")\n+    @SqlType(\"varchar(x)\")\n     public static Slice charSubstr(@SqlType(\"char(x)\") Slice utf8, @SqlType(StandardTypes.BIGINT) long start)\n     {\n         return substr(utf8, start);\n@@ -367,10 +367,10 @@ public final class StringFunctions\n     @Description(\"Substring of given length starting at an index\")\n     @ScalarFunction(\"substr\")\n     @LiteralParameters(\"x\")\n-    @SqlType(\"char(x)\")\n+    @SqlType(\"varchar(x)\")\n     public static Slice charSubstr(@SqlType(\"char(x)\") Slice utf8, @SqlType(StandardTypes.BIGINT) long start, @SqlType(StandardTypes.BIGINT) long length)\n     {\n-        return trimTrailingSpaces(substr(utf8, start, length));\n+        return substr(utf8, start, length);\n     }\n \n     @ScalarFunction\ndiff --git a/presto-main/src/test/java/io/prestosql/operator/scalar/TestStringFunctions.java b/presto-main/src/test/java/io/prestosql/operator/scalar/TestStringFunctions.java\nindex da44808cdd9..b758aba3ad0 100644\n--- a/presto-main/src/test/java/io/prestosql/operator/scalar/TestStringFunctions.java\n+++ b/presto-main/src/test/java/io/prestosql/operator/scalar/TestStringFunctions.java\n@@ -390,41 +390,41 @@ public class TestStringFunctions\n     @Test\n     public void testCharSubstring()\n     {\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5)\", createCharType(13), padRight(\"ratically\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 50)\", createCharType(13), padRight(\"\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -5)\", createCharType(13), padRight(\"cally\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -50)\", createCharType(13), padRight(\"\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 0)\", createCharType(13), padRight(\"\", 13));\n-\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5, 6)\", createCharType(13), padRight(\"ratica\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5, 10)\", createCharType(13), padRight(\"ratically\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5, 50)\", createCharType(13), padRight(\"ratically\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 50, 10)\", createCharType(13), padRight(\"\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -5, 4)\", createCharType(13), padRight(\"call\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -5, 40)\", createCharType(13), padRight(\"cally\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -50, 4)\", createCharType(13), padRight(\"\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 0, 4)\", createCharType(13), padRight(\"\", 13));\n-        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5, 0)\", createCharType(13), padRight(\"\", 13));\n-\n-        assertFunction(\"SUBSTR(CAST('abc def' AS CHAR(7)), 1, 4)\", createCharType(7), padRight(\"abc\", 7));\n-\n-        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 5)\", createCharType(13), padRight(\"ratically\", 13));\n-        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 50)\", createCharType(13), padRight(\"\", 13));\n-        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM -5)\", createCharType(13), padRight(\"cally\", 13));\n-        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM -50)\", createCharType(13), padRight(\"\", 13));\n-        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 0)\", createCharType(13), padRight(\"\", 13));\n-\n-        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 5 FOR 6)\", createCharType(13), padRight(\"ratica\", 13));\n-        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 5 FOR 50)\", createCharType(13), padRight(\"ratically\", 13));\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5)\", createVarcharType(13), \"ratically\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 50)\", createVarcharType(13), \"\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -5)\", createVarcharType(13), \"cally\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -50)\", createVarcharType(13), \"\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 0)\", createVarcharType(13), \"\");\n+\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5, 6)\", createVarcharType(13), \"ratica\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5, 10)\", createVarcharType(13), \"ratically\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5, 50)\", createVarcharType(13), \"ratically\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 50, 10)\", createVarcharType(13), \"\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -5, 4)\", createVarcharType(13), \"call\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -5, 40)\", createVarcharType(13), \"cally\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), -50, 4)\", createVarcharType(13), \"\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 0, 4)\", createVarcharType(13), \"\");\n+        assertFunction(\"SUBSTR(CAST('Quadratically' AS CHAR(13)), 5, 0)\", createVarcharType(13), \"\");\n+\n+        assertFunction(\"SUBSTR(CAST('abc def' AS CHAR(7)), 1, 4)\", createVarcharType(7), \"abc \");\n+\n+        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 5)\", createVarcharType(13), \"ratically\");\n+        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 50)\", createVarcharType(13), \"\");\n+        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM -5)\", createVarcharType(13), \"cally\");\n+        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM -50)\", createVarcharType(13), \"\");\n+        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 0)\", createVarcharType(13), \"\");\n+\n+        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 5 FOR 6)\", createVarcharType(13), \"ratica\");\n+        assertFunction(\"SUBSTRING(CAST('Quadratically' AS CHAR(13)) FROM 5 FOR 50)\", createVarcharType(13), \"ratically\");\n         //\n         // Test SUBSTRING for non-ASCII\n-        assertFunction(\"SUBSTRING(CAST('\\u4FE1\\u5FF5,\\u7231,\\u5E0C\\u671B' AS CHAR(7)) FROM 1 FOR 1)\", createCharType(7), padRight(\"\\u4FE1\", 7));\n-        assertFunction(\"SUBSTRING(CAST('\\u4FE1\\u5FF5,\\u7231,\\u5E0C\\u671B' AS CHAR(7)) FROM 3 FOR 5)\", createCharType(7), padRight(\",\\u7231,\\u5E0C\\u671B\", 7));\n-        assertFunction(\"SUBSTRING(CAST('\\u4FE1\\u5FF5,\\u7231,\\u5E0C\\u671B' AS CHAR(7)) FROM 4)\", createCharType(7), padRight(\"\\u7231,\\u5E0C\\u671B\", 7));\n-        assertFunction(\"SUBSTRING(CAST('\\u4FE1\\u5FF5,\\u7231,\\u5E0C\\u671B' AS CHAR(7)) FROM -2)\", createCharType(7), padRight(\"\\u5E0C\\u671B\", 7));\n-        assertFunction(\"SUBSTRING(CAST('\\uD801\\uDC2Dend' AS CHAR(4)) FROM 1 FOR 1)\", createCharType(4), padRight(\"\\uD801\\uDC2D\", 4));\n-        assertFunction(\"SUBSTRING(CAST('\\uD801\\uDC2Dend' AS CHAR(4)) FROM 2 FOR 3)\", createCharType(4), padRight(\"end\", 4));\n-        assertFunction(\"SUBSTRING(CAST('\\uD801\\uDC2Dend' AS CHAR(40)) FROM 2 FOR 3)\", createCharType(40), padRight(\"end\", 40));\n+        assertFunction(\"SUBSTRING(CAST('\\u4FE1\\u5FF5,\\u7231,\\u5E0C\\u671B' AS CHAR(7)) FROM 1 FOR 1)\", createVarcharType(7), \"\\u4FE1\");\n+        assertFunction(\"SUBSTRING(CAST('\\u4FE1\\u5FF5,\\u7231,\\u5E0C\\u671B' AS CHAR(7)) FROM 3 FOR 5)\", createVarcharType(7), \",\\u7231,\\u5E0C\\u671B\");\n+        assertFunction(\"SUBSTRING(CAST('\\u4FE1\\u5FF5,\\u7231,\\u5E0C\\u671B' AS CHAR(7)) FROM 4)\", createVarcharType(7), \"\\u7231,\\u5E0C\\u671B\");\n+        assertFunction(\"SUBSTRING(CAST('\\u4FE1\\u5FF5,\\u7231,\\u5E0C\\u671B' AS CHAR(7)) FROM -2)\", createVarcharType(7), \"\\u5E0C\\u671B\");\n+        assertFunction(\"SUBSTRING(CAST('\\uD801\\uDC2Dend' AS CHAR(4)) FROM 1 FOR 1)\", createVarcharType(4), \"\\uD801\\uDC2D\");\n+        assertFunction(\"SUBSTRING(CAST('\\uD801\\uDC2Dend' AS CHAR(4)) FROM 2 FOR 3)\", createVarcharType(4), \"end\");\n+        assertFunction(\"SUBSTRING(CAST('\\uD801\\uDC2Dend' AS CHAR(40)) FROM 2 FOR 3)\", createVarcharType(40), \"end\");\n     }\n \n     @Test\n"}
{"instance_id": "prettier__prettier-3723", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/language-css/printer-postcss.js b/src/language-css/printer-postcss.js\nindex 794ae8035..522983d3d 100644\n--- a/src/language-css/printer-postcss.js\n+++ b/src/language-css/printer-postcss.js\n@@ -30,6 +30,9 @@ function genericPrint(path, options, print) {\n \n   switch (n.type) {\n     case \"css-root\": {\n+      if (!n.nodes || n.nodes.length === 0) {\n+        return \"\";\n+      }\n       return concat([printNodeSequence(path, options, print), hardline]);\n     }\n     case \"css-comment\": {\n"}
{"instance_id": "serverless__serverless-7617", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/events/apigateway.md b/docs/providers/aws/events/apigateway.md\nindex 27922e7c8..8b508204f 100644\n--- a/docs/providers/aws/events/apigateway.md\n+++ b/docs/providers/aws/events/apigateway.md\n@@ -189,7 +189,7 @@ JSON.parse(event.body);\n \n ### HTTP Endpoint with Extended Options\n \n-Here we've defined an POST endpoint for the path `posts/create`.\n+Here we've defined a POST endpoint for the path `posts/create`. You can optionally set `operationName` to control the AWS API Gateway Method `OperationName` (exported as Swagger `operationId`).\n \n ```yml\n # serverless.yml\n@@ -201,6 +201,7 @@ functions:\n       - http:\n           path: posts/create\n           method: post\n+          operationName: CreatePost\n ```\n \n ### Enabling CORS\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\nindex 11d1027f3..944e32224 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/index.js\n@@ -22,6 +22,10 @@ module.exports = {\n         },\n       };\n \n+      if (event.http.operationName) {\n+        template.Properties.OperationName = event.http.operationName;\n+      }\n+\n       if (event.http.private) {\n         template.Properties.ApiKeyRequired = true;\n       } else {\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\nindex f421ba74d..0c4f523ff 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\n@@ -47,6 +47,14 @@ module.exports = {\n           http.path = this.getHttpPath(http, functionName);\n           http.method = this.getHttpMethod(http, functionName);\n \n+          if (_.has(http, 'operationName') && typeof http.operationName !== 'string') {\n+            const errorMessage = [\n+              'Invalid \"operationName\" property in function \"' + functionName + '\"',\n+              ' for http event in serverless.yml. It must be a string.',\n+            ].join('');\n+            throw new this.serverless.classes.Error(errorMessage);\n+          }\n+\n           if (http.authorizer) {\n             http.authorizer = this.getAuthorizer(http, functionName);\n           }\n"}
{"instance_id": "serverless__serverless-7102", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/guides/best-practices/provisioned-concurrency.md b/docs/guides/best-practices/provisioned-concurrency.md\nnew file mode 100644\nindex 000000000..365f4a1a8\n--- /dev/null\n+++ b/docs/guides/best-practices/provisioned-concurrency.md\n@@ -0,0 +1,63 @@\n+<!--\n+title: Best Practices - Provisioned Concurrency\n+menuText: Provisioned Concurrency\n+menuOrder: 10\n+description: Best practices for using AWS Lambda Provisioned Concurrency with the Serverless Framework\n+layout: Doc\n+-->\n+\n+# Provisioned Concurrency Best Practices\n+\n+Provisioned Concurrency keeps a chosen number of Lambda execution environments initialized and ready to respond. It can only be applied to published versions and aliases, not $LATEST.\n+\n+Key points:\n+- Configure Provisioned Concurrency on an alias or published version.\n+- Event sources like API Gateway invoke $LATEST by default unless you target an alias/version.\n+- Weighted alias traffic shifting is not compatible with Provisioned Concurrency.\n+\n+## Event source routing\n+\n+To benefit from Provisioned Concurrency, ensure event sources invoke an alias or version that has Provisioned Concurrency configured.\n+\n+- API Gateway: Override the integration URI to include an alias suffix and grant invoke permissions to that alias.\n+- Other sources (SQS, SNS, EventBridge): Where applicable, wire triggers to alias ARNs.\n+\n+Reference ARN pattern for API Gateway integration:\n+- arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${functionName}:${aliasName}/invocations\n+\n+## Deployment lifecycle\n+\n+Each deploy publishes a new version. Maintain a stable alias per stage (e.g., dev, prod) and update that alias to the newly published version.\n+\n+Avoid weighted aliases with Provisioned Concurrency. Perform direct alias switches, or coordinate with CodeDeploy strategies that do not use weights for traffic shifting.\n+\n+## Cost management\n+\n+- Enable Provisioned Concurrency only where needed (e.g., production).\n+- Use pruning tools to delete old versions (e.g., serverless-prune-plugin).\n+- Monitor metrics for Provisioned Concurrency (utilization, spillover) and adjust values as required.\n+\n+Stage-based configuration example:\n+\n+```yml\n+custom:\n+  pc: ${env:PC, null} # e.g., export PC=5 in prod, leave unset in dev\n+functions:\n+  hello:\n+    handler: handler.hello\n+    provisionedConcurrency: ${self:custom.pc}\n+```\n+\n+## Troubleshooting\n+\n+- NotStabilized errors during deploy: Provisioned Concurrency may take time to be applied. Consider retries or deployment steps that wait for stabilization.\n+- Alias targeting: Confirm that integration URIs and triggers reference alias ARNs, not $LATEST.\n+- IAM permissions: Ensure event sources have lambda:InvokeFunction permissions against the alias ARN.\n+- Console verification: In the Lambda console, check that Provisioned Concurrency is configured on the alias you invoke.\n+\n+## End-to-end example (alias per stage)\n+\n+- Configure `provisionedConcurrency` on the function.\n+- Keep an alias named after the stage (e.g., prod) and wire API Gateway to that alias via a resources override.\n+- Deploy and confirm API Gateway integration points to the alias ARN.\n+- Verify reduced cold starts and Provisioned Concurrency utilization in metrics.\n\\ No newline at end of file\ndiff --git a/docs/providers/aws/events/apigateway.md b/docs/providers/aws/events/apigateway.md\nindex d2cde1bb5..53f534466 100644\n--- a/docs/providers/aws/events/apigateway.md\n+++ b/docs/providers/aws/events/apigateway.md\n@@ -522,6 +522,40 @@ functions:\n           async: true # default is false\n ```\n \n+### Invoking Lambda versions and aliases with API Gateway\n+\n+By default, API Gateway invokes the unqualified Lambda function ($LATEST). Provisioned Concurrency applies only to published versions and aliases. To route traffic to a specific version or alias, the integration URI must reference the qualified Lambda ARN:\n+\n+- arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${functionName}:${aliasName}/invocations\n+\n+When using provisionedConcurrency, target the alias that has the ProvisionedConcurrencyConfig.\n+\n+Minimal example of overriding a Method Integration to invoke an alias and granting invoke permissions:\n+\n+```yml\n+resources:\n+  Resources:\n+    ApiGatewayMethodHelloGet:\n+      Type: AWS::ApiGateway::Method\n+      Properties:\n+        Integration:\n+          Type: AWS\n+          IntegrationHttpMethod: POST\n+          Uri:\n+            Fn::Sub: arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${self:service}-${self:provider.stage}-hello:${self:provider.stage}/invocations\n+    HelloAliasInvokePermission:\n+      Type: AWS::Lambda::Permission\n+      Properties:\n+        Action: lambda:InvokeFunction\n+        FunctionName:\n+          Fn::Sub: arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${self:service}-${self:provider.stage}-hello:${self:provider.stage}\n+        Principal: apigateway.amazonaws.com\n+```\n+\n+Limitations and deployment notes:\n+- Weighted alias traffic shifting is not compatible with Provisioned Concurrency. Use full alias switches.\n+- Updates to Provisioned Concurrency may take time to stabilize; deployments may temporarily fail with NotStabilized while capacity is being applied.\n+\n ### Catching Exceptions In Your Lambda Function\n \n In case an exception is thrown in your lambda function AWS will send an error message with `Process exited before completing request`. This will be caught by the regular expression for the 500 HTTP status and the 500 status will be returned.\ndiff --git a/docs/providers/aws/guide/functions.md b/docs/providers/aws/guide/functions.md\nindex 02b14c9f6..86213c56d 100644\n--- a/docs/providers/aws/guide/functions.md\n+++ b/docs/providers/aws/guide/functions.md\n@@ -46,6 +46,29 @@ functions:\n     tracing: PassThrough # optional, overwrite, can be 'Active' or 'PassThrough'\n ```\n \n+Important: Provisioned concurrency is configured on a published version or alias. API Gateway and many event sources invoke the unqualified function ($LATEST) by default unless explicitly configured to target a version or alias. To benefit from provisioned concurrency, ensure your event sources invoke a published version or alias that has provisioned concurrency configured.\n+\n+With API Gateway, wire the integration URI to an alias ARN (for example: `arn:aws:lambda:region:account:function:functionName:aliasName`) so requests are routed to the alias with provisioned capacity. See the API Gateway docs section on invoking Lambda versions and aliases.\n+\n+Deployment lifecycle and cost: Each deployment publishes a new version. If API Gateway keeps invoking `$LATEST`, provisioned capacity will accumulate on unused versions. Use an alias per stage and pruning tools to keep costs predictable.\n+\n+Environment-specific configuration: Enable provisioned concurrency only in production by using variables/conditionals. If your framework version does not support setting `0`, omit the property via variables when you do not want it applied.\n+\n+```yml\n+# Stage-based provisioned concurrency\n+custom:\n+  provisionedConcurrency: ${env:PC, null} # e.g., export PC=5 in prod, leave unset in dev\n+\n+functions:\n+  hello:\n+    handler: handler.hello\n+    provisionedConcurrency: ${self:custom.provisionedConcurrency}\n+    events:\n+      - http:\n+          path: hello\n+          method: get\n+```\n+\n The `handler` property points to the file and module containing the code you want to run in your function.\n \n ```javascript\ndiff --git a/examples/aws-node-provisioned-concurrency-alias/README.md b/examples/aws-node-provisioned-concurrency-alias/README.md\nnew file mode 100644\nindex 000000000..a026a8539\n--- /dev/null\n+++ b/examples/aws-node-provisioned-concurrency-alias/README.md\n@@ -0,0 +1,28 @@\n+# AWS Node Provisioned Concurrency with Alias\n+\n+This example shows how to use AWS Lambda Provisioned Concurrency with API Gateway by invoking a Lambda alias.\n+\n+Key concepts:\n+- Provisioned Concurrency applies to published versions and aliases, not $LATEST.\n+- API Gateway invokes $LATEST by default. To use Provisioned Concurrency, target an alias/version in the integration URI.\n+- Use a stage-named alias (e.g., dev, prod) and update it on each deploy.\n+\n+## Setup\n+\n+1. Optionally set a provisioned concurrency value for production:\n+   - export PC=5\n+2. Deploy:\n+   - serverless deploy --stage dev\n+   - serverless deploy --stage prod\n+3. Verify:\n+   - In Lambda console, confirm Provisioned Concurrency on the prod alias.\n+   - In API Gateway console, check the Method Integration URI includes the alias suffix `:prod`.\n+\n+## Test\n+\n+- Curl the endpoint and observe reduced cold starts in prod compared to dev.\n+\n+## Cleanup\n+\n+- Remove old versions using pruning tools (e.g., serverless-prune-plugin).\n+- Adjust PC values as needed.\ndiff --git a/examples/aws-node-provisioned-concurrency-alias/handler.js b/examples/aws-node-provisioned-concurrency-alias/handler.js\nnew file mode 100644\nindex 000000000..8b8a13a31\n--- /dev/null\n+++ b/examples/aws-node-provisioned-concurrency-alias/handler.js\n@@ -0,0 +1,17 @@\n+'use strict';\n+\n+let coldStart = true;\n+\n+module.exports.hello = async (event) => {\n+  const now = new Date().toISOString();\n+  const message = coldStart ? 'Hello from a COLD start' : 'Hello from a WARM start';\n+  const response = {\n+    statusCode: 200,\n+    headers: {\n+      'Content-Type': 'application/json'\n+    },\n+    body: JSON.stringify({ message, time: now })\n+  };\n+  coldStart = false;\n+  return response;\n+};\ndiff --git a/examples/aws-node-provisioned-concurrency-alias/serverless.yml b/examples/aws-node-provisioned-concurrency-alias/serverless.yml\nnew file mode 100644\nindex 000000000..c1c84534f\n--- /dev/null\n+++ b/examples/aws-node-provisioned-concurrency-alias/serverless.yml\n@@ -0,0 +1,36 @@\n+service: aws-node-provisioned-concurrency-alias\n+\n+provider:\n+  name: aws\n+  runtime: nodejs18.x\n+  stage: ${opt:stage, 'dev'}\n+\n+custom:\n+  pc: ${env:PC, null} # e.g., export PC=5 in prod, leave unset in dev\n+\n+functions:\n+  hello:\n+    handler: handler.hello\n+    provisionedConcurrency: ${self:custom.pc}\n+    events:\n+      - http:\n+          path: hello\n+          method: get\n+\n+resources:\n+  Resources:\n+    ApiGatewayMethodHelloGet:\n+      Type: AWS::ApiGateway::Method\n+      Properties:\n+        Integration:\n+          Type: AWS\n+          IntegrationHttpMethod: POST\n+          Uri:\n+            Fn::Sub: arn:aws:apigateway:${AWS::Region}:lambda:path/2015-03-31/functions/arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${self:service}-${self:provider.stage}-hello:${self:provider.stage}/invocations\n+    HelloAliasInvokePermission:\n+      Type: AWS::Lambda::Permission\n+      Properties:\n+        Action: lambda:InvokeFunction\n+        FunctionName:\n+          Fn::Sub: arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:${self:service}-${self:provider.stage}-hello:${self:provider.stage}\n+        Principal: apigateway.amazonaws.com\n"}
{"instance_id": "prettier__prettier-3436", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/printer.js b/src/printer.js\nindex fe7b38c0b..ed706ec4c 100644\n--- a/src/printer.js\n+++ b/src/printer.js\n@@ -204,7 +204,8 @@ function genericPrint(path, options, printPath, args) {\n   } else {\n     // Nodes with decorators can't have parentheses, so we can avoid\n     // computing path.needsParens() except in this case.\n-    needsParens = path.needsParens(options);\n+    needsParens =\n+      node.type === \"TSParenthesizedType\" ? false : path.needsParens(options);\n   }\n \n   const parts = [];\n@@ -2569,7 +2570,14 @@ function genericPrintNoParens(path, options, print, args) {\n     case \"TSTypeQuery\":\n       return concat([\"typeof \", path.call(print, \"exprName\")]);\n     case \"TSParenthesizedType\": {\n-      return path.call(print, \"typeAnnotation\");\n+      return group(\n+        concat([\n+          \"(\",\n+          indent(concat([softline, path.call(print, \"typeAnnotation\")])),\n+          softline,\n+          \")\"\n+        ])\n+      );\n     }\n     case \"TSIndexSignature\": {\n       const parent = path.getParentNode();\n"}
{"instance_id": "serverless__serverless-6987", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\nindex decf7ff49..08e1f24f7 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/permissions.js\n@@ -20,22 +20,48 @@ module.exports = {\n             },\n             Action: 'lambda:InvokeFunction',\n             Principal: 'apigateway.amazonaws.com',\n-            SourceArn: {\n-              'Fn::Join': [\n-                '',\n-                [\n-                  'arn:',\n-                  { Ref: 'AWS::Partition' },\n-                  ':execute-api:',\n-                  { Ref: 'AWS::Region' },\n-                  ':',\n-                  { Ref: 'AWS::AccountId' },\n-                  ':',\n-                  this.provider.getApiGatewayRestApiId(),\n-                  '/*/*',\n-                ],\n-              ],\n-            },\n+            SourceArn:\n+              singlePermissionMapping.event.http &&\n+              singlePermissionMapping.event.http.integration === 'lambda' &&\n+              this.serverless.service.provider &&\n+              this.serverless.service.provider.apiGateway &&\n+              Array.isArray(this.serverless.service.provider.apiGateway.binaryMediaTypes) &&\n+              this.serverless.service.provider.apiGateway.binaryMediaTypes.length > 0\n+                ? {\n+                    'Fn::Join': [\n+                      '',\n+                      [\n+                        'arn:',\n+                        { Ref: 'AWS::Partition' },\n+                        ':execute-api:',\n+                        { Ref: 'AWS::Region' },\n+                        ':',\n+                        { Ref: 'AWS::AccountId' },\n+                        ':',\n+                        this.provider.getApiGatewayRestApiId(),\n+                        '/*/' +\n+                          String(singlePermissionMapping.event.http.method).toUpperCase() +\n+                          '/' +\n+                          String(singlePermissionMapping.event.http.path || '').replace(/^\\//, ''),\n+                      ],\n+                    ],\n+                  }\n+                : {\n+                    'Fn::Join': [\n+                      '',\n+                      [\n+                        'arn:',\n+                        { Ref: 'AWS::Partition' },\n+                        ':execute-api:',\n+                        { Ref: 'AWS::Region' },\n+                        ':',\n+                        { Ref: 'AWS::AccountId' },\n+                        ':',\n+                        this.provider.getApiGatewayRestApiId(),\n+                        '/*/*',\n+                      ],\n+                    ],\n+                  },\n           },\n         },\n       });\n"}
{"instance_id": "serverless__serverless-6827", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/lib/naming.js b/lib/plugins/aws/lib/naming.js\nindex 9fe9a4b1f..086c43168 100644\n--- a/lib/plugins/aws/lib/naming.js\n+++ b/lib/plugins/aws/lib/naming.js\n@@ -424,10 +424,12 @@ module.exports = {\n       functionName\n     )}LambdaPermissionAlexaSmartHome${alexaSmartHomeIndex}`;\n   },\n-  getLambdaCloudWatchLogPermissionLogicalId(functionName) {\n+  getLambdaCloudWatchLogPermissionLogicalId(functionName, logsIndex) {\n     return `${this.getNormalizedFunctionName(\n       functionName\n-    )}LambdaPermissionLogsSubscriptionFilterCloudWatchLog`;\n+    )}LambdaPermissionLogsSubscriptionFilterCloudWatchLog${\n+      logsIndex != null ? logsIndex : ''\n+    }`;\n   },\n   getLambdaCognitoUserPoolPermissionLogicalId(functionName, poolId, triggerSource) {\n     return `${this.getNormalizedFunctionName(\n"}
{"instance_id": "serverless__serverless-3534", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/providers/aws/events/apigateway.md b/docs/providers/aws/events/apigateway.md\nindex a903d6d2e..25426f822 100644\n--- a/docs/providers/aws/events/apigateway.md\n+++ b/docs/providers/aws/events/apigateway.md\n@@ -14,11 +14,13 @@ layout: Doc\n \n To create HTTP endpoints as Event sources for your AWS Lambda Functions, use the Serverless Framework's easy AWS API Gateway Events syntax.\n \n-There are two ways you can configure your HTTP endpoints to integrate with your AWS Lambda Functions:\n+There are four ways you can configure your HTTP endpoints to integrate with backends:\n * lambda-proxy (Recommended)\n * lambda\n+* http-proxy\n+* http\n \n-The difference between these is `lambda-proxy` automatically passes the content of the HTTP request into your AWS Lambda function (headers, body, etc.) and allows you to configure your response (headers, status code, body) in the code of your AWS Lambda Function.  Whereas, the `lambda` method makes you explicitly define headers, status codes, and more in the configuration of each API Gateway Endpoint (not in code).  We highly recommend using the `lambda-proxy` method if it supports your use-case, since the `lambda` method is highly tedious.\n+The difference between these is `lambda-proxy` automatically passes the content of the HTTP request into your AWS Lambda function (headers, body, etc.) and allows you to configure your response (headers, status code, body) in the code of your AWS Lambda Function.  Whereas, the `lambda` method makes you explicitly define headers, status codes, and more in the configuration of each API Gateway Endpoint (not in code). For non-Lambda backends, `http-proxy` forwards requests directly to an HTTP/HTTPS endpoint with minimal transformation, and `http` allows custom request/response mappings to an HTTP/HTTPS endpoint.\n \n By default, the Framework uses the `lambda-proxy` method (i.e., everything is passed into your Lambda), and nothing is required by you to enable it.\n \n@@ -288,6 +290,60 @@ Please note that those are the API keys names, not the actual values. Once you d\n \n Clients connecting to this Rest API will then need to set any of these API keys values in the `x-api-key` header of their request. This is only necessary for functions where the `private` property is set to true.\n \n+## HTTP Proxy Integration\n+\n+You can configure an API Gateway route that proxies directly to an HTTP/HTTPS backend without a Lambda function.\n+\n+Example using a catch-all path parameter to forward to an external service:\n+\n+```yml\n+functions:\n+  legacyProxy:\n+    handler: handler.dummy # handler is not invoked for http-proxy integration\n+    events:\n+      - http:\n+          path: legacy/{proxy+}\n+          method: any\n+          integration: http-proxy\n+          request:\n+            uri: https://myapp.com/oldEndpoint/{proxy}\n+            parameters:\n+              paths:\n+                proxy: true\n+```\n+\n+Notes:\n+- Request/response mapping configuration is ignored for `http-proxy` and will be stripped with a warning.\n+- CORS preflight (OPTIONS) can be enabled as usual. Actual CORS headers must be provided by the upstream service.\n+\n+## HTTP Integration\n+\n+You can integrate API Gateway with an HTTP/HTTPS backend while defining request templates, pass-through behavior and response mappings.\n+\n+```yml\n+functions:\n+  httpForward:\n+    handler: handler.dummy\n+    events:\n+      - http:\n+          path: external/data\n+          method: get\n+          integration: http\n+          request:\n+            uri: https://api.example.com/data\n+            passThrough: WHEN_NO_MATCH\n+            template:\n+              application/json: '{\"id\": \"$input.params(''id'')\" }'\n+          response:\n+            headers:\n+              Content-Type: integration.response.header.Content-Type\n+            statusCodes:\n+              200:\n+                pattern: ''\n+              404:\n+                pattern: '[\\\\s\\\\S]*[404][\\\\s\\\\S]*'\n+```\n+\n ## Lambda Integration\n \n This method is more complicated and involves a lot more configuration of the `http` event syntax.\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\nindex 765e3ee65..d853f1bdb 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/integration.js\n@@ -45,28 +45,89 @@ const DEFAULT_COMMON_TEMPLATE = `\n \n module.exports = {\n   getMethodIntegration(http, lambdaLogicalId) {\n-    const integration = {\n-      IntegrationHttpMethod: 'POST',\n-      Type: http.integration,\n-      Uri: {\n-        'Fn::Join': ['',\n-          [\n-            'arn:aws:apigateway:',\n-            { Ref: 'AWS::Region' },\n-            ':lambda:path/2015-03-31/functions/',\n-            { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] },\n-            '/invocations',\n-          ],\n-        ],\n-      },\n-    };\n+    let integration;\n \n     if (http.integration === 'AWS') {\n+      integration = {\n+        IntegrationHttpMethod: 'POST',\n+        Type: http.integration,\n+        Uri: {\n+          'Fn::Join': ['',\n+            [\n+              'arn:aws:apigateway:',\n+              { Ref: 'AWS::Region' },\n+              ':lambda:path/2015-03-31/functions/',\n+              { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] },\n+              '/invocations',\n+            ],\n+          ],\n+        },\n+      };\n+\n       _.assign(integration, {\n         PassthroughBehavior: http.request && http.request.passThrough,\n         RequestTemplates: this.getIntegrationRequestTemplates(http),\n         IntegrationResponses: this.getIntegrationResponses(http),\n       });\n+    } else if (http.integration === 'HTTP') {\n+      integration = {\n+        IntegrationHttpMethod: http.method.toUpperCase() === 'ANY' ? 'ANY' : http.method.toUpperCase(),\n+        Type: 'HTTP',\n+        Uri: http.request.uri,\n+        PassthroughBehavior: http.request && http.request.passThrough,\n+        RequestTemplates: this.getIntegrationRequestTemplates(http),\n+        IntegrationResponses: this.getIntegrationResponses(http),\n+      };\n+      if (http.request && http.request.parameters) {\n+        // Map method.request.path/header/querystring params to integration.request.* for passthrough\n+        const requestParams = {};\n+        Object.keys(http.request.parameters).forEach((key) => {\n+          const parts = key.split('.');\n+          const location = parts[2];\n+          const name = parts[3];\n+          requestParams[`integration.request.${location}.${name}`] = key;\n+        });\n+        if (Object.keys(requestParams).length) {\n+          integration.RequestParameters = requestParams;\n+        }\n+      }\n+    } else if (http.integration === 'HTTP_PROXY') {\n+      integration = {\n+        IntegrationHttpMethod: http.method.toUpperCase() === 'ANY' ? 'ANY' : http.method.toUpperCase(),\n+        Type: 'HTTP_PROXY',\n+        Uri: http.request.uri,\n+      };\n+      if (http.request && http.request.parameters) {\n+        // Map method.request.path/header/querystring params to integration.request.* for passthrough\n+        const requestParams = {};\n+        Object.keys(http.request.parameters).forEach((key) => {\n+          // key is like method.request.path.proxy\n+          const parts = key.split('.');\n+          const location = parts[2]; // path | header | querystring\n+          const name = parts[3];\n+          requestParams[`integration.request.${location}.${name}`] = key;\n+        });\n+        if (Object.keys(requestParams).length) {\n+          integration.RequestParameters = requestParams;\n+        }\n+      }\n+    } else {\n+      // default AWS_PROXY (lambda-proxy)\n+      integration = {\n+        IntegrationHttpMethod: 'POST',\n+        Type: http.integration,\n+        Uri: {\n+          'Fn::Join': ['',\n+            [\n+              'arn:aws:apigateway:',\n+              { Ref: 'AWS::Region' },\n+              ':lambda:path/2015-03-31/functions/',\n+              { 'Fn::GetAtt': [lambdaLogicalId, 'Arn'] },\n+              '/invocations',\n+            ],\n+          ],\n+        },\n+      };\n     }\n \n     return {\ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/responses.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/responses.js\nindex 776306a01..263cd78d1 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/method/responses.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/method/responses.js\n@@ -7,7 +7,7 @@ module.exports = {\n   getMethodResponses(http) {\n     const methodResponses = [];\n \n-    if (http.integration === 'AWS') {\n+    if (http.integration === 'AWS' || http.integration === 'HTTP') {\n       if (http.response) {\n         const methodResponseHeaders = [];\n \ndiff --git a/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js b/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\nindex 60c3f1eb8..9fd4e9367 100644\n--- a/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\n+++ b/lib/plugins/aws/package/compile/events/apiGateway/lib/validate.js\n@@ -93,6 +93,77 @@ module.exports = {\n             } else {\n               http.response.statusCodes = DEFAULT_STATUS_CODES;\n             }\n+          } else if (http.integration === 'HTTP') {\n+            if (http.request) {\n+              http.request = this.getRequest(http);\n+            } else {\n+              http.request = {};\n+            }\n+\n+            if (typeof http.request.uri !== 'string' || http.request.uri.length === 0) {\n+              const errorMessage = [\n+                `Missing or invalid \"request.uri\" property in function \"${functionName}\"`,\n+                ' for http event using HTTP integration in serverless.yml.',\n+                ' Please specify a valid backend URL, e.g. https://example.com/path.',\n+              ].join('');\n+              throw new this.serverless.classes.Error(errorMessage);\n+            }\n+\n+            if (http.request.parameters) {\n+              http.request.parameters = this.getRequestParameters(http.request);\n+            }\n+\n+            http.request.passThrough = this.getRequestPassThrough(http);\n+\n+            if (http.response) {\n+              http.response = this.getResponse(http);\n+            } else {\n+              http.response = {};\n+            }\n+\n+            if (http.response.statusCodes) {\n+              http.response.statusCodes = _.assign({}, http.response.statusCodes);\n+\n+              if (!_.some(http.response.statusCodes, code => code.pattern === '')) {\n+                http.response.statusCodes['200'] = DEFAULT_STATUS_CODES['200'];\n+              }\n+            } else {\n+              http.response.statusCodes = DEFAULT_STATUS_CODES;\n+            }\n+          } else if (http.integration === 'HTTP_PROXY') {\n+            if (http.request) {\n+              http.request = this.getRequest(http);\n+            } else {\n+              http.request = {};\n+            }\n+\n+            if (typeof http.request.uri !== 'string' || http.request.uri.length === 0) {\n+              const errorMessage = [\n+                `Missing or invalid \"request.uri\" property in function \"${functionName}\"`,\n+                ' for http event using HTTP-PROXY integration in serverless.yml.',\n+                ' Please specify a valid backend URL, e.g. https://example.com/path.',\n+              ].join('');\n+              throw new this.serverless.classes.Error(errorMessage);\n+            }\n+\n+            if (http.request.parameters) {\n+              http.request.parameters = this.getRequestParameters(http.request);\n+            }\n+\n+            // show a warning when request / response config is used with HTTP_PROXY\n+            if ((http.request && http.request.template) || http.response) {\n+              const warningMessage = [\n+                'Warning! You\\'re using the HTTP-PROXY in combination with request / response',\n+                ` configuration in your function \"${functionName}\".`,\n+                ' Serverless will remove this configuration automatically before deployment.',\n+              ].join('');\n+              this.serverless.cli.log(warningMessage);\n+\n+              if (http.request) {\n+                delete http.request.template;\n+              }\n+              delete http.response;\n+            }\n           } else if (http.integration === 'AWS_PROXY') {\n            // show a warning when request / response config is used with AWS_PROXY (LAMBDA-PROXY)\n             if (http.request || http.response) {\n@@ -299,7 +370,7 @@ module.exports = {\n   getIntegration(http, functionName) {\n     if (http.integration) {\n       const allowedIntegrations = [\n-        'LAMBDA-PROXY', 'LAMBDA',\n+        'LAMBDA-PROXY', 'LAMBDA', 'HTTP-PROXY', 'HTTP',\n       ];\n       // normalize the integration for further processing\n       const normalizedIntegration = http.integration.toUpperCase();\n@@ -308,13 +379,19 @@ module.exports = {\n         const errorMessage = [\n           `Invalid APIG integration \"${http.integration}\"`,\n           ` in function \"${functionName}\".`,\n-          ' Supported integrations are: lambda, lambda-proxy.',\n+          ' Supported integrations are: lambda, lambda-proxy, http, http-proxy.',\n         ].join('');\n         throw new this.serverless.classes.Error(errorMessage);\n       }\n       if (normalizedIntegration === 'LAMBDA') {\n         return 'AWS';\n       }\n+      if (normalizedIntegration === 'HTTP') {\n+        return 'HTTP';\n+      }\n+      if (normalizedIntegration === 'HTTP-PROXY') {\n+        return 'HTTP_PROXY';\n+      }\n     }\n     return 'AWS_PROXY';\n   },\n"}
{"instance_id": "serverless__serverless-3187", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/lib/plugins/aws/deploy/compile/events/apiGateway/lib/method/index.js b/lib/plugins/aws/deploy/compile/events/apiGateway/lib/method/index.js\nindex aa5cbe4bd..2df41f048 100644\n--- a/lib/plugins/aws/deploy/compile/events/apiGateway/lib/method/index.js\n+++ b/lib/plugins/aws/deploy/compile/events/apiGateway/lib/method/index.js\n@@ -45,9 +45,12 @@ module.exports = {\n       let extraCognitoPoolClaims;\n       if (event.http.authorizer) {\n         const claims = event.http.authorizer.claims || [];\n-        extraCognitoPoolClaims = _.map(claims, claim =>\n-            `\"${claim}\": \"$context.authorizer.claims.${claim}\",`\n-        );\n+        if (claims.length) {\n+          const joinedClaims = _.map(claims, claim =>\n+            `\"${claim}\": \"$context.authorizer.claims.${claim}\"`\n+          ).join(', ');\n+          extraCognitoPoolClaims = `${joinedClaims},`;\n+        }\n       }\n       const requestTemplates = template.Properties.Integration.RequestTemplates;\n       _.forEach(requestTemplates, (value, key) => {\n"}
{"instance_id": "serverless__serverless-2014", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/02-providers/aws/events/01-apigateway.md b/docs/02-providers/aws/events/01-apigateway.md\nindex 4ffaa8b05..d1542b403 100644\n--- a/docs/02-providers/aws/events/01-apigateway.md\n+++ b/docs/02-providers/aws/events/01-apigateway.md\n@@ -467,6 +467,8 @@ functions:\n \n This example is the default setting and is exactly the same as the previous example. The `Access-Control-Allow-Methods` header is set automatically, based on the endpoints specified in your service configuration with CORS enabled.\n \n+Note: When multiple HTTP events share the same path, Serverless will generate a single preflight OPTIONS method for that path and aggregate CORS settings across those events. The allowed methods, headers, and origins are the union of values configured on each event with CORS enabled.\n+\n **Note:** If you are using the default lambda proxy integration, remember to include `Access-Control-Allow-Origin` in your returned headers object otherwise CORS will fail.\n \n ```\ndiff --git a/lib/plugins/aws/deploy/compile/events/apiGateway/lib/methods.js b/lib/plugins/aws/deploy/compile/events/apiGateway/lib/methods.js\nindex 8895c7f60..2f68adfc7 100644\n--- a/lib/plugins/aws/deploy/compile/events/apiGateway/lib/methods.js\n+++ b/lib/plugins/aws/deploy/compile/events/apiGateway/lib/methods.js\n@@ -220,11 +220,24 @@ module.exports = {\n                 cors.headers = headers;\n               }\n \n-              if (!cors.methods.indexOf('OPTIONS') > -1) {\n+              if (cors.origins) {\n+                if (!Array.isArray(cors.origins)) {\n+                  const errorMessage = [\n+                    'CORS origin values must be provided as an array.',\n+                    ' Please check the docs for more info.',\n+                  ].join('');\n+                  throw new this.serverless.classes\n+                  .Error(errorMessage);\n+                }\n+              } else {\n+                cors.origins = ['*'];\n+              }\n+\n+              if (cors.methods.indexOf('OPTIONS') === -1) {\n                 cors.methods.push('OPTIONS');\n               }\n \n-              if (!cors.methods.indexOf(method.toUpperCase()) > -1) {\n+              if (cors.methods.indexOf(method.toUpperCase()) === -1) {\n                 cors.methods.push(method.toUpperCase());\n               }\n             } else {\n@@ -232,8 +245,16 @@ module.exports = {\n             }\n \n             if (corsConfig[path]) {\n+              // Union array fields to aggregate CORS settings across events for the same path\n               cors.methods = _.union(cors.methods, corsConfig[path].methods);\n-              corsConfig[path] = _.merge(corsConfig[path], cors);\n+              cors.headers = _.union(cors.headers || [], corsConfig[path].headers || []);\n+              cors.origins = _.union(cors.origins || [], corsConfig[path].origins || []);\n+              // Merge back any non-array properties while preserving unioned arrays\n+              corsConfig[path] = _.assign({}, corsConfig[path], cors, {\n+                methods: cors.methods,\n+                headers: cors.headers,\n+                origins: cors.origins,\n+              });\n             } else {\n               corsConfig[path] = cors;\n             }\n"}
{"instance_id": "microsoft__vscode-110094", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/common/controller/cursorTypeOperations.ts b/src/vs/editor/common/controller/cursorTypeOperations.ts\nindex cf538a83386..bea0492a149 100644\n--- a/src/vs/editor/common/controller/cursorTypeOperations.ts\n+++ b/src/vs/editor/common/controller/cursorTypeOperations.ts\n@@ -619,7 +619,26 @@ export class TypeOperations {\n \t\tlet commands: ICommand[] = [];\n \t\tfor (let i = 0, len = selections.length; i < len; i++) {\n \t\t\tconst selection = selections[i];\n-\t\t\tcommands[i] = new TypeWithAutoClosingCommand(selection, ch, insertOpenCharacter, autoClosingPair.close);\n+\t\t\tconst position = selection.getPosition();\n+\t\t\tconst lineText = model.getLineContent(position.lineNumber);\n+\t\t\tlet closeCharacter = autoClosingPair.close;\n+\t\t\t// Avoid duplicating the typed character if the close string starts with it\n+\t\t\tif (insertOpenCharacter && closeCharacter.length > 0 && closeCharacter.charAt(0) === ch) {\n+\t\t\t\tcloseCharacter = closeCharacter.substring(1);\n+\t\t\t}\n+\t\t\t// Avoid inserting characters that already exist to the right of the cursor\n+\t\t\tif (closeCharacter.length > 0) {\n+\t\t\t\tconst afterText = lineText.substring(position.column - 1);\n+\t\t\t\tlet overlap = 0;\n+\t\t\t\tconst max = Math.min(closeCharacter.length, afterText.length);\n+\t\t\t\twhile (overlap < max && afterText.charAt(overlap) === closeCharacter.charAt(overlap)) {\n+\t\t\t\t\toverlap++;\n+\t\t\t\t}\n+\t\t\t\tif (overlap > 0) {\n+\t\t\t\t\tcloseCharacter = closeCharacter.substring(overlap);\n+\t\t\t\t}\n+\t\t\t}\n+\t\t\tcommands[i] = new TypeWithAutoClosingCommand(selection, ch, insertOpenCharacter, closeCharacter);\n \t\t}\n \t\treturn new EditOperationResult(EditOperationType.Typing, commands, {\n \t\t\tshouldPushStackElementBefore: true,\n"}
{"instance_id": "microsoft__vscode-106767", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/contrib/suggest/suggestModel.ts b/src/vs/editor/contrib/suggest/suggestModel.ts\nindex bb4f269ece8..ba1a482eb78 100644\n--- a/src/vs/editor/contrib/suggest/suggestModel.ts\n+++ b/src/vs/editor/contrib/suggest/suggestModel.ts\n@@ -384,13 +384,19 @@ export class SuggestModel implements IDisposable {\n \t\tconst auto = context.auto;\n \t\tconst ctx = new LineContext(model, this._editor.getPosition(), auto, context.shy);\n \n-\t\t// Cancel previous requests, change state & update UI\n-\t\tthis.cancel(retrigger);\n+\t\t// Cancel previous request token but preserve anchor when retriggering\n+\t\tif (this._requestToken) {\n+\t\t\tthis._requestToken.cancel();\n+\t\t\tthis._requestToken = undefined;\n+\t\t}\n+\t\t// Change state & update UI\n \t\tthis._state = auto ? State.Auto : State.Manual;\n-\t\tthis._onDidTrigger.fire({ auto, shy: context.shy, position: this._editor.getPosition() });\n+\t\t// Determine anchor position: keep previous anchor when retriggering\n+\t\tconst anchorContext = retrigger && this._context ? this._context : ctx;\n+\t\tthis._onDidTrigger.fire({ auto, shy: context.shy, position: new Position(anchorContext.lineNumber, anchorContext.column) });\n \n-\t\t// Capture context when request was sent\n-\t\tthis._context = ctx;\n+\t\t// Capture anchor context when request was sent\n+\t\tthis._context = anchorContext;\n \n \t\t// Build context for request\n \t\tlet suggestCtx: CompletionContext;\n@@ -428,7 +434,7 @@ export class SuggestModel implements IDisposable {\n \n \t\tlet completions = provideSuggestionItems(\n \t\t\tmodel,\n-\t\t\tthis._editor.getPosition(),\n+\t\t\tnew Position(this._context!.lineNumber, this._context!.column),\n \t\t\tnew CompletionOptions(snippetSortOrder, itemKindFilter, onlyFrom),\n \t\t\tsuggestCtx,\n \t\t\tthis._requestToken.token\n"}
{"instance_id": "microsoft__vscode-122991", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/common/controller/cursorDeleteOperations.ts b/src/vs/editor/common/controller/cursorDeleteOperations.ts\nindex 6854a4e6386..d3cba306c88 100644\n--- a/src/vs/editor/common/controller/cursorDeleteOperations.ts\n+++ b/src/vs/editor/common/controller/cursorDeleteOperations.ts\n@@ -199,7 +199,9 @@ export class DeleteOperations {\n \n \tprivate static decreasePositionInModelBy1Column(position: Position, model: ICursorSimpleModel): Position | undefined {\n \t\tif (position.column > 1) {\n-\t\t\treturn position.delta(0, -1);\n+\t\t\tconst lineContent = model.getLineContent(position.lineNumber);\n+\t\t\tconst dec = strings.prevCharLength(lineContent, position.column - 1);\n+\t\t\treturn position.delta(0, -dec);\n \t\t} else if (position.lineNumber > 1) {\n \t\t\tconst newLine = position.lineNumber - 1;\n \t\t\treturn new Position(newLine, model.getLineMaxColumn(newLine));\n"}
{"instance_id": "microsoft__vscode-135805", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/common/config/editorOptions.ts b/src/vs/editor/common/config/editorOptions.ts\nindex 45b8fc9753a..0982ce63950 100644\n--- a/src/vs/editor/common/config/editorOptions.ts\n+++ b/src/vs/editor/common/config/editorOptions.ts\n@@ -369,6 +369,13 @@ export interface IEditorOptions {\n \t * Defaults to 'spread'.\n \t */\n \tmultiCursorPaste?: 'spread' | 'full';\n+\t/**\n+\t * Controls how Add Cursor Above/Below navigate when word wrap is enabled.\n+\t * When 'logical', navigation uses model lines.\n+\t * When 'visual', and word wrap is not 'off', navigation uses wrapped view lines.\n+\t * Defaults to 'logical'.\n+\t */\n+\tmultiCursorWrapBehavior?: 'logical' | 'visual';\n \t/**\n \t * Configure the editor's accessibility support.\n \t * Defaults to 'auto'. It is best to leave this to 'auto'.\n@@ -4180,6 +4187,7 @@ export const enum EditorOption {\n \tmultiCursorMergeOverlapping,\n \tmultiCursorModifier,\n \tmultiCursorPaste,\n+\tmultiCursorWrapBehavior,\n \toccurrencesHighlight,\n \toverviewRulerBorder,\n \toverviewRulerLanes,\n@@ -4593,6 +4601,18 @@ export const EditorOptions = {\n \t\t\tmarkdownDescription: nls.localize('multiCursorPaste', \"Controls pasting when the line count of the pasted text matches the cursor count.\")\n \t\t}\n \t)),\n+\tmultiCursorWrapBehavior: register(new EditorStringEnumOption(\n+\t\tEditorOption.multiCursorWrapBehavior, 'multiCursorWrapBehavior',\n+\t\t'logical' as 'logical' | 'visual',\n+\t\t['logical', 'visual'] as const,\n+\t\t{\n+\t\t\tmarkdownEnumDescriptions: [\n+\t\t\t\tnls.localize('multiCursorWrapBehavior.logical', \"Add Cursor Above/Below navigates by model lines (default).\"),\n+\t\t\t\tnls.localize('multiCursorWrapBehavior.visual', \"Add Cursor Above/Below navigates by wrapped view lines when word wrap is enabled.\"),\n+\t\t\t],\n+\t\t\tmarkdownDescription: nls.localize('multiCursorWrapBehavior', \"Controls how Add Cursor Above/Below navigate when word wrap is enabled.\"),\n+\t\t}\n+\t)),\n \toccurrencesHighlight: register(new EditorBooleanOption(\n \t\tEditorOption.occurrencesHighlight, 'occurrencesHighlight', true,\n \t\t{ description: nls.localize('occurrencesHighlight', \"Controls whether the editor should highlight semantic symbol occurrences.\") }\ndiff --git a/src/vs/editor/contrib/multicursor/multicursor.ts b/src/vs/editor/contrib/multicursor/multicursor.ts\nindex 3d6e21879cc..ff669734137 100644\n--- a/src/vs/editor/contrib/multicursor/multicursor.ts\n+++ b/src/vs/editor/contrib/multicursor/multicursor.ts\n@@ -70,7 +70,14 @@ export class InsertCursorAbove extends EditorAction {\n \t\t\treturn;\n \t\t}\n \n-\t\tconst useLogicalLine = (args && args.logicalLine === true);\n+\t\tlet useLogicalLine: boolean;\n+\t\tif (args && typeof args.logicalLine === 'boolean') {\n+\t\t\tuseLogicalLine = args.logicalLine;\n+\t\t} else {\n+\t\t\tconst behavior = editor.getOption(EditorOption.multiCursorWrapBehavior);\n+\t\t\tconst wordWrap = editor.getOption(EditorOption.wordWrap);\n+\t\t\tuseLogicalLine = !(behavior === 'visual' && wordWrap !== 'off');\n+\t\t}\n \t\tconst viewModel = editor._getViewModel();\n \n \t\tif (viewModel.cursorConfig.readOnly) {\n@@ -120,7 +127,14 @@ export class InsertCursorBelow extends EditorAction {\n \t\t\treturn;\n \t\t}\n \n-\t\tconst useLogicalLine = (args && args.logicalLine === true);\n+\t\tlet useLogicalLine: boolean;\n+\t\tif (args && typeof args.logicalLine === 'boolean') {\n+\t\t\tuseLogicalLine = args.logicalLine;\n+\t\t} else {\n+\t\t\tconst behavior = editor.getOption(EditorOption.multiCursorWrapBehavior);\n+\t\t\tconst wordWrap = editor.getOption(EditorOption.wordWrap);\n+\t\t\tuseLogicalLine = !(behavior === 'visual' && wordWrap !== 'off');\n+\t\t}\n \t\tconst viewModel = editor._getViewModel();\n \n \t\tif (viewModel.cursorConfig.readOnly) {\n"}
{"instance_id": "microsoft__vscode-148971", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/base/browser/markdownRenderer.ts b/src/vs/base/browser/markdownRenderer.ts\nindex 72c25e77c2b..5f9cfdfb91c 100644\n--- a/src/vs/base/browser/markdownRenderer.ts\n+++ b/src/vs/base/browser/markdownRenderer.ts\n@@ -199,7 +199,19 @@ export function renderMarkdown(markdown: IMarkdownString, options: MarkdownRende\n \t\t\t}\n \t\t\ttry {\n \t\t\t\tlet href = target.dataset['href'];\n+\t\t\t\tif (!href) {\n+\t\t\t\t\t// Fallback to standard href attribute for raw HTML anchors\n+\t\t\t\t\thref = target.getAttribute('href') || '';\n+\t\t\t\t}\n \t\t\t\tif (href) {\n+\t\t\t\t\t// Apply same trust checks and filtering used for markdown links\n+\t\t\t\t\tif (\n+\t\t\t\t\t\t/^data:|javascript:/i.test(href)\n+\t\t\t\t\t\t|| (/^command:/i.test(href) && !markdown.isTrusted)\n+\t\t\t\t\t\t|| /^command:(\\/\\/\\/)?_workbench\\.downloadResource/i.test(href)\n+\t\t\t\t\t) {\n+\t\t\t\t\t\treturn;\n+\t\t\t\t\t}\n \t\t\t\t\tif (markdown.baseUri) {\n \t\t\t\t\t\thref = resolveWithBaseUri(URI.from(markdown.baseUri), href);\n \t\t\t\t\t}\n"}
{"instance_id": "microsoft__vscode-164396", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/workbench/api/browser/mainThreadLanguageFeatures.ts b/src/vs/workbench/api/browser/mainThreadLanguageFeatures.ts\nindex 99ac22e555e..99f3373b6d1 100644\n--- a/src/vs/workbench/api/browser/mainThreadLanguageFeatures.ts\n+++ b/src/vs/workbench/api/browser/mainThreadLanguageFeatures.ts\n@@ -39,6 +39,8 @@ export class MainThreadLanguageFeatures extends Disposable implements MainThread\n \n \tprivate readonly _proxy: ExtHostLanguageFeaturesShape;\n \tprivate readonly _registrations = this._register(new DisposableMap<number>());\n+\tprivate readonly _semanticTokensEmitters = new Map<number, Emitter<void>>();\n+\tprivate readonly _semanticTokensProviderToEventHandle = new Map<number, number>();\n \n \tconstructor(\n \t\textHostContext: IExtHostContext,\n@@ -82,6 +84,21 @@ export class MainThreadLanguageFeatures extends Disposable implements MainThread\n \n \t$unregister(handle: number): void {\n \t\tthis._registrations.deleteAndDispose(handle);\n+\t\t// cleanup possible semantic tokens emitters by either event handle or provider handle\n+\t\tconst directEmitter = this._semanticTokensEmitters.get(handle);\n+\t\tif (directEmitter) {\n+\t\t\tdirectEmitter.dispose();\n+\t\t\tthis._semanticTokensEmitters.delete(handle);\n+\t\t}\n+\t\tconst eventHandle = this._semanticTokensProviderToEventHandle.get(handle);\n+\t\tif (typeof eventHandle === 'number') {\n+\t\t\tconst emitter = this._semanticTokensEmitters.get(eventHandle);\n+\t\t\tif (emitter) {\n+\t\t\t\temitter.dispose();\n+\t\t\t\tthis._semanticTokensEmitters.delete(eventHandle);\n+\t\t\t}\n+\t\t\tthis._semanticTokensProviderToEventHandle.delete(handle);\n+\t\t}\n \t}\n \n \t//#region --- revive functions\n@@ -450,16 +467,18 @@ export class MainThreadLanguageFeatures extends Disposable implements MainThread\n \t\tlet event: Event<void> | undefined = undefined;\n \t\tif (typeof eventHandle === 'number') {\n \t\t\tconst emitter = new Emitter<void>();\n-\t\t\tthis._registrations.set(eventHandle, emitter);\n+\t\t\tthis._semanticTokensEmitters.set(eventHandle, emitter);\n+\t\t\tthis._semanticTokensProviderToEventHandle.set(handle, eventHandle);\n \t\t\tevent = emitter.event;\n \t\t}\n \t\tthis._registrations.set(handle, this._languageFeaturesService.documentSemanticTokensProvider.register(selector, new MainThreadDocumentSemanticTokensProvider(this._proxy, handle, legend, event)));\n \t}\n \n \t$emitDocumentSemanticTokensEvent(eventHandle: number): void {\n-\t\tconst obj = this._registrations.get(eventHandle);\n-\t\tif (obj instanceof Emitter) {\n-\t\t\tobj.fire(undefined);\n+\t\tconst emitter = this._semanticTokensEmitters.get(eventHandle);\n+\t\tif (emitter) {\n+\t\t\t// defer emission to avoid reentrancy issues\n+\t\t\tPromise.resolve().then(() => emitter.fire(undefined));\n \t\t}\n \t}\n \n"}
{"instance_id": "angular__angular-37561", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/core/src/render3/di.ts b/packages/core/src/render3/di.ts\nindex 14a40667cd..0f7b18b1a5 100644\n--- a/packages/core/src/render3/di.ts\n+++ b/packages/core/src/render3/di.ts\n@@ -658,6 +658,11 @@ export function getFactoryOf<T>(type: Type<any>): FactoryFn<T>|null {\n export function getInheritedFactory<T>(type: Type<any>): (type: Type<T>) => T {\n   return noSideEffects(() => {\n     const proto = Object.getPrototypeOf(type.prototype).constructor as Type<any>;\n+    // Guard against prototype loops or decorator-induced class replacement that results\n+    // in the same constructor being returned, which would cause infinite recursion.\n+    if (proto === type) {\n+      return (t) => new t();\n+    }\n     const factory = (proto as any)[NG_FACTORY_DEF] || getFactoryOf<T>(proto);\n     if (factory !== null) {\n       return factory;\n"}
{"instance_id": "mui__material-ui-11451", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/ListItem/ListItem.js b/packages/material-ui/src/ListItem/ListItem.js\nindex 9918957705..2c69325077 100644\n--- a/packages/material-ui/src/ListItem/ListItem.js\n+++ b/packages/material-ui/src/ListItem/ListItem.js\n@@ -105,7 +105,7 @@ class ListItem extends React.Component {\n \n     if (button) {\n       componentProps.component = componentProp || 'div';\n-      componentProps.focusVisibleClassName = classes.focusVisible;\n+      componentProps.focusVisibleClassName = classNames(classes.focusVisible, componentProps.focusVisibleClassName);\n       Component = ButtonBase;\n     }\n \n"}
{"instance_id": "mui__material-ui-11858", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/ListItemText/ListItemText.d.ts b/packages/material-ui/src/ListItemText/ListItemText.d.ts\nindex c52c1d3f66..78d450e8af 100644\n--- a/packages/material-ui/src/ListItemText/ListItemText.d.ts\n+++ b/packages/material-ui/src/ListItemText/ListItemText.d.ts\n@@ -7,6 +7,7 @@ export interface ListItemTextProps\n   inset?: boolean;\n   primary?: React.ReactNode;\n   secondary?: React.ReactNode;\n+  color?: import('../Typography').TypographyProps['color'];\n }\n \n export type ListItemTextClassKey =\ndiff --git a/packages/material-ui/src/ListItemText/ListItemText.js b/packages/material-ui/src/ListItemText/ListItemText.js\nindex a6a02f34df..bcbfb0fd64 100644\n--- a/packages/material-ui/src/ListItemText/ListItemText.js\n+++ b/packages/material-ui/src/ListItemText/ListItemText.js\n@@ -43,6 +43,7 @@ function ListItemText(props, context) {\n     inset,\n     primary: primaryProp,\n     secondary: secondaryProp,\n+    color,\n     ...other\n   } = props;\n   const { dense } = context;\n@@ -54,6 +55,7 @@ function ListItemText(props, context) {\n         variant=\"subheading\"\n         className={classNames(classes.primary, { [classes.textDense]: dense })}\n         component=\"span\"\n+        color={color}\n       >\n         {primary}\n       </Typography>\n@@ -68,7 +70,7 @@ function ListItemText(props, context) {\n         className={classNames(classes.secondary, {\n           [classes.textDense]: dense,\n         })}\n-        color=\"textSecondary\"\n+        color={color || \"textSecondary\"}\n       >\n         {secondary}\n       </Typography>\n@@ -127,6 +129,10 @@ ListItemText.propTypes = {\n    * The secondary content element.\n    */\n   secondary: PropTypes.node,\n+  /**\n+   * The color of the text. It will be applied to both primary and secondary Typography unless overridden.\n+   */\n+  color: PropTypes.oneOf(['inherit', 'primary', 'textSecondary', 'secondary', 'error', 'default']),\n };\n \n ListItemText.defaultProps = {\n"}
{"instance_id": "mui__material-ui-11987", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-icons/src/utils/createSvgIcon.js b/packages/material-ui-icons/src/utils/createSvgIcon.js\nindex f06884e164..3a8ded8bee 100644\n--- a/packages/material-ui-icons/src/utils/createSvgIcon.js\n+++ b/packages/material-ui-icons/src/utils/createSvgIcon.js\n@@ -5,6 +5,7 @@ import SvgIcon from '@material-ui/core/SvgIcon';\n function createSvgIcon(path, displayName) {\n   let Icon = props => (\n     <SvgIcon {...props}>\n+      {props.children}\n       {path}\n     </SvgIcon>\n   );\n"}
{"instance_id": "mui__material-ui-12406", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Input/Textarea.js b/packages/material-ui/src/Input/Textarea.js\nindex 8dfa1a7aeb..1e00b04629 100644\n--- a/packages/material-ui/src/Input/Textarea.js\n+++ b/packages/material-ui/src/Input/Textarea.js\n@@ -109,8 +109,10 @@ class Textarea extends React.Component {\n \n     if (!this.isControlled) {\n       // The component is not controlled, we need to update the shallow value.\n-      this.shadowRef.value = this.value;\n-      this.syncHeightWithShadow();\n+      if (this.shadowRef) {\n+        this.shadowRef.value = this.value;\n+        this.syncHeightWithShadow();\n+      }\n     }\n \n     if (this.props.onChange) {\n@@ -121,6 +123,11 @@ class Textarea extends React.Component {\n   syncHeightWithShadow() {\n     const props = this.props;\n \n+    // If the shadow refs are not available (e.g., in test environments), bail out early.\n+    if (!this.singlelineShadowRef || !this.shadowRef) {\n+      return;\n+    }\n+\n     if (this.isControlled) {\n       // The component is controlled, we need to update the shallow value.\n       this.shadowRef.value = props.value == null ? '' : String(props.value);\n"}
{"instance_id": "mui__material-ui-13430", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/CircularProgress/CircularProgress.js b/packages/material-ui/src/CircularProgress/CircularProgress.js\nindex bf32f77980..d96e9eaa35 100644\n--- a/packages/material-ui/src/CircularProgress/CircularProgress.js\n+++ b/packages/material-ui/src/CircularProgress/CircularProgress.js\n@@ -63,6 +63,12 @@ export const styles = theme => ({\n     strokeDasharray: '80px, 200px',\n     strokeDashoffset: '0px', // Add the unit to fix a Edge 16 and below bug.\n   },\n+  /* Styles applied to the `circle` svg path if `variant=\"indeterminate\"` and `disableShrink`. */\n+  circleDisableShrink: {\n+    animation: 'none',\n+    strokeDasharray: '80px, 200px',\n+    strokeDashoffset: '0px',\n+  },\n   '@keyframes mui-progress-circular-rotate': {\n     '100%': {\n       transform: 'rotate(360deg)',\n@@ -92,7 +98,7 @@ export const styles = theme => ({\n  * attribute to `true` on that region until it has finished loading.\n  */\n function CircularProgress(props) {\n-  const { classes, className, color, size, style, thickness, value, variant, ...other } = props;\n+  const { classes, className, color, size, style, thickness, value, variant, disableShrink, ...other } = props;\n \n   const circleStyle = {};\n   const rootStyle = {};\n@@ -133,7 +139,8 @@ function CircularProgress(props) {\n       <svg className={classes.svg} viewBox={`${SIZE / 2} ${SIZE / 2} ${SIZE} ${SIZE}`}>\n         <circle\n           className={classNames(classes.circle, {\n-            [classes.circleIndeterminate]: variant === 'indeterminate',\n+            [classes.circleIndeterminate]: variant === 'indeterminate' && !disableShrink,\n+            [classes.circleDisableShrink]: variant === 'indeterminate' && disableShrink,\n             [classes.circleStatic]: variant === 'static',\n           })}\n           style={circleStyle}\n@@ -184,6 +191,10 @@ CircularProgress.propTypes = {\n    * Use indeterminate when there is no progress value.\n    */\n   variant: PropTypes.oneOf(['determinate', 'indeterminate', 'static']),\n+  /**\n+   * If true, the shrink animation is disabled. This only works if variant is 'indeterminate'.\n+   */\n+  disableShrink: PropTypes.bool,\n };\n \n CircularProgress.defaultProps = {\n@@ -192,6 +203,7 @@ CircularProgress.defaultProps = {\n   thickness: 3.6,\n   value: 0,\n   variant: 'indeterminate',\n+  disableShrink: false,\n };\n \n export default withStyles(styles, { name: 'MuiCircularProgress', flip: false })(CircularProgress);\n"}
{"instance_id": "mui__material-ui-13534", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/src/pages/demos/badges/SimpleBadge.js b/docs/src/pages/demos/badges/SimpleBadge.js\nindex 99f73f0f66..420d9b6e86 100644\n--- a/docs/src/pages/demos/badges/SimpleBadge.js\n+++ b/docs/src/pages/demos/badges/SimpleBadge.js\n@@ -30,6 +30,9 @@ function SimpleBadge(props) {\n         <Badge className={classes.margin} badgeContent={10} color=\"secondary\">\n           <MailIcon />\n         </Badge>\n+        <Badge className={classes.margin} badgeContent={4} color=\"secondary\" invisible>\n+          <MailIcon />\n+        </Badge>\n         <IconButton aria-label=\"4 pending messages\" className={classes.margin}>\n           <Badge badgeContent={4} color=\"primary\">\n             <MailIcon />\ndiff --git a/docs/src/pages/demos/badges/badges.md b/docs/src/pages/demos/badges/badges.md\nindex 5bc6ab5894..e3f80877cb 100644\n--- a/docs/src/pages/demos/badges/badges.md\n+++ b/docs/src/pages/demos/badges/badges.md\n@@ -16,3 +16,7 @@ Examples of badges containing text, using primary and secondary colors. The badg\n ## Customized Badge\n \n {{\"demo\": \"pages/demos/badges/CustomizedBadge.js\"}}\n+\n+## Badge visibility\n+\n+You can quickly hide the badge by using the invisible prop. When true, the badge contents and background are not rendered, while the children remain visible. See the Simple Badges demo for an example.\ndiff --git a/packages/material-ui/src/Badge/Badge.js b/packages/material-ui/src/Badge/Badge.js\nindex ba646a49b6..dcb1771a09 100644\n--- a/packages/material-ui/src/Badge/Badge.js\n+++ b/packages/material-ui/src/Badge/Badge.js\n@@ -60,6 +60,7 @@ function Badge(props) {\n     className,\n     color,\n     component: ComponentProp,\n+    invisible,\n     ...other\n   } = props;\n \n@@ -70,7 +71,7 @@ function Badge(props) {\n   return (\n     <ComponentProp className={classNames(classes.root, className)} {...other}>\n       {children}\n-      <span className={badgeClassName}>{badgeContent}</span>\n+      {!invisible && <span className={badgeClassName}>{badgeContent}</span>}\n     </ComponentProp>\n   );\n }\n@@ -97,6 +98,10 @@ Badge.propTypes = {\n    * The color of the component. It supports those theme colors that make sense for this component.\n    */\n   color: PropTypes.oneOf(['default', 'primary', 'secondary', 'error']),\n+  /**\n+   * If true, the badge is invisible.\n+   */\n+  invisible: PropTypes.bool,\n   /**\n    * The component used for the root node.\n    * Either a string to use a DOM element or a component.\n@@ -107,6 +112,7 @@ Badge.propTypes = {\n Badge.defaultProps = {\n   color: 'default',\n   component: 'span',\n+  invisible: false,\n };\n \n export default withStyles(styles, { name: 'MuiBadge' })(Badge);\n"}
{"instance_id": "mui__material-ui-13690", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Tooltip/Tooltip.js b/packages/material-ui/src/Tooltip/Tooltip.js\nindex de16c64fd2..4e27fdfbed 100644\n--- a/packages/material-ui/src/Tooltip/Tooltip.js\n+++ b/packages/material-ui/src/Tooltip/Tooltip.js\n@@ -280,7 +280,7 @@ class Tooltip extends React.Component {\n \n     const childrenProps = {\n       'aria-describedby': open ? id || this.defaultId : null,\n-      title: !open && typeof title === 'string' ? title : null,\n+      title: !open && typeof title === 'string' && !disableHoverListener ? title : null,\n       ...other,\n       ...children.props,\n       className: classNames(other.className, children.props.className),\n"}
{"instance_id": "mui__material-ui-13778", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Modal/ModalManager.js b/packages/material-ui/src/Modal/ModalManager.js\nindex eac18c250c..e4be9f2452 100644\n--- a/packages/material-ui/src/Modal/ModalManager.js\n+++ b/packages/material-ui/src/Modal/ModalManager.js\n@@ -50,6 +50,9 @@ function setContainerStyle(data) {\n }\n \n function removeContainerStyle(data) {\n+  if (!data.style) {\n+    return;\n+  }\n   Object.keys(data.style).forEach(key => {\n     data.container.style[key] = data.style[key];\n   });\n@@ -144,7 +147,7 @@ class ModalManager {\n \n     // If that was the last modal in a container, clean up the container.\n     if (data.modals.length === 0) {\n-      if (this.handleContainerOverflow) {\n+      if (this.handleContainerOverflow && data.style) {\n         removeContainerStyle(data);\n       }\n \n"}
{"instance_id": "mui__material-ui-13789", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Backdrop/Backdrop.js b/packages/material-ui/src/Backdrop/Backdrop.js\nindex 9566869e73..8d4e609c07 100644\n--- a/packages/material-ui/src/Backdrop/Backdrop.js\n+++ b/packages/material-ui/src/Backdrop/Backdrop.js\n@@ -29,7 +29,7 @@ function Backdrop(props) {\n   const { classes, className, invisible, open, transitionDuration, ...other } = props;\n \n   return (\n-    <Fade in={open} timeout={transitionDuration} {...other}>\n+    <Fade in={open} timeout={transitionDuration}>\n       <div\n         data-mui-test=\"Backdrop\"\n         className={classNames(\n@@ -40,6 +40,7 @@ function Backdrop(props) {\n           className,\n         )}\n         aria-hidden=\"true\"\n+        {...other}\n       />\n     </Fade>\n   );\ndiff --git a/packages/material-ui/src/Dialog/Dialog.js b/packages/material-ui/src/Dialog/Dialog.js\nindex 669a80c29a..d23976b33a 100644\n--- a/packages/material-ui/src/Dialog/Dialog.js\n+++ b/packages/material-ui/src/Dialog/Dialog.js\n@@ -117,11 +117,18 @@ export const styles = theme => ({\n  * Dialogs are overlaid modal paper based components with a backdrop.\n  */\n class Dialog extends React.Component {\n+  backdropMouseDown = false;\n   handleBackdropClick = event => {\n     if (event.target !== event.currentTarget) {\n       return;\n     }\n \n+    // Only consider it a backdrop click if the last mousedown was on the backdrop container\n+    if (!this.backdropMouseDown) {\n+      return;\n+    }\n+    this.backdropMouseDown = false;\n+\n     if (this.props.onBackdropClick) {\n       this.props.onBackdropClick(event);\n     }\n@@ -131,6 +138,12 @@ class Dialog extends React.Component {\n     }\n   };\n \n+  handleBackdropMouseDown = event => {\n+    if (event.target === event.currentTarget) {\n+      this.backdropMouseDown = true;\n+    }\n+  };\n+\n   render() {\n     const {\n       BackdropProps,\n@@ -191,6 +204,7 @@ class Dialog extends React.Component {\n         >\n           <div\n             className={classNames(classes.container, classes[`scroll${capitalize(scroll)}`])}\n+            onMouseDown={this.handleBackdropMouseDown}\n             onClick={this.handleBackdropClick}\n             role=\"document\"\n           >\ndiff --git a/packages/material-ui/src/Modal/Modal.js b/packages/material-ui/src/Modal/Modal.js\nindex 8f122acffe..5efe21f4f5 100644\n--- a/packages/material-ui/src/Modal/Modal.js\n+++ b/packages/material-ui/src/Modal/Modal.js\n@@ -59,6 +59,8 @@ if (process.env.NODE_ENV !== 'production' && !React.createContext) {\n class Modal extends React.Component {\n   mounted = false;\n \n+  backdropMouseDown = false;\n+\n   constructor(props) {\n     super();\n     this.state = {\n@@ -157,6 +159,12 @@ class Modal extends React.Component {\n       return;\n     }\n \n+    // Only consider it a backdrop click if the last mousedown was on the backdrop\n+    if (!this.backdropMouseDown) {\n+      return;\n+    }\n+    this.backdropMouseDown = false;\n+\n     if (this.props.onBackdropClick) {\n       this.props.onBackdropClick(event);\n     }\n@@ -166,6 +174,13 @@ class Modal extends React.Component {\n     }\n   };\n \n+  handleBackdropMouseDown = event => {\n+    // We only start a backdrop click interaction if mousedown started on the backdrop\n+    if (event.target === event.currentTarget) {\n+      this.backdropMouseDown = true;\n+    }\n+  };\n+\n   handleKeyDown = event => {\n     // event.defaultPrevented:\n     //\n@@ -332,7 +347,12 @@ class Modal extends React.Component {\n           {...other}\n         >\n           {hideBackdrop ? null : (\n-            <BackdropComponent open={open} onClick={this.handleBackdropClick} {...BackdropProps} />\n+            <BackdropComponent\n+              open={open}\n+              onMouseDown={this.handleBackdropMouseDown}\n+              onClick={this.handleBackdropClick}\n+              {...BackdropProps}\n+            />\n           )}\n           <RootRef rootRef={this.onRootRef}>{React.cloneElement(children, childProps)}</RootRef>\n         </div>\n"}
{"instance_id": "mui__material-ui-14364", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/InputBase/InputBase.js b/packages/material-ui/src/InputBase/InputBase.js\nindex cd565a633b..73e38b5abd 100644\n--- a/packages/material-ui/src/InputBase/InputBase.js\n+++ b/packages/material-ui/src/InputBase/InputBase.js\n@@ -180,7 +180,7 @@ class InputBase extends React.Component {\n         muiFormControl.onBlur();\n       }\n     }\n-    if (this.isControlled) {\n+    if (this.isControlled && prevProps.value !== this.props.value) {\n       this.checkDirty(this.props);\n     } // else performed in the onChange\n   }\n"}
{"instance_id": "mui__material-ui-14496", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Tooltip/Tooltip.js b/packages/material-ui/src/Tooltip/Tooltip.js\nindex 5d1ceb6048..8af9e57956 100644\n--- a/packages/material-ui/src/Tooltip/Tooltip.js\n+++ b/packages/material-ui/src/Tooltip/Tooltip.js\n@@ -130,7 +130,10 @@ class Tooltip extends React.Component {\n     // We need to account for this eventuality.\n     this.focusTimer = setTimeout(() => {\n       // We need to make sure the focus hasn't moved since the event was triggered.\n-      if (this.childrenRef === document.activeElement) {\n+      if (\n+        this.childrenRef === document.activeElement ||\n+        (this.childrenRef && this.childrenRef.contains(document.activeElement))\n+      ) {\n         this.handleEnter(event);\n       }\n     });\n"}
{"instance_id": "mui__material-ui-14882", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/LinearProgress/LinearProgress.js b/packages/material-ui/src/LinearProgress/LinearProgress.js\nindex e29a58959e..03267eb2de 100644\n--- a/packages/material-ui/src/LinearProgress/LinearProgress.js\n+++ b/packages/material-ui/src/LinearProgress/LinearProgress.js\n@@ -71,8 +71,7 @@ export const styles = theme => ({\n     left: 0,\n     bottom: 0,\n     top: 0,\n-    transition: 'transform 0.2s linear',\n-    transformOrigin: 'left',\n+    transition: 'width 0.2s linear',\n   },\n   /* Styles applied to the bar elements if `color=\"primary\"`; bar2 if `variant` not \"buffer\". */\n   barColorPrimary: {\n@@ -92,12 +91,12 @@ export const styles = theme => ({\n   },\n   /* Styles applied to the bar1 element if `variant=\"determinate\"`. */\n   bar1Determinate: {\n-    transition: `transform .${TRANSITION_DURATION}s linear`,\n+    transition: `width .${TRANSITION_DURATION}s linear`,\n   },\n   /* Styles applied to the bar1 element if `variant=\"buffer\"`. */\n   bar1Buffer: {\n     zIndex: 1,\n-    transition: `transform .${TRANSITION_DURATION}s linear`,\n+    transition: `width .${TRANSITION_DURATION}s linear`,\n   },\n   /* Styles applied to the bar2 element if `variant=\"indeterminate or query\"`. */\n   bar2Indeterminate: {\n@@ -110,7 +109,7 @@ export const styles = theme => ({\n   },\n   /* Styles applied to the bar2 element if `variant=\"buffer\"`. */\n   bar2Buffer: {\n-    transition: `transform .${TRANSITION_DURATION}s linear`,\n+    transition: `width .${TRANSITION_DURATION}s linear`,\n   },\n   // Legends:\n   // || represents the viewport\n@@ -211,7 +210,7 @@ const LinearProgress = React.forwardRef(function LinearProgress(props, ref) {\n   if (variant === 'determinate' || variant === 'buffer') {\n     if (value !== undefined) {\n       rootProps['aria-valuenow'] = Math.round(value);\n-      inlineStyles.bar1.transform = `scaleX(${value / 100})`;\n+      inlineStyles.bar1.width = `${value}%`;\n     } else {\n       warning(\n         false,\n@@ -222,7 +221,7 @@ const LinearProgress = React.forwardRef(function LinearProgress(props, ref) {\n   }\n   if (variant === 'buffer') {\n     if (valueBuffer !== undefined) {\n-      inlineStyles.bar2.transform = `scaleX(${(valueBuffer || 0) / 100})`;\n+      inlineStyles.bar2.width = `${valueBuffer || 0}%`;\n     } else {\n       warning(\n         false,\n"}
{"instance_id": "mui__material-ui-15359", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/src/pages/utils/popper/popper.md b/docs/src/pages/utils/popper/popper.md\nindex 999bdd961f..1a98121874 100644\n--- a/docs/src/pages/utils/popper/popper.md\n+++ b/docs/src/pages/utils/popper/popper.md\n@@ -19,6 +19,7 @@ The placement of the popper updates with the available area in the viewport.\n - Clicking away does not hide the `Popper` component. \n   If you need this behavior, you can use [`ClickAwayListener`](utils/click-away-listener/) - see the example in the [menu documentation section](/demos/menus/#menulist-composition).\n - The `anchorEl` is passed as the reference object to create a new `Popper.js` instance.\n+- You can pass `popperOptions` to control the underlying Popper.js instance. Callbacks `onCreate` and `onUpdate` are supported and will be invoked in addition to internal state updates. For compatibility, if only `onUpdate` is provided (and `onCreate` is not), `onUpdate` will be called once upon creation to reflect the initial placement update.\n \n ## Simple Popper\n \ndiff --git a/packages/material-ui/src/Popper/Popper.d.ts b/packages/material-ui/src/Popper/Popper.d.ts\nindex 23ca7c4b58..9ac851d65e 100644\n--- a/packages/material-ui/src/Popper/Popper.d.ts\n+++ b/packages/material-ui/src/Popper/Popper.d.ts\n@@ -32,7 +32,17 @@ export interface PopperProps extends React.HTMLAttributes<HTMLDivElement> {\n   modifiers?: object;\n   open: boolean;\n   placement?: PopperPlacementType;\n-  popperOptions?: object;\n+  /**\n+   * Options passed to the underlying popper.js instance. Supports popper.js callbacks\n+   * such as `onCreate` and `onUpdate`. If only `onUpdate` is provided (and `onCreate` is not),\n+   * `onUpdate` will be called once upon creation to reflect the initial placement update.\n+   */\n+  popperOptions?: {\n+    onCreate?: (data: object) => void;\n+    onUpdate?: (data: object) => void;\n+    modifiers?: object;\n+    [key: string]: any;\n+  };\n }\n \n declare const Popper: React.ComponentType<PopperProps>;\ndiff --git a/packages/material-ui/src/Popper/Popper.js b/packages/material-ui/src/Popper/Popper.js\nindex ce37362db8..b726c85180 100644\n--- a/packages/material-ui/src/Popper/Popper.js\n+++ b/packages/material-ui/src/Popper/Popper.js\n@@ -96,8 +96,20 @@ class Popper extends React.Component {\n       },\n       // We could have been using a custom modifier like react-popper is doing.\n       // But it seems this is the best public API for this use case.\n-      onCreate: this.handlePopperUpdate,\n-      onUpdate: this.handlePopperUpdate,\n+      onCreate: data => {\n+        this.handlePopperUpdate(data);\n+        if (popperOptions.onCreate) {\n+          popperOptions.onCreate(data);\n+        } else if (popperOptions.onUpdate) {\n+          popperOptions.onUpdate(data);\n+        }\n+      },\n+      onUpdate: data => {\n+        this.handlePopperUpdate(data);\n+        if (popperOptions.onUpdate) {\n+          popperOptions.onUpdate(data);\n+        }\n+      },\n     });\n   };\n \n"}
{"instance_id": "mui__material-ui-15526", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/src/pages/utils/transitions/transitions.md b/docs/src/pages/utils/transitions/transitions.md\nindex 73c990f1d9..c2488f2a9b 100644\n--- a/docs/src/pages/utils/transitions/transitions.md\n+++ b/docs/src/pages/utils/transitions/transitions.md\n@@ -35,6 +35,27 @@ export default Main() {\n }\n ```\n \n+In addition to the `style` property, the transition child must be able to receive a `ref` and\n+forward it to a DOM element. Transition components (Fade, Grow, Zoom, Slide) attach a `ref` to\n+their child and rely on it to access the underlying DOM node.\n+\n+If you pass a custom function component as the child, use `React.forwardRef` and forward the `ref`\n+to the DOM element that also receives the injected `style` prop.\n+\n+If you cannot modify the child (for example, third-party components like Formik's `Field`),\n+wrap it in a DOM element and spread the injected props on that element:\n+\n+```jsx\n+<Zoom in={in}>\n+  <div>\n+    <Field name=\"title\" component={MyInput} />\n+  </div>\n+</Zoom>\n+```\n+\n+Troubleshooting: If you see the warning\n+\"Function components cannot be given refs. Attempts to access this ref will fail. Did you mean to use React.forwardRef?\\n\\nCheck the render method of `Transition`.\",\n+it means the transition child does not forward its ref. Use `React.forwardRef` on the child or wrap it in a DOM element.\n ## Collapse\n \n Expand vertically from the top of the child element.\ndiff --git a/packages/material-ui/src/Zoom/Zoom.js b/packages/material-ui/src/Zoom/Zoom.js\nindex b0e37b1534..79caa172b9 100644\n--- a/packages/material-ui/src/Zoom/Zoom.js\n+++ b/packages/material-ui/src/Zoom/Zoom.js\n@@ -73,7 +73,8 @@ const Zoom = React.forwardRef(function Zoom(props, ref) {\n \n Zoom.propTypes = {\n   /**\n-   * A single child content element.\n+   * A single child content element that must be able to hold a ref\n+   * and forward it to the underlying DOM node.\n    */\n   children: PropTypes.element,\n   /**\n"}
{"instance_id": "mui__material-ui-15534", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/FormControlLabel/FormControlLabel.js b/packages/material-ui/src/FormControlLabel/FormControlLabel.js\nindex 4d6b47ca96..cac5435190 100644\n--- a/packages/material-ui/src/FormControlLabel/FormControlLabel.js\n+++ b/packages/material-ui/src/FormControlLabel/FormControlLabel.js\n@@ -18,7 +18,7 @@ export const styles = theme => ({\n     WebkitTapHighlightColor: 'transparent',\n     marginLeft: -11,\n     marginRight: 16, // used for row presentation of radio/checkbox\n-    '&$disabled': {\n+    '&[data-disabled=\"true\"]': {\n       cursor: 'default',\n     },\n   },\n@@ -39,10 +39,10 @@ export const styles = theme => ({\n     marginLeft: 16,\n   },\n   /* Styles applied to the root element if `disabled={true}`. */\n-  disabled: {},\n+  disabled: {}, // no longer used for root styling; kept for API compatibility\n   /* Styles applied to the label's Typography component. */\n   label: {\n-    '&$disabled': {\n+    '&[data-disabled=\"true\"]': {\n       color: theme.palette.text.disabled,\n     },\n   },\n@@ -92,17 +92,18 @@ const FormControlLabel = React.forwardRef(function FormControlLabel(props, ref)\n         classes.root,\n         {\n           [classes[`labelPlacement${capitalize(labelPlacement)}`]]: labelPlacement !== 'end',\n-          [classes.disabled]: disabled,\n         },\n-        classNameProp,\n+        classNameProp && classNameProp.split(' ').filter(token => token !== 'disabled').join(' ')\n       )}\n+      data-disabled={disabled ? 'true' : undefined}\n       ref={ref}\n       {...other}\n     >\n       {React.cloneElement(control, controlProps)}\n       <Typography\n         component=\"span\"\n-        className={clsx(classes.label, { [classes.disabled]: disabled })}\n+        className={clsx(classes.label)}\n+        data-disabled={disabled ? 'true' : undefined}\n       >\n         {label}\n       </Typography>\n"}
{"instance_id": "mui__material-ui-16397", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/ButtonBase/ButtonBase.js b/packages/material-ui/src/ButtonBase/ButtonBase.js\nindex d157b568e3..2450f5afa0 100644\n--- a/packages/material-ui/src/ButtonBase/ButtonBase.js\n+++ b/packages/material-ui/src/ButtonBase/ButtonBase.js\n@@ -268,7 +268,12 @@ const ButtonBase = React.forwardRef(function ButtonBase(props, ref) {\n     buttonProps.type = type;\n     buttonProps.disabled = disabled;\n   } else {\n-    buttonProps.role = 'button';\n+    // Avoid applying button role to elements that are links\n+    // - native anchors with href\n+    // - components with `href` or `to` props that will render links\n+    if (!(ComponentProp === 'a' && other.href) && !other.href && !other.to) {\n+      buttonProps.role = 'button';\n+    }\n     buttonProps['aria-disabled'] = disabled;\n   }\n \n"}
{"instance_id": "mui__material-ui-17301", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/SpeedDialAction/SpeedDialAction.js b/packages/material-ui-lab/src/SpeedDialAction/SpeedDialAction.js\nindex dbcbebb7a0..e9ebb7d286 100644\n--- a/packages/material-ui-lab/src/SpeedDialAction/SpeedDialAction.js\n+++ b/packages/material-ui-lab/src/SpeedDialAction/SpeedDialAction.js\n@@ -12,9 +12,9 @@ export const styles = theme => ({\n   button: {\n     margin: 8,\n     color: theme.palette.text.secondary,\n-    backgroundColor: theme.palette.common.white,\n+    backgroundColor: theme.palette.background.paper,\n     '&:hover': {\n-      backgroundColor: emphasize(theme.palette.common.white, 0.15),\n+      backgroundColor: emphasize(theme.palette.background.paper, 0.15),\n     },\n     transition: `${theme.transitions.create('transform', {\n       duration: theme.transitions.duration.shorter,\n"}
{"instance_id": "mui__material-ui-17829", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/pages/api/chip.md b/docs/pages/api/chip.md\nindex 665a07ae8d..e7c2475e98 100644\n--- a/docs/pages/api/chip.md\n+++ b/docs/pages/api/chip.md\n@@ -27,11 +27,14 @@ Chips represent complex entities in small blocks, such as a contact.\n | <span class=\"prop-name\">avatar</span> | <span class=\"prop-type\">element</span> |  | Avatar element. |\n | <span class=\"prop-name\">children</span> | <span class=\"prop-type\">unsupportedProp</span> |  | This prop isn't supported. Use the `component` prop if you need to change the children structure. |\n | <span class=\"prop-name\">classes</span> | <span class=\"prop-type\">object</span> |  | Override or extend the styles applied to the component. See [CSS API](#css) below for more details. |\n-| <span class=\"prop-name\">clickable</span> | <span class=\"prop-type\">bool</span> |  | If true, the chip will appear clickable, and will raise when pressed, even if the onClick prop is not defined. If false, the chip will not be clickable, even if onClick prop is defined. This can be used, for example, along with the component prop to indicate an anchor Chip is clickable. |\n+| <span class=\"prop-name\">clickable</span> | <span class=\"prop-type\">bool</span> |  | If true, the chip will appear clickable, and will raise and display a ripple when pressed, even if the onClick prop is not defined. If false, the chip will not be clickable, even if onClick prop is defined. This can be used, for example, along with the component prop to indicate an anchor Chip is clickable. |\n | <span class=\"prop-name\">color</span> | <span class=\"prop-type\">'default'<br>&#124;&nbsp;'primary'<br>&#124;&nbsp;'secondary'</span> | <span class=\"prop-default\">'default'</span> | The color of the component. It supports those theme colors that make sense for this component. |\n | <span class=\"prop-name\">component</span> | <span class=\"prop-type\">elementType</span> | <span class=\"prop-default\">'div'</span> | The component used for the root node. Either a string to use a DOM element or a component. |\n | <span class=\"prop-name\">deleteIcon</span> | <span class=\"prop-type\">element</span> |  | Override the default delete icon element. Shown only if `onDelete` is set. |\n | <span class=\"prop-name\">disabled</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, the chip should be displayed in a disabled state. |\n+| <span class=\"prop-name\">disableFocusRipple</span> | <span class=\"prop-type\">bool</span> |  | If `true`, the keyboard focus ripple effect is disabled. |\n+| <span class=\"prop-name\">disableRipple</span> | <span class=\"prop-type\">bool</span> |  | If `true`, the ripple effect is disabled. |\n+| <span class=\"prop-name\">disableTouchRipple</span> | <span class=\"prop-type\">bool</span> |  | If `true`, the touch ripple effect is disabled. |\n | <span class=\"prop-name\">icon</span> | <span class=\"prop-type\">element</span> |  | Icon element. |\n | <span class=\"prop-name\">label</span> | <span class=\"prop-type\">node</span> |  | The content of the label. |\n | <span class=\"prop-name\">onDelete</span> | <span class=\"prop-type\">func</span> |  | Callback function fired when the delete icon is clicked. If set, the delete icon will be shown. |\ndiff --git a/packages/material-ui/src/Chip/Chip.js b/packages/material-ui/src/Chip/Chip.js\nindex 5a7d605d72..6bec8ca0d1 100644\n--- a/packages/material-ui/src/Chip/Chip.js\n+++ b/packages/material-ui/src/Chip/Chip.js\n@@ -7,6 +7,7 @@ import { emphasize, fade } from '../styles/colorManipulator';\n import useForkRef from '../utils/useForkRef';\n import unsupportedProp from '../utils/unsupportedProp';\n import capitalize from '../utils/capitalize';\n+import ButtonBase from '../ButtonBase';\n import '../Avatar'; // So we don't have any override priority issue.\n \n export const styles = theme => {\n@@ -275,6 +276,9 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n     component: Component = 'div',\n     deleteIcon: deleteIconProp,\n     disabled = false,\n+    disableFocusRipple = false,\n+    disableRipple = false,\n+    disableTouchRipple = false,\n     icon: iconProp,\n     label,\n     onClick,\n@@ -297,6 +301,11 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n     }\n   };\n \n+  const preventPropagation = event => {\n+    // Prevent ripple when interacting with the delete icon\n+    event.stopPropagation();\n+  };\n+\n   const handleKeyDown = event => {\n     if (onKeyDown) {\n       onKeyDown(event);\n@@ -350,11 +359,15 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n         React.cloneElement(deleteIconProp, {\n           className: clsx(deleteIconProp.props.className, classes.deleteIcon, customClasses),\n           onClick: handleDeleteIconClick,\n+          onMouseDown: preventPropagation,\n+          onTouchStart: preventPropagation,\n         })\n       ) : (\n         <CancelIcon\n           className={clsx(classes.deleteIcon, customClasses)}\n           onClick={handleDeleteIconClick}\n+          onMouseDown={preventPropagation}\n+          onTouchStart={preventPropagation}\n         />\n       );\n   }\n@@ -389,41 +402,82 @@ const Chip = React.forwardRef(function Chip(props, ref) {\n   }\n \n   return (\n-    <Component\n-      role={clickable || onDelete ? 'button' : undefined}\n-      className={clsx(\n-        classes.root,\n-        {\n-          [classes.disabled]: disabled,\n-          [classes.sizeSmall]: small,\n-          [classes[`color${capitalize(color)}`]]: color !== 'default',\n-          [classes.clickable]: clickable,\n-          [classes[`clickableColor${capitalize(color)}`]]: clickable && color !== 'default',\n-          [classes.deletable]: onDelete,\n-          [classes[`deletableColor${capitalize(color)}`]]: onDelete && color !== 'default',\n-          [classes.outlined]: variant === 'outlined',\n-          [classes.outlinedPrimary]: variant === 'outlined' && color === 'primary',\n-          [classes.outlinedSecondary]: variant === 'outlined' && color === 'secondary',\n-        },\n-        className,\n-      )}\n-      tabIndex={clickable || onDelete ? 0 : undefined}\n-      onClick={onClick}\n-      onKeyDown={handleKeyDown}\n-      onKeyUp={handleKeyUp}\n-      ref={handleRef}\n-      {...other}\n-    >\n-      {avatar || icon}\n-      <span\n-        className={clsx(classes.label, {\n-          [classes.labelSmall]: small,\n-        })}\n+    clickable ? (\n+      <ButtonBase\n+        className={clsx(\n+          classes.root,\n+          {\n+            [classes.disabled]: disabled,\n+            [classes.sizeSmall]: small,\n+            [classes[`color${capitalize(color)}`]]: color !== 'default',\n+            [classes.clickable]: clickable,\n+            [classes[`clickableColor${capitalize(color)}`]]: clickable && color !== 'default',\n+            [classes.deletable]: onDelete,\n+            [classes[`deletableColor${capitalize(color)}`]]: onDelete && color !== 'default',\n+            [classes.outlined]: variant === 'outlined',\n+            [classes.outlinedPrimary]: variant === 'outlined' && color === 'primary',\n+            [classes.outlinedSecondary]: variant === 'outlined' && color === 'secondary',\n+          },\n+          className,\n+        )}\n+        component={Component}\n+        disabled={disabled}\n+        disableRipple={disableRipple}\n+        disableTouchRipple={disableTouchRipple}\n+        focusRipple={!disableFocusRipple}\n+        onClick={onClick}\n+        onKeyDown={handleKeyDown}\n+        onKeyUp={handleKeyUp}\n+        ref={handleRef}\n+        {...other}\n       >\n-        {label}\n-      </span>\n-      {deleteIcon}\n-    </Component>\n+        {avatar || icon}\n+        <span\n+          className={clsx(classes.label, {\n+            [classes.labelSmall]: small,\n+          })}\n+        >\n+          {label}\n+        </span>\n+        {deleteIcon}\n+      </ButtonBase>\n+    ) : (\n+      <Component\n+        role={clickable || onDelete ? 'button' : undefined}\n+        className={clsx(\n+          classes.root,\n+          {\n+            [classes.disabled]: disabled,\n+            [classes.sizeSmall]: small,\n+            [classes[`color${capitalize(color)}`]]: color !== 'default',\n+            [classes.clickable]: clickable,\n+            [classes[`clickableColor${capitalize(color)}`]]: clickable && color !== 'default',\n+            [classes.deletable]: onDelete,\n+            [classes[`deletableColor${capitalize(color)}`]]: onDelete && color !== 'default',\n+            [classes.outlined]: variant === 'outlined',\n+            [classes.outlinedPrimary]: variant === 'outlined' && color === 'primary',\n+            [classes.outlinedSecondary]: variant === 'outlined' && color === 'secondary',\n+          },\n+          className,\n+        )}\n+        tabIndex={clickable || onDelete ? 0 : undefined}\n+        onClick={onClick}\n+        onKeyDown={handleKeyDown}\n+        onKeyUp={handleKeyUp}\n+        ref={handleRef}\n+        {...other}\n+      >\n+        {avatar || icon}\n+        <span\n+          className={clsx(classes.label, {\n+            [classes.labelSmall]: small,\n+          })}\n+        >\n+          {label}\n+        </span>\n+        {deleteIcon}\n+      </Component>\n+    )\n   );\n });\n \n@@ -471,6 +525,18 @@ Chip.propTypes = {\n    * If `true`, the chip should be displayed in a disabled state.\n    */\n   disabled: PropTypes.bool,\n+  /**\n+   * If `true`, the keyboard focus ripple effect is disabled.\n+   */\n+  disableFocusRipple: PropTypes.bool,\n+  /**\n+   * If `true`, the ripple effect is disabled.\n+   */\n+  disableRipple: PropTypes.bool,\n+  /**\n+   * If `true`, the touch ripple effect is disabled.\n+   */\n+  disableTouchRipple: PropTypes.bool,\n   /**\n    * Icon element.\n    */\n"}
{"instance_id": "mui__material-ui-18141", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/pages/api/select.md b/docs/pages/api/select.md\nindex 0a5bb77a73..fd14668cae 100644\n--- a/docs/pages/api/select.md\n+++ b/docs/pages/api/select.md\n@@ -32,7 +32,7 @@ You can learn more about the difference by [reading this guide](/guides/minimizi\n | <span class=\"prop-name\">IconComponent</span> | <span class=\"prop-type\">elementType</span> | <span class=\"prop-default\">ArrowDropDownIcon</span> | The icon that displays the arrow. |\n | <span class=\"prop-name\">input</span> | <span class=\"prop-type\">element</span> |  | An `Input` element; does not have to be a material-ui specific `Input`. |\n | <span class=\"prop-name\">inputProps</span> | <span class=\"prop-type\">object</span> |  | [Attributes](https://developer.mozilla.org/en-US/docs/Web/HTML/Element/input#Attributes) applied to the `input` element. When `native` is `true`, the attributes are applied on the `select` element. |\n-| <span class=\"prop-name\">labelId</span> | <span class=\"prop-type\">string</span> |  | The idea of an element that acts as an additional label. The Select will be labelled by the additional label and the selected value. |\n+| <span class=\"prop-name\">labelId</span> | <span class=\"prop-type\">string</span> |  | The id of an element that acts as an additional label. The Select will be labelled by the additional label and the selected value. |\n | <span class=\"prop-name\">labelWidth</span> | <span class=\"prop-type\">number</span> | <span class=\"prop-default\">0</span> | The label width to be used on OutlinedInput. This prop is required when the `variant` prop is `outlined`. |\n | <span class=\"prop-name\">MenuProps</span> | <span class=\"prop-type\">object</span> |  | Props applied to the [`Menu`](/api/menu/) element. |\n | <span class=\"prop-name\">multiple</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If true, `value` must be an array and the menu will support multiple selections. |\ndiff --git a/packages/material-ui/src/Select/Select.js b/packages/material-ui/src/Select/Select.js\nindex 0fec819d6f..4ac2b5dba9 100644\n--- a/packages/material-ui/src/Select/Select.js\n+++ b/packages/material-ui/src/Select/Select.js\n@@ -69,7 +69,7 @@ const Select = React.forwardRef(function Select(props, ref) {\n       type: undefined, // We render a select. We can ignore the type provided by the `Input`.\n       multiple,\n       ...(native\n-        ? {}\n+        ? { id }\n         : {\n             autoWidth,\n             displayEmpty,\n"}
{"instance_id": "mui__material-ui-18683", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/useMediaQuery/useMediaQuery.js b/packages/material-ui/src/useMediaQuery/useMediaQuery.js\nindex e969caa2fa..2cb368de0b 100644\n--- a/packages/material-ui/src/useMediaQuery/useMediaQuery.js\n+++ b/packages/material-ui/src/useMediaQuery/useMediaQuery.js\n@@ -1,9 +1,6 @@\n import React from 'react';\n import { getThemeProps, useTheme } from '@material-ui/styles';\n \n-// This variable will be true once the server-side hydration is completed.\n-let hydrationCompleted = false;\n-\n function useMediaQuery(queryInput, options = {}) {\n   const theme = useTheme();\n   const props = getThemeProps({\n@@ -40,7 +37,7 @@ function useMediaQuery(queryInput, options = {}) {\n   };\n \n   const [match, setMatch] = React.useState(() => {\n-    if ((hydrationCompleted || noSsr) && supportMatchMedia) {\n+    if (noSsr && supportMatchMedia) {\n       return window.matchMedia(query).matches;\n     }\n     if (ssrMatchMedia) {\n@@ -54,7 +51,6 @@ function useMediaQuery(queryInput, options = {}) {\n \n   React.useEffect(() => {\n     let active = true;\n-    hydrationCompleted = true;\n \n     if (!supportMatchMedia) {\n       return undefined;\n@@ -80,8 +76,4 @@ function useMediaQuery(queryInput, options = {}) {\n   return match;\n }\n \n-export function testReset() {\n-  hydrationCompleted = false;\n-}\n-\n export default useMediaQuery;\ndiff --git a/packages/material-ui/src/useMediaQuery/useMediaQuery.test.js b/packages/material-ui/src/useMediaQuery/useMediaQuery.test.js\nindex 1cb18922f5..8f78066595 100644\n--- a/packages/material-ui/src/useMediaQuery/useMediaQuery.test.js\n+++ b/packages/material-ui/src/useMediaQuery/useMediaQuery.test.js\n@@ -7,7 +7,7 @@ import { createRender } from '@material-ui/core/test-utils';\n import mediaQuery from 'css-mediaquery';\n import { expect } from 'chai';\n import { spy, stub } from 'sinon';\n-import useMediaQuery, { testReset } from './useMediaQuery';\n+import useMediaQuery from './useMediaQuery';\n \n function createMatchMedia(width, ref) {\n   const listeners = [];\n@@ -45,7 +45,6 @@ describe('useMediaQuery', () => {\n   let values;\n \n   beforeEach(() => {\n-    testReset();\n     values = spy();\n   });\n \n@@ -188,7 +187,7 @@ describe('useMediaQuery', () => {\n \n       render(<Test />);\n       expect(text()).to.equal('false');\n-      expect(values.callCount).to.equal(3);\n+      expect(values.callCount).to.equal(4);\n     });\n \n     it('should be able to change the query dynamically', () => {\n"}
{"instance_id": "mui__material-ui-18796", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/Autocomplete/Autocomplete.js b/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\nindex 991500fc58..23036bb95d 100644\n--- a/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\n+++ b/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\n@@ -262,6 +262,7 @@ const Autocomplete = React.forwardRef(function Autocomplete(props, ref) {\n     renderTags,\n     size = 'medium',\n     value: valueProp,\n+    suppressInputChangeOnSelect = false,\n     ...other\n   } = props;\n   /* eslint-enable no-unused-vars */\n@@ -699,6 +700,10 @@ Autocomplete.propTypes = {\n    * You can customize the equality behavior with the `getOptionSelected` prop.\n    */\n   value: PropTypes.any,\n+  /**\n+   * If `true`, do not call onInputChange when the input value changes due to selecting an option.\n+   */\n+  suppressInputChangeOnSelect: PropTypes.bool,\n };\n \n export default withStyles(styles, { name: 'MuiAutocomplete' })(Autocomplete);\ndiff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.d.ts b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.d.ts\nindex 310167c6c7..dfc70eca8b 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.d.ts\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.d.ts\n@@ -141,6 +141,10 @@ export interface UseAutocompleteProps {\n    * @param {string} value\n    */\n   onInputChange?: (event: React.ChangeEvent<{}>, value: any) => void;\n+  /**\n+   * If `true`, do not call onInputChange when the input value changes due to selecting an option.\n+   */\n+  suppressInputChangeOnSelect?: boolean;\n   /**\n    * Callback fired when the popup requests to be opened.\n    * Use in controlled mode (see open).\ndiff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 38f9ee430a..5db15d5664 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -93,6 +93,7 @@ export default function useAutocomplete(props) {\n     onClose,\n     onOpen,\n     onInputChange,\n+    suppressInputChangeOnSelect = false,\n     open: openProp,\n     options = [],\n     value: valueProp,\n@@ -185,7 +186,7 @@ export default function useAutocomplete(props) {\n \n   const [focused, setFocused] = React.useState(false);\n \n-  const resetInputValue = useEventCallback((event, newValue) => {\n+  const resetInputValue = useEventCallback((event, newValue, reason) => {\n     let newInputValue;\n     if (multiple) {\n       newInputValue = '';\n@@ -218,12 +219,14 @@ export default function useAutocomplete(props) {\n     setInputValue(newInputValue);\n \n     if (onInputChange) {\n-      onInputChange(event, newInputValue);\n+      if (!(suppressInputChangeOnSelect && reason === 'select')) {\n+        onInputChange(event, newInputValue);\n+      }\n     }\n   });\n \n   React.useEffect(() => {\n-    resetInputValue(null, value);\n+    resetInputValue(null, value, 'reset');\n   }, [value, resetInputValue]);\n \n   const { current: isOpenControlled } = React.useRef(openProp != null);\n@@ -415,7 +418,7 @@ export default function useAutocomplete(props) {\n     }\n   };\n \n-  const selectNewValue = (event, newValue) => {\n+  const selectNewValue = (event, newValue, reason = 'select') => {\n     if (multiple) {\n       const item = newValue;\n       newValue = Array.isArray(value) ? [...value] : [];\n@@ -439,7 +442,7 @@ export default function useAutocomplete(props) {\n       handleClose(event);\n     }\n \n-    resetInputValue(event, newValue);\n+    resetInputValue(event, newValue, reason);\n \n     selectedIndexRef.current = -1;\n   };\n@@ -570,7 +573,7 @@ export default function useAutocomplete(props) {\n         if (highlightedIndexRef.current !== -1 && popupOpen) {\n           // We don't want to validate the form.\n           event.preventDefault();\n-          selectNewValue(event, filteredOptions[highlightedIndexRef.current]);\n+          selectNewValue(event, filteredOptions[highlightedIndexRef.current], 'select');\n \n           // Move the selection to the end.\n           if (autoComplete) {\n@@ -580,7 +583,7 @@ export default function useAutocomplete(props) {\n             );\n           }\n         } else if (freeSolo && inputValueFilter !== '') {\n-          selectNewValue(event, inputValue);\n+          selectNewValue(event, inputValue, 'freeSolo');\n         }\n         break;\n       case 'Escape':\n@@ -629,7 +632,7 @@ export default function useAutocomplete(props) {\n     if (autoSelect && selectedIndexRef.current !== -1) {\n       handleValue(event, filteredOptions[selectedIndexRef.current]);\n     } else if (!freeSolo) {\n-      resetInputValue(event, value);\n+      resetInputValue(event, value, 'reset');\n     }\n \n     handleClose(event);\n@@ -668,7 +671,7 @@ export default function useAutocomplete(props) {\n \n   const handleOptionClick = event => {\n     const index = Number(event.currentTarget.getAttribute('data-option-index'));\n-    selectNewValue(event, filteredOptions[index]);\n+    selectNewValue(event, filteredOptions[index], 'select');\n   };\n \n   const handleTagDelete = index => event => {\n@@ -930,6 +933,10 @@ useAutocomplete.propTypes = {\n    * If `true`, the highlight can move to the input.\n    */\n   includeInputInList: PropTypes.bool,\n+  /**\n+   * If `true`, do not call onInputChange when the input value changes due to selecting an option.\n+   */\n+  suppressInputChangeOnSelect: PropTypes.bool,\n   /**\n    * If `true`, `value` must be an array and the menu will support multiple selections.\n    */\n"}
{"instance_id": "mui__material-ui-19072", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "mui__material-ui-18824", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/pages/api/card.md b/docs/pages/api/card.md\nindex 4f6f56ce01..ec9ea46eeb 100644\n--- a/docs/pages/api/card.md\n+++ b/docs/pages/api/card.md\n@@ -27,6 +27,7 @@ You can learn more about the difference by [reading this guide](/guides/minimizi\n | <span class=\"prop-name\">children</span> | <span class=\"prop-type\">node</span> |  | The content of the component. |\n | <span class=\"prop-name\">classes</span> | <span class=\"prop-type\">object</span> |  | Override or extend the styles applied to the component. See [CSS API](#css) below for more details. |\n | <span class=\"prop-name\">raised</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, the card will use raised styling. |\n+| <span class=\"prop-name\">variant</span> | <span class=\"prop-type\">'elevation' &#124; 'outlined'</span> | <span class=\"prop-default\">'elevation'</span> | The variant to use. When `outlined`, a 1px border is applied and the `raised` prop is ignored. |\n \n The `ref` is forwarded to the root element.\n \n@@ -40,6 +41,7 @@ Any other props supplied will be provided to the root element ([Paper](/api/pape\n | Rule name | Global class | Description |\n |:-----|:-------------|:------------|\n | <span class=\"prop-name\">root</span> | <span class=\"prop-name\">.MuiCard-root</span> | Styles applied to the root element.\n+| <span class=\"prop-name\">outlined</span> | <span class=\"prop-name\">.MuiCard-outlined</span> | Styles applied to the root element if `variant=\"outlined\"`.\n \n You can override the style of the component thanks to one of these customization points:\n \ndiff --git a/docs/pages/api/paper.md b/docs/pages/api/paper.md\nindex 8d9d5aae7e..0658a4d718 100644\n--- a/docs/pages/api/paper.md\n+++ b/docs/pages/api/paper.md\n@@ -29,6 +29,7 @@ You can learn more about the difference by [reading this guide](/guides/minimizi\n | <span class=\"prop-name\">component</span> | <span class=\"prop-type\">elementType</span> | <span class=\"prop-default\">'div'</span> | The component used for the root node. Either a string to use a DOM element or a component. |\n | <span class=\"prop-name\">elevation</span> | <span class=\"prop-type\">number</span> | <span class=\"prop-default\">1</span> | Shadow depth, corresponds to `dp` in the spec. It accepts values between 0 and 24 inclusive. |\n | <span class=\"prop-name\">square</span> | <span class=\"prop-type\">bool</span> | <span class=\"prop-default\">false</span> | If `true`, rounded corners are disabled. |\n+| <span class=\"prop-name\">variant</span> | <span class=\"prop-type\">'elevation' &#124; 'outlined'</span> | <span class=\"prop-default\">'elevation'</span> | The variant to use. When `outlined`, the elevation prop is ignored and a 1px border is applied. |\n \n The `ref` is forwarded to the root element.\n \n@@ -43,6 +44,7 @@ Any other props supplied will be provided to the root element (native element).\n |:-----|:-------------|:------------|\n | <span class=\"prop-name\">root</span> | <span class=\"prop-name\">.MuiPaper-root</span> | Styles applied to the root element.\n | <span class=\"prop-name\">rounded</span> | <span class=\"prop-name\">.MuiPaper-rounded</span> | Styles applied to the root element if `square={false}`.\n+| <span class=\"prop-name\">outlined</span> | <span class=\"prop-name\">.MuiPaper-outlined</span> | Styles applied to the root element if `variant=\"outlined\"`.\n | <span class=\"prop-name\">elevation0</span> | <span class=\"prop-name\">.MuiPaper-elevation0</span> | \n | <span class=\"prop-name\">elevation1</span> | <span class=\"prop-name\">.MuiPaper-elevation1</span> | \n | <span class=\"prop-name\">elevation2</span> | <span class=\"prop-name\">.MuiPaper-elevation2</span> | \ndiff --git a/packages/material-ui/src/Card/Card.d.ts b/packages/material-ui/src/Card/Card.d.ts\nindex 0104856e1e..c8ae5a598f 100644\n--- a/packages/material-ui/src/Card/Card.d.ts\n+++ b/packages/material-ui/src/Card/Card.d.ts\n@@ -4,9 +4,10 @@ import { PaperProps } from '../Paper';\n \n export interface CardProps extends StandardProps<PaperProps, CardClassKey> {\n   raised?: boolean;\n+  variant?: 'elevation' | 'outlined';\n }\n \n-export type CardClassKey = 'root';\n+export type CardClassKey = 'root' | 'outlined';\n \n declare const Card: React.ComponentType<CardProps>;\n \ndiff --git a/packages/material-ui/src/Card/Card.js b/packages/material-ui/src/Card/Card.js\nindex dd15d21827..d898266d2b 100644\n--- a/packages/material-ui/src/Card/Card.js\n+++ b/packages/material-ui/src/Card/Card.js\n@@ -9,15 +9,22 @@ export const styles = {\n   root: {\n     overflow: 'hidden',\n   },\n+  /* Styles applied to the root element if `variant=\"outlined\"`. */\n+  outlined: {},\n };\n \n const Card = React.forwardRef(function Card(props, ref) {\n-  const { classes, className, raised = false, ...other } = props;\n+  const { classes, className, raised = false, variant = 'elevation', ...other } = props;\n+\n+  const elevation = raised ? 8 : 1;\n \n   return (\n     <Paper\n-      className={clsx(classes.root, className)}\n-      elevation={raised ? 8 : 1}\n+      className={clsx(classes.root, {\n+        [classes.outlined]: variant === 'outlined',\n+      }, className)}\n+      elevation={variant === 'elevation' ? elevation : undefined}\n+      variant={variant}\n       ref={ref}\n       {...other}\n     />\n@@ -42,6 +49,10 @@ Card.propTypes = {\n    * If `true`, the card will use raised styling.\n    */\n   raised: PropTypes.bool,\n+  /**\n+   * The variant to use.\n+   */\n+  variant: PropTypes.oneOf(['elevation', 'outlined']),\n };\n \n export default withStyles(styles, { name: 'MuiCard' })(Card);\ndiff --git a/packages/material-ui/src/Paper/Paper.d.ts b/packages/material-ui/src/Paper/Paper.d.ts\nindex 02de56d360..3d1a5fd31b 100644\n--- a/packages/material-ui/src/Paper/Paper.d.ts\n+++ b/packages/material-ui/src/Paper/Paper.d.ts\n@@ -6,11 +6,13 @@ export interface PaperProps\n   component?: React.ElementType<React.HTMLAttributes<HTMLElement>>;\n   elevation?: number;\n   square?: boolean;\n+  variant?: 'elevation' | 'outlined';\n }\n \n export type PaperClassKey =\n   | 'root'\n   | 'rounded'\n+  | 'outlined'\n   | 'elevation0'\n   | 'elevation1'\n   | 'elevation2'\ndiff --git a/packages/material-ui/src/Paper/Paper.js b/packages/material-ui/src/Paper/Paper.js\nindex 9b1a9ee36c..545b5b72b8 100644\n--- a/packages/material-ui/src/Paper/Paper.js\n+++ b/packages/material-ui/src/Paper/Paper.js\n@@ -22,6 +22,11 @@ export const styles = theme => {\n     rounded: {\n       borderRadius: theme.shape.borderRadius,\n     },\n+    /* Styles applied to the root element if `variant=\"outlined\"`. */\n+    outlined: {\n+      border: `1px solid ${theme.palette.divider}`,\n+      boxShadow: 'none',\n+    },\n     ...elevations,\n   };\n };\n@@ -33,11 +38,12 @@ const Paper = React.forwardRef(function Paper(props, ref) {\n     component: Component = 'div',\n     square = false,\n     elevation = 1,\n+    variant = 'elevation',\n     ...other\n   } = props;\n \n   if (process.env.NODE_ENV !== 'production') {\n-    if (classes[`elevation${elevation}`] === undefined) {\n+    if (variant === 'elevation' && classes[`elevation${elevation}`] === undefined) {\n       console.error(`Material-UI: this elevation \\`${elevation}\\` is not implemented.`);\n     }\n   }\n@@ -46,7 +52,7 @@ const Paper = React.forwardRef(function Paper(props, ref) {\n     <Component\n       className={clsx(\n         classes.root,\n-        classes[`elevation${elevation}`],\n+        variant === 'outlined' ? classes.outlined : classes[`elevation${elevation}`],\n         {\n           [classes.rounded]: !square,\n         },\n@@ -86,6 +92,10 @@ Paper.propTypes = {\n    * If `true`, rounded corners are disabled.\n    */\n   square: PropTypes.bool,\n+  /**\n+   * The variant to use.\n+   */\n+  variant: PropTypes.oneOf(['elevation', 'outlined']),\n };\n \n export default withStyles(styles, { name: 'MuiPaper' })(Paper);\n"}
{"instance_id": "mui__material-ui-19121", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\nindex 4037be9ee9..510457de14 100644\n--- a/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui-lab/src/useAutocomplete/useAutocomplete.js\n@@ -782,21 +782,28 @@ export default function useAutocomplete(props) {\n \n   let groupedOptions = filteredOptions;\n   if (groupBy) {\n-    groupedOptions = filteredOptions.reduce((acc, option, index) => {\n+    const indexByKey = {};\n+    const result = [];\n+    filteredOptions.forEach(option => {\n       const key = groupBy(option);\n-\n-      if (acc.length > 0 && acc[acc.length - 1].key === key) {\n-        acc[acc.length - 1].options.push(option);\n-      } else {\n-        acc.push({\n+      if (indexByKey[key] === undefined) {\n+        indexByKey[key] = result.length;\n+        result.push({\n           key,\n-          index,\n-          options: [option],\n+          index: 0,\n+          options: [],\n         });\n       }\n+      result[indexByKey[key]].options.push(option);\n+    });\n+\n+    let counter = 0;\n+    result.forEach(group => {\n+      group.index = counter;\n+      counter += group.options.length;\n+    });\n \n-      return acc;\n-    }, []);\n+    groupedOptions = result;\n   }\n \n   return {\n"}
{"instance_id": "mui__material-ui-19257", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/Autocomplete/Autocomplete.js b/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\nindex eebefc7301..1c639527d1 100644\n--- a/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\n+++ b/packages/material-ui-lab/src/Autocomplete/Autocomplete.js\n@@ -94,6 +94,38 @@ export const styles = theme => ({\n       },\n     },\n   },\n+  /* Styles applied to adjust padding when a single end adornment icon is present. */\n+  inputRootSingleEndAdornment: {\n+    paddingRight: 32,\n+    '&[class*=\"MuiOutlinedInput-root\"]': {\n+      paddingRight: 32,\n+    },\n+    '&[class*=\"MuiOutlinedInput-root\"][class*=\"MuiOutlinedInput-marginDense\"]': {\n+      paddingRight: 32,\n+    },\n+    '&[class*=\"MuiFilledInput-root\"]': {\n+      paddingRight: 32,\n+    },\n+    '&[class*=\"MuiFilledInput-root\"][class*=\"MuiFilledInput-marginDense\"]': {\n+      paddingRight: 32,\n+    },\n+  },\n+  /* Styles applied to adjust padding when no end adornment icons are present. */\n+  inputRootNoEndAdornment: {\n+    paddingRight: 0,\n+    '&[class*=\"MuiOutlinedInput-root\"]': {\n+      paddingRight: 9,\n+    },\n+    '&[class*=\"MuiOutlinedInput-root\"][class*=\"MuiOutlinedInput-marginDense\"]': {\n+      paddingRight: 6,\n+    },\n+    '&[class*=\"MuiFilledInput-root\"]': {\n+      paddingRight: 0,\n+    },\n+    '&[class*=\"MuiFilledInput-root\"][class*=\"MuiFilledInput-marginDense\"]': {\n+      paddingRight: 0,\n+    },\n+  },\n   /* Styles applied to the input element. */\n   input: {\n     flexGrow: 1,\n@@ -365,7 +397,20 @@ const Autocomplete = React.forwardRef(function Autocomplete(props, ref) {\n           InputLabelProps: getInputLabelProps(),\n           InputProps: {\n             ref: setAnchorEl,\n-            className: classes.inputRoot,\n+            className: clsx(\n+              classes.inputRoot,\n+              (() => {\n+                const hasClear = !disableClearable && !disabled;\n+                const hasPopup = ((!freeSolo || forcePopupIcon === true) && forcePopupIcon !== false);\n+                if (hasClear && hasPopup) {\n+                  return null;\n+                }\n+                if (hasClear || hasPopup) {\n+                  return classes.inputRootSingleEndAdornment;\n+                }\n+                return classes.inputRootNoEndAdornment;\n+              })(),\n+            ),\n             startAdornment,\n             endAdornment: (\n               <div className={classes.endAdornment}>\n"}
{"instance_id": "mui__material-ui-20232", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/TreeItem/TreeItem.js b/packages/material-ui-lab/src/TreeItem/TreeItem.js\nindex d6f8a835ee..363a5cd5b6 100644\n--- a/packages/material-ui-lab/src/TreeItem/TreeItem.js\n+++ b/packages/material-ui-lab/src/TreeItem/TreeItem.js\n@@ -123,6 +123,7 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n     isTabbable,\n     multiSelect,\n     selectionDisabled,\n+    treeHasFocus,\n     getParent,\n     mapFirstChar,\n     addNodeToNodeMap,\n@@ -360,10 +361,10 @@ const TreeItem = React.forwardRef(function TreeItem(props, ref) {\n   }, [mapFirstChar, nodeId, label]);\n \n   React.useEffect(() => {\n-    if (focused) {\n+    if (focused && treeHasFocus) {\n       nodeRef.current.focus();\n     }\n-  }, [focused]);\n+  }, [focused, treeHasFocus]);\n \n   let ariaSelected;\n   if (multiSelect) {\ndiff --git a/packages/material-ui-lab/src/TreeView/TreeView.js b/packages/material-ui-lab/src/TreeView/TreeView.js\nindex b60bd18019..e7272861ae 100644\n--- a/packages/material-ui-lab/src/TreeView/TreeView.js\n+++ b/packages/material-ui-lab/src/TreeView/TreeView.js\n@@ -74,6 +74,8 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n     name: 'TreeView',\n   });\n \n+  const [treeHasFocus, setTreeHasFocus] = React.useState(false);\n+\n   /*\n    * Status Helpers\n    */\n@@ -512,12 +514,21 @@ const TreeView = React.forwardRef(function TreeView(props, ref) {\n         mapFirstChar,\n         addNodeToNodeMap,\n         removeNodeFromNodeMap,\n+        treeHasFocus,\n       }}\n     >\n       <ul\n         role=\"tree\"\n         aria-multiselectable={multiSelect}\n         className={clsx(classes.root, className)}\n+        onFocus={() => setTreeHasFocus(true)}\n+        onBlur={(event) => {\n+          const currentTarget = event.currentTarget;\n+          const related = event.relatedTarget;\n+          if (!related || (currentTarget && !currentTarget.contains(related))) {\n+            setTreeHasFocus(false);\n+          }\n+        }}\n         ref={ref}\n         {...other}\n       >\n"}
{"instance_id": "mui__material-ui-25072", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Button/Button.js b/packages/material-ui/src/Button/Button.js\nindex 11a700c67b..3d4ac6d9ab 100644\n--- a/packages/material-ui/src/Button/Button.js\n+++ b/packages/material-ui/src/Button/Button.js\n@@ -34,7 +34,7 @@ const overridesResolver = (props, styles) => {\n };\n \n const useUtilityClasses = (styleProps) => {\n-  const { color, disableElevation, fullWidth, size, variant, classes } = styleProps;\n+  const { color, disableElevation, fullWidth, size, variant, classes, disabled } = styleProps;\n \n   const slots = {\n     root: [\n@@ -45,6 +45,7 @@ const useUtilityClasses = (styleProps) => {\n       `${variant}Size${capitalize(size)}`,\n       color === 'inherit' && 'colorInherit',\n       disableElevation && 'disableElevation',\n+      disabled && 'disabled',\n       fullWidth && 'fullWidth',\n     ],\n     label: ['label'],\n"}
{"instance_id": "mui__material-ui-25874", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/pages/api-docs/loading-button.json b/docs/pages/api-docs/loading-button.json\nindex 2f40fbf015..550b962593 100644\n--- a/docs/pages/api-docs/loading-button.json\n+++ b/docs/pages/api-docs/loading-button.json\n@@ -3,7 +3,8 @@\n     \"children\": { \"type\": { \"name\": \"node\" } },\n     \"classes\": { \"type\": { \"name\": \"object\" } },\n     \"disabled\": { \"type\": { \"name\": \"bool\" } },\n-    \"pending\": { \"type\": { \"name\": \"bool\" } },\n+    \"loading\": { \"type\": { \"name\": \"bool\" } },\n+    \"pending\": { \"type\": { \"name\": \"bool\" }, \"deprecated\": true },\n     \"pendingIndicator\": {\n       \"type\": { \"name\": \"node\" },\n       \"default\": \"<CircularProgress color=\\\"inherit\\\" size={16} />\"\ndiff --git a/packages/material-ui-lab/src/LoadingButton/LoadingButton.d.ts b/packages/material-ui-lab/src/LoadingButton/LoadingButton.d.ts\nindex 5edb30d84b..b3107e5677 100644\n--- a/packages/material-ui-lab/src/LoadingButton/LoadingButton.d.ts\n+++ b/packages/material-ui-lab/src/LoadingButton/LoadingButton.d.ts\n@@ -12,7 +12,7 @@ export type LoadingButtonTypeMap<\n     classes?: {\n       /** Styles applied to the root element. */\n       root?: string;\n-      /** Styles applied to the root element if `pending={true}`. */\n+      /** Styles applied to the root element if `loading={true}`. */\n       pending?: string;\n       /** Styles applied to the pendingIndicator element. */\n       pendingIndicator?: string;\n@@ -22,20 +22,24 @@ export type LoadingButtonTypeMap<\n       pendingIndicatorStart?: string;\n       /** Styles applied to the pendingIndicator element if `pendingPosition=\"end\"`. */\n       pendingIndicatorEnd?: string;\n-      /** Styles applied to the endIcon element if `pending={true}` and `pendingPosition=\"end\"`. */\n+      /** Styles applied to the endIcon element if `loading={true}` and `pendingPosition=\"end\"`. */\n       endIconPendingEnd?: string;\n-      /** Styles applied to the startIcon element if `pending={true}` and `pendingPosition=\"start\"`. */\n+      /** Styles applied to the startIcon element if `loading={true}` and `pendingPosition=\"start\"`. */\n       startIconPendingStart?: string;\n-      /** Styles applied to the label element if `pending={true}` and `pendingPosition=\"center\"`. */\n+      /** Styles applied to the label element if `loading={true}` and `pendingPosition=\"center\"`. */\n       labelPendingCenter?: string;\n     };\n     /**\n-     * If `true`, the pending indicator is shown.\n+     * If `true`, the loading indicator is shown.\n      * @default false\n      */\n+    loading?: boolean;\n+    /**\n+     * @deprecated Use `loading` instead.\n+     */\n     pending?: boolean;\n     /**\n-     * Element placed before the children if the button is in pending state.\n+     * Element placed before the children if the button is in loading state.\n      * @default <CircularProgress color=\"inherit\" size={16} />\n      */\n     pendingIndicator?: React.ReactNode;\ndiff --git a/packages/material-ui-lab/src/LoadingButton/LoadingButton.js b/packages/material-ui-lab/src/LoadingButton/LoadingButton.js\nindex dc35fd06de..060cfe236c 100644\n--- a/packages/material-ui-lab/src/LoadingButton/LoadingButton.js\n+++ b/packages/material-ui-lab/src/LoadingButton/LoadingButton.js\n@@ -53,31 +53,34 @@ const LoadingButton = React.forwardRef(function LoadingButton(props, ref) {\n     classes,\n     className,\n     disabled = false,\n-    pending = false,\n+    loading: loadingProp,\n+    pending: pendingProp = false,\n     pendingIndicator = PendingIndicator,\n     pendingPosition = 'center',\n     ...other\n   } = props;\n \n+  const loading = loadingProp !== undefined ? loadingProp : pendingProp;\n+\n   return (\n     <Button\n       className={clsx(\n         classes.root,\n         {\n-          [classes.pending]: pending,\n+          [classes.pending]: loading,\n         },\n         className,\n       )}\n-      disabled={disabled || pending}\n+      disabled={disabled || loading}\n       ref={ref}\n       classes={{\n-        startIcon: classes[`startIcon${pending ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n-        endIcon: classes[`endIcon${pending ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n-        label: classes[`label${pending ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n+        startIcon: classes[`startIcon${loading ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n+        endIcon: classes[`endIcon${loading ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n+        label: classes[`label${loading ? 'Pending' : ''}${capitalize(pendingPosition)}`],\n       }}\n       {...other}\n     >\n-      {pending && (\n+      {loading && (\n         <div\n           className={clsx(\n             classes.pendingIndicator,\n@@ -116,9 +119,13 @@ LoadingButton.propTypes /* remove-proptypes */ = {\n    */\n   disabled: PropTypes.bool,\n   /**\n-   * If `true`, the pending indicator is shown.\n+   * If `true`, the loading indicator is shown.\n    * @default false\n    */\n+  loading: PropTypes.bool,\n+  /**\n+   * @deprecated Use `loading` instead.\n+   */\n   pending: PropTypes.bool,\n   /**\n    * Element placed before the children if the button is in pending state.\n"}
{"instance_id": "mui__material-ui-26061", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/Tabs/Tabs.js b/packages/material-ui/src/Tabs/Tabs.js\nindex bfc1558613..02886a19f8 100644\n--- a/packages/material-ui/src/Tabs/Tabs.js\n+++ b/packages/material-ui/src/Tabs/Tabs.js\n@@ -597,6 +597,49 @@ const Tabs = React.forwardRef(function Tabs(inProps, ref) {\n       return;\n     }\n \n+    const list = tabListRef.current;\n+    if (!list) {\n+      return;\n+    }\n+\n+    const isDisabled = (elem) =>\n+      elem.disabled === true || elem.getAttribute('aria-disabled') === 'true';\n+\n+    const nextItem = (listEl, item) => {\n+      const next = item ? item.nextElementSibling : listEl.firstChild;\n+      return next || listEl.firstChild;\n+    };\n+\n+    const previousItem = (listEl, item) => {\n+      const prev = item ? item.previousElementSibling : listEl.lastChild;\n+      return prev || listEl.lastChild;\n+    };\n+\n+    const moveFocus = (current, traversal) => {\n+      let wrappedOnce = false;\n+      let nextFocus = traversal(list, current);\n+\n+      while (nextFocus) {\n+        if (nextFocus === list.firstChild) {\n+          if (wrappedOnce) {\n+            return null;\n+          }\n+          wrappedOnce = true;\n+        }\n+\n+        const hasRoleTab = nextFocus.getAttribute && nextFocus.getAttribute('role') === 'tab';\n+        const disabled = isDisabled(nextFocus);\n+\n+        if (!hasRoleTab || disabled) {\n+          nextFocus = traversal(list, nextFocus);\n+        } else {\n+          return nextFocus;\n+        }\n+      }\n+\n+      return null;\n+    };\n+\n     let newFocusTarget = null;\n     let previousItemKey = orientation === 'horizontal' ? 'ArrowLeft' : 'ArrowUp';\n     let nextItemKey = orientation === 'horizontal' ? 'ArrowRight' : 'ArrowDown';\n@@ -608,16 +651,16 @@ const Tabs = React.forwardRef(function Tabs(inProps, ref) {\n \n     switch (event.key) {\n       case previousItemKey:\n-        newFocusTarget = target.previousElementSibling || tabListRef.current.lastChild;\n+        newFocusTarget = moveFocus(target, previousItem);\n         break;\n       case nextItemKey:\n-        newFocusTarget = target.nextElementSibling || tabListRef.current.firstChild;\n+        newFocusTarget = moveFocus(target, nextItem);\n         break;\n       case 'Home':\n-        newFocusTarget = tabListRef.current.firstChild;\n+        newFocusTarget = moveFocus(null, nextItem);\n         break;\n       case 'End':\n-        newFocusTarget = tabListRef.current.lastChild;\n+        newFocusTarget = moveFocus(null, previousItem);\n         break;\n       default:\n         break;\n"}
{"instance_id": "mui__material-ui-26098", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/TablePagination/TablePagination.js b/packages/material-ui/src/TablePagination/TablePagination.js\nindex 92e6f047a1..83c7f58287 100644\n--- a/packages/material-ui/src/TablePagination/TablePagination.js\n+++ b/packages/material-ui/src/TablePagination/TablePagination.js\n@@ -119,7 +119,7 @@ const TablePaginationMenuItem = experimentalStyled(\n     slot: 'MenuItem',\n     overridesResolver: (props, styles) => styles.menuItem,\n   },\n-)();\n+)({});\n \n const TablePaginationDisplayedRows = experimentalStyled(\n   'p',\ndiff --git a/packages/material-ui/src/styles/experimentalStyled.js b/packages/material-ui/src/styles/experimentalStyled.js\nindex a240d421b8..3b5b7760d6 100644\n--- a/packages/material-ui/src/styles/experimentalStyled.js\n+++ b/packages/material-ui/src/styles/experimentalStyled.js\n@@ -154,6 +154,12 @@ const experimentalStyled = (tag, options, muiOptions = {}) => {\n       // If the type is function, we need to define the default theme\n       transformedStyleArg = ({ theme: themeInput, ...other }) =>\n         styleArg({ theme: isEmpty(themeInput) ? defaultTheme : themeInput, ...other });\n+    } else if (styleArg === undefined && numOfCustomFnsApplied > 0) {\n+      // If no styles are provided, ensure a valid empty template is passed\n+      // so that styled engines like styled-components can handle interpolations.\n+      const placeholders = new Array(numOfCustomFnsApplied + 1).fill('');\n+      transformedStyleArg = placeholders;\n+      transformedStyleArg.raw = placeholders;\n     }\n \n     const Component = defaultStyledResolver(transformedStyleArg, ...expressionsWithDefaultTheme);\n"}
{"instance_id": "mui__material-ui-26170", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/TabList/TabList.js b/packages/material-ui-lab/src/TabList/TabList.js\nindex 95a1783db7..498c8345af 100644\n--- a/packages/material-ui-lab/src/TabList/TabList.js\n+++ b/packages/material-ui-lab/src/TabList/TabList.js\n@@ -1,4 +1,5 @@\n import * as React from 'react';\n+import { isFragment } from 'react-is';\n import PropTypes from 'prop-types';\n import Tabs from '@material-ui/core/Tabs';\n import { useTabContext, getTabId, getPanelId } from '../TabContext';\n@@ -10,6 +11,21 @@ const TabList = React.forwardRef(function TabList(props, ref) {\n     throw new TypeError('No TabContext provided');\n   }\n   const children = React.Children.map(childrenProp, (child) => {\n+    if (!React.isValidElement(child)) {\n+      return null;\n+    }\n+\n+    if (process.env.NODE_ENV !== 'production') {\n+      if (isFragment(child)) {\n+        console.error(\n+          [\n+            \"Material-UI: The TabList component doesn't accept a Fragment as a child.\",\n+            'Consider providing an array instead.',\n+          ].join('\\n'),\n+        );\n+      }\n+    }\n+\n     return React.cloneElement(child, {\n       // SOMEDAY: `Tabs` will set those themselves\n       'aria-controls': getPanelId(context, child.props.value),\n"}
{"instance_id": "trinodb__trino-2575", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-main/src/main/java/io/prestosql/connector/informationschema/InformationSchemaMetadata.java b/presto-main/src/main/java/io/prestosql/connector/informationschema/InformationSchemaMetadata.java\nindex 1981e3092f9..e4490f2be8f 100644\n--- a/presto-main/src/main/java/io/prestosql/connector/informationschema/InformationSchemaMetadata.java\n+++ b/presto-main/src/main/java/io/prestosql/connector/informationschema/InformationSchemaMetadata.java\n@@ -279,6 +279,7 @@ public class InformationSchemaMetadata\n                             .orElseGet(() -> listSchemaNames(session)))\n                     .flatMap(prefix -> tables.get().stream()\n                             .filter(this::isLowerCase)\n+                            .filter(table -> !table.isEmpty())\n                             .map(table -> new QualifiedObjectName(catalogName, prefix.getSchemaName().get(), table)))\n                     .filter(objectName -> !isColumnsEnumeratingTable(informationSchemaTable) || metadata.getTableHandle(session, objectName).isPresent() || metadata.getView(session, objectName).isPresent())\n                     .filter(objectName -> !predicate.isPresent() || predicate.get().test(asFixedValues(objectName)))\n"}
{"instance_id": "microsoft__vscode-132628", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/editor/contrib/inlineCompletions/inlineCompletionToGhostText.ts b/src/vs/editor/contrib/inlineCompletions/inlineCompletionToGhostText.ts\nindex 10ead6cf9bd..cd13bea03c5 100644\n--- a/src/vs/editor/contrib/inlineCompletions/inlineCompletionToGhostText.ts\n+++ b/src/vs/editor/contrib/inlineCompletions/inlineCompletionToGhostText.ts\n@@ -38,6 +38,10 @@ export function inlineCompletionToGhostText(\n \n \tconst lineNumber = inlineCompletion.range.startLineNumber;\n \n+\tif (cursorPosition && cursorPosition.lineNumber !== lineNumber) {\n+\t\treturn undefined;\n+\t}\n+\n \tconst parts = new Array<GhostTextPart>();\n \n \tif (mode === 'prefix') {\ndiff --git a/src/vs/editor/contrib/inlineCompletions/inlineCompletionsModel.ts b/src/vs/editor/contrib/inlineCompletions/inlineCompletionsModel.ts\nindex cdccdbda1be..27d80399a5a 100644\n--- a/src/vs/editor/contrib/inlineCompletions/inlineCompletionsModel.ts\n+++ b/src/vs/editor/contrib/inlineCompletions/inlineCompletionsModel.ts\n@@ -147,6 +147,7 @@ export class InlineCompletionsModel extends Disposable implements GhostTextWidge\n \n \tpublic hide(): void {\n \t\tthis.completionSession.clear();\n+\t\tthis.cache.clear();\n \t\tthis.onDidChangeEmitter.fire();\n \t}\n \n@@ -299,6 +300,9 @@ export class InlineCompletionsSession extends BaseGhostTextWidgetModel {\n \t//#endregion\n \n \tpublic get ghostText(): GhostText | undefined {\n+\t\tif (!this.isValid) {\n+\t\t\treturn undefined;\n+\t\t}\n \t\tconst currentCompletion = this.currentCompletion;\n \t\tconst mode = this.editor.getOptions().get(EditorOption.inlineSuggest).mode;\n \t\treturn currentCompletion ? inlineCompletionToGhostText(currentCompletion, this.editor.getModel(), mode, this.editor.getPosition()) : undefined;\n"}
{"instance_id": "microsoft__vscode-173585", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/vs/base/browser/keyboardEvent.ts b/src/vs/base/browser/keyboardEvent.ts\nindex 75943736534..19ee502156b 100644\n--- a/src/vs/base/browser/keyboardEvent.ts\n+++ b/src/vs/base/browser/keyboardEvent.ts\n@@ -11,8 +11,8 @@ import * as platform from 'vs/base/common/platform';\n \n \n function extractKeyCode(e: KeyboardEvent): KeyCode {\n-\tif (e.charCode) {\n-\t\t// \"keypress\" events mostly\n+\tif (e.charCode && !e.ctrlKey && !e.altKey && !e.metaKey) {\n+\t\t// \"keypress\" events mostly (only when no modifiers are pressed)\n \t\tconst char = String.fromCharCode(e.charCode).toUpperCase();\n \t\treturn KeyCodeUtils.fromString(char);\n \t}\ndiff --git a/src/vs/base/common/keybindingParser.ts b/src/vs/base/common/keybindingParser.ts\nindex 3c36b8103f9..cf8f128a3eb 100644\n--- a/src/vs/base/common/keybindingParser.ts\n+++ b/src/vs/base/common/keybindingParser.ts\n@@ -78,7 +78,7 @@ export class KeybindingParser {\n \t\tconst scanCodeMatch = mods.key.match(/^\\[([^\\]]+)\\]$/);\n \t\tif (scanCodeMatch) {\n \t\t\tconst strScanCode = scanCodeMatch[1];\n-\t\t\tconst scanCode = ScanCodeUtils.lowerCaseToEnum(strScanCode);\n+\t\t\tconst scanCode = ScanCodeUtils.lowerCaseToEnum(strScanCode.toLowerCase());\n \t\t\treturn [new ScanCodeChord(mods.ctrl, mods.shift, mods.alt, mods.meta, scanCode), mods.remains];\n \t\t}\n \t\tconst keyCode = KeyCodeUtils.fromUserSettings(mods.key);\n"}
{"instance_id": "mui__material-ui-19278", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-lab/src/Skeleton/Skeleton.js b/packages/material-ui-lab/src/Skeleton/Skeleton.js\nindex c4696edc76..d525af0837 100644\n--- a/packages/material-ui-lab/src/Skeleton/Skeleton.js\n+++ b/packages/material-ui-lab/src/Skeleton/Skeleton.js\n@@ -15,6 +15,7 @@ export const styles = theme => ({\n     marginTop: 0,\n     marginBottom: 0,\n     height: 'auto',\n+    display: 'inline-block',\n     transformOrigin: '0 60%',\n     transform: 'scale(1, 0.60)',\n     borderRadius: theme.shape.borderRadius,\n@@ -74,13 +75,15 @@ const Skeleton = React.forwardRef(function Skeleton(props, ref) {\n     animation = 'pulse',\n     classes,\n     className,\n-    component: Component = 'div',\n+    component,\n     height,\n     variant = 'text',\n     width,\n     ...other\n   } = props;\n \n+  const Component = component || (variant === 'text' ? 'span' : 'div');\n+\n   return (\n     <Component\n       ref={ref}\n"}
{"instance_id": "mui__material-ui-26623", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/pages/api-docs/slide.json b/docs/pages/api-docs/slide.json\nindex c700c27df1..71c5866837 100644\n--- a/docs/pages/api-docs/slide.json\n+++ b/docs/pages/api-docs/slide.json\n@@ -9,6 +9,12 @@\n       },\n       \"default\": \"'down'\"\n     },\n+    \"container\": {\n+      \"type\": {\n+        \"name\": \"union\",\n+        \"description\": \"HTMLElement<br>&#124;&nbsp;() => HTMLElement\"\n+      }\n+    },\n     \"easing\": {\n       \"type\": {\n         \"name\": \"union\",\ndiff --git a/packages/material-ui/src/Slide/Slide.d.ts b/packages/material-ui/src/Slide/Slide.d.ts\nindex f9fcdfd2f4..760dc227b1 100644\n--- a/packages/material-ui/src/Slide/Slide.d.ts\n+++ b/packages/material-ui/src/Slide/Slide.d.ts\n@@ -17,6 +17,10 @@ export interface SlideProps extends TransitionProps {\n    * @default 'down'\n    */\n   direction?: 'left' | 'right' | 'up' | 'down';\n+  /**\n+   * The container element to use as the boundary for the transition. If not provided, the window is used.\n+   */\n+  container?: Element | (() => Element);\n   /**\n    * The transition timing function.\n    * You may specify a single easing or a object containing enter and exit values.\ndiff --git a/packages/material-ui/src/Slide/Slide.js b/packages/material-ui/src/Slide/Slide.js\nindex f5c3f266f1..5d1a3a535b 100644\n--- a/packages/material-ui/src/Slide/Slide.js\n+++ b/packages/material-ui/src/Slide/Slide.js\n@@ -1,7 +1,7 @@\n import * as React from 'react';\n import PropTypes from 'prop-types';\n import { Transition } from 'react-transition-group';\n-import { elementAcceptingRef } from '@material-ui/utils';\n+import { elementAcceptingRef, HTMLElementType } from '@material-ui/utils';\n import debounce from '../utils/debounce';\n import useForkRef from '../utils/useForkRef';\n import useTheme from '../styles/useTheme';\n@@ -11,7 +11,7 @@ import { ownerWindow } from '../utils';\n \n // Translate the node so it can't be seen on the screen.\n // Later, we're going to translate the node back to its original location with `none`.\n-function getTranslateValue(direction, node) {\n+function getTranslateValue(direction, node, container) {\n   const rect = node.getBoundingClientRect();\n   const containerWindow = ownerWindow(node);\n   let transform;\n@@ -34,6 +34,32 @@ function getTranslateValue(direction, node) {\n     offsetY = parseInt(transformValues[5], 10);\n   }\n \n+  let resolvedContainer = container;\n+  if (typeof resolvedContainer === 'function') {\n+    resolvedContainer = resolvedContainer();\n+  }\n+  const containerElement =\n+    resolvedContainer && resolvedContainer.nodeType === 1 ? resolvedContainer : null;\n+\n+  if (containerElement) {\n+    const containerRect = containerElement.getBoundingClientRect();\n+\n+    if (direction === 'left') {\n+      return `translateX(${containerRect.right}px) translateX(${offsetX - rect.left}px)`;\n+    }\n+\n+    if (direction === 'right') {\n+      return `translateX(-${rect.left + rect.width - offsetX - containerRect.left}px)`;\n+    }\n+\n+    if (direction === 'up') {\n+      return `translateY(${containerRect.bottom}px) translateY(${offsetY - rect.top}px)`;\n+    }\n+\n+    // direction === 'down'\n+    return `translateY(-${rect.top + rect.height - offsetY - containerRect.top}px)`;\n+  }\n+\n   if (direction === 'left') {\n     return `translateX(${containerWindow.innerWidth}px) translateX(${offsetX - rect.left}px)`;\n   }\n@@ -50,8 +76,8 @@ function getTranslateValue(direction, node) {\n   return `translateY(-${rect.top + rect.height - offsetY}px)`;\n }\n \n-export function setTranslateValue(direction, node) {\n-  const transform = getTranslateValue(direction, node);\n+export function setTranslateValue(direction, node, container) {\n+  const transform = getTranslateValue(direction, node, container);\n \n   if (transform) {\n     node.style.webkitTransform = transform;\n@@ -90,6 +116,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n     timeout = defaultTimeout,\n     // eslint-disable-next-line react/prop-types\n     TransitionComponent = Transition,\n+    container,\n     ...other\n   } = props;\n \n@@ -110,7 +137,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n   };\n \n   const handleEnter = normalizedTransitionCallback((node, isAppearing) => {\n-    setTranslateValue(direction, node);\n+    setTranslateValue(direction, node, container);\n     reflow(node);\n \n     if (onEnter) {\n@@ -155,7 +182,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n     node.style.webkitTransition = theme.transitions.create('-webkit-transform', transitionProps);\n     node.style.transition = theme.transitions.create('transform', transitionProps);\n \n-    setTranslateValue(direction, node);\n+    setTranslateValue(direction, node, container);\n \n     if (onExit) {\n       onExit(node);\n@@ -174,9 +201,9 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n \n   const updatePosition = React.useCallback(() => {\n     if (childrenRef.current) {\n-      setTranslateValue(direction, childrenRef.current);\n+      setTranslateValue(direction, childrenRef.current, container);\n     }\n-  }, [direction]);\n+  }, [direction, container]);\n \n   React.useEffect(() => {\n     // Skip configuration where the position is screen size invariant.\n@@ -186,7 +213,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n \n     const handleResize = debounce(() => {\n       if (childrenRef.current) {\n-        setTranslateValue(direction, childrenRef.current);\n+        setTranslateValue(direction, childrenRef.current, container);\n       }\n     });\n \n@@ -196,7 +223,7 @@ const Slide = React.forwardRef(function Slide(props, ref) {\n       handleResize.clear();\n       containerWindow.removeEventListener('resize', handleResize);\n     };\n-  }, [direction, inProp]);\n+  }, [direction, inProp, container]);\n \n   React.useEffect(() => {\n     if (!inProp) {\n@@ -274,6 +301,10 @@ Slide.propTypes /* remove-proptypes */ = {\n    * If `true`, the component will transition in.\n    */\n   in: PropTypes.bool,\n+  /**\n+   * The container element to use as the boundary for the transition. If not provided, the window is used.\n+   */\n+  container: PropTypes.oneOfType([HTMLElementType, PropTypes.func]),\n   /**\n    * @ignore\n    */\n"}
{"instance_id": "mui__material-ui-26746", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui-system/src/createTheme/createBreakpoints.js b/packages/material-ui-system/src/createTheme/createBreakpoints.js\nindex 32c3f6e1f1..6c47c46ab8 100644\n--- a/packages/material-ui-system/src/createTheme/createBreakpoints.js\n+++ b/packages/material-ui-system/src/createTheme/createBreakpoints.js\n@@ -10,8 +10,8 @@ export default function createBreakpoints(breakpoints) {\n     values = {\n       xs: 0,\n       sm: 600,\n-      md: 960,\n-      lg: 1280,\n+      md: 1024,\n+      lg: 1440,\n       xl: 1920,\n     },\n     unit = 'px',\n"}
{"instance_id": "mui__material-ui-28186", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-material/src/ButtonBase/ButtonBase.js b/packages/mui-material/src/ButtonBase/ButtonBase.js\nindex f36a1b97c6..2b35698d12 100644\n--- a/packages/mui-material/src/ButtonBase/ButtonBase.js\n+++ b/packages/mui-material/src/ButtonBase/ButtonBase.js\n@@ -140,6 +140,19 @@ const ButtonBase = React.forwardRef(function ButtonBase(inProps, ref) {\n     rippleRef,\n   });\n \n+  React.useEffect(() => {\n+    if (!enableTouchRipple || !rippleRef.current) {\n+      return;\n+    }\n+    if (focusVisible) {\n+      if (focusRipple) {\n+        rippleRef.current.pulsate();\n+      }\n+    } else {\n+      rippleRef.current.stop({ type: 'blur' });\n+    }\n+  }, [enableTouchRipple, focusVisible, focusRipple]);\n+\n   if (process.env.NODE_ENV !== 'production') {\n     // eslint-disable-next-line react-hooks/rules-of-hooks\n     React.useEffect(() => {\n@@ -173,7 +186,7 @@ const ButtonBase = React.forwardRef(function ButtonBase(inProps, ref) {\n       as={ComponentProp}\n       className={clsx(classes.root, className)}\n       ownerState={ownerState}\n-      {...getRootProps(getRippleHandlers(props))}\n+      {...getRippleHandlers(getRootProps(props))}\n       {...other}\n     >\n       {children}\ndiff --git a/packages/mui-material/src/ButtonBase/TouchRipple.js b/packages/mui-material/src/ButtonBase/TouchRipple.js\nindex 9c7d61731c..4812297774 100644\n--- a/packages/mui-material/src/ButtonBase/TouchRipple.js\n+++ b/packages/mui-material/src/ButtonBase/TouchRipple.js\n@@ -284,6 +284,10 @@ const TouchRipple = React.forwardRef(function TouchRipple(inProps, ref) {\n     startTimerCommit.current = null;\n \n     setRipples((oldRipples) => {\n+      if (event && event.type === 'blur') {\n+        // Clear all ripples on blur to ensure focus ripple is removed\n+        return [];\n+      }\n       if (oldRipples.length > 0) {\n         return oldRipples.slice(1);\n       }\n"}
{"instance_id": "mui__material-ui-27312", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/useAutocomplete/useAutocomplete.js b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\nindex 31f88be71e..6049998016 100644\n--- a/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n+++ b/packages/material-ui/src/useAutocomplete/useAutocomplete.js\n@@ -75,6 +75,7 @@ export default function useAutocomplete(props) {\n     disableCloseOnSelect = false,\n     disabledItemsFocusable = false,\n     disableListWrap = false,\n+    disabled = false,\n     filterOptions = defaultFilterOptions,\n     filterSelectedOptions = false,\n     freeSolo = false,\n@@ -182,7 +183,13 @@ export default function useAutocomplete(props) {\n   const inputValueIsSelectedValue =\n     !multiple && value != null && inputValue === getOptionLabel(value);\n \n-  const popupOpen = open;\n+  React.useEffect(() => {\n+    if (disabled && open) {\n+      handleClose(null, 'blur');\n+    }\n+  }, [disabled, open]);\n+\n+  const popupOpen = open && !disabled;\n \n   const filteredOptions = popupOpen\n     ? filterOptions(\n"}
{"instance_id": "mui__material-ui-28813", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-system/src/spacing.js b/packages/mui-system/src/spacing.js\nindex 2c8ccba9f2..455c50bea5 100644\n--- a/packages/mui-system/src/spacing.js\n+++ b/packages/mui-system/src/spacing.js\n@@ -59,6 +59,12 @@ const marginKeys = [\n   'marginLeft',\n   'marginX',\n   'marginY',\n+  'marginInline',\n+  'marginInlineStart',\n+  'marginInlineEnd',\n+  'marginBlock',\n+  'marginBlockStart',\n+  'marginBlockEnd',\n ];\n \n const paddingKeys = [\n@@ -76,6 +82,12 @@ const paddingKeys = [\n   'paddingLeft',\n   'paddingX',\n   'paddingY',\n+  'paddingInline',\n+  'paddingInlineStart',\n+  'paddingInlineEnd',\n+  'paddingBlock',\n+  'paddingBlockStart',\n+  'paddingBlockEnd',\n ];\n \n const spacingKeys = [...marginKeys, ...paddingKeys];\n"}
{"instance_id": "mui__material-ui-28190", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-core/src/AutocompleteUnstyled/useAutocomplete.js b/packages/mui-core/src/AutocompleteUnstyled/useAutocomplete.js\nindex 1d34b6b507..a021f1df9d 100644\n--- a/packages/mui-core/src/AutocompleteUnstyled/useAutocomplete.js\n+++ b/packages/mui-core/src/AutocompleteUnstyled/useAutocomplete.js\n@@ -156,6 +156,10 @@ export default function useAutocomplete(props) {\n       if (multiple) {\n         newInputValue = '';\n       } else if (newValue == null) {\n+        if (freeSolo && !clearOnBlur) {\n+          // In freeSolo mode without clearOnBlur, keep the current input; no state change\n+          return;\n+        }\n         newInputValue = '';\n       } else {\n         const optionLabel = getOptionLabel(newValue);\n@@ -172,7 +176,7 @@ export default function useAutocomplete(props) {\n         onInputChange(event, newInputValue, 'reset');\n       }\n     },\n-    [getOptionLabel, inputValue, multiple, onInputChange, setInputValueState],\n+    [clearOnBlur, freeSolo, getOptionLabel, inputValue, multiple, onInputChange, setInputValueState],\n   );\n \n   const prevValue = React.useRef();\n@@ -848,11 +852,13 @@ export default function useAutocomplete(props) {\n       selectNewValue(event, filteredOptions[highlightedIndexRef.current], 'blur');\n     } else if (autoSelect && freeSolo && inputValue !== '') {\n       selectNewValue(event, inputValue, 'blur', 'freeSolo');\n-    } else if (clearOnBlur) {\n-      resetInputValue(event, value);\n     }\n \n     handleClose(event, 'blur');\n+\n+    if (clearOnBlur) {\n+      resetInputValue(event, value);\n+    }\n   };\n \n   const handleInputChange = (event) => {\n@@ -872,7 +878,9 @@ export default function useAutocomplete(props) {\n         handleValue(event, null, 'clear');\n       }\n     } else {\n-      handleOpen(event);\n+      if (focused) {\n+        handleOpen(event);\n+      }\n     }\n   };\n \n"}
{"instance_id": "mui__material-ui-42412", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-material/src/styles/responsiveFontSizes.js b/packages/mui-material/src/styles/responsiveFontSizes.js\nindex fe0a5a6eda..794630656a 100644\n--- a/packages/mui-material/src/styles/responsiveFontSizes.js\n+++ b/packages/mui-material/src/styles/responsiveFontSizes.js\n@@ -34,6 +34,9 @@ export default function responsiveFontSizes(themeInput, options = {}) {\n \n   variants.forEach((variant) => {\n     const style = typography[variant];\n+    if (style == null) {\n+      return;\n+    }\n     const remFontSize = parseFloat(convert(style.fontSize, 'rem'));\n \n     if (remFontSize <= 1) {\n"}
{"instance_id": "huggingface__transformers-23126", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/hf_argparser.py b/src/transformers/hf_argparser.py\nindex b1fa67f458..d99461ecec 100644\n--- a/src/transformers/hf_argparser.py\n+++ b/src/transformers/hf_argparser.py\n@@ -32,6 +32,13 @@ except ImportError:\n     # For Python 3.7\n     from typing_extensions import Literal\n \n+try:\n+    # For Python >=3.10 where PEP 604 'X | Y' introduces types.UnionType\n+    from types import UnionType\n+except ImportError:\n+    # For Python versions where UnionType is not available\n+    UnionType = None\n+\n \n DataClass = NewType(\"DataClass\", Any)\n DataClassType = NewType(\"DataClassType\", Any)\n@@ -159,7 +166,7 @@ class HfArgumentParser(ArgumentParser):\n             aliases = [aliases]\n \n         origin_type = getattr(field.type, \"__origin__\", field.type)\n-        if origin_type is Union:\n+        if origin_type is Union or (UnionType is not None and type(origin_type) is UnionType):\n             if str not in field.type.__args__ and (\n                 len(field.type.__args__) != 2 or type(None) not in field.type.__args__\n             ):\n"}
{"instance_id": "huggingface__transformers-23223", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/feature_extraction_utils.py b/src/transformers/feature_extraction_utils.py\nindex 7823c4cf9e..c2b9dab7af 100644\n--- a/src/transformers/feature_extraction_utils.py\n+++ b/src/transformers/feature_extraction_utils.py\n@@ -143,8 +143,20 @@ class BatchFeature(UserDict):\n             import torch  # noqa\n \n             def as_tensor(value):\n-                if isinstance(value, (list, tuple)) and len(value) > 0 and isinstance(value[0], np.ndarray):\n-                    value = np.array(value)\n+                if isinstance(value, (list, tuple)) and len(value) > 0:\n+                    # If list/tuple of numpy arrays, stack via numpy first for efficiency\n+                    if isinstance(value[0], np.ndarray):\n+                        value = np.array(value)\n+                    # If list/tuple of torch tensors, stack to avoid adding an extra leading dimension\n+                    elif torch.is_tensor(value[0]):\n+                        # If single element that is already a batched tensor, return it directly to avoid spurious dim\n+                        if len(value) == 1 and value[0].ndim > 1:\n+                            return value[0]\n+                        try:\n+                            return torch.stack(list(value))\n+                        except Exception:\n+                            # Fallback to default conversion\n+                            return torch.tensor(value)\n                 return torch.tensor(value)\n \n             is_tensor = torch.is_tensor\ndiff --git a/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py b/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\nindex 9550b7c2a9..1b25793dd8 100644\n--- a/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\n+++ b/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\n@@ -22,7 +22,7 @@ import numpy as np\n \n from ...feature_extraction_sequence_utils import SequenceFeatureExtractor\n from ...feature_extraction_utils import BatchFeature\n-from ...utils import PaddingStrategy, TensorType, logging\n+from ...utils import PaddingStrategy, TensorType, logging, is_torch_available\n \n \n logger = logging.get_logger(__name__)\n@@ -101,7 +101,7 @@ class Wav2Vec2FeatureExtractor(SequenceFeatureExtractor):\n \n     def __call__(\n         self,\n-        raw_speech: Union[np.ndarray, List[float], List[np.ndarray], List[List[float]]],\n+        raw_speech: Union[np.ndarray, List[float], List[np.ndarray], List[List[float]], \"torch.Tensor\"],\n         padding: Union[bool, str, PaddingStrategy] = False,\n         max_length: Optional[int] = None,\n         truncation: bool = False,\n@@ -115,9 +115,10 @@ class Wav2Vec2FeatureExtractor(SequenceFeatureExtractor):\n         Main method to featurize and prepare for the model one or several sequence(s).\n \n         Args:\n-            raw_speech (`np.ndarray`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`):\n-                The sequence or batch of sequences to be padded. Each sequence can be a numpy array, a list of float\n-                values, a list of numpy arrays or a list of list of float values.\n+            raw_speech (`np.ndarray`, `torch.Tensor`, `List[float]`, `List[np.ndarray]`, `List[List[float]]`, `List[torch.Tensor]`):\n+                The sequence or batch of sequences to be padded. Each sequence can be a 1D numpy array or torch tensor,\n+                a list of float values, or a list of numpy arrays / torch tensors. Batched inputs can be provided as a\n+                2D numpy array or torch tensor with shape `(batch, length)` or as a list of sequences.\n             padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `False`):\n                 Select a strategy to pad the returned sequences (according to the model's padding side and padding\n                 index) among:\n@@ -181,13 +182,40 @@ class Wav2Vec2FeatureExtractor(SequenceFeatureExtractor):\n                 \"Failing to do so can result in silent errors that might be hard to debug.\"\n             )\n \n-        is_batched = bool(\n-            isinstance(raw_speech, (list, tuple))\n-            and (isinstance(raw_speech[0], np.ndarray) or isinstance(raw_speech[0], (tuple, list)))\n-        )\n-\n-        # always return batch\n-        if not is_batched:\n+        # Detect if input is batched and normalize inputs to a list of per-example arrays/tensors\n+        if is_torch_available():\n+            import torch  # noqa\n+        else:\n+            torch = None\n+\n+        if isinstance(raw_speech, (list, tuple)):\n+            has_elems = len(raw_speech) > 0\n+            first = raw_speech[0] if has_elems else None\n+            is_batched = bool(\n+                has_elems\n+                and (\n+                    isinstance(first, np.ndarray)\n+                    or isinstance(first, (tuple, list))\n+                    or (torch is not None and torch.is_tensor(first))\n+                )\n+            )\n+            # Convert elements to numpy if they are torch tensors\n+            if torch is not None and has_elems and torch.is_tensor(first):\n+                raw_speech = [t.detach().cpu().numpy() for t in raw_speech]\n+        elif torch is not None and torch.is_tensor(raw_speech):\n+            is_batched = raw_speech.ndim > 1\n+            if is_batched:\n+                raw_speech = [t.detach().cpu().numpy() for t in raw_speech]\n+            else:\n+                raw_speech = [raw_speech.detach().cpu().numpy()]\n+        elif isinstance(raw_speech, np.ndarray):\n+            is_batched = raw_speech.ndim > 1\n+            if is_batched:\n+                raw_speech = [np.asarray(x) for x in raw_speech]\n+            else:\n+                raw_speech = [np.asarray(raw_speech)]\n+        else:\n+            is_batched = False\n             raw_speech = [raw_speech]\n \n         # convert into correct format for padding\n"}
{"instance_id": "huggingface__transformers-23796", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/whisper/tokenization_whisper_fast.py b/src/transformers/models/whisper/tokenization_whisper_fast.py\nindex be4ad842a7..a31fe00056 100644\n--- a/src/transformers/models/whisper/tokenization_whisper_fast.py\n+++ b/src/transformers/models/whisper/tokenization_whisper_fast.py\n@@ -494,7 +494,7 @@ class WhisperTokenizerFast(PreTrainedTokenizerFast):\n     # Copied from transformers.models.whisper.tokenization_whisper.WhisperTokenizer.get_prompt_ids\n     def get_prompt_ids(self, text: str, return_tensors=\"np\"):\n         \"\"\"Converts prompt text to IDs that can be passed to [`~WhisperForConditionalGeneration.generate`].\"\"\"\n-        batch_encoding = self(\"<|startofprev|>\", text.strip(), add_prefix_space=True, add_special_tokens=False)\n+        batch_encoding = self(\"<|startofprev|>\", \" \" + text.strip(), add_special_tokens=False)\n \n         # Check for special tokens\n         prompt_text_ids = batch_encoding[\"input_ids\"][1:]\n"}
{"instance_id": "huggingface__transformers-24238", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/generation/configuration_utils.py b/src/transformers/generation/configuration_utils.py\nindex 9f3bedcdeb..ca3ddcc271 100644\n--- a/src/transformers/generation/configuration_utils.py\n+++ b/src/transformers/generation/configuration_utils.py\n@@ -569,9 +569,11 @@ class GenerationConfig(PushToHubMixin):\n         if \"_commit_hash\" in kwargs and \"_commit_hash\" in config_dict:\n             kwargs[\"_commit_hash\"] = config_dict[\"_commit_hash\"]\n \n-        # remove all the arguments that are in the config_dict\n-\n-        config = cls(**config_dict, **kwargs)\n+        # Merge config_dict with kwargs, giving priority to kwargs overrides to avoid duplicate keys\n+        init_kwargs = copy.deepcopy(config_dict)\n+        init_kwargs.update(kwargs)\n+        config = cls(**init_kwargs)\n+        # Identify kwargs that were not used to update the config\n         unused_kwargs = config.update(**kwargs)\n \n         logger.info(f\"Generate config {config}\")\n"}
{"instance_id": "huggingface__transformers-25636", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/gpt2/modeling_flax_gpt2.py b/src/transformers/models/gpt2/modeling_flax_gpt2.py\nindex 8973e081a3..0a5742c49c 100644\n--- a/src/transformers/models/gpt2/modeling_flax_gpt2.py\n+++ b/src/transformers/models/gpt2/modeling_flax_gpt2.py\n@@ -753,7 +753,7 @@ class FlaxGPT2LMHeadModel(FlaxGPT2PreTrainedModel):\n         extended_attention_mask = jnp.ones((batch_size, max_length), dtype=\"i4\")\n         if attention_mask is not None:\n             position_ids = attention_mask.cumsum(axis=-1) - 1\n-            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask, (0, 0))\n+            extended_attention_mask = lax.dynamic_update_slice(extended_attention_mask, attention_mask.astype(\"i4\"), (0, 0))\n         else:\n             position_ids = jnp.broadcast_to(jnp.arange(seq_length, dtype=\"i4\")[None, :], (batch_size, seq_length))\n \n"}
{"instance_id": "huggingface__transformers-25884", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/pipelines/base.py b/src/transformers/pipelines/base.py\nindex 153e8e9f6b..6ae72e1a2f 100644\n--- a/src/transformers/pipelines/base.py\n+++ b/src/transformers/pipelines/base.py\n@@ -869,6 +869,9 @@ class Pipeline(_ScikitCompat):\n         if self.tokenizer is not None:\n             self.tokenizer.save_pretrained(save_directory)\n \n+        if self.image_processor is not None:\n+            self.image_processor.save_pretrained(save_directory)\n+\n         if self.feature_extractor is not None:\n             self.feature_extractor.save_pretrained(save_directory)\n \n"}
{"instance_id": "huggingface__transformers-26568", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/swin2sr/configuration_swin2sr.py b/src/transformers/models/swin2sr/configuration_swin2sr.py\nindex c65274e0ae..120e9cb5d6 100644\n--- a/src/transformers/models/swin2sr/configuration_swin2sr.py\n+++ b/src/transformers/models/swin2sr/configuration_swin2sr.py\n@@ -43,7 +43,11 @@ class Swin2SRConfig(PretrainedConfig):\n         patch_size (`int`, *optional*, defaults to 1):\n             The size (resolution) of each patch.\n         num_channels (`int`, *optional*, defaults to 3):\n-            The number of input channels.\n+            The number of input channels. Deprecated in favor of `num_channels_in` and `num_channels_out`. If both are not provided, `num_channels` will be used for both input and output channels.\n+        num_channels_in (`int`, *optional*, defaults to 3):\n+            The number of input channels. If not provided, falls back to `num_channels` or `num_channels_out`.\n+        num_channels_out (`int`, *optional*, defaults to 3):\n+            The number of output channels. If not provided, falls back to `num_channels` or `num_channels_in`.\n         embed_dim (`int`, *optional*, defaults to 180):\n             Dimensionality of patch embedding.\n         depths (`list(int)`, *optional*, defaults to `[6, 6, 6, 6, 6, 6]`):\n@@ -108,6 +112,8 @@ class Swin2SRConfig(PretrainedConfig):\n         image_size=64,\n         patch_size=1,\n         num_channels=3,\n+        num_channels_in=None,\n+        num_channels_out=None,\n         embed_dim=180,\n         depths=[6, 6, 6, 6, 6, 6],\n         num_heads=[6, 6, 6, 6, 6, 6],\n@@ -131,7 +137,21 @@ class Swin2SRConfig(PretrainedConfig):\n \n         self.image_size = image_size\n         self.patch_size = patch_size\n-        self.num_channels = num_channels\n+        # Backward compatibility and flexibility for input/output channels\n+        if num_channels_in is None and num_channels_out is None:\n+            self.num_channels_in = num_channels\n+            self.num_channels_out = num_channels\n+        elif num_channels_in is None:\n+            self.num_channels_in = num_channels_out\n+            self.num_channels_out = num_channels_out\n+        elif num_channels_out is None:\n+            self.num_channels_in = num_channels_in\n+            self.num_channels_out = num_channels_in\n+        else:\n+            self.num_channels_in = num_channels_in\n+            self.num_channels_out = num_channels_out\n+        # Keep alias for backward compatibility\n+        self.num_channels = self.num_channels_in\n         self.embed_dim = embed_dim\n         self.depths = depths\n         self.num_layers = len(depths)\ndiff --git a/src/transformers/models/swin2sr/modeling_swin2sr.py b/src/transformers/models/swin2sr/modeling_swin2sr.py\nindex 72de9ac1cb..12c64a7e3f 100644\n--- a/src/transformers/models/swin2sr/modeling_swin2sr.py\n+++ b/src/transformers/models/swin2sr/modeling_swin2sr.py\n@@ -849,14 +849,19 @@ class Swin2SRModel(Swin2SRPreTrainedModel):\n         super().__init__(config)\n         self.config = config\n \n-        if config.num_channels == 3:\n+        if config.num_channels_in == 3:\n             rgb_mean = (0.4488, 0.4371, 0.4040)\n-            self.mean = torch.Tensor(rgb_mean).view(1, 3, 1, 1)\n+            self.input_mean = torch.Tensor(rgb_mean).view(1, 3, 1, 1)\n         else:\n-            self.mean = torch.zeros(1, 1, 1, 1)\n+            self.input_mean = torch.zeros(1, config.num_channels_in, 1, 1)\n+        if config.num_channels_out == 3:\n+            rgb_mean = (0.4488, 0.4371, 0.4040)\n+            self.output_mean = torch.Tensor(rgb_mean).view(1, 3, 1, 1)\n+        else:\n+            self.output_mean = torch.zeros(1, config.num_channels_out, 1, 1)\n         self.img_range = config.img_range\n \n-        self.first_convolution = nn.Conv2d(config.num_channels, config.embed_dim, 3, 1, 1)\n+        self.first_convolution = nn.Conv2d(config.num_channels_in, config.embed_dim, 3, 1, 1)\n         self.embeddings = Swin2SREmbeddings(config)\n         self.encoder = Swin2SREncoder(config, grid_size=self.embeddings.patch_embeddings.patches_resolution)\n \n@@ -888,8 +893,8 @@ class Swin2SRModel(Swin2SRPreTrainedModel):\n         pixel_values = nn.functional.pad(pixel_values, (0, modulo_pad_width, 0, modulo_pad_height), \"reflect\")\n \n         # 2. normalize\n-        self.mean = self.mean.type_as(pixel_values)\n-        pixel_values = (pixel_values - self.mean) * self.img_range\n+        self.input_mean = self.input_mean.type_as(pixel_values)\n+        pixel_values = (pixel_values - self.input_mean) * self.img_range\n \n         return pixel_values\n \n@@ -1026,7 +1031,7 @@ class PixelShuffleUpsampler(nn.Module):\n         self.conv_before_upsample = nn.Conv2d(config.embed_dim, num_features, 3, 1, 1)\n         self.activation = nn.LeakyReLU(inplace=True)\n         self.upsample = Upsample(config.upscale, num_features)\n-        self.final_convolution = nn.Conv2d(num_features, config.num_channels, 3, 1, 1)\n+        self.final_convolution = nn.Conv2d(num_features, config.num_channels_out, 3, 1, 1)\n \n     def forward(self, sequence_output):\n         x = self.conv_before_upsample(sequence_output)\n@@ -1048,7 +1053,7 @@ class NearestConvUpsampler(nn.Module):\n         self.conv_up1 = nn.Conv2d(num_features, num_features, 3, 1, 1)\n         self.conv_up2 = nn.Conv2d(num_features, num_features, 3, 1, 1)\n         self.conv_hr = nn.Conv2d(num_features, num_features, 3, 1, 1)\n-        self.final_convolution = nn.Conv2d(num_features, config.num_channels, 3, 1, 1)\n+        self.final_convolution = nn.Conv2d(num_features, config.num_channels_out, 3, 1, 1)\n         self.lrelu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n \n     def forward(self, sequence_output):\n@@ -1069,13 +1074,13 @@ class PixelShuffleAuxUpsampler(nn.Module):\n         super().__init__()\n \n         self.upscale = config.upscale\n-        self.conv_bicubic = nn.Conv2d(config.num_channels, num_features, 3, 1, 1)\n+        self.conv_bicubic = nn.Conv2d(config.num_channels_in, num_features, 3, 1, 1)\n         self.conv_before_upsample = nn.Conv2d(config.embed_dim, num_features, 3, 1, 1)\n         self.activation = nn.LeakyReLU(inplace=True)\n-        self.conv_aux = nn.Conv2d(num_features, config.num_channels, 3, 1, 1)\n-        self.conv_after_aux = nn.Sequential(nn.Conv2d(3, num_features, 3, 1, 1), nn.LeakyReLU(inplace=True))\n+        self.conv_aux = nn.Conv2d(num_features, config.num_channels_out, 3, 1, 1)\n+        self.conv_after_aux = nn.Sequential(nn.Conv2d(config.num_channels_out, num_features, 3, 1, 1), nn.LeakyReLU(inplace=True))\n         self.upsample = Upsample(config.upscale, num_features)\n-        self.final_convolution = nn.Conv2d(num_features, config.num_channels, 3, 1, 1)\n+        self.final_convolution = nn.Conv2d(num_features, config.num_channels_out, 3, 1, 1)\n \n     def forward(self, sequence_output, bicubic, height, width):\n         bicubic = self.conv_bicubic(bicubic)\n@@ -1114,13 +1119,13 @@ class Swin2SRForImageSuperResolution(Swin2SRPreTrainedModel):\n             self.upsample = PixelShuffleAuxUpsampler(config, num_features)\n         elif self.upsampler == \"pixelshuffledirect\":\n             # for lightweight SR (to save parameters)\n-            self.upsample = UpsampleOneStep(config.upscale, config.embed_dim, config.num_channels)\n+            self.upsample = UpsampleOneStep(config.upscale, config.embed_dim, config.num_channels_out)\n         elif self.upsampler == \"nearest+conv\":\n             # for real-world SR (less artifacts)\n             self.upsample = NearestConvUpsampler(config, num_features)\n         else:\n             # for image denoising and JPEG compression artifact reduction\n-            self.final_convolution = nn.Conv2d(config.embed_dim, config.num_channels, 3, 1, 1)\n+            self.final_convolution = nn.Conv2d(config.embed_dim, config.num_channels_out, 3, 1, 1)\n \n         # Initialize weights and apply final processing\n         self.post_init()\n@@ -1191,11 +1196,15 @@ class Swin2SRForImageSuperResolution(Swin2SRPreTrainedModel):\n             reconstruction = self.upsample(sequence_output)\n         elif self.upsampler == \"pixelshuffle_aux\":\n             reconstruction, aux = self.upsample(sequence_output, bicubic, height, width)\n-            aux = aux / self.swin2sr.img_range + self.swin2sr.mean\n+            aux = aux / self.swin2sr.img_range + self.swin2sr.output_mean\n         else:\n-            reconstruction = pixel_values + self.final_convolution(sequence_output)\n+            # Only add residual if input and output channels match\n+            if self.config.num_channels_in == self.config.num_channels_out:\n+                reconstruction = pixel_values + self.final_convolution(sequence_output)\n+            else:\n+                reconstruction = self.final_convolution(sequence_output)\n \n-        reconstruction = reconstruction / self.swin2sr.img_range + self.swin2sr.mean\n+        reconstruction = reconstruction / self.swin2sr.img_range + self.swin2sr.output_mean\n         reconstruction = reconstruction[:, :, : height * self.upscale, : width * self.upscale]\n \n         loss = None\n"}
{"instance_id": "huggingface__transformers-26752", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/en/model_doc/encoder-decoder.md b/docs/source/en/model_doc/encoder-decoder.md\nindex 8e26a3b9e4..26c45f8bc1 100644\n--- a/docs/source/en/model_doc/encoder-decoder.md\n+++ b/docs/source/en/model_doc/encoder-decoder.md\n@@ -135,7 +135,7 @@ target sequence).\n ...     return_tensors=\"pt\",\n ... ).input_ids\n \n->>> # the forward function automatically creates the correct decoder_input_ids\n+>>> # the forward function automatically creates the correct decoder_input_ids and decoder_attention_mask\n >>> loss = model(input_ids=input_ids, labels=labels).loss\n ```\n \ndiff --git a/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py b/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py\nindex 3548e48c59..f7099f55aa 100644\n--- a/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py\n+++ b/src/transformers/models/encoder_decoder/modeling_encoder_decoder.py\n@@ -620,6 +620,13 @@ class EncoderDecoderModel(PreTrainedModel):\n             decoder_input_ids = shift_tokens_right(\n                 labels, self.config.pad_token_id, self.config.decoder_start_token_id\n             )\n+            if decoder_attention_mask is None and self.config.pad_token_id is not None:\n+                decoder_attention_mask = decoder_input_ids.ne(self.config.pad_token_id)\n+                if self.config.decoder_start_token_id is not None and self.config.pad_token_id == self.config.decoder_start_token_id:\n+                    # Ensure the start token is not masked even if it equals the pad token id\n+                    decoder_attention_mask[:, 0] = True\n+        elif decoder_input_ids is not None and decoder_attention_mask is None and self.config.pad_token_id is not None:\n+            decoder_attention_mask = decoder_input_ids.ne(self.config.pad_token_id)\n \n         # Decode\n         decoder_outputs = self.decoder(\n"}
{"instance_id": "huggingface__transformers-26164", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/generation/utils.py b/src/transformers/generation/utils.py\nindex 3b1bef6f04..03abc5bc2c 100644\n--- a/src/transformers/generation/utils.py\n+++ b/src/transformers/generation/utils.py\n@@ -1525,6 +1525,14 @@ class GenerationMixin:\n                     \"(https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\"\n                 )\n             generation_config.max_length = generation_config.max_new_tokens + input_ids_length\n+        # Clamp the effective max_length to the model's maximum supported target length for encoder-decoder models.\n+        if self.config.is_encoder_decoder:\n+            max_supported_length = getattr(self.config, \"max_target_positions\", None)\n+            if max_supported_length is not None and generation_config.max_length is not None and generation_config.max_length > max_supported_length:\n+                logger.warning(\n+                    f\"The requested total generation length (prompt + new tokens = {generation_config.max_length}) exceeds the model's maximum target positions ({max_supported_length}). Capping `max_length` to {max_supported_length}. Consider decreasing `max_new_tokens` and/or shortening the prompt.\"\n+                )\n+                generation_config.max_length = max_supported_length\n         self._validate_generated_length(generation_config, input_ids_length, has_default_max_length)\n \n         # 7. determine generation mode\ndiff --git a/src/transformers/models/whisper/modeling_whisper.py b/src/transformers/models/whisper/modeling_whisper.py\nindex 926101156d..f5bcd3af22 100644\n--- a/src/transformers/models/whisper/modeling_whisper.py\n+++ b/src/transformers/models/whisper/modeling_whisper.py\n@@ -1719,13 +1719,22 @@ class WhisperForConditionalGeneration(WhisperPreTrainedModel):\n             decoder_start_token_id, *text_prompt_ids = prompt_ids\n             # Slicing the text prompt ids in a manner consistent with the OpenAI implementation\n             # to accomodate context space for the prefix (see https://github.com/openai/whisper/blob/c09a7ae299c4c34c5839a76380ae407e7d785914/whisper/decoding.py#L599)\n-            text_prompt_ids = text_prompt_ids[-self.config.max_length // 2 - 1 :]\n+            # Use `max_target_positions` and take at most `(max_target_positions // 2 - 1)` tokens from the end.\n+            text_prompt_ids = text_prompt_ids[-self.config.max_target_positions // 2 + 1 :]\n             # Set the decoder_start_token_id to <|startofprev|>\n             kwargs.update({\"decoder_start_token_id\": decoder_start_token_id})\n \n             # If the user passes `max_new_tokens`, increase its number to account for the prompt\n             if kwargs.get(\"max_new_tokens\", None) is not None:\n                 kwargs[\"max_new_tokens\"] += len(text_prompt_ids)\n+                # Ensure the total number of generation steps (excluding the initial decoder start token)\n+                # does not exceed the model's maximum target positions.\n+                max_total_new_tokens_allowed = self.config.max_target_positions - 1\n+                if kwargs[\"max_new_tokens\"] > max_total_new_tokens_allowed:\n+                    logger.warning(\n+                        f\"Requested `max_new_tokens` (including prompt) ({kwargs['max_new_tokens']}) exceeds the model's maximum target positions ({self.config.max_target_positions - 1}). Capping `max_new_tokens` to {max_total_new_tokens_allowed}.\"\n+                    )\n+                    kwargs[\"max_new_tokens\"] = max_total_new_tokens_allowed\n \n             # Reformat the forced_decoder_ids to incorporate the prompt\n             non_prompt_forced_decoder_ids = (\n"}
{"instance_id": "huggingface__transformers-26839", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/idefics/modeling_idefics.py b/src/transformers/models/idefics/modeling_idefics.py\nindex 28841903a1..b76dd96176 100644\n--- a/src/transformers/models/idefics/modeling_idefics.py\n+++ b/src/transformers/models/idefics/modeling_idefics.py\n@@ -697,6 +697,11 @@ class IdeficsAttention(nn.Module):\n                 raise ValueError(\n                     f\"Attention mask should be of size {(bsz, 1, q_len, kv_seq_len)}, but is {attention_mask.size()}\"\n                 )\n+            # Ensure mask dtype is compatible with SDPA: convert boolean mask (True = masked) to additive float mask\n+            if attention_mask.dtype == torch.bool:\n+                float_mask = torch.zeros_like(attention_mask, dtype=query_states.dtype)\n+                float_mask = float_mask.masked_fill(attention_mask, torch.finfo(query_states.dtype).min)\n+                attention_mask = float_mask\n \n         attn_output = nn.functional.scaled_dot_product_attention(\n             query_states,\n@@ -915,9 +920,22 @@ class IdeficsGatedCrossAttentionLayer(nn.Module):\n             output_attentions=output_attentions,\n         )\n         hidden_states = nn.functional.dropout(hidden_states, p=self.config, training=self.training)\n+        # build a per-token gate: if a token cannot attend any image keys, zero out cross-attn contribution\n+        if image_attention_mask is not None:\n+            # image_attention_mask is expected to be of shape (bsz, 1, q_len, kv_len)\n+            attn_mask = image_attention_mask.squeeze(1)\n+            if attn_mask.dtype == torch.bool:\n+                # True means masked, so allowed positions are where mask is False\n+                allowed = (~attn_mask).any(dim=-1)\n+            else:\n+                # float additive mask: masked positions carry -inf, allowed positions are finite (typically 0.0)\n+                allowed = torch.isfinite(attn_mask).any(dim=-1)\n+            token_gate = allowed.to(hidden_states.dtype).unsqueeze(-1)\n+        else:\n+            token_gate = torch.ones(hidden_states.size(0), hidden_states.size(1), 1, dtype=hidden_states.dtype, device=hidden_states.device)\n         # when there are no images the model is used in pure language mode\n         gate = 0 if no_images else 1\n-        hidden_states = residual + gate * self.act_cross_attn(self.alpha_cross_attn) * hidden_states\n+        hidden_states = residual + gate * token_gate * self.act_cross_attn(self.alpha_cross_attn) * hidden_states\n \n         # Fully Connected\n         residual = hidden_states\n"}
{"instance_id": "huggingface__transformers-27114", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/llama/modeling_llama.py b/src/transformers/models/llama/modeling_llama.py\nindex 703ebf0d95..13b2b29a0c 100644\n--- a/src/transformers/models/llama/modeling_llama.py\n+++ b/src/transformers/models/llama/modeling_llama.py\n@@ -384,6 +384,24 @@ class LlamaAttention(nn.Module):\n \n         past_key_value = (key_states, value_states) if use_cache else None\n \n+        input_dtype = query_states.dtype\n+        if input_dtype == torch.float32:\n+            # Handle the case where the model is quantized\n+            if hasattr(self.config, \"_pre_quantization_dtype\"):\n+                target_dtype = self.config._pre_quantization_dtype\n+            else:\n+                target_dtype = self.q_proj.weight.dtype\n+\n+            logger.warning_once(\n+                f\"The input hidden states seems to be silently casted in float32, this might be related to\"\n+                f\" the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in\"\n+                f\" {target_dtype}.\"\n+            )\n+\n+            query_states = query_states.to(target_dtype)\n+            key_states = key_states.to(target_dtype)\n+            value_states = value_states.to(target_dtype)\n+\n         key_states = repeat_kv(key_states, self.num_key_value_groups)\n         value_states = repeat_kv(value_states, self.num_key_value_groups)\n \n@@ -519,7 +537,7 @@ class LlamaFlashAttention2(LlamaAttention):\n             value_states = value_states.to(target_dtype)\n \n         attn_output = self._flash_attention_forward(\n-            query_states, key_states, value_states, attention_mask, q_len, dropout=dropout_rate\n+            query_states, key_states, value_states, attention_mask, q_len, dropout=dropout_rate, softmax_scale=1.0 / math.sqrt(self.head_dim)\n         )\n \n         attn_output = attn_output.reshape(bsz, q_len, self.hidden_size).contiguous()\n"}
{"instance_id": "huggingface__transformers-27663", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/yolos/image_processing_yolos.py b/src/transformers/models/yolos/image_processing_yolos.py\nindex 3b0c635c0e..bc791def59 100644\n--- a/src/transformers/models/yolos/image_processing_yolos.py\n+++ b/src/transformers/models/yolos/image_processing_yolos.py\n@@ -117,7 +117,7 @@ def get_size_with_aspect_ratio(image_size, size, max_size=None) -> Tuple[int, in\n         min_original_size = float(min((height, width)))\n         max_original_size = float(max((height, width)))\n         if max_original_size / min_original_size * size > max_size:\n-            size = int(round(max_size * min_original_size / max_original_size))\n+            size = int(max_size * min_original_size / max_original_size)\n \n     if (height <= width and height == size) or (width <= height and width == size):\n         return height, width\n"}
{"instance_id": "huggingface__transformers-27463", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/en/main_classes/image_processor.md b/docs/source/en/main_classes/image_processor.md\nindex 04a3cd1337..b03cc8e636 100644\n--- a/docs/source/en/main_classes/image_processor.md\n+++ b/docs/source/en/main_classes/image_processor.md\n@@ -16,7 +16,7 @@ rendered properly in your Markdown viewer.\n \n # Image Processor\n \n-An image processor is in charge of preparing input features for vision models and post processing their outputs. This includes transformations such as resizing, normalization, and conversion to PyTorch, TensorFlow, Flax and Numpy tensors. It may also include model specific post-processing such as converting logits to segmentation masks.\n+An image processor is in charge of preparing input features for vision models and post processing their outputs. This includes transformations such as resizing, normalization, and conversion to PyTorch, TensorFlow, Flax and Numpy tensors. It may also include model specific post-processing such as converting logits to segmentation masks. Some image processors also accept targets (e.g., segmentation masks) and apply the corresponding geometric transforms (resize, pad) to keep inputs and targets aligned during training.\n \n \n ## ImageProcessingMixin\ndiff --git a/docs/source/en/model_doc/sam.md b/docs/source/en/model_doc/sam.md\nindex d2a472957a..8149a3618c 100644\n--- a/docs/source/en/model_doc/sam.md\n+++ b/docs/source/en/model_doc/sam.md\n@@ -66,6 +66,32 @@ masks = processor.image_processor.post_process_masks(\n scores = outputs.iou_scores\n ```\n \n+For fine-tuning, you can either:\n+\n+- Downsample ground-truth masks via the processor and compute loss at low resolution:\n+\n+```python\n+# ground_truth_mask should be a binary mask at the original image resolution\n+inputs = processor(raw_image, ground_truth_masks=ground_truth_mask, input_points=input_points, return_tensors=\"pt\").to(device)\n+outputs = model(**inputs)\n+# outputs.pred_masks has shape (batch_size, num_masks, 256, 256) by default\n+# inputs[\"ground_truth_masks\"] is resized/padded to match this low-resolution\n+loss = loss_fn(outputs.pred_masks, inputs[\"ground_truth_masks\"])  # e.g., BCEWithLogitsLoss\n+```\n+\n+- Or upscale predictions back to original image size and compute loss at full resolution:\n+\n+```python\n+inputs = processor(raw_image, input_points=input_points, return_tensors=\"pt\").to(device)\n+outputs = model(**inputs)\n+# Get masks at original image size (set binarize=False for logits-based losses)\n+up_masks = processor.image_processor.post_process_masks(\n+    outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu(), binarize=False\n+)\n+# Compare against original-resolution ground-truth mask\n+loss = loss_fn(up_masks[0], original_ground_truth_mask)\n+```\n+\n Resources:\n \n - [Demo notebook](https://github.com/huggingface/notebooks/blob/main/examples/segment_anything.ipynb) for using the model.\ndiff --git a/src/transformers/models/sam/image_processing_sam.py b/src/transformers/models/sam/image_processing_sam.py\nindex a5c5c1e5fb..16db7389e3 100644\n--- a/src/transformers/models/sam/image_processing_sam.py\n+++ b/src/transformers/models/sam/image_processing_sam.py\n@@ -239,6 +239,7 @@ class SamImageProcessor(BaseImageProcessor):\n     def preprocess(\n         self,\n         images: ImageInput,\n+        ground_truth_masks: Optional[ImageInput] = None,\n         do_resize: Optional[bool] = None,\n         size: Optional[Dict[str, int]] = None,\n         resample: Optional[\"PILImageResampling\"] = None,\n@@ -386,12 +387,51 @@ class SamImageProcessor(BaseImageProcessor):\n         images = [\n             to_channel_dimension_format(image, data_format, input_channel_dim=input_data_format) for image in images\n         ]\n+\n+        # Optionally process ground-truth masks to the low-resolution decoder scale\n+        processed_masks = None\n+        if ground_truth_masks is not None:\n+            gt_masks = make_list_of_images(ground_truth_masks)\n+            processed_masks = []\n+            # derive low-res target sizes from image resize/pad sizes (default 256x256)\n+            low_res_size = {\"longest_edge\": size[\"longest_edge\"] // 4}\n+            low_res_pad_size = {\"height\": pad_size[\"height\"] // 4, \"width\": pad_size[\"width\"] // 4}\n+            for mask in gt_masks:\n+                mask_np = to_numpy_array(mask)\n+                # Add channel dimension if missing - needed for certain transformations\n+                if mask_np.ndim == 2:\n+                    mask_np = mask_np[None, ...]\n+                    mask_input_format = ChannelDimension.FIRST\n+                else:\n+                    mask_input_format = infer_channel_dimension_format(mask_np, num_channels=1)\n+                if do_resize:\n+                    mask_np = self.resize(\n+                        image=mask_np,\n+                        size=low_res_size,\n+                        resample=PILImageResampling.NEAREST,\n+                        input_data_format=mask_input_format,\n+                    )\n+                if do_pad:\n+                    mask_np = self.pad_image(\n+                        image=mask_np,\n+                        pad_size=low_res_pad_size,\n+                        input_data_format=mask_input_format,\n+                    )\n+                # Convert to the requested data_format\n+                mask_np = to_channel_dimension_format(mask_np, data_format, input_channel_dim=mask_input_format)\n+                # SAM fine-tuning typically expects float masks\n+                mask_np = mask_np.astype(np.float32)\n+                processed_masks.append(mask_np)\n+\n+        data = {\n+            \"pixel_values\": images,\n+            \"original_sizes\": original_sizes,\n+            \"reshaped_input_sizes\": reshaped_input_sizes,\n+        }\n+        if processed_masks is not None:\n+            data[\"ground_truth_masks\"] = processed_masks\n         encoded_outputs = BatchFeature(\n-            data={\n-                \"pixel_values\": images,\n-                \"original_sizes\": original_sizes,\n-                \"reshaped_input_sizes\": reshaped_input_sizes,\n-            },\n+            data=data,\n             tensor_type=return_tensors,\n         )\n         return encoded_outputs\ndiff --git a/src/transformers/models/sam/processing_sam.py b/src/transformers/models/sam/processing_sam.py\nindex 7c632b2151..853742dd48 100644\n--- a/src/transformers/models/sam/processing_sam.py\n+++ b/src/transformers/models/sam/processing_sam.py\n@@ -57,6 +57,7 @@ class SamProcessor(ProcessorMixin):\n     def __call__(\n         self,\n         images=None,\n+        ground_truth_masks=None,\n         input_points=None,\n         input_labels=None,\n         input_boxes=None,\n@@ -69,6 +70,7 @@ class SamProcessor(ProcessorMixin):\n         \"\"\"\n         encoding_image_processor = self.image_processor(\n             images,\n+            ground_truth_masks=ground_truth_masks,\n             return_tensors=return_tensors,\n             **kwargs,\n         )\n"}
{"instance_id": "huggingface__transformers-28071", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/speecht5/modeling_speecht5.py b/src/transformers/models/speecht5/modeling_speecht5.py\nindex a5e228b6a8..a78f47b803 100644\n--- a/src/transformers/models/speecht5/modeling_speecht5.py\n+++ b/src/transformers/models/speecht5/modeling_speecht5.py\n@@ -81,6 +81,25 @@ def shift_spectrograms_right(input_values: torch.Tensor, reduction_factor: int =\n     return shifted_input_values\n \n \n+def shift_decoder_attention_mask_right(attention_mask: torch.Tensor, reduction_factor: int = 1):\n+    \"\"\"\n+    Shift decoder attention mask one timestep to the right. Also applies the reduction factor to the sequence length.\n+    \"\"\"\n+    if reduction_factor > 1:\n+        attention_mask = attention_mask[:, reduction_factor - 1 :: reduction_factor]\n+\n+    shifted_attention_mask = attention_mask.new_zeros(attention_mask.shape)\n+    shifted_attention_mask[:, 1:] = attention_mask[:, :-1].clone()\n+\n+    # set first position to 1 (attend to initial BOS-like frame)\n+    if shifted_attention_mask.dtype == torch.bool:\n+        shifted_attention_mask[:, 0] = True\n+    else:\n+        shifted_attention_mask[:, 0] = 1\n+\n+    return shifted_attention_mask\n+\n+\n # Copied from transformers.models.wav2vec2.modeling_wav2vec2._compute_mask_indices\n def _compute_mask_indices(\n     shape: Tuple[int, int],\n@@ -2028,6 +2047,11 @@ SPEECHT5_INPUTS_DOCSTRING = r\"\"\"\n             and modify to your needs. See diagram 1 in [the paper](https://arxiv.org/abs/1910.13461) for more\n             information on the default strategy.\n \n+            Note: when training with `labels` and a `reduction_factor > 1`, the decoder inputs are reduced and shifted\n+            internally. In this case, any provided `decoder_attention_mask` will be reduced and shifted in the same way;\n+            if not provided, it is derived from `labels` and adjusted accordingly so that its shape matches the decoder\n+            inputs.\n+\n         head_mask (`torch.FloatTensor` of shape `(encoder_layers, encoder_attention_heads)`, *optional*):\n             Mask to nullify selected heads of the attention modules in the encoder. Mask values selected in `[0, 1]`:\n \n@@ -2700,6 +2724,18 @@ class SpeechT5ForTextToSpeech(SpeechT5PreTrainedModel):\n         if labels is not None:\n             if decoder_input_values is None:\n                 decoder_input_values = shift_spectrograms_right(labels, self.config.reduction_factor)\n+            # Adjust decoder attention mask to match reduced and shifted decoder inputs\n+            if decoder_attention_mask is not None:\n+                decoder_attention_mask = shift_decoder_attention_mask_right(\n+                    decoder_attention_mask, self.config.reduction_factor\n+                )\n+            else:\n+                # Derive decoder attention mask from labels (-100.0 indicates padding)\n+                # A timestep is considered valid if it is not padded across mel bins; we check the first bin.\n+                derived_mask = (labels[:, :, 0] != -100.0)\n+                decoder_attention_mask = shift_decoder_attention_mask_right(\n+                    derived_mask.to(torch.long), self.config.reduction_factor\n+                )\n             if self.config.use_guided_attention_loss:\n                 output_attentions = True\n \n"}
{"instance_id": "huggingface__transformers-27717", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/nllb/tokenization_nllb.py b/src/transformers/models/nllb/tokenization_nllb.py\nindex 7daf729c13..89487c044d 100644\n--- a/src/transformers/models/nllb/tokenization_nllb.py\n+++ b/src/transformers/models/nllb/tokenization_nllb.py\n@@ -113,6 +113,10 @@ class NllbTokenizer(PreTrainedTokenizer):\n             The language to use as target language for translation.\n         sp_model_kwargs (`Dict[str, str]`):\n             Additional keyword arguments to pass to the model initialization.\n+        language_codes (`List[str]`, *optional*):\n+            Optional override for the list of supported language codes. If provided, these codes will be used\n+            to build the tokenizer's language-specific special tokens and ids instead of the default\n+            `FAIRSEQ_LANGUAGE_CODES`. The order defines id assignment. All codes must be unique.\n     \"\"\"\n \n     vocab_files_names = VOCAB_FILES_NAMES\n@@ -137,6 +141,7 @@ class NllbTokenizer(PreTrainedTokenizer):\n         src_lang=None,\n         tgt_lang=None,\n         sp_model_kwargs: Optional[Dict[str, Any]] = None,\n+        language_codes: Optional[List[str]] = None,\n         additional_special_tokens=None,\n         legacy_behaviour=False,\n         **kwargs,\n@@ -167,8 +172,23 @@ class NllbTokenizer(PreTrainedTokenizer):\n         self.fairseq_offset = 1\n \n         self.sp_model_size = len(self.sp_model)\n+        # Resolve language codes: allow override via `language_codes` while defaulting to FAIRSEQ_LANGUAGE_CODES\n+        if language_codes is None:\n+            resolved_language_codes = list(FAIRSEQ_LANGUAGE_CODES)\n+        else:\n+            if not isinstance(language_codes, (list, tuple)):\n+                raise ValueError(\"`language_codes` must be a list of strings.\")\n+            resolved_language_codes = list(language_codes)\n+            if not all(isinstance(code, str) for code in resolved_language_codes):\n+                raise ValueError(\"`language_codes` must be a list of strings.\")\n+            if len(set(resolved_language_codes)) != len(resolved_language_codes):\n+                raise ValueError(\"`language_codes` must contain unique language codes.\")\n+            if len(resolved_language_codes) == 0:\n+                raise ValueError(\"`language_codes` must contain at least one language code.\")\n+        self.language_codes = resolved_language_codes\n+\n         self.lang_code_to_id = {\n-            code: self.sp_model_size + i + self.fairseq_offset for i, code in enumerate(FAIRSEQ_LANGUAGE_CODES)\n+            code: self.sp_model_size + i + self.fairseq_offset for i, code in enumerate(self.language_codes)\n         }\n         self.id_to_lang_code = {v: k for k, v in self.lang_code_to_id.items()}\n         self.fairseq_tokens_to_ids[\"<mask>\"] = len(self.sp_model) + len(self.lang_code_to_id) + self.fairseq_offset\n@@ -176,7 +196,17 @@ class NllbTokenizer(PreTrainedTokenizer):\n         self.fairseq_tokens_to_ids.update(self.lang_code_to_id)\n         self.fairseq_ids_to_tokens = {v: k for k, v in self.fairseq_tokens_to_ids.items()}\n \n-        self._src_lang = src_lang if src_lang is not None else \"eng_Latn\"\n+        # Determine the source language: default to 'eng_Latn' if available, otherwise the first provided code\n+        if src_lang is not None:\n+            if src_lang not in self.lang_code_to_id:\n+                raise ValueError(f\"Provided `src_lang` ({src_lang}) is not in the tokenizer language codes.\")\n+            self._src_lang = src_lang\n+        else:\n+            self._src_lang = \"eng_Latn\" if \"eng_Latn\" in self.lang_code_to_id else self.language_codes[0]\n+        # Validate tgt_lang if provided\n+        if tgt_lang is not None and tgt_lang not in self.lang_code_to_id:\n+            raise ValueError(f\"Provided `tgt_lang` ({tgt_lang}) is not in the tokenizer language codes.\")\n+\n         self.cur_lang_code_id = self.lang_code_to_id[self._src_lang]\n \n         _additional_special_tokens = list(self.lang_code_to_id.keys())\n@@ -201,6 +231,7 @@ class NllbTokenizer(PreTrainedTokenizer):\n             additional_special_tokens=_additional_special_tokens,\n             sp_model_kwargs=self.sp_model_kwargs,\n             legacy_behaviour=legacy_behaviour,\n+            language_codes=self.language_codes,\n             **kwargs,\n         )\n \n@@ -398,6 +429,8 @@ class NllbTokenizer(PreTrainedTokenizer):\n         - In legacy mode: No prefix and suffix=[eos, src_lang_code].\n         - In default mode: Prefix=[src_lang_code], suffix = [eos]\n         \"\"\"\n+        if src_lang not in self.lang_code_to_id:\n+            raise ValueError(f\"`src_lang` ({src_lang}) is not in the tokenizer language codes.\")\n         self.cur_lang_code = self.lang_code_to_id[src_lang]\n         if self.legacy_behaviour:\n             self.prefix_tokens = []\n@@ -411,6 +444,8 @@ class NllbTokenizer(PreTrainedTokenizer):\n         - In legacy mode: No prefix and suffix=[eos, tgt_lang_code].\n         - In default mode: Prefix=[tgt_lang_code], suffix = [eos]\n         \"\"\"\n+        if lang not in self.lang_code_to_id:\n+            raise ValueError(f\"`tgt_lang` ({lang}) is not in the tokenizer language codes.\")\n         self.cur_lang_code = self.lang_code_to_id[lang]\n         if self.legacy_behaviour:\n             self.prefix_tokens = []\n"}
{"instance_id": "huggingface__transformers-28115", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/mixtral/modeling_mixtral.py b/src/transformers/models/mixtral/modeling_mixtral.py\nindex c07346c6de..ff86c0a17b 100644\n--- a/src/transformers/models/mixtral/modeling_mixtral.py\n+++ b/src/transformers/models/mixtral/modeling_mixtral.py\n@@ -98,8 +98,11 @@ def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tenso\n         compute_device = gate_logits[0].device\n         gate_logits = torch.cat([gate.to(compute_device) for gate in gate_logits], dim=0)\n \n-    routing_weights, selected_experts = torch.topk(gate_logits, top_k, dim=-1)\n-    routing_weights = routing_weights.softmax(dim=-1)\n+    if num_experts is None:\n+        num_experts = gate_logits.shape[-1]\n+\n+    _, selected_experts = torch.topk(gate_logits, top_k, dim=-1)\n+    routing_probs = gate_logits.softmax(dim=-1)\n \n     # cast the expert indices to int64, otherwise one-hot encoding will fail\n     if selected_experts.dtype != torch.int64:\n@@ -117,8 +120,8 @@ def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tenso\n     expert_mask = expert_mask.to(torch.float32)\n     tokens_per_group_and_expert = torch.mean(expert_mask, axis=-2)\n \n-    router_prob_per_group_and_expert = torch.mean(routing_weights, axis=-1)\n-    return torch.mean(tokens_per_group_and_expert * router_prob_per_group_and_expert.unsqueeze(-1)) * (num_experts**2)\n+    router_prob_per_group_and_expert = torch.mean(routing_probs, axis=-2)\n+    return torch.mean(tokens_per_group_and_expert * router_prob_per_group_and_expert) * (num_experts**2)\n \n \n # Copied from transformers.models.llama.modeling_llama._get_unpad_data\n"}
{"instance_id": "huggingface__transformers-28517", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/mixtral/modeling_mixtral.py b/src/transformers/models/mixtral/modeling_mixtral.py\nindex 99bd282086..192492397f 100644\n--- a/src/transformers/models/mixtral/modeling_mixtral.py\n+++ b/src/transformers/models/mixtral/modeling_mixtral.py\n@@ -74,7 +74,12 @@ logger = logging.get_logger(__name__)\n _CONFIG_FOR_DOC = \"MixtralConfig\"\n \n \n-def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tensor = None, top_k=2) -> float:\n+def load_balancing_loss_func(\n+    gate_logits: torch.Tensor,\n+    num_experts: torch.Tensor = None,\n+    top_k=2,\n+    attention_mask: Optional[torch.Tensor] = None,\n+) -> float:\n     r\"\"\"\n     Computes auxiliary load balancing loss as in Switch Transformer - implemented in Pytorch.\n \n@@ -88,6 +93,9 @@ def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tenso\n             shape [batch_size X sequence_length, num_experts].\n         num_experts (`int`, *optional*):\n             Number of experts\n+        attention_mask (`torch.Tensor`, *optional*):\n+            Padding mask of shape `(batch_size, sequence_length)` where 1 indicates non-padding tokens and 0 indicates\n+            padding tokens. When provided, padding tokens are excluded from the auxiliary load balancing loss.\n \n     Returns:\n         The auxiliary loss.\n@@ -95,20 +103,32 @@ def load_balancing_loss_func(gate_logits: torch.Tensor, num_experts: torch.Tenso\n     if gate_logits is None or not isinstance(gate_logits, tuple):\n         return 0\n \n-    if isinstance(gate_logits, tuple):\n-        compute_device = gate_logits[0].device\n-        concatenated_gate_logits = torch.cat([layer_gate.to(compute_device) for layer_gate in gate_logits], dim=0)\n+    compute_device = gate_logits[0].device\n+    concatenated_gate_logits = torch.cat([layer_gate.to(compute_device) for layer_gate in gate_logits], dim=0)\n \n     routing_weights = torch.nn.functional.softmax(concatenated_gate_logits, dim=-1)\n \n     _, selected_experts = torch.topk(routing_weights, top_k, dim=-1)\n \n+    # If an attention mask is provided, exclude padding tokens from the loss computation\n+    if attention_mask is not None:\n+        # Flatten to (batch_size * sequence_length) and convert to boolean mask\n+        flat_mask = (attention_mask.reshape(-1).to(compute_device) != 0)\n+        # Repeat the mask for each layer to match the concatenated gate logits\n+        num_layers = len(gate_logits)\n+        repeated_mask = flat_mask.repeat(num_layers)\n+        # If all tokens are padding, return 0 to avoid division by zero\n+        if repeated_mask.sum() == 0:\n+            return 0\n+        routing_weights = routing_weights[repeated_mask]\n+        selected_experts = selected_experts[repeated_mask]\n+\n     expert_mask = torch.nn.functional.one_hot(selected_experts, num_experts)\n \n-    # Compute the percentage of tokens routed to each experts\n+    # Compute the percentage of tokens routed to each expert (averaged over non-padding tokens if mask provided)\n     tokens_per_expert = torch.mean(expert_mask.float(), dim=0)\n \n-    # Compute the average probability of routing to these experts\n+    # Compute the average probability of routing to these experts (averaged over non-padding tokens if mask provided)\n     router_prob_per_expert = torch.mean(routing_weights, dim=0)\n \n     overall_loss = torch.sum(tokens_per_expert * router_prob_per_expert.unsqueeze(0))\n@@ -1347,7 +1367,10 @@ class MixtralForCausalLM(MixtralPreTrainedModel):\n         aux_loss = None\n         if output_router_logits:\n             aux_loss = load_balancing_loss_func(\n-                outputs.router_logits if return_dict else outputs[-1], self.num_experts, self.num_experts_per_tok\n+                outputs.router_logits if return_dict else outputs[-1],\n+                self.num_experts,\n+                self.num_experts_per_tok,\n+                attention_mask=attention_mask,\n             )\n             if labels is not None:\n                 loss += self.router_aux_loss_coef * aux_loss\n"}
{"instance_id": "huggingface__transformers-29311", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/wav2vec2/tokenization_wav2vec2.py b/src/transformers/models/wav2vec2/tokenization_wav2vec2.py\nindex 00bb00fba3..9f347a6a93 100644\n--- a/src/transformers/models/wav2vec2/tokenization_wav2vec2.py\n+++ b/src/transformers/models/wav2vec2/tokenization_wav2vec2.py\n@@ -434,7 +434,7 @@ class Wav2Vec2CTCTokenizer(PreTrainedTokenizer):\n \n         result = []\n         for token in filtered_tokens:\n-            if skip_special_tokens and token in self.all_special_ids:\n+            if skip_special_tokens and token in self.all_special_tokens:\n                 continue\n             result.append(token)\n \n"}
{"instance_id": "huggingface__transformers-29449", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/idefics/processing_idefics.py b/src/transformers/models/idefics/processing_idefics.py\nindex 590e2475ca..92e139a38f 100644\n--- a/src/transformers/models/idefics/processing_idefics.py\n+++ b/src/transformers/models/idefics/processing_idefics.py\n@@ -331,6 +331,7 @@ class IdeficsProcessor(ProcessorMixin):\n             padding=padding,\n             truncation=truncation,\n             max_length=max_length,\n+            return_attention_mask=True,\n         )\n         all_texts = text_encoding[\"input_ids\"]\n \n@@ -344,14 +345,23 @@ class IdeficsProcessor(ProcessorMixin):\n         output_input_ids = []\n         output_images = []\n         output_attention_masks = []\n-        for text, images in zip(all_texts, all_images):\n-            padded_input_ids = [self.tokenizer.pad_token_id] * max_seq_len\n-            unpadded_seq_len = len(text)\n-            start = max_seq_len - unpadded_seq_len\n-            padded_input_ids[start:] = text[:max_seq_len]\n-\n-            attention_mask = torch.zeros((max_seq_len,), dtype=torch.long)\n-            attention_mask[start:] = 1\n+        all_attention_masks = text_encoding.get(\"attention_mask\", None)\n+        padding_side = getattr(self.tokenizer, \"padding_side\", \"right\")\n+        for idx, (text, images) in enumerate(zip(all_texts, all_images)):\n+            # Use tokenizer-provided input_ids and attention_mask when the tokenizer has already padded to max_seq_len.\n+            seq_len = len(text)\n+            if all_attention_masks is not None and seq_len == max_seq_len:\n+                padded_input_ids = text\n+                attention_mask = torch.tensor(all_attention_masks[idx], dtype=torch.long)\n+            else:\n+                if padding_side == \"right\":\n+                    padded_input_ids = text[:max_seq_len] + [self.tokenizer.pad_token_id] * (max_seq_len - seq_len)\n+                    attention_mask = torch.zeros((max_seq_len,), dtype=torch.long)\n+                    attention_mask[:seq_len] = 1\n+                else:\n+                    padded_input_ids = [self.tokenizer.pad_token_id] * (max_seq_len - seq_len) + text[:max_seq_len]\n+                    attention_mask = torch.zeros((max_seq_len,), dtype=torch.long)\n+                    attention_mask[-seq_len:] = 1\n \n             image_count = padded_input_ids.count(self.image_token_id)\n             local_max_num_images = min(image_count, max_num_images)\n"}
{"instance_id": "huggingface__transformers-28563", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/whisper/modeling_whisper.py b/src/transformers/models/whisper/modeling_whisper.py\nindex a3550c791c..6927d3152e 100644\n--- a/src/transformers/models/whisper/modeling_whisper.py\n+++ b/src/transformers/models/whisper/modeling_whisper.py\n@@ -2957,6 +2957,9 @@ class WhisperForAudioClassification(WhisperPreTrainedModel):\n         output_hidden_states = (\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n+        if self.config.use_weighted_layer_sum:\n+            # Weighted layer sum requires hidden states from all layers\n+            output_hidden_states = True\n         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         if encoder_outputs is None:\n@@ -2969,11 +2972,18 @@ class WhisperForAudioClassification(WhisperPreTrainedModel):\n             )\n \n         if self.config.use_weighted_layer_sum:\n-            hidden_states = torch.stack(encoder_outputs, dim=1)\n+            # Use per-layer hidden states for weighted sum depending on return_dict\n+            if return_dict:\n+                per_layer_hidden_states = encoder_outputs.hidden_states\n+            else:\n+                per_layer_hidden_states = encoder_outputs[1]\n+            if per_layer_hidden_states is None:\n+                raise ValueError(\"use_weighted_layer_sum=True requires output_hidden_states=True to be set.\")\n+            hidden_states = torch.stack(per_layer_hidden_states, dim=1)\n             norm_weights = nn.functional.softmax(self.layer_weights, dim=-1)\n             hidden_states = (hidden_states * norm_weights.view(-1, 1, 1)).sum(dim=1)\n         else:\n-            hidden_states = encoder_outputs[0]\n+            hidden_states = encoder_outputs.last_hidden_state if return_dict else encoder_outputs[0]\n \n         hidden_states = self.projector(hidden_states)\n         pooled_output = hidden_states.mean(dim=1)\n"}
{"instance_id": "huggingface__transformers-29519", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/en/model_doc/mistral.md b/docs/source/en/model_doc/mistral.md\nindex 0ab2142061..d2b6e8626b 100644\n--- a/docs/source/en/model_doc/mistral.md\n+++ b/docs/source/en/model_doc/mistral.md\n@@ -130,8 +130,10 @@ Below is a expected speedup diagram that compares pure inference time between th\n \n ### Sliding window Attention\n \n-The current implementation supports the sliding window attention mechanism and memory efficient cache management. \n-To enable sliding window attention, just make sure to have a `flash-attn` version that is compatible with sliding window attention (`>=2.3.0`). \n+The current implementation supports the sliding window attention mechanism and memory efficient cache management.\n+To enable sliding window attention, just make sure to have a `flash-attn` version that is compatible with sliding window attention (`>=2.3.0`).\n+\n+The sliding window size controls how many previous tokens each position can attend to. For a given token, attention is always allowed to the token itself and up to `sliding_window` preceding tokens. For example, `sliding_window=2` means each position attends to itself and the two previous positions.\n \n The Flash Attention-2 model uses also a more memory efficient cache slicing mechanism - as recommended per the official implementation of Mistral model that use rolling cache mechanism we keep the cache size fixed (`self.config.sliding_window`), support batched generation only for `padding_side=\"left\"` and use the absolute position of the current token to compute the positional embedding.\n \ndiff --git a/src/transformers/modeling_attn_mask_utils.py b/src/transformers/modeling_attn_mask_utils.py\nindex faae0d763f..aa7875e305 100755\n--- a/src/transformers/modeling_attn_mask_utils.py\n+++ b/src/transformers/modeling_attn_mask_utils.py\n@@ -164,7 +164,7 @@ class AttentionMaskConverter:\n \n         # add lower triangular sliding window mask if necessary\n         if sliding_window is not None:\n-            diagonal = past_key_values_length - sliding_window + 1\n+            diagonal = past_key_values_length - sliding_window\n \n             context_mask = 1 - torch.triu(torch.ones_like(mask, dtype=torch.int), diagonal=diagonal)\n             mask.masked_fill_(context_mask.bool(), torch.finfo(dtype).min)\ndiff --git a/src/transformers/models/mistral/configuration_mistral.py b/src/transformers/models/mistral/configuration_mistral.py\nindex a6c4634f61..98f3a797e3 100644\n--- a/src/transformers/models/mistral/configuration_mistral.py\n+++ b/src/transformers/models/mistral/configuration_mistral.py\n@@ -81,7 +81,7 @@ class MistralConfig(PretrainedConfig):\n         rope_theta (`float`, *optional*, defaults to 10000.0):\n             The base period of the RoPE embeddings.\n         sliding_window (`int`, *optional*, defaults to 4096):\n-            Sliding window attention window size. If not specified, will default to `4096`.\n+            Sliding window attention window size. This specifies the number of previous positions each token can attend to; the current token is always included. For example, `sliding_window=2` allows each position to attend to itself and the two preceding positions. If not specified, will default to `4096`.\n         attention_dropout (`float`, *optional*, defaults to 0.0):\n             The dropout ratio for the attention probabilities.\n \ndiff --git a/src/transformers/models/mistral/modeling_mistral.py b/src/transformers/models/mistral/modeling_mistral.py\nindex fbba155f19..54430257ad 100644\n--- a/src/transformers/models/mistral/modeling_mistral.py\n+++ b/src/transformers/models/mistral/modeling_mistral.py\n@@ -1006,6 +1006,7 @@ class MistralModel(MistralPreTrainedModel):\n                 (batch_size, seq_length),\n                 inputs_embeds,\n                 past_key_values_length,\n+                sliding_window=self.config.sliding_window,\n             )\n         else:\n             # 4d mask is passed through the layers\n"}
{"instance_id": "huggingface__transformers-29563", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/mamba/modeling_mamba.py b/src/transformers/models/mamba/modeling_mamba.py\nindex 4870c0281f..8e9f18129b 100644\n--- a/src/transformers/models/mamba/modeling_mamba.py\n+++ b/src/transformers/models/mamba/modeling_mamba.py\n@@ -152,7 +152,8 @@ class MambaMixer(nn.Module):\n                     conv_states = nn.functional.pad(\n                         hidden_states, (self.conv_kernel_size - hidden_states.shape[-1], 0)\n                     )\n-                    cache_params.conv_states[self.layer_idx].copy_(conv_states)\n+                    with torch.no_grad():\n+                        cache_params.conv_states[self.layer_idx].copy_(conv_states.detach())\n                 hidden_states = causal_conv1d_fn(\n                     hidden_states, conv_weights, self.conv1d.bias, activation=self.activation\n                 )\n@@ -195,7 +196,8 @@ class MambaMixer(nn.Module):\n                     return_last_state=True,\n                 )\n                 if ssm_state is not None and cache_params is not None:\n-                    cache_params.ssm_states[self.layer_idx].copy_(ssm_state)\n+                    with torch.no_grad():\n+                        cache_params.ssm_states[self.layer_idx].copy_(ssm_state.detach())\n \n             # 4. Final linear projection\n             contextualized_states = self.out_proj(scan_outputs.transpose(1, 2))\n@@ -214,9 +216,10 @@ class MambaMixer(nn.Module):\n             ssm_state = cache_params.ssm_states[self.layer_idx]\n             if cache_params.seqlen_offset > 0:\n                 conv_state = cache_params.conv_states[self.layer_idx]                   # [batch, intermediate_size, conv_kernel_size]\n-                conv_state = torch.roll(conv_state, shifts=-1, dims=-1)\n-                conv_state[:, :, -1] = hidden_states[:, :, 0]\n-                cache_params.conv_states[self.layer_idx].copy_(conv_state)\n+                with torch.no_grad():\n+                    conv_state = torch.roll(conv_state, shifts=-1, dims=-1)\n+                    conv_state[:, :, -1] = hidden_states[:, :, 0].detach()\n+                    cache_params.conv_states[self.layer_idx].copy_(conv_state)\n                 hidden_states = torch.sum(conv_state * self.conv1d.weight[:, 0, :], dim=-1)\n                 if self.use_conv_bias:\n                     hidden_states += self.conv1d.bias\n@@ -226,7 +229,8 @@ class MambaMixer(nn.Module):\n                     hidden_states,\n                     (self.conv_kernel_size - hidden_states.shape[-1], 0)\n                 )\n-                cache_params.conv_states[self.layer_idx].copy_(conv_state)\n+                with torch.no_grad():\n+                    cache_params.conv_states[self.layer_idx].copy_(conv_state.detach())\n                 hidden_states = self.act(self.conv1d(hidden_states)[..., :seq_len])     # [batch, intermediate_size, seq_len]\n         else:\n             ssm_state = torch.zeros(\n@@ -261,7 +265,8 @@ class MambaMixer(nn.Module):\n         scan_output = (scan_output * self.act(gate))\n \n         if cache_params is not None:\n-            cache_params.ssm_states[self.layer_idx].copy_(ssm_state)\n+            with torch.no_grad():\n+                cache_params.ssm_states[self.layer_idx].copy_(ssm_state.detach())\n \n         # 4. Final linear projection\n         contextualized_states = self.out_proj(scan_output.transpose(1, 2))             # [batch, seq_len, hidden_size]\n@@ -526,6 +531,9 @@ class MambaModel(MambaPreTrainedModel):\n             output_hidden_states if output_hidden_states is not None else self.config.output_hidden_states\n         )\n         use_cache = use_cache if use_cache is not None else (self.config.use_cache if not self.training else False)\n+        # Disable cache when autograd is enabled to avoid in-place writes interfering with gradients\n+        if torch.is_grad_enabled():\n+            use_cache = False\n         return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n \n         if (input_ids is None) ^ (inputs_embeds is not None):  # ^ is python for xor\n"}
{"instance_id": "huggingface__transformers-29675", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/generation/configuration_utils.py b/src/transformers/generation/configuration_utils.py\nindex 974e1452d0..3e62b4d160 100644\n--- a/src/transformers/generation/configuration_utils.py\n+++ b/src/transformers/generation/configuration_utils.py\n@@ -378,6 +378,17 @@ class GenerationConfig(PushToHubMixin):\n         self._commit_hash = kwargs.pop(\"_commit_hash\", None)\n         self.transformers_version = kwargs.pop(\"transformers_version\", __version__)\n \n+        # Strict validation toggle from kwargs or environment variable\n+        strict_validation = kwargs.pop(\"strict_validation\", None)\n+        env_strict = os.environ.get(\"HF_GENERATION_CONFIG_STRICT_INIT\", None)\n+        if strict_validation is None:\n+            strict_on_init = env_strict is not None and str(env_strict).lower() in (\"1\", \"true\", \"yes\")\n+        else:\n+            strict_on_init = (\n+                strict_validation is True\n+                or (isinstance(strict_validation, str) and strict_validation.lower() in (\"1\", \"true\", \"yes\"))\n+            )\n+\n         # Additional attributes without default values\n         if not self._from_model_config:\n             # we don't want to copy values from the model config if we're initializing a `GenerationConfig` from a\n@@ -390,7 +401,11 @@ class GenerationConfig(PushToHubMixin):\n                     raise err\n \n         # Validate the values of the attributes\n-        self.validate(is_init=True)\n+        if strict_on_init:\n+            # Run strict validation that turns warnings into an error to fail fast\n+            self.validate_strict(is_init=True)\n+        else:\n+            self.validate(is_init=True)\n \n     def __hash__(self):\n         return hash(self.to_json_string(ignore_metadata=True))\n@@ -628,6 +643,18 @@ class GenerationConfig(PushToHubMixin):\n                     \"`generate()` (or a pipeline) directly.\"\n                 )\n \n+    def validate_strict(self, is_init: bool = False):\n+        try:\n+            with warnings.catch_warnings(record=True) as caught_warnings:\n+                self.validate(is_init=is_init)\n+            if len(caught_warnings) > 0:\n+                raise ValueError(str([w.message for w in caught_warnings]))\n+        except ValueError as exc:\n+            raise ValueError(\n+                \"The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. \"\n+                \"Fix these issues before proceeding.\\n\\nThrown during validation:\\n\" + str(exc)\n+            )\n+\n     def save_pretrained(\n         self,\n         save_directory: Union[str, os.PathLike],\n@@ -884,10 +911,34 @@ class GenerationConfig(PushToHubMixin):\n         if kwargs.get(\"return_unused_kwargs\") is True:\n             config, unused_kwargs = cls.from_dict(config_dict, **kwargs)\n             config._original_object_hash = hash(config)  # Hash to detect whether the instance was modified\n+            # Early strict validation option for from_pretrained\n+            env_strict = os.environ.get(\"HF_GENERATION_CONFIG_STRICT_INIT\", None)\n+            strict_validation = kwargs.get(\"strict_validation\", None)\n+            if strict_validation is None:\n+                strict_on_load = env_strict is not None and str(env_strict).lower() in (\"1\", \"true\", \"yes\")\n+            else:\n+                strict_on_load = (\n+                    strict_validation is True\n+                    or (isinstance(strict_validation, str) and strict_validation.lower() in (\"1\", \"true\", \"yes\"))\n+                )\n+            if strict_on_load:\n+                config.validate_strict(is_init=True)\n             return config, unused_kwargs\n         else:\n             config = cls.from_dict(config_dict, **kwargs)\n             config._original_object_hash = hash(config)  # Hash to detect whether the instance was modified\n+            # Early strict validation option for from_pretrained\n+            env_strict = os.environ.get(\"HF_GENERATION_CONFIG_STRICT_INIT\", None)\n+            strict_validation = kwargs.get(\"strict_validation\", None)\n+            if strict_validation is None:\n+                strict_on_load = env_strict is not None and str(env_strict).lower() in (\"1\", \"true\", \"yes\")\n+            else:\n+                strict_on_load = (\n+                    strict_validation is True\n+                    or (isinstance(strict_validation, str) and strict_validation.lower() in (\"1\", \"true\", \"yes\"))\n+                )\n+            if strict_on_load:\n+                config.validate_strict(is_init=True)\n             return config\n \n     @classmethod\ndiff --git a/src/transformers/modeling_utils.py b/src/transformers/modeling_utils.py\nindex 2868343bfc..45ee85c478 100644\n--- a/src/transformers/modeling_utils.py\n+++ b/src/transformers/modeling_utils.py\n@@ -3563,12 +3563,18 @@ class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix\n                     subfolder=subfolder,\n                     _from_auto=from_auto_class,\n                     _from_pipeline=from_pipeline,\n+                    strict_validation=os.environ.get(\"HF_GENERATION_CONFIG_STRICT_INIT\", None),\n                     **kwargs,\n                 )\n             except OSError:\n                 logger.info(\n                     \"Generation config file not found, using a generation config created from the model config.\"\n                 )\n+                # Validate early if strict init is enabled\n+                env_strict = os.environ.get(\"HF_GENERATION_CONFIG_STRICT_INIT\", None)\n+                if env_strict is not None and str(env_strict).lower() in (\"1\", \"true\", \"yes\"):\n+                    model.generation_config = GenerationConfig.from_model_config(model.config)\n+                    model.generation_config.validate_strict(is_init=True)\n                 pass\n \n         # Dispatch model with hooks on all devices if necessary\ndiff --git a/src/transformers/trainer.py b/src/transformers/trainer.py\nindex f40645d3ac..c82c209aa9 100755\n--- a/src/transformers/trainer.py\n+++ b/src/transformers/trainer.py\n@@ -499,6 +499,20 @@ class Trainer:\n         self.model_wrapped = model\n         self.model = model\n \n+        # Early validation of generation_config to fail fast if enabled\n+        try:\n+            env_strict = os.environ.get(\"HF_GENERATION_CONFIG_EARLY_VALIDATION\", None)\n+            if env_strict is not None and str(env_strict).lower() in (\"1\", \"true\", \"yes\"):\n+                if hasattr(self.model, \"can_generate\") and self.model.can_generate():\n+                    gen_cfg = getattr(self.model, \"generation_config\", None)\n+                    if gen_cfg is not None:\n+                        gen_cfg.validate_strict(is_init=True)\n+        except ValueError as exc:\n+            raise ValueError(\n+                \"Invalid generation configuration detected during Trainer initialization. \"\n+                \"Fix these issues before starting training.\\n\\nThrown during validation:\\n\" + str(exc)\n+            )\n+\n         self.neftune_noise_alpha = args.neftune_noise_alpha\n \n         self.compute_metrics = compute_metrics\n"}
{"instance_id": "huggingface__transformers-30556", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/en/main_classes/data_collator.md b/docs/source/en/main_classes/data_collator.md\nindex 74e653dd11..f2aa9fb698 100644\n--- a/docs/source/en/main_classes/data_collator.md\n+++ b/docs/source/en/main_classes/data_collator.md\n@@ -46,6 +46,13 @@ Examples of use can be found in the [example scripts](../examples) or [example n\n \n [[autodoc]] data.data_collator.DataCollatorForSeq2Seq\n \n+Note: Labels are padded by this collator before calling the tokenizer pad method, since `tokenizer.pad` does not handle\n+labels. The label padding follows the `padding` strategy:\n+- When `padding='max_length'` and `max_length` is provided, labels are padded to `max_length` (subject to `pad_to_multiple_of`).\n+- When `padding=True` or `padding='longest'`, labels are padded to the longest label length in the batch (subject to `pad_to_multiple_of`).\n+- When `padding=False` or `padding='do_not_pad'`, inputs are not padded, but labels are still padded to the longest label\n+  length in the batch to allow tensorization.\n+\n ## DataCollatorForLanguageModeling\n \n [[autodoc]] data.data_collator.DataCollatorForLanguageModeling\ndiff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex b81e1f1757..376c04b153 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -589,17 +589,39 @@ class DataCollatorForSeq2Seq:\n         # We have to pad the labels before calling `tokenizer.pad` as this method won't pad them and needs them of the\n         # same length to return tensors.\n         if labels is not None:\n+            # Determine target label length based on padding strategy\n             max_label_length = max(len(l) for l in labels)\n-            if self.pad_to_multiple_of is not None:\n-                max_label_length = (\n-                    (max_label_length + self.pad_to_multiple_of - 1)\n+            # Map padding arg to a PaddingStrategy\n+            if self.padding is True:\n+                padding_strategy = PaddingStrategy.LONGEST\n+            elif self.padding is False:\n+                padding_strategy = PaddingStrategy.DO_NOT_PAD\n+            elif isinstance(self.padding, str):\n+                padding_strategy = PaddingStrategy(self.padding)\n+            elif isinstance(self.padding, PaddingStrategy):\n+                padding_strategy = self.padding\n+            else:\n+                padding_strategy = PaddingStrategy.LONGEST\n+\n+            if padding_strategy == PaddingStrategy.MAX_LENGTH:\n+                target_label_length = self.max_length if self.max_length is not None else getattr(self.tokenizer, \"model_max_length\", None)\n+                if target_label_length is None:\n+                    target_label_length = max_label_length\n+            else:\n+                # For LONGEST and DO_NOT_PAD, pad labels to longest length in batch to enable tensorization\n+                target_label_length = max_label_length\n+\n+            if self.pad_to_multiple_of is not None and target_label_length is not None:\n+                target_label_length = (\n+                    (target_label_length + self.pad_to_multiple_of - 1)\n                     // self.pad_to_multiple_of\n                     * self.pad_to_multiple_of\n                 )\n \n             padding_side = self.tokenizer.padding_side\n             for feature in features:\n-                remainder = [self.label_pad_token_id] * (max_label_length - len(feature[\"labels\"]))\n+                pad_length = max(target_label_length - len(feature[\"labels\"]), 0)\n+                remainder = [self.label_pad_token_id] * pad_length\n                 if isinstance(feature[\"labels\"], list):\n                     feature[\"labels\"] = (\n                         feature[\"labels\"] + remainder if padding_side == \"right\" else remainder + feature[\"labels\"]\n"}
{"instance_id": "huggingface__transformers-30602", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/modeling_utils.py b/src/transformers/modeling_utils.py\nindex 1ed8040f88..6de36bfe74 100644\n--- a/src/transformers/modeling_utils.py\n+++ b/src/transformers/modeling_utils.py\n@@ -2755,6 +2755,9 @@ class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix\n                     - A path or url to a model folder containing a *flax checkpoint file* in *.msgpack* format (e.g,\n                       `./flax_model/` containing `flax_model.msgpack`). In this case, `from_flax` should be set to\n                       `True`.\n+                    - A path or url to a model folder containing a *safetensors checkpoint file* (e.g., `./model/` containing\n+                      `model.safetensors`). In this case, `use_safetensors` should be left as default (`None`) or set to `True`,\n+                      and the `safetensors` library must be installed.\n                     - `None` if you are both providing the configuration and state dictionary (resp. with keyword\n                       arguments `config` and `state_dict`).\n             model_args (sequence of positional arguments, *optional*):\n@@ -3262,10 +3265,17 @@ class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix\n                         f\" {pretrained_model_name_or_path}.\"\n                     )\n                 else:\n+                    expected_files = [\n+                        _add_variant(WEIGHTS_NAME, variant),\n+                        TF2_WEIGHTS_NAME,\n+                        TF_WEIGHTS_NAME + \".index\",\n+                        FLAX_WEIGHTS_NAME,\n+                    ]\n+                    if use_safetensors is not False and is_safetensors_available():\n+                        expected_files.insert(0, _add_variant(SAFE_WEIGHTS_NAME, variant))\n+                    expected_str = \", \".join(expected_files[:-1]) + f\" or {expected_files[-1]}\"\n                     raise EnvironmentError(\n-                        f\"Error no file named {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME},\"\n-                        f\" {TF_WEIGHTS_NAME + '.index'} or {FLAX_WEIGHTS_NAME} found in directory\"\n-                        f\" {pretrained_model_name_or_path}.\"\n+                        f\"Error no file named {expected_str} found in directory {pretrained_model_name_or_path}.\"\n                     )\n             elif os.path.isfile(os.path.join(subfolder, pretrained_model_name_or_path)):\n                 archive_file = pretrained_model_name_or_path\n@@ -3408,10 +3418,17 @@ class PreTrainedModel(nn.Module, ModuleUtilsMixin, GenerationMixin, PushToHubMix\n                                 f\" {variant}. Use `variant=None` to load this model from those weights.\"\n                             )\n                         else:\n+                            expected_files = [\n+                                _add_variant(WEIGHTS_NAME, variant),\n+                                TF2_WEIGHTS_NAME,\n+                                TF_WEIGHTS_NAME,\n+                                FLAX_WEIGHTS_NAME,\n+                            ]\n+                            if use_safetensors is not False and is_safetensors_available():\n+                                expected_files.insert(0, _add_variant(SAFE_WEIGHTS_NAME, variant))\n+                            expected_str = \", \".join(expected_files[:-1]) + f\" or {expected_files[-1]}\"\n                             raise EnvironmentError(\n-                                f\"{pretrained_model_name_or_path} does not appear to have a file named\"\n-                                f\" {_add_variant(WEIGHTS_NAME, variant)}, {TF2_WEIGHTS_NAME}, {TF_WEIGHTS_NAME} or\"\n-                                f\" {FLAX_WEIGHTS_NAME}.\"\n+                                f\"{pretrained_model_name_or_path} does not appear to have a file named {expected_str}.\"\n                             )\n                 except EnvironmentError:\n                     # Raise any environment error raise by `cached_file`. It will have a helpful error message adapted\n"}
{"instance_id": "huggingface__transformers-29688", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/whisper/generation_whisper.py b/src/transformers/models/whisper/generation_whisper.py\nindex b3865140f2..c579b1c7b6 100644\n--- a/src/transformers/models/whisper/generation_whisper.py\n+++ b/src/transformers/models/whisper/generation_whisper.py\n@@ -262,7 +262,7 @@ class WhisperGenerationMixin:\n         synced_gpus: bool = False,\n         return_timestamps: Optional[bool] = None,\n         task: Optional[str] = None,\n-        language: Optional[str] = None,\n+        language: Optional[Union[str, List[str]]] = None,\n         is_multilingual: Optional[bool] = None,\n         prompt_ids: Optional[torch.Tensor] = None,\n         prompt_condition_type: Optional[str] = None,  # first-segment, all-segments\n@@ -329,10 +329,11 @@ class WhisperGenerationMixin:\n             task (`str`, *optional*):\n                 Task to use for generation, either \"translate\" or \"transcribe\". The `model.config.forced_decoder_ids`\n                 will be updated accordingly.\n-            language (`str`, *optional*):\n-                Language token to use for generation, can be either in the form of `<|en|>`, `en` or `english`. You can\n-                find all the possible language tokens in the `model.generation_config.lang_to_id` dictionary.\n-            is_multilingual (`bool`, *optional*):\n+            language (`str` or `List[str]`, *optional*):\n+                Language token(s) to use for generation. Can be either in the form of `<|en|>`, `en` or `english`. When\n+                passing a list, its length must match the batch size, allowing each item in the batch to use its own\n+                language. You can find all the possible language tokens in the `model.generation_config.lang_to_id`\n+                dictionary.            is_multilingual (`bool`, *optional*):\n                 Whether or not the model is multilingual.\n             prompt_ids (`torch.Tensor`, *optional*):\n                 Rank-1 tensor of token IDs created by passing text to [`~WhisperProcessor.get_prompt_ids`] that is\n@@ -555,8 +556,14 @@ class WhisperGenerationMixin:\n \n             decoder_input_ids = kwargs.pop(\"decoder_input_ids\", None)\n             if decoder_input_ids is None:\n-                one_tensor = torch.ones((batch_size, 1), device=self.device, dtype=torch.long)\n-                decoder_input_ids = torch.cat([t * one_tensor for t in init_tokens], dim=-1)\n+                columns = []\n+                for t in init_tokens:\n+                    if torch.is_tensor(t):\n+                        col = t.to(self.device)\n+                    else:\n+                        col = torch.ones((batch_size, 1), device=self.device, dtype=torch.long) * t\n+                    columns.append(col)\n+                decoder_input_ids = torch.cat(columns, dim=-1)\n \n             if prompt_ids is not None:\n                 decoder_input_ids = torch.cat(\n@@ -1070,8 +1077,13 @@ class WhisperGenerationMixin:\n                     \"to `generate`. Either set the language using the `forced_decoder_ids` in the model config, \"\n                     \"or update the generation config as per the instructions https://github.com/huggingface/transformers/issues/25084#issuecomment-1664398224\"\n                 )\n-            language = language.lower()\n-            generation_config.language = language\n+            if isinstance(language, list):\n+                generation_config.language_list = [l.lower() for l in language]\n+                # Ensure we don't also set a single language string\n+                generation_config.language = None\n+            else:\n+                language = language.lower()\n+                generation_config.language = language\n \n         if task is not None:\n             if not hasattr(generation_config, \"task_to_id\"):\n@@ -1093,7 +1105,9 @@ class WhisperGenerationMixin:\n             return lst\n \n         task = getattr(generation_config, \"task\", None)\n+        # Accept both single language and list of languages\n         language = getattr(generation_config, \"language\", None)\n+        language_list = getattr(generation_config, \"language_list\", None)\n \n         forced_decoder_ids = generation_config.forced_decoder_ids\n         if forced_decoder_ids is not None:\n@@ -1110,9 +1124,9 @@ class WhisperGenerationMixin:\n                 f\"You have passed task={task}, but also have set `forced_decoder_ids` to {forced_decoder_ids} which creates a conflict. `forced_decoder_ids` will be ignored in favor of task={task}.\"\n             )\n             forced_decoder_ids = None\n-        elif forced_decoder_ids is not None and language is not None:\n+        elif forced_decoder_ids is not None and (language is not None or getattr(generation_config, \"language_ids\", None) is not None):\n             logger.info(\n-                f\"You have passed language={language}, but also have set `forced_decoder_ids` to {forced_decoder_ids} which creates a conflict. `forced_decoder_ids` will be ignored in favor of language={language}.\"\n+                f\"You have specified a language for generation, but also have set `forced_decoder_ids` to {forced_decoder_ids} which creates a conflict. `forced_decoder_ids` will be ignored in favor of the specified language.\"\n             )\n             forced_decoder_ids = None\n \n@@ -1133,7 +1147,35 @@ class WhisperGenerationMixin:\n         generation_config.forced_decoder_ids = None\n \n         is_lang_id_undefined = len(init_tokens) <= 1 or (len(init_tokens) > 1 and init_tokens[1] is None)\n-        if language is not None:\n+        if language_list is not None:\n+            # Per-item languages: build a tensor of lang_ids\n+            lang_ids = []\n+            for language in language_list:\n+                if language in generation_config.lang_to_id.keys():\n+                    language_token = language\n+                elif language in TO_LANGUAGE_CODE.keys():\n+                    language_token = f\"<|{TO_LANGUAGE_CODE[language]}|>\"\n+                elif language in TO_LANGUAGE_CODE.values():\n+                    language_token = f\"<|{language}|>\"\n+                else:\n+                    is_language_code = len(language) == 2\n+                    raise ValueError(\n+                        f\"Unsupported language: {language}. Language should be one of:\"\n+                        f\" {list(TO_LANGUAGE_CODE.values()) if is_language_code else list(TO_LANGUAGE_CODE.keys())}.\"\n+                    )\n+                if language_token not in generation_config.lang_to_id:\n+                    raise ValueError(\n+                        f\"{language_token} is not supported by this specific model as it is not in the `generation_config.lang_to_id`.\"\n+                        \"(You should just add it to the generation config)\"\n+                    )\n+                lang_ids.append(generation_config.lang_to_id[language_token])\n+            lang_ids_tensor = torch.tensor(lang_ids, dtype=torch.long, device=self.device).view(-1, 1)\n+            # Overwrite language ids in init tokens\n+            if len(init_tokens) > 1:\n+                init_tokens[1] = lang_ids_tensor\n+            else:\n+                init_tokens.append(lang_ids_tensor)\n+        elif language is not None:\n             if language in generation_config.lang_to_id.keys():\n                 language_token = language\n             elif language in TO_LANGUAGE_CODE.keys():\n@@ -1157,7 +1199,7 @@ class WhisperGenerationMixin:\n             # if language is defined it'll overwrite language ids that might have already been defined via the generation_config\n             replace_or_add(init_tokens, lang_id, generation_config.lang_to_id.values())\n         elif hasattr(generation_config, \"lang_to_id\") and is_lang_id_undefined:\n-            # language is not defined or intentially set to `None` to trigger language detection\n+            # language is not defined or intentionally set to `None` to trigger language detection\n             lang_ids = self.detect_language(\n                 input_features=input_features,\n                 encoder_outputs=kwargs.get(\"encoder_outputs\", None),\n@@ -1165,18 +1207,14 @@ class WhisperGenerationMixin:\n                 num_segment_frames=num_segment_frames,\n             )\n \n-            if torch.unique(lang_ids).shape[0] > 1:\n-                raise ValueError(\n-                    \"Multiple languages detected when trying to predict the most likely target language for transcription. It is currently not supported to transcribe to different languages in a single batch. Please make sure to either force a single language by passing `language='...'` or make sure all input audio is of the same language.\"\n-                )\n-\n-            lang_id = lang_ids[0].item()\n+            # Allow mixed-language batches: use per-item detected language ids\n+            lang_ids_tensor = lang_ids.to(self.device).view(-1, 1)\n \n             # append or replace lang_id to init_tokens\n             if len(init_tokens) > 1:\n-                init_tokens[1] = lang_id\n+                init_tokens[1] = lang_ids_tensor\n             else:\n-                init_tokens.append(lang_id)\n+                init_tokens.append(lang_ids_tensor)\n \n         if task is not None:\n             if task in TASK_IDS:\n@@ -1458,8 +1496,19 @@ class WhisperGenerationMixin:\n     ):\n         cut_off_length = config.max_target_positions // 2 - 1\n \n-        one_tensor = torch.ones((cur_bsz, 1), device=device, dtype=torch.long)\n-        decoder_input_ids = torch.cat([t * one_tensor for t in init_tokens], dim=-1)\n+        columns = []\n+        for t in init_tokens:\n+            if torch.is_tensor(t):\n+                # If per-item language ids were provided/detected, select according to current batch map\n+                if t.shape[0] != cur_bsz:\n+                    # In long-form, batch can be reduced, so we need to index using batch_idx_map\n+                    indexed = torch.stack([t[bi] for bi in batch_idx_map], dim=0).to(device)\n+                else:\n+                    indexed = t.to(device)\n+                columns.append(indexed)\n+            else:\n+                columns.append(torch.ones((cur_bsz, 1), device=device, dtype=torch.long) * t)\n+        decoder_input_ids = torch.cat(columns, dim=-1)\n \n         prev_start_of_text = getattr(generation_config, \"prev_sot_token_id\", None)\n         if prev_start_of_text is None:\ndiff --git a/src/transformers/pipelines/automatic_speech_recognition.py b/src/transformers/pipelines/automatic_speech_recognition.py\nindex de1a9b57ac..a682beac9e 100644\n--- a/src/transformers/pipelines/automatic_speech_recognition.py\n+++ b/src/transformers/pipelines/automatic_speech_recognition.py\n@@ -12,7 +12,7 @@\n # See the License for the specific language governing permissions and\n # limitations under the License.\n from collections import defaultdict\n-from typing import TYPE_CHECKING, Dict, Optional, Union\n+from typing import TYPE_CHECKING, Dict, Optional, Union, List\n \n import numpy as np\n import requests\n@@ -294,6 +294,7 @@ class AutomaticSpeechRecognitionPipeline(ChunkPipeline):\n         return_language=None,\n         generate_kwargs=None,\n         max_new_tokens=None,\n+        language: Optional[Union[str, List[str]]] = None,\n     ):\n         # No parameters on this pipeline right now\n         preprocess_params = {}\n@@ -319,6 +320,8 @@ class AutomaticSpeechRecognitionPipeline(ChunkPipeline):\n                     \" only 1 version\"\n                 )\n             forward_params.update(generate_kwargs)\n+        if language is not None:\n+            forward_params[\"language\"] = language\n \n         postprocess_params = {}\n         if decoder_kwargs is not None:\n"}
{"instance_id": "huggingface__transformers-30899", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/generation/configuration_utils.py b/src/transformers/generation/configuration_utils.py\nindex 9a5fee5207..c4ab074de1 100644\n--- a/src/transformers/generation/configuration_utils.py\n+++ b/src/transformers/generation/configuration_utils.py\n@@ -275,7 +275,7 @@ class GenerationConfig(PushToHubMixin):\n         decoder_start_token_id (`Union[int, List[int]]`, *optional*):\n             If an encoder-decoder model starts decoding with a different token than *bos*, the id of that token or a list of length\n             `batch_size`. Indicating a list enables different start ids for each element in the batch\n-            (e.g. multilingual models with different target languages in one batch)\n+            (e.g. multilingual models with different target languages in one batch). For T5-family models, this defaults to the pad token (`pad_token_id`) when not explicitly provided.\n \n         > Generation parameters exclusive to assistant generation\n \ndiff --git a/src/transformers/generation/utils.py b/src/transformers/generation/utils.py\nindex 4b71fe9519..d030df421e 100644\n--- a/src/transformers/generation/utils.py\n+++ b/src/transformers/generation/utils.py\n@@ -1378,11 +1378,23 @@ class GenerationMixin:\n                 return token\n             return torch.tensor(token, device=device, dtype=torch.long)\n \n-        bos_token_id = _tensor_or_none(generation_config.bos_token_id, device=device)\n-        eos_token_id = _tensor_or_none(generation_config.eos_token_id, device=device)\n-        pad_token_id = _tensor_or_none(generation_config.pad_token_id, device=device)\n-        decoder_start_token_id = _tensor_or_none(generation_config.decoder_start_token_id, device=device)\n-        decoder_start_token_id = decoder_start_token_id if decoder_start_token_id is not None else bos_token_id\n+        # Merge generation_config special tokens with model defaults when missing\n+        bos_token_id_raw = generation_config.bos_token_id if generation_config.bos_token_id is not None else getattr(self.config, \"bos_token_id\", None)\n+        eos_token_id_raw = generation_config.eos_token_id if generation_config.eos_token_id is not None else getattr(self.config, \"eos_token_id\", None)\n+        pad_token_id_raw = generation_config.pad_token_id if generation_config.pad_token_id is not None else getattr(self.config, \"pad_token_id\", None)\n+        decoder_start_token_id_raw = generation_config.decoder_start_token_id if generation_config.decoder_start_token_id is not None else getattr(self.config, \"decoder_start_token_id\", None)\n+\n+        bos_token_id = _tensor_or_none(bos_token_id_raw, device=device)\n+        eos_token_id = _tensor_or_none(eos_token_id_raw, device=device)\n+        pad_token_id = _tensor_or_none(pad_token_id_raw, device=device)\n+        decoder_start_token_id = _tensor_or_none(decoder_start_token_id_raw, device=device)\n+\n+        # Fallbacks: if decoder_start_token_id is still None, prefer BOS; for T5-family fallback to PAD\n+        if decoder_start_token_id is None:\n+            if bos_token_id is not None:\n+                decoder_start_token_id = bos_token_id\n+            elif getattr(self.config, \"model_type\", None) in [\"t5\", \"mt5\"] and pad_token_id is not None:\n+                decoder_start_token_id = pad_token_id\n \n         # We can have more than one eos token. Always treat it as a 1D tensor (when it exists).\n         if eos_token_id is not None and eos_token_id.ndim == 0:\ndiff --git a/src/transformers/models/t5/configuration_t5.py b/src/transformers/models/t5/configuration_t5.py\nindex eec47e5eb2..856c43b0de 100644\n--- a/src/transformers/models/t5/configuration_t5.py\n+++ b/src/transformers/models/t5/configuration_t5.py\n@@ -129,10 +129,14 @@ class T5Config(PretrainedConfig):\n         if feed_forward_proj == \"gated-gelu\":\n             self.dense_act_fn = \"gelu_new\"\n \n+        # Ensure decoder_start_token_id defaults to pad_token_id for T5 if not provided\n+        decoder_start_token_id = kwargs.pop(\"decoder_start_token_id\", pad_token_id)\n+\n         super().__init__(\n             pad_token_id=pad_token_id,\n             eos_token_id=eos_token_id,\n             is_encoder_decoder=is_encoder_decoder,\n+            decoder_start_token_id=decoder_start_token_id,\n             **kwargs,\n         )\n \n"}
{"instance_id": "huggingface__transformers-30934", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex 016fae4405..6679427254 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -489,12 +489,13 @@ def center_crop(\n     right_pad = left_pad + orig_width\n     new_image[..., top_pad:bottom_pad, left_pad:right_pad] = image\n \n-    top += top_pad\n-    bottom += top_pad\n-    left += left_pad\n-    right += left_pad\n+    # Recompute crop indices relative to the padded canvas to avoid floor division issues on negative values\n+    top = (new_height - crop_height) // 2\n+    bottom = top + crop_height\n+    left = (new_width - crop_width) // 2\n+    right = left + crop_width\n \n-    new_image = new_image[..., max(0, top) : min(new_height, bottom), max(0, left) : min(new_width, right)]\n+    new_image = new_image[..., top:bottom, left:right]\n     new_image = to_channel_dimension_format(new_image, output_data_format, ChannelDimension.FIRST)\n \n     if not return_numpy:\n"}
{"instance_id": "huggingface__transformers-31217", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/en/main_classes/pipelines.md b/docs/source/en/main_classes/pipelines.md\nindex 1e8f93f3ba..df5e3608ea 100644\n--- a/docs/source/en/main_classes/pipelines.md\n+++ b/docs/source/en/main_classes/pipelines.md\n@@ -57,6 +57,26 @@ To call a pipeline on many items, you can call it with a *list*.\n  {'label': 'NEGATIVE', 'score': 0.9996669292449951}]\n ```\n \n+For multimodal pipelines like visual question answering, you can pass lists to broadcast inputs:\n+\n+```python\n+>>> vqa = pipeline(\"visual-question-answering\", model=\"dandelin/vilt-b32-finetuned-vqa\")\n+>>> urls = [\n+...     \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\",\n+...     \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/tree.png\",\n+... ]\n+>>> vqa(image=urls, question=\"What's in the image?\", top_k=1)\n+# [{'score': ..., 'answer': ...}, {'score': ..., 'answer': ...}]\n+\n+>>> # Or broadcast a single image over multiple questions\n+>>> vqa(image=urls[0], question=[\"What's in the image?\", \"Is this a tree?\"], top_k=1)\n+# [{'score': ..., 'answer': ...}, {'score': ..., 'answer': ...}]\n+\n+>>> # Or pass pairwise lists of equal length\n+>>> vqa(image=urls, question=[\"What's in the image?\", \"Is this a tree?\"], top_k=1)\n+# [{'score': ..., 'answer': ...}, {'score': ..., 'answer': ...}]\n+```\n+\n To iterate over full datasets it is recommended to use a `dataset` directly. This means you don't need to allocate\n the whole dataset at once, nor do you need to do batching yourself. This should work just as fast as custom loops on\n GPU. If it doesn't don't hesitate to create an issue.\ndiff --git a/docs/source/en/tasks/visual_question_answering.md b/docs/source/en/tasks/visual_question_answering.md\nindex c45f12dbc1..bde8fcad0e 100644\n--- a/docs/source/en/tasks/visual_question_answering.md\n+++ b/docs/source/en/tasks/visual_question_answering.md\n@@ -322,6 +322,21 @@ learned something from the data and take the first example from the dataset to i\n [{'score': 0.5498199462890625, 'answer': 'down'}]\n ```\n \n+You can also pass lists to broadcast questions over multiple images or vice versa:\n+\n+```py\n+>>> urls = [\n+...     \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/parrots.png\",\n+...     \"https://huggingface.co/datasets/Narsil/image_dummy/raw/main/tree.png\",\n+... ]\n+>>> pipe(image=urls, question=\"What's in the image?\", top_k=1)\n+\n+>>> pipe(image=image, question=[\"Where is he looking?\", \"Is he skating?\"], top_k=1)\n+\n+>>> # Pairwise lists of equal length are also supported\n+>>> pipe(image=[image, image], question=[\"Where is he looking?\", \"Is he skating?\"], top_k=1)\n+```\n+\n Even though not very confident, the model indeed has learned something. With more examples and longer training, you'll get far better results!\n \n You can also manually replicate the results of the pipeline if you'd like:\ndiff --git a/src/transformers/pipelines/visual_question_answering.py b/src/transformers/pipelines/visual_question_answering.py\nindex 9106b19d33..298b4729ba 100644\n--- a/src/transformers/pipelines/visual_question_answering.py\n+++ b/src/transformers/pipelines/visual_question_answering.py\n@@ -98,23 +98,46 @@ class VisualQuestionAnsweringPipeline(Pipeline):\n         Return:\n             A dictionary or a list of dictionaries containing the result. The dictionaries contain the following keys:\n \n-            - **label** (`str`) -- The label identified by the model.\n-            - **score** (`int`) -- The score attributed by the model for that label.\n+            - **answer** (`str`) -- The answer identified by the model.\n+            - **score** (`float`) -- The score attributed by the model for that answer.\n         \"\"\"\n-        if isinstance(image, (Image.Image, str)) and isinstance(question, str):\n-            inputs = {\"image\": image, \"question\": question}\n-        else:\n-            \"\"\"\n-            Supports the following format\n-            - {\"image\": image, \"question\": question}\n-            - [{\"image\": image, \"question\": question}]\n-            - Generator and datasets\n-            \"\"\"\n+        # Normalize inputs to support broadcasting between images and questions.\n+        # Accept a single image/question, a dict or list of dicts, or lists of images/questions.\n+        if isinstance(image, dict):\n             inputs = image\n+        elif isinstance(image, list):\n+            # List input: can be a list of dicts or a list of images.\n+            if len(image) == 0:\n+                inputs = []\n+            elif isinstance(image[0], dict):\n+                inputs = image\n+            else:\n+                if question is None:\n+                    raise ValueError(\"When providing a list of images, you must also provide a question.\")\n+                if isinstance(question, list):\n+                    if len(question) != len(image):\n+                        raise ValueError(\n+                            \"When providing a list of images and a list of questions, both lists must have the same length.\"\n+                        )\n+                    inputs = [{\"image\": img, \"question\": q} for img, q in zip(image, question)]\n+                else:\n+                    inputs = [{\"image\": img, \"question\": question} for img in image]\n+        else:\n+            # Scalar image input (str or PIL.Image)\n+            if isinstance(question, list):\n+                inputs = [{\"image\": image, \"question\": q} for q in question]\n+            elif isinstance(question, str):\n+                inputs = {\"image\": image, \"question\": question}\n+            else:\n+                raise ValueError(\"You must provide a 'question' when calling the visual question answering pipeline.\")\n         results = super().__call__(inputs, **kwargs)\n         return results\n \n     def preprocess(self, inputs, padding=False, truncation=False, timeout=None):\n+        if not isinstance(inputs, dict) or \"image\" not in inputs or \"question\" not in inputs:\n+            raise ValueError(\n+                \"Each input to the visual question answering pipeline must be a dict with 'image' and 'question' keys.\"\n+            )\n         image = load_image(inputs[\"image\"], timeout=timeout)\n         model_inputs = self.tokenizer(\n             inputs[\"question\"], return_tensors=self.framework, padding=padding, truncation=truncation\n"}
{"instance_id": "huggingface__transformers-31448", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/generation/configuration_utils.py b/src/transformers/generation/configuration_utils.py\nindex 0e15014b34..625014653b 100644\n--- a/src/transformers/generation/configuration_utils.py\n+++ b/src/transformers/generation/configuration_utils.py\n@@ -115,7 +115,9 @@ class GenerationConfig(PushToHubMixin):\n             The maximum amount of time you allow the computation to run for in seconds. generation will still finish\n             the current pass after allocated time has been passed.\n         stop_strings(`str or List[str]`, *optional*):\n-            A string or a list of strings that should terminate generation if the model outputs them.\n+            A string or a list of strings that should terminate generation if the model outputs them. If a provided stop\n+            string cannot be matched by the tokenizer's tokenization (e.g., due to leading-space semantics), generation\n+            will proceed normally and the stop condition will simply never trigger; no error is raised.\n \n         > Parameters that control the generation strategy used\n \ndiff --git a/src/transformers/generation/stopping_criteria.py b/src/transformers/generation/stopping_criteria.py\nindex 9cc485e460..45a6b7844d 100644\n--- a/src/transformers/generation/stopping_criteria.py\n+++ b/src/transformers/generation/stopping_criteria.py\n@@ -285,7 +285,7 @@ class StopStringCriteria(StoppingCriteria):\n         # We don't use the tokenizer in the cache key, because I don't trust it to have well-behaved equality\n         if (token_list, token_indices, stop_strings) in STOP_STRING_EMBEDDING_CACHE:\n             embedding_vec, max_valid_positions, max_valid_end_lens = STOP_STRING_EMBEDDING_CACHE[\n-                (token_list, token_indices, self.stop_strings)\n+                (token_list, token_indices, stop_strings)\n             ]\n             STOP_STRING_EMBEDDING_CACHE.move_to_end((token_list, token_indices, stop_strings))\n         else:\n@@ -373,10 +373,11 @@ class StopStringCriteria(StoppingCriteria):\n             token_list, token_indices, stop_strings\n         )\n \n-        max_valid_positions = max(\n-            len(val) for positions in token_valid_positions.values() for val in positions.values()\n-        )\n-        max_valid_end_lens = max(len(val) for positions in token_end_overlaps.values() for val in positions.values())\n+        # Compute the maximum sizes, guarding against the case where there are no valid positions or end overlaps\n+        positions_values = [len(val) for positions in token_valid_positions.values() for val in positions.values()]\n+        end_lens_values = [len(val) for positions in token_end_overlaps.values() for val in positions.values()]\n+        max_valid_positions = max(positions_values) if positions_values else 0\n+        max_valid_end_lens = max(end_lens_values) if end_lens_values else 0\n         vec_size = len(stop_strings) * (max_valid_positions + max_valid_end_lens) + 1\n         gather_vec = np.full((len(token_list), vec_size), dtype=np.int32, fill_value=-1)\n \n@@ -422,6 +423,10 @@ class StopStringCriteria(StoppingCriteria):\n         # The embedding vec contains the valid positions, end_lengths and total lengths for each token\n         embedded = F.embedding(flipped_ids, self.embedding_vec)\n \n+        # If there are no possible end overlaps, stop strings can never match; return all False early\n+        if self.max_valid_end_lens == 0:\n+            return torch.zeros((input_ids.shape[0],), dtype=torch.bool, device=input_ids.device)\n+\n         # Now we split the embedding vector. valid_positions is the positions in the stop string the token can fit\n         valid_positions = embedded[:, 1:, : max_valid_positions * self.num_stop_strings].unflatten(\n             -1, (self.num_stop_strings, -1)\n"}
{"instance_id": "huggingface__transformers-30964", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/en/model_doc/llama.md b/docs/source/en/model_doc/llama.md\nindex 2f0eb63da0..594dcdcef9 100644\n--- a/docs/source/en/model_doc/llama.md\n+++ b/docs/source/en/model_doc/llama.md\n@@ -50,6 +50,8 @@ come in several checkpoints they each contain a part of each weight of the model\n \n - The LLaMA tokenizer is a BPE model based on [sentencepiece](https://github.com/google/sentencepiece). One quirk of sentencepiece is that when decoding a sequence, if the first token is the start of the word (e.g. \"Banana\"), the tokenizer does not prepend the prefix space to the string.\n \n+- Important: The `add_prefix_space` flag only takes effect when using the non-legacy behavior (`legacy=False`). Under the default legacy behavior (`legacy=True`), SentencePiece's dummy prefix remains active and the leading underline (``) may appear regardless of `add_prefix_space`. For `LlamaTokenizerFast`, passing `add_prefix_space` will set `from_slow=True` internally, but you should also set `legacy=False` for the flag to be respected.\n+\n This model was contributed by [zphang](https://huggingface.co/zphang) with contributions from [BlackSamorez](https://huggingface.co/BlackSamorez). The code of the implementation in Hugging Face is based on GPT-NeoX [here](https://github.com/EleutherAI/gpt-neox). The original code of the authors can be found [here](https://github.com/facebookresearch/llama). The Flax version of the implementation was contributed by [afmck](https://huggingface.co/afmck) with the code in the implementation based on Hugging Face's Flax GPT-Neo.\n \n \ndiff --git a/src/transformers/models/llama/tokenization_llama.py b/src/transformers/models/llama/tokenization_llama.py\nindex 5392afb763..d9c5db04f8 100644\n--- a/src/transformers/models/llama/tokenization_llama.py\n+++ b/src/transformers/models/llama/tokenization_llama.py\n@@ -123,7 +123,10 @@ class LlamaTokenizer(PreTrainedTokenizer):\n             Checkout the [pull request](https://github.com/huggingface/transformers/pull/24565) for more details.\n         add_prefix_space (`bool`, *optional*, defaults to `True`):\n             Whether or not to add an initial space to the input. This allows to treat the leading word just as any\n-            other word. Again, this should be set with `from_slow=True` to make sure it's taken into account.\n+            other word.\n+            Note: `add_prefix_space` is only applied when `legacy=False`. For `LlamaTokenizerFast`, passing\n+            `add_prefix_space` will internally set `from_slow=True`, but you must also set `legacy=False` for the flag\n+            to take effect.\n     \"\"\"\n \n     vocab_files_names = VOCAB_FILES_NAMES\n@@ -170,6 +173,12 @@ class LlamaTokenizer(PreTrainedTokenizer):\n         self.sp_model = self.get_spm_processor(kwargs.pop(\"from_slow\", False))\n         self.add_prefix_space = add_prefix_space\n \n+        # Inform users that add_prefix_space only has an effect when legacy=False\n+        if self.legacy and add_prefix_space is False:\n+            logger.warning_once(\n+                \"`add_prefix_space` is ignored when `legacy=True`. Set `legacy=False` to enable `add_prefix_space` control.\"\n+            )\n+\n         super().__init__(\n             bos_token=bos_token,\n             eos_token=eos_token,\ndiff --git a/src/transformers/models/llama/tokenization_llama_fast.py b/src/transformers/models/llama/tokenization_llama_fast.py\nindex 580290841c..5b8edacf77 100644\n--- a/src/transformers/models/llama/tokenization_llama_fast.py\n+++ b/src/transformers/models/llama/tokenization_llama_fast.py\n@@ -152,6 +152,10 @@ class LlamaTokenizerFast(PreTrainedTokenizerFast):\n \n         if add_prefix_space is not None:\n             kwargs[\"from_slow\"] = True\n+            if legacy:\n+                logger.warning_once(\n+                    \"`add_prefix_space` only takes effect when `legacy=False`. Please set `legacy=False` to enable it.\"\n+                )\n \n         super().__init__(\n             vocab_file=vocab_file,\n"}
{"instance_id": "huggingface__transformers-31646", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/encodec/modeling_encodec.py b/src/transformers/models/encodec/modeling_encodec.py\nindex 9627742b9e..f325a6adbe 100644\n--- a/src/transformers/models/encodec/modeling_encodec.py\n+++ b/src/transformers/models/encodec/modeling_encodec.py\n@@ -729,7 +729,7 @@ class EncodecModel(EncodecPreTrainedModel):\n                 Whether or not to return a [`~utils.ModelOutput`] instead of a plain tuple.\n \n         \"\"\"\n-        return_dict = return_dict or self.config.return_dict\n+        return_dict = return_dict if return_dict is not None else self.config.return_dict\n \n         chunk_length = self.config.chunk_length\n         if chunk_length is None:\n@@ -786,7 +786,7 @@ class EncodecModel(EncodecPreTrainedModel):\n         >>> audio_codes = outputs.audio_codes\n         >>> audio_values = outputs.audio_values\n         ```\"\"\"\n-        return_dict = return_dict or self.config.return_dict\n+        return_dict = return_dict if return_dict is not None else self.config.return_dict\n \n         if padding_mask is None:\n             padding_mask = torch.ones_like(input_values).bool()\n"}
{"instance_id": "langchain-ai__langchain-4009", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/callbacks/openai_info.py b/langchain/callbacks/openai_info.py\nindex 3c77f1f221..1bb2d976de 100644\n--- a/langchain/callbacks/openai_info.py\n+++ b/langchain/callbacks/openai_info.py\n@@ -1,4 +1,5 @@\n \"\"\"Callback Handler that prints to std out.\"\"\"\n+import logging\n from typing import Any, Dict, List, Optional, Union\n \n from langchain.callbacks.base import BaseCallbackHandler\n@@ -28,18 +29,24 @@ def get_openai_model_cost_per_1k_tokens(\n         \"text-davinci-003\": 0.02,\n         \"text-davinci-002\": 0.02,\n         \"code-davinci-002\": 0.02,\n+        \"davinci\": 0.02,\n     }\n \n-    cost = model_cost_mapping.get(\n-        model_name.lower()\n-        + (\"-completion\" if is_completion and model_name.startswith(\"gpt-4\") else \"\"),\n-        None,\n-    )\n+    name = model_name.lower()\n+    # Normalize fine-tuned model names that include a base model prefix before a colon,\n+    # e.g., \"curie:ft-...\" or \"davinci:ft-...\" -> use the base model for cost lookup.\n+    if \":\" in name:\n+        name = name.split(\":\", 1)[0]\n+\n+    lookup_name = name + (\"-completion\" if is_completion and name.startswith(\"gpt-4\") else \"\")\n+    cost = model_cost_mapping.get(lookup_name, None)\n+\n     if cost is None:\n-        raise ValueError(\n-            f\"Unknown model: {model_name}. Please provide a valid OpenAI model name.\"\n-            \"Known models are: \" + \", \".join(model_cost_mapping.keys())\n+        logging.warning(\n+            \"Unknown OpenAI model for cost calculation: %s. Cost will be treated as $0.0 per 1k tokens.\",\n+            model_name,\n         )\n+        return 0.0\n \n     return cost\n \n@@ -84,14 +91,19 @@ class OpenAICallbackHandler(BaseCallbackHandler):\n             if \"token_usage\" in response.llm_output:\n                 token_usage = response.llm_output[\"token_usage\"]\n                 if \"model_name\" in response.llm_output:\n-                    completion_cost = get_openai_model_cost_per_1k_tokens(\n-                        response.llm_output[\"model_name\"], is_completion=True\n-                    ) * (token_usage.get(\"completion_tokens\", 0) / 1000)\n-                    prompt_cost = get_openai_model_cost_per_1k_tokens(\n-                        response.llm_output[\"model_name\"]\n-                    ) * (token_usage.get(\"prompt_tokens\", 0) / 1000)\n-\n-                    self.total_cost += prompt_cost + completion_cost\n+                    try:\n+                        completion_cost = get_openai_model_cost_per_1k_tokens(\n+                            response.llm_output[\"model_name\"], is_completion=True\n+                        ) * (token_usage.get(\"completion_tokens\", 0) / 1000)\n+                        prompt_cost = get_openai_model_cost_per_1k_tokens(\n+                            response.llm_output[\"model_name\"]\n+                        ) * (token_usage.get(\"prompt_tokens\", 0) / 1000)\n+\n+                        self.total_cost += prompt_cost + completion_cost\n+                    except Exception:\n+                        # If cost lookup fails for unknown models, skip cost update\n+                        # but continue tracking token usage.\n+                        pass\n \n                 if \"total_tokens\" in token_usage:\n                     self.total_tokens += token_usage[\"total_tokens\"]\n"}
{"instance_id": "langchain-ai__langchain-3367", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/agents/mrkl/output_parser.py b/langchain/agents/mrkl/output_parser.py\nindex 0309609bb9..431748defd 100644\n--- a/langchain/agents/mrkl/output_parser.py\n+++ b/langchain/agents/mrkl/output_parser.py\n@@ -13,15 +13,17 @@ class MRKLOutputParser(AgentOutputParser):\n         return FORMAT_INSTRUCTIONS\n \n     def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n+        # Normalize line endings to '\\n' to be robust across platforms\n+        text = text.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")\n         if FINAL_ANSWER_ACTION in text:\n             return AgentFinish(\n                 {\"output\": text.split(FINAL_ANSWER_ACTION)[-1].strip()}, text\n             )\n-        # \\s matches against tab/newline/whitespace\n-        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n+        # \\s matches tabs/newlines/whitespace; allow optional whitespace before 'Action Input'\n+        regex = r\"Action\\s*\\d*\\s*:(.*?)\\s*Action\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n         match = re.search(regex, text, re.DOTALL)\n         if not match:\n             raise OutputParserException(f\"Could not parse LLM output: `{text}`\")\n         action = match.group(1).strip()\n-        action_input = match.group(2)\n-        return AgentAction(action, action_input.strip(\" \").strip('\"'), text)\n+        action_input = match.group(2).strip().strip('\"')\n+        return AgentAction(action, action_input, text)\n"}
{"instance_id": "langchain-ai__langchain-5625", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/text_splitter.py b/langchain/text_splitter.py\nindex 77f34d063b..f999eb9b89 100644\n--- a/langchain/text_splitter.py\n+++ b/langchain/text_splitter.py\n@@ -35,7 +35,7 @@ def _split_text(text: str, separator: str, keep_separator: bool) -> List[str]:\n     if separator:\n         if keep_separator:\n             # The parentheses in the pattern keep the delimiters in the result.\n-            _splits = re.split(f\"({separator})\", text)\n+            _splits = re.split(f\"({re.escape(separator)})\", text)\n             splits = [_splits[i] + _splits[i + 1] for i in range(1, len(_splits), 2)]\n             if len(_splits) % 2 == 0:\n                 splits += _splits[-1:]\n"}
{"instance_id": "langchain-ai__langchain-5584", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/vectorstores/chroma.py b/langchain/vectorstores/chroma.py\nindex 39577b0cf5..e70182beff 100644\n--- a/langchain/vectorstores/chroma.py\n+++ b/langchain/vectorstores/chroma.py\n@@ -352,15 +352,13 @@ class Chroma(VectorStore):\n         \"\"\"\n         text = document.page_content\n         metadata = document.metadata\n-        if self._embedding_function is None:\n-            raise ValueError(\n-                \"For update, you must specify an embedding function on creation.\"\n-            )\n-        embeddings = self._embedding_function.embed_documents(list(text))\n+        embeddings = None\n+        if self._embedding_function is not None:\n+            embeddings = self._embedding_function.embed_documents([text])\n \n         self._collection.update(\n             ids=[document_id],\n-            embeddings=[embeddings[0]],\n+            embeddings=embeddings,\n             documents=[text],\n             metadatas=[metadata],\n         )\n"}
{"instance_id": "langchain-ai__langchain-6765", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/agents/initialize.py b/langchain/agents/initialize.py\nindex cb26fb630a..a0e2e4f67b 100644\n--- a/langchain/agents/initialize.py\n+++ b/langchain/agents/initialize.py\n@@ -1,5 +1,5 @@\n \"\"\"Load agent.\"\"\"\n-from typing import Any, Optional, Sequence\n+from typing import Any, Optional, Sequence, Union\n \n from langchain.agents.agent import AgentExecutor\n from langchain.agents.agent_types import AgentType\n@@ -12,7 +12,7 @@ from langchain.tools.base import BaseTool\n def initialize_agent(\n     tools: Sequence[BaseTool],\n     llm: BaseLanguageModel,\n-    agent: Optional[AgentType] = None,\n+    agent: Optional[Union[AgentType, str]] = None,\n     callback_manager: Optional[BaseCallbackManager] = None,\n     agent_path: Optional[str] = None,\n     agent_kwargs: Optional[dict] = None,\n@@ -36,6 +36,7 @@ def initialize_agent(\n \n     Returns:\n         An agent executor\n+    \n     \"\"\"\n     tags_ = list(tags) if tags else []\n     if agent is None and agent_path is None:\n@@ -46,6 +47,15 @@ def initialize_agent(\n             \"but at most only one should be.\"\n         )\n     if agent is not None:\n+        # Normalize agent to AgentType if a string is provided\n+        if isinstance(agent, str):\n+            try:\n+                agent = AgentType(agent)\n+            except ValueError:\n+                raise ValueError(\n+                    f\"Got unknown agent type: {agent}. \"\n+                    f\"Valid types are: {[a.value for a in AGENT_TO_CLASS.keys()]}\"\n+                )\n         if agent not in AGENT_TO_CLASS:\n             raise ValueError(\n                 f\"Got unknown agent type: {agent}. \"\n@@ -63,7 +73,8 @@ def initialize_agent(\n         )\n         try:\n             # TODO: Add tags from the serialized object directly.\n-            tags_.append(agent_obj._agent_type)\n+            _type = agent_obj._agent_type\n+            tags_.append(_type.value if isinstance(_type, AgentType) else _type)\n         except NotImplementedError:\n             pass\n     else:\n"}
{"instance_id": "langchain-ai__langchain-20064", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "langchain-ai__langchain-19331", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/libs/core/langchain_core/language_models/llms.py b/libs/core/langchain_core/language_models/llms.py\nindex 7fe90a0ffd..6e8d03a31b 100644\n--- a/libs/core/langchain_core/language_models/llms.py\n+++ b/libs/core/langchain_core/language_models/llms.py\n@@ -116,14 +116,14 @@ def create_base_retry_decorator(\n \n \n def get_prompts(\n-    params: Dict[str, Any], prompts: List[str]\n+    params: Dict[str, Any], prompts: List[str], cache: Optional[BaseCache] = None\n ) -> Tuple[Dict[int, List], str, List[int], List[str]]:\n     \"\"\"Get prompts that are already cached.\"\"\"\n     llm_string = str(sorted([(k, v) for k, v in params.items()]))\n     missing_prompts = []\n     missing_prompt_idxs = []\n     existing_prompts = {}\n-    llm_cache = get_llm_cache()\n+    llm_cache = cache if cache is not None else get_llm_cache()\n     for i, prompt in enumerate(prompts):\n         if llm_cache is not None:\n             cache_val = llm_cache.lookup(prompt, llm_string)\n@@ -136,14 +136,14 @@ def get_prompts(\n \n \n async def aget_prompts(\n-    params: Dict[str, Any], prompts: List[str]\n+    params: Dict[str, Any], prompts: List[str], cache: Optional[BaseCache] = None\n ) -> Tuple[Dict[int, List], str, List[int], List[str]]:\n     \"\"\"Get prompts that are already cached. Async version.\"\"\"\n     llm_string = str(sorted([(k, v) for k, v in params.items()]))\n     missing_prompts = []\n     missing_prompt_idxs = []\n     existing_prompts = {}\n-    llm_cache = get_llm_cache()\n+    llm_cache = cache if cache is not None else get_llm_cache()\n     for i, prompt in enumerate(prompts):\n         if llm_cache:\n             cache_val = await llm_cache.alookup(prompt, llm_string)\n@@ -161,9 +161,10 @@ def update_cache(\n     missing_prompt_idxs: List[int],\n     new_results: LLMResult,\n     prompts: List[str],\n+    cache: Optional[BaseCache] = None,\n ) -> Optional[dict]:\n     \"\"\"Update the cache and get the LLM output.\"\"\"\n-    llm_cache = get_llm_cache()\n+    llm_cache = cache if cache is not None else get_llm_cache()\n     for i, result in enumerate(new_results.generations):\n         existing_prompts[missing_prompt_idxs[i]] = result\n         prompt = prompts[missing_prompt_idxs[i]]\n@@ -179,9 +180,10 @@ async def aupdate_cache(\n     missing_prompt_idxs: List[int],\n     new_results: LLMResult,\n     prompts: List[str],\n+    cache: Optional[BaseCache] = None,\n ) -> Optional[dict]:\n     \"\"\"Update the cache and get the LLM output. Async version\"\"\"\n-    llm_cache = get_llm_cache()\n+    llm_cache = cache if cache is not None else get_llm_cache()\n     for i, result in enumerate(new_results.generations):\n         existing_prompts[missing_prompt_idxs[i]] = result\n         prompt = prompts[missing_prompt_idxs[i]]\n@@ -712,22 +714,23 @@ class BaseLLM(BaseLanguageModel[str], ABC):\n         params = self.dict()\n         params[\"stop\"] = stop\n         options = {\"stop\": stop}\n+        if isinstance(self.cache, BaseCache):\n+            llm_cache = self.cache\n+        elif self.cache is False:\n+            llm_cache = None\n+        else:\n+            llm_cache = get_llm_cache()\n         (\n             existing_prompts,\n             llm_string,\n             missing_prompt_idxs,\n             missing_prompts,\n-        ) = get_prompts(params, prompts)\n-        if isinstance(self.cache, BaseCache):\n-            raise NotImplementedError(\n-                \"Local cache is not yet supported for \" \"LLMs (only chat models)\"\n-            )\n-        disregard_cache = self.cache is not None and not self.cache\n+        ) = get_prompts(params, prompts, llm_cache)\n         new_arg_supported = inspect.signature(self._generate).parameters.get(\n             \"run_manager\"\n         )\n-        if get_llm_cache() is None or disregard_cache:\n-            if self.cache is not None and self.cache:\n+        if llm_cache is None:\n+            if self.cache is True:\n                 raise ValueError(\n                     \"Asked to cache, but no cache found at `langchain.cache`.\"\n                 )\n@@ -765,7 +768,7 @@ class BaseLLM(BaseLanguageModel[str], ABC):\n                 missing_prompts, stop, run_managers, bool(new_arg_supported), **kwargs\n             )\n             llm_output = update_cache(\n-                existing_prompts, llm_string, missing_prompt_idxs, new_results, prompts\n+                existing_prompts, llm_string, missing_prompt_idxs, new_results, prompts, llm_cache\n             )\n             run_info = (\n                 [RunInfo(run_id=run_manager.run_id) for run_manager in run_managers]\n@@ -925,23 +928,23 @@ class BaseLLM(BaseLanguageModel[str], ABC):\n         params = self.dict()\n         params[\"stop\"] = stop\n         options = {\"stop\": stop}\n+        if isinstance(self.cache, BaseCache):\n+            llm_cache = self.cache\n+        elif self.cache is False:\n+            llm_cache = None\n+        else:\n+            llm_cache = get_llm_cache()\n         (\n             existing_prompts,\n             llm_string,\n             missing_prompt_idxs,\n             missing_prompts,\n-        ) = await aget_prompts(params, prompts)\n-        if isinstance(self.cache, BaseCache):\n-            raise NotImplementedError(\n-                \"Local cache is not yet supported for \" \"LLMs (only chat models)\"\n-            )\n-\n-        disregard_cache = self.cache is not None and not self.cache\n+        ) = await aget_prompts(params, prompts, llm_cache)\n         new_arg_supported = inspect.signature(self._agenerate).parameters.get(\n             \"run_manager\"\n         )\n-        if get_llm_cache() is None or disregard_cache:\n-            if self.cache is not None and self.cache:\n+        if llm_cache is None:\n+            if self.cache is True:\n                 raise ValueError(\n                     \"Asked to cache, but no cache found at `langchain.cache`.\"\n                 )\n@@ -993,7 +996,7 @@ class BaseLLM(BaseLanguageModel[str], ABC):\n                 **kwargs,  # type: ignore[arg-type]\n             )\n             llm_output = await aupdate_cache(\n-                existing_prompts, llm_string, missing_prompt_idxs, new_results, prompts\n+                existing_prompts, llm_string, missing_prompt_idxs, new_results, prompts, llm_cache\n             )\n             run_info = (\n                 [RunInfo(run_id=run_manager.run_id) for run_manager in run_managers]  # type: ignore[attr-defined]\n"}
{"instance_id": "yt-dlp__yt-dlp-5195", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/yt_dlp/cookies.py b/yt_dlp/cookies.py\nindex 3032d0712..61e5ea340 100644\n--- a/yt_dlp/cookies.py\n+++ b/yt_dlp/cookies.py\n@@ -1022,22 +1022,23 @@ class LenientSimpleCookie(http.cookies.SimpleCookie):\n         (?P<key>                       # Start of group 'key'\n         [\"\"\" + _LEGAL_KEY_CHARS + r\"\"\"]+?# Any word of at least one letter\n         )                              # End of group 'key'\n-        (                              # Optional group: there may not be a value.\n-        \\s*=\\s*                          # Equal Sign\n-        (                                # Start of potential value\n-        (?P<val>                           # Start of group 'val'\n-        \"(?:[^\\\\\"]|\\\\.)*\"                    # Any doublequoted string\n-        |                                    # or\n-        \\w{3},\\s[\\w\\d\\s-]{9,11}\\s[\\d:]{8}\\sGMT # Special case for \"expires\" attr\n-        |                                    # or\n-        [\"\"\" + _LEGAL_VALUE_CHARS + r\"\"\"]*     # Any word or empty string\n-        )                                  # End of group 'val'\n-        |                                  # or\n-        (?P<bad>(?:\\\\;|[^;])*?)            # 'bad' group fallback for invalid values\n-        )                                # End of potential value\n-        )?                             # End of optional value group\n-        \\s*                            # Any number of spaces.\n-        (\\s+|;|$)                      # Ending either at space, semicolon, or EOS.\n+        (?:                             # Distinguish valued vs non-valued tokens\n+            \\s*=\\s*                      # Equal Sign for valued token\n+            (                              # Start of potential value\n+                (?P<val>                       # Start of group 'val'\n+                    \"(?:[^\\\\\"]|\\\\.)*\"            # Any doublequoted string\n+                    |                            # or\n+                    \\w{3},\\s[\\w\\d\\s-]{9,11}\\s[\\d:]{8}\\sGMT # Special case for \"expires\" attr\n+                    |                            # or\n+                    [^;]*                        # Unquoted value up to next semicolon (can include spaces)\n+                )                              # End of group 'val'\n+                |                              # or\n+                (?P<bad>(?:\\\\;|[^;])*)        # 'bad' group fallback for invalid values\n+            )                                # End of potential value\n+            \\s* (?:;|$)                      # Valued tokens end only at semicolon or EOS\n+        |                                   # or\n+            \\s* (?:\\s+|;|$)                # Non-valued tokens end at space, semicolon, or EOS\n+        )\n         \"\"\", re.ASCII | re.VERBOSE)\n \n     def load(self, data):\n"}
{"instance_id": "yt-dlp__yt-dlp-4841", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/yt_dlp/extractor/dplay.py b/yt_dlp/extractor/dplay.py\nindex e16856b2b..808496c96 100644\n--- a/yt_dlp/extractor/dplay.py\n+++ b/yt_dlp/extractor/dplay.py\n@@ -170,7 +170,7 @@ def _get_disco_api_info(self, url, display_id, disco_host, realm, country, domai\n             'formats': formats,\n             'subtitles': subtitles,\n             'http_headers': {\n-                'referer': domain,\n+                'referer': url,\n             },\n         }\n \n"}
{"instance_id": "yt-dlp__yt-dlp-5933", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/yt_dlp/options.py b/yt_dlp/options.py\nindex 83e851b19..54f099f9a 100644\n--- a/yt_dlp/options.py\n+++ b/yt_dlp/options.py\n@@ -79,6 +79,26 @@ def _read_user_conf(package_name, default=None):\n         return default if default is not None else [], None\n \n     def _read_system_conf(package_name, default=None):\n+        # Legacy system-wide config files: /etc/<package_name>.conf and /etc/<package_name>.conf.txt\n+        system_conf_file = os.path.join('/etc', f'{package_name}.conf')\n+        system_conf = Config.read_file(system_conf_file, default=None)\n+        if system_conf is None:\n+            system_conf_file = system_conf_file + '.txt'\n+            system_conf = Config.read_file(system_conf_file, default=None)\n+        if system_conf is not None:\n+            return system_conf, system_conf_file\n+\n+        # Also check for <dir>/<package_name>.conf(.txt) inside system config directories\n+        for config_dir in get_system_config_dirs(package_name):\n+            conf_file_path = os.path.join(config_dir, f'{package_name}.conf')\n+            conf = Config.read_file(conf_file_path, default=None)\n+            if conf is None:\n+                conf_file_path += '.txt'\n+                conf = Config.read_file(conf_file_path, default=None)\n+            if conf is not None:\n+                return conf, conf_file_path\n+\n+        # Package config directories (e.g. /etc/<package_name>/config or config.txt)\n         system_conf, system_conf_file = _load_from_config_dirs(get_system_config_dirs(package_name))\n         if system_conf is not None:\n             return system_conf, system_conf_file\n"}
{"instance_id": "yt-dlp__yt-dlp-9862", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/yt_dlp/YoutubeDL.py b/yt_dlp/YoutubeDL.py\nindex e56c3ed3c..a8440c83b 100644\n--- a/yt_dlp/YoutubeDL.py\n+++ b/yt_dlp/YoutubeDL.py\n@@ -2191,7 +2191,7 @@ def _select_formats(self, formats, selector):\n         }))\n \n     def _default_format_spec(self, info_dict, download=True):\n-        download = download and not self.params.get('simulate')\n+        download = download\n         prefer_best = download and (\n             self.params['outtmpl']['default'] == '-'\n             or info_dict.get('is_live') and not self.params.get('live_from_start'))\n"}
{"instance_id": "keras-team__keras-18553", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/backend/torch/nn.py b/keras/backend/torch/nn.py\nindex c04584c48..4524a7b79 100644\n--- a/keras/backend/torch/nn.py\n+++ b/keras/backend/torch/nn.py\n@@ -337,7 +337,7 @@ def conv(\n         inputs = _transpose_spatial_inputs(inputs)\n     # Transpose kernel from keras format to torch format.\n     kernel = _transpose_conv_kernel(kernel)\n-    if padding == \"same\":\n+    if isinstance(padding, str) and padding.lower() == \"same\":\n         inputs = _apply_same_padding(\n             inputs,\n             kernel.shape[2:],\n"}
{"instance_id": "yt-dlp__yt-dlp-10390", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/yt_dlp/cache.py b/yt_dlp/cache.py\nindex 71dca82b3..a19078b6c 100644\n--- a/yt_dlp/cache.py\n+++ b/yt_dlp/cache.py\n@@ -64,7 +64,17 @@ def load(self, section, key, dtype='json', default=None, *, min_ver=None):\n             try:\n                 with open(cache_fn, encoding='utf-8') as cachef:\n                     self._ydl.write_debug(f'Loading {section}.{key} from cache')\n-                    return self._validate(json.load(cachef), min_ver)\n+                    cached = self._validate(json.load(cachef), min_ver)\n+                    # Validate schema for youtube-sigfuncs to avoid using invalid cache entries\n+                    if section == 'youtube-sigfuncs' and isinstance(cached, dict):\n+                        func_name = cached.get('func_name')\n+                        func_code = cached.get('func_code')\n+                        if not func_name or not func_code or not isinstance(func_name, str) or not isinstance(func_code, str):\n+                            self._ydl.write_debug(f'Discarding invalid cache {cache_fn!r} for youtube-sigfuncs')\n+                            with contextlib.suppress(OSError):\n+                                os.remove(cache_fn)\n+                            return default\n+                    return cached\n             except (ValueError, KeyError):\n                 try:\n                     file_size = os.path.getsize(cache_fn)\ndiff --git a/yt_dlp/plugins.py b/yt_dlp/plugins.py\nindex 3cc879fd7..7db433a25 100644\n--- a/yt_dlp/plugins.py\n+++ b/yt_dlp/plugins.py\n@@ -138,7 +138,9 @@ def load_module(module, module_name, suffix):\n def load_plugins(name, suffix):\n     classes = {}\n \n-    for finder, module_name, _ in iter_modules(name):\n+    # Ensure deterministic plugin import order\n+    module_entries = sorted(iter_modules(name), key=lambda x: x[1])\n+    for finder, module_name, _ in module_entries:\n         if any(x.startswith('_') for x in module_name.split('.')):\n             continue\n         try:\n"}
{"instance_id": "keras-team__keras-18871", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/models/model.py b/keras/models/model.py\nindex ee89bb424..200fce661 100644\n--- a/keras/models/model.py\n+++ b/keras/models/model.py\n@@ -7,11 +7,13 @@ from keras import backend\n from keras import utils\n from keras.api_export import keras_export\n from keras.layers.layer import Layer\n-from keras.legacy.saving import legacy_h5_format\n+\n from keras.models.variable_mapping import map_trackable_variables\n from keras.saving import saving_api\n from keras.saving import saving_lib\n+\n from keras.trainers import trainer as base_trainer\n+\n from keras.utils import io_utils\n from keras.utils import summary_utils\n from keras.utils import traceback_utils\n@@ -303,60 +305,7 @@ class Model(Trainer, Layer):\n \n         Thus models can be reinstantiated in the exact same state.\n         \"\"\"\n-        include_optimizer = kwargs.pop(\"include_optimizer\", True)\n-        save_format = kwargs.pop(\"save_format\", None)\n-        if kwargs:\n-            raise ValueError(\n-                \"The following argument(s) are not supported: \"\n-                f\"{list(kwargs.keys())}\"\n-            )\n-        if save_format:\n-            if str(filepath).endswith((\".h5\", \".hdf5\")) or str(\n-                filepath\n-            ).endswith(\".keras\"):\n-                warnings.warn(\n-                    \"The `save_format` argument is deprecated in Keras 3. \"\n-                    \"We recommend removing this argument as it can be inferred \"\n-                    \"from the file path. \"\n-                    f\"Received: save_format={save_format}\"\n-                )\n-            else:\n-                raise ValueError(\n-                    \"The `save_format` argument is deprecated in Keras 3. \"\n-                    \"Please remove this argument and pass a file path with \"\n-                    \"either `.keras` or `.h5` extension.\"\n-                    f\"Received: save_format={save_format}\"\n-                )\n-        try:\n-            exists = os.path.exists(filepath)\n-        except TypeError:\n-            exists = False\n-        if exists and not overwrite:\n-            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n-            if not proceed:\n-                return\n-        if str(filepath).endswith(\".keras\"):\n-            saving_lib.save_model(self, filepath)\n-        elif str(filepath).endswith((\".h5\", \".hdf5\")):\n-            # Deprecation warnings\n-            warnings.warn(\n-                \"You are saving your model as an HDF5 file via `model.save()`. \"\n-                \"This file format is considered legacy. \"\n-                \"We recommend using instead the native Keras format, \"\n-                \"e.g. `model.save('my_model.keras')`.\"\n-            )\n-            legacy_h5_format.save_model_to_hdf5(\n-                self, filepath, overwrite, include_optimizer\n-            )\n-        else:\n-            raise ValueError(\n-                \"Invalid filepath extension for saving. \"\n-                \"Please add either a `.keras` extension for the native Keras \"\n-                f\"format (recommended) or a `.h5` extension. \"\n-                \"Use `tf.saved_model.save()` if you want to export a \"\n-                \"SavedModel for use with TFLite/TFServing/etc. \"\n-                f\"Received: filepath={filepath}.\"\n-            )\n+        saving_api.save_model(self, filepath, overwrite=overwrite, **kwargs)\n \n     @traceback_utils.filter_traceback\n     def save_weights(self, filepath, overwrite=True):\ndiff --git a/keras/saving/__init__.py b/keras/saving/__init__.py\nindex 9f709a3c1..1ae1f7e67 100644\n--- a/keras/saving/__init__.py\n+++ b/keras/saving/__init__.py\n@@ -5,5 +5,7 @@ from keras.saving.object_registration import get_registered_name\n from keras.saving.object_registration import get_registered_object\n from keras.saving.object_registration import register_keras_serializable\n from keras.saving.saving_api import load_model\n+from keras.saving.saving_api import save_model\n from keras.saving.serialization_lib import deserialize_keras_object\n from keras.saving.serialization_lib import serialize_keras_object\n+\ndiff --git a/keras/saving/saving_api.py b/keras/saving/saving_api.py\nindex d0fb5697e..2dc97f25a 100644\n--- a/keras/saving/saving_api.py\n+++ b/keras/saving/saving_api.py\n@@ -1,7 +1,7 @@\n import os\n import zipfile\n \n-from absl import logging\n+import warnings\n \n from keras.api_export import keras_export\n from keras.legacy.saving import legacy_h5_format\n@@ -51,12 +51,17 @@ def save_model(model, filepath, overwrite=True, **kwargs):\n     Thus models can be reinstantiated in the exact same state.\n     \"\"\"\n     include_optimizer = kwargs.pop(\"include_optimizer\", True)\n-    save_format = kwargs.pop(\"save_format\", False)\n+    save_format = kwargs.pop(\"save_format\", None)\n+    if kwargs:\n+        raise ValueError(\n+            \"The following argument(s) are not supported: \"\n+            f\"{list(kwargs.keys())}\"\n+        )\n     if save_format:\n         if str(filepath).endswith((\".h5\", \".hdf5\")) or str(filepath).endswith(\n             \".keras\"\n         ):\n-            logging.warning(\n+            warnings.warn(\n                 \"The `save_format` argument is deprecated in Keras 3. \"\n                 \"We recommend removing this argument as it can be inferred \"\n                 \"from the file path. \"\n@@ -69,15 +74,19 @@ def save_model(model, filepath, overwrite=True, **kwargs):\n                 \"either `.keras` or `.h5` extension.\"\n                 f\"Received: save_format={save_format}\"\n             )\n-    if kwargs:\n-        raise ValueError(\n-            \"The following argument(s) are not supported: \"\n-            f\"{list(kwargs.keys())}\"\n-        )\n+\n+    try:\n+        exists = os.path.exists(filepath)\n+    except TypeError:\n+        exists = False\n+    if exists and not overwrite:\n+        proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n+        if not proceed:\n+            return\n \n     # Deprecation warnings\n     if str(filepath).endswith((\".h5\", \".hdf5\")):\n-        logging.warning(\n+        warnings.warn(\n             \"You are saving your model as an HDF5 file via `model.save()`. \"\n             \"This file format is considered legacy. \"\n             \"We recommend using instead the native Keras format, \"\n@@ -85,15 +94,6 @@ def save_model(model, filepath, overwrite=True, **kwargs):\n         )\n \n     if str(filepath).endswith(\".keras\"):\n-        # If file exists and should not be overwritten.\n-        try:\n-            exists = os.path.exists(filepath)\n-        except TypeError:\n-            exists = False\n-        if exists and not overwrite:\n-            proceed = io_utils.ask_to_proceed_with_overwrite(filepath)\n-            if not proceed:\n-                return\n         saving_lib.save_model(model, filepath)\n     elif str(filepath).endswith((\".h5\", \".hdf5\")):\n         legacy_h5_format.save_model_to_hdf5(\n"}
{"instance_id": "keras-team__keras-18975", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/trainers/compile_utils.py b/keras/trainers/compile_utils.py\nindex 8f830f4c9..ea9319143 100644\n--- a/keras/trainers/compile_utils.py\n+++ b/keras/trainers/compile_utils.py\n@@ -43,6 +43,11 @@ def is_function_like(value):\n \n \n def is_binary_or_sparse_categorical(y_true, y_pred):\n+    # Unwrap single-element list/tuple inputs to handle nested structures safely\n+    if isinstance(y_true, (list, tuple)) and len(y_true) == 1:\n+        y_true = y_true[0]\n+    if isinstance(y_pred, (list, tuple)) and len(y_pred) == 1:\n+        y_pred = y_pred[0]\n     y_t_rank = len(y_true.shape)\n     y_p_rank = len(y_pred.shape)\n     y_t_last_dim = y_true.shape[-1]\n@@ -99,6 +104,11 @@ def get_loss(identifier, y_true, y_pred):\n     if str(identifier).lower() not in [\"crossentropy\", \"ce\"]:\n         loss_obj = losses_module.get(identifier)\n     else:\n+        # Unwrap single-element lists to avoid passing lists to shape inspection\n+        if isinstance(y_true, (list, tuple)) and len(y_true) == 1:\n+            y_true = y_true[0]\n+        if isinstance(y_pred, (list, tuple)) and len(y_pred) == 1:\n+            y_pred = y_pred[0]\n         is_binary, is_sparse_categorical = is_binary_or_sparse_categorical(\n             y_true, y_pred\n         )\n@@ -477,7 +487,16 @@ class CompileLoss(losses_module.Loss):\n         # Iterate over all possible loss formats:\n         # plain function, list/tuple, dict\n         if is_function_like(loss):\n-            flat_losses.append(get_loss(loss, y_true, y_pred))\n+            # Unwrap single-output case so get_loss sees tensors, not 1-element lists\n+            if isinstance(y_true, (list, tuple)) and len(y_true) == 1:\n+                yt = y_true[0]\n+            else:\n+                yt = y_true\n+            if isinstance(y_pred, (list, tuple)) and len(y_pred) == 1:\n+                yp = y_pred[0]\n+            else:\n+                yp = y_pred\n+            flat_losses.append(get_loss(loss, yt, yp))\n             if loss_weights:\n                 if not isinstance(loss_weights, float):\n                     raise ValueError(\n@@ -508,9 +527,13 @@ class CompileLoss(losses_module.Loss):\n                     \"corresponding to that output). \"\n                     f\"Received: loss={loss}\"\n                 )\n-            flat_losses = [\n-                get_loss(fn, y_true, y_pred) for fn in loss if fn is not None\n-            ]\n+            flat_losses = []\n+            for i, fn in enumerate(loss):\n+                if fn is None:\n+                    continue\n+                yt = y_true[i] if isinstance(y_true, (list, tuple)) else y_true\n+                yp = y_pred[i] if isinstance(y_pred, (list, tuple)) else y_pred\n+                flat_losses.append(get_loss(fn, yt, yp))\n             if loss_weights:\n                 if not isinstance(loss_weights, (list, tuple)):\n                     raise ValueError(\n"}
{"instance_id": "keras-team__keras-19190", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/layers/preprocessing/text_vectorization.py b/keras/layers/preprocessing/text_vectorization.py\nindex 2e1fa4633..5f1ccf36e 100644\n--- a/keras/layers/preprocessing/text_vectorization.py\n+++ b/keras/layers/preprocessing/text_vectorization.py\n@@ -492,6 +492,9 @@ class TextVectorization(Layer):\n             config[\"split\"] = serialization_lib.deserialize_keras_object(\n                 config[\"split\"]\n             )\n+        # Normalize ngrams field: JSON deserialization turns tuples into lists.\n+        if \"ngrams\" in config and isinstance(config[\"ngrams\"], list):\n+            config[\"ngrams\"] = tuple(config[\"ngrams\"])\n         return cls(**config)\n \n     def set_vocabulary(self, vocabulary, idf_weights=None):\n"}
{"instance_id": "keras-team__keras-19201", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/backend/jax/distribution_lib.py b/keras/backend/jax/distribution_lib.py\nindex 704b13a48..8ba1724c5 100644\n--- a/keras/backend/jax/distribution_lib.py\n+++ b/keras/backend/jax/distribution_lib.py\n@@ -200,12 +200,12 @@ def initialize(job_addresses, num_processes, process_id):\n                 f\"{len(job_addresses)} jobs, but num_processes is \"\n                 f\"{num_processes}\"\n             )\n-        corrdinator_address = job_addresses[0]\n+        coordinator_address = job_addresses[0]\n     else:\n-        corrdinator_address = job_addresses\n+        coordinator_address = job_addresses\n \n     jax.distributed.initialize(\n-        corrdinator_address=corrdinator_address,\n+        coordinator_address,\n         num_processes=num_processes,\n         process_id=process_id,\n     )\n"}
{"instance_id": "keras-team__keras-19466", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/ops/numpy.py b/keras/ops/numpy.py\nindex 25f1809d6..c7758adfd 100644\n--- a/keras/ops/numpy.py\n+++ b/keras/ops/numpy.py\n@@ -3992,6 +3992,14 @@ class Nonzero(Operation):\n     def call(self, x):\n         return backend.numpy.nonzero(x)\n \n+    def compute_output_spec(self, x):\n+        # Return a tuple of index arrays, one per input dimension.\n+        # Each index array has shape (None,) since the number of non-zeros\n+        # is data-dependent, and dtype int32.\n+        return tuple(\n+            KerasTensor((None,), dtype=\"int32\") for _ in range(x.ndim)\n+        )\n+\n \n @keras_export([\"keras.ops.nonzero\", \"keras.ops.numpy.nonzero\"])\n def nonzero(x):\n@@ -4003,6 +4011,8 @@ def nonzero(x):\n     Returns:\n         Indices of elements that are non-zero.\n     \"\"\"\n+    if any_symbolic_tensors((x,)):\n+        return Nonzero().symbolic_call(x)\n     return backend.numpy.nonzero(x)\n \n \n"}
{"instance_id": "keras-team__keras-19459", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/backend/config.py b/keras/backend/config.py\nindex 8725e27b5..64342adbe 100644\n--- a/keras/backend/config.py\n+++ b/keras/backend/config.py\n@@ -205,7 +205,7 @@ if os.path.exists(_config_path):\n     except ValueError:\n         _config = {}\n     _floatx = _config.get(\"floatx\", floatx())\n-    assert _floatx in {\"float16\", \"float32\", \"float64\"}\n+    assert _floatx in {\"bfloat16\", \"float16\", \"float32\", \"float64\"}\n     _epsilon = _config.get(\"epsilon\", epsilon())\n     assert isinstance(_epsilon, float)\n     _backend = _config.get(\"backend\", _BACKEND)\ndiff --git a/keras/layers/regularization/gaussian_dropout.py b/keras/layers/regularization/gaussian_dropout.py\nindex 15f66781c..7470db379 100644\n--- a/keras/layers/regularization/gaussian_dropout.py\n+++ b/keras/layers/regularization/gaussian_dropout.py\n@@ -44,6 +44,7 @@ class GaussianDropout(layers.Layer):\n                 shape=ops.shape(inputs),\n                 mean=1.0,\n                 stddev=stddev,\n+                dtype=ops.dtype(inputs),\n                 seed=self.seed_generator,\n             )\n         return inputs\n"}
{"instance_id": "keras-team__keras-19484", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/optimizers/adam.py b/keras/optimizers/adam.py\nindex f1db87ff9..ad90b2c0e 100644\n--- a/keras/optimizers/adam.py\n+++ b/keras/optimizers/adam.py\n@@ -113,11 +113,28 @@ class Adam(optimizer.Optimizer):\n         lr = ops.cast(learning_rate, variable.dtype)\n         gradient = ops.cast(gradient, variable.dtype)\n         local_step = ops.cast(self.iterations + 1, variable.dtype)\n+        # Resolve beta_1 and beta_2 if they are callables (support 0-arg or step-arg)\n+        if callable(self.beta_1):\n+            try:\n+                beta_1_value = self.beta_1(self.iterations)\n+            except TypeError:\n+                beta_1_value = self.beta_1()\n+        else:\n+            beta_1_value = self.beta_1\n+        if callable(self.beta_2):\n+            try:\n+                beta_2_value = self.beta_2(self.iterations)\n+            except TypeError:\n+                beta_2_value = self.beta_2()\n+        else:\n+            beta_2_value = self.beta_2\n+        beta_1 = ops.cast(beta_1_value, variable.dtype)\n+        beta_2 = ops.cast(beta_2_value, variable.dtype)\n         beta_1_power = ops.power(\n-            ops.cast(self.beta_1, variable.dtype), local_step\n+            beta_1, local_step\n         )\n         beta_2_power = ops.power(\n-            ops.cast(self.beta_2, variable.dtype), local_step\n+            beta_2, local_step\n         )\n \n         m = self._momentums[self._get_variable_index(variable)]\n@@ -126,12 +143,12 @@ class Adam(optimizer.Optimizer):\n         alpha = lr * ops.sqrt(1 - beta_2_power) / (1 - beta_1_power)\n \n         self.assign_add(\n-            m, ops.multiply(ops.subtract(gradient, m), 1 - self.beta_1)\n+            m, ops.multiply(ops.subtract(gradient, m), 1 - beta_1)\n         )\n         self.assign_add(\n             v,\n             ops.multiply(\n-                ops.subtract(ops.square(gradient), v), 1 - self.beta_2\n+                ops.subtract(ops.square(gradient), v), 1 - beta_2\n             ),\n         )\n         if self.amsgrad:\ndiff --git a/keras/optimizers/base_optimizer.py b/keras/optimizers/base_optimizer.py\nindex e18f3c1de..a2db0f70c 100644\n--- a/keras/optimizers/base_optimizer.py\n+++ b/keras/optimizers/base_optimizer.py\n@@ -567,7 +567,10 @@ class BaseOptimizer:\n         ):\n             return self._learning_rate(self.iterations)\n         elif callable(self._learning_rate):\n-            return self._learning_rate(self.iterations)\n+            try:\n+                return self._learning_rate(self.iterations)\n+            except TypeError:\n+                return self._learning_rate()\n         return self._learning_rate\n \n     def _filter_empty_gradients(self, grads, vars):\n"}
{"instance_id": "keras-team__keras-19641", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/backend/tensorflow/nn.py b/keras/src/backend/tensorflow/nn.py\nindex cb6bff3b4..ce514084c 100644\n--- a/keras/src/backend/tensorflow/nn.py\n+++ b/keras/src/backend/tensorflow/nn.py\n@@ -226,9 +226,28 @@ def conv(\n     data_format=None,\n     dilation_rate=1,\n ):\n+    data_format = backend.standardize_data_format(data_format)\n+\n+    # Determine input channels based on the original data_format before any\n+    # potential transposition.\n+    if data_format == \"channels_last\":\n+        channels = inputs.shape[-1]\n+    else:\n+        channels = inputs.shape[1]\n+\n+    # TensorFlow CPU does not generally support 3D conv with NCDHW\n+    # (channels_first). For rank-5 inputs, transpose to NDHWC internally\n+    # and transpose outputs back to NCDHW to preserve public semantics.\n+    transpose_back = False\n+    effective_data_format = data_format\n+    if data_format == \"channels_first\" and len(inputs.shape) == 5:\n+        inputs = tf.transpose(inputs, (0, 2, 3, 4, 1))\n+        effective_data_format = \"channels_last\"\n+        transpose_back = True\n+\n     def _conv():\n-        tf_data_format = _convert_data_format(data_format, len(inputs.shape))\n-        return tf.nn.convolution(\n+        tf_data_format = _convert_data_format(effective_data_format, len(inputs.shape))\n+        outputs = tf.nn.convolution(\n             inputs,\n             kernel,\n             strides,\n@@ -236,6 +255,9 @@ def conv(\n             data_format=tf_data_format,\n             dilations=dilation_rate,\n         )\n+        if transpose_back:\n+            outputs = tf.transpose(outputs, (0, 4, 1, 2, 3))\n+        return outputs\n \n     # Reason for making this function is in Tensorflow, `groups > 1` does not\n     # work on CPU for `tf.nn.convolution`, but wrapping it by XLA works.\n@@ -243,13 +265,8 @@ def conv(\n     def _conv_xla():\n         return _conv()\n \n-    data_format = backend.standardize_data_format(data_format)\n-    if data_format == \"channels_last\":\n-        channels = inputs.shape[-1]\n-    else:\n-        channels = inputs.shape[1]\n     if channels != kernel.shape[-2]:\n-        # If kernel's in_channel does not match input's channels,  it indicates\n+        # If kernel's in_channel does not match input's channels, it indicates\n         # convolution is broken down into groups.\n         return _conv_xla()\n     return _conv()\n"}
{"instance_id": "keras-team__keras-19636", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/dtype_policies/dtype_policy.py b/keras/src/dtype_policies/dtype_policy.py\nindex a55eaa4c0..2f99cfd2d 100644\n--- a/keras/src/dtype_policies/dtype_policy.py\n+++ b/keras/src/dtype_policies/dtype_policy.py\n@@ -153,7 +153,14 @@ class DTypePolicy:\n                 x.dtype = dtype\n             return x\n         elif hasattr(x, \"__array__\"):\n-            return ops.convert_to_tensor(x, dtype=dtype)\n+            t = ops.convert_to_tensor(x)\n+            if (\n+                autocast\n+                and backend.is_float_dtype(t.dtype)\n+                and t.dtype != dtype\n+            ):\n+                t = ops.cast(t, dtype=dtype)\n+            return t\n         return x\n \n     def get_config(self):\n"}
{"instance_id": "keras-team__keras-19773", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/layers/preprocessing/string_lookup.py b/keras/src/layers/preprocessing/string_lookup.py\nindex 848ac99b1..8e8f4ac4c 100644\n--- a/keras/src/layers/preprocessing/string_lookup.py\n+++ b/keras/src/layers/preprocessing/string_lookup.py\n@@ -316,6 +316,7 @@ class StringLookup(IndexLookup):\n             raise ValueError(\n                 \"`sparse=True` can only be used with the \" \"TensorFlow backend.\"\n             )\n+        self.encoding = encoding\n         super().__init__(\n             max_tokens=max_tokens,\n             num_oov_indices=num_oov_indices,\n@@ -331,7 +332,6 @@ class StringLookup(IndexLookup):\n             vocabulary_dtype=\"string\",\n             **kwargs,\n         )\n-        self.encoding = encoding\n         self._convert_input_args = False\n         self._allow_non_tensor_positional_args = True\n         self.supports_jit = False\n"}
{"instance_id": "mui__material-ui-26807", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/material-ui/src/StepLabel/StepLabel.d.ts b/packages/material-ui/src/StepLabel/StepLabel.d.ts\nindex 521ffd3155..8518540e5e 100644\n--- a/packages/material-ui/src/StepLabel/StepLabel.d.ts\n+++ b/packages/material-ui/src/StepLabel/StepLabel.d.ts\n@@ -2,6 +2,7 @@ import * as React from 'react';\n import { SxProps } from '@material-ui/system';\n import { InternalStandardProps as StandardProps } from '..';\n import { StepIconProps } from '../StepIcon';\n+import { TypographyProps } from '../Typography';\n import { Theme } from '../styles';\n import { StepLabelClasses } from './stepLabelClasses';\n \n@@ -35,6 +36,12 @@ export interface StepLabelProps extends StandardProps<React.HTMLAttributes<HTMLD\n    * Props applied to the [`StepIcon`](/api/step-icon/) element.\n    */\n   StepIconProps?: Partial<StepIconProps>;\n+  /**\n+   * Props applied to the label [`Typography`](/api/typography/) element.\n+   */\n+  componentsProps?: {\n+    label?: TypographyProps<'span', { component?: 'span' }>;\n+  };\n   /**\n    * The system prop that allows defining system overrides as well as additional CSS styles.\n    */\ndiff --git a/packages/material-ui/src/StepLabel/StepLabel.js b/packages/material-ui/src/StepLabel/StepLabel.js\nindex e03382fbec..5a901c067a 100644\n--- a/packages/material-ui/src/StepLabel/StepLabel.js\n+++ b/packages/material-ui/src/StepLabel/StepLabel.js\n@@ -124,6 +124,7 @@ const StepLabel = React.forwardRef(function StepLabel(inProps, ref) {\n     optional,\n     StepIconComponent: StepIconComponentProp,\n     StepIconProps,\n+    componentsProps = {},\n     ...other\n   } = props;\n \n@@ -149,6 +150,9 @@ const StepLabel = React.forwardRef(function StepLabel(inProps, ref) {\n \n   const classes = useUtilityClasses(styleProps);\n \n+  const labelProps = (componentsProps && componentsProps.label) || {};\n+  const labelClassName = clsx(classes.label, labelProps.className);\n+\n   return (\n     <StepLabelRoot\n       className={clsx(classes.root, className)}\n@@ -173,8 +177,9 @@ const StepLabel = React.forwardRef(function StepLabel(inProps, ref) {\n             variant=\"body2\"\n             component=\"span\"\n             display=\"block\"\n-            className={classes.label}\n             styleProps={styleProps}\n+            {...labelProps}\n+            className={labelClassName}\n           >\n             {children}\n           </StepLabelLabel>\n@@ -198,6 +203,12 @@ StepLabel.propTypes /* remove-proptypes */ = {\n    * Override or extend the styles applied to the component.\n    */\n   classes: PropTypes.object,\n+  /**\n+   * Props applied to the label [`Typography`](/api/typography/) element.\n+   */\n+  componentsProps: PropTypes.shape({\n+    label: PropTypes.object,\n+  }),\n   /**\n    * @ignore\n    */\n"}
{"instance_id": "mui__material-ui-29023", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-material/src/Tooltip/Tooltip.d.ts b/packages/mui-material/src/Tooltip/Tooltip.d.ts\nindex bad0ac0dd5..999e2eefd0 100644\n--- a/packages/mui-material/src/Tooltip/Tooltip.d.ts\n+++ b/packages/mui-material/src/Tooltip/Tooltip.d.ts\n@@ -37,7 +37,7 @@ export interface TooltipProps extends StandardProps<React.HTMLAttributes<HTMLDiv\n    * @default {}\n    */\n   componentsProps?: {\n-    popper?: PopperProps & TooltipComponentsPropsOverrides;\n+    popper?: Partial<PopperProps> & TooltipComponentsPropsOverrides;\n     transition?: TransitionProps & TooltipComponentsPropsOverrides;\n     tooltip?: React.HTMLProps<HTMLDivElement> &\n       MUIStyledCommonProps &\ndiff --git a/packages/mui-material/src/Tooltip/Tooltip.js b/packages/mui-material/src/Tooltip/Tooltip.js\nindex 920e22f237..89d8ae155f 100644\n--- a/packages/mui-material/src/Tooltip/Tooltip.js\n+++ b/packages/mui-material/src/Tooltip/Tooltip.js\n@@ -679,7 +679,7 @@ const Tooltip = React.forwardRef(function Tooltip(inProps, ref) {\n         transition\n         {...interactiveWrapperListeners}\n         {...popperProps}\n-        className={clsx(classes.popper, componentsProps.popper?.className)}\n+        className={clsx(classes.popper, popperProps.className)}\n         popperOptions={popperOptions}\n       >\n         {({ TransitionProps: TransitionPropsInner }) => (\n"}
{"instance_id": "mui__material-ui-34138", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-material/src/Step/Step.js b/packages/mui-material/src/Step/Step.js\nindex df0c6ab669..1ae1e35415 100644\n--- a/packages/mui-material/src/Step/Step.js\n+++ b/packages/mui-material/src/Step/Step.js\n@@ -19,7 +19,7 @@ const useUtilityClasses = (ownerState) => {\n   return composeClasses(slots, getStepUtilityClass, classes);\n };\n \n-const StepRoot = styled('div', {\n+const StepRoot = styled('li', {\n   name: 'MuiStep',\n   slot: 'Root',\n   overridesResolver: (props, styles) => {\n@@ -36,6 +36,7 @@ const StepRoot = styled('div', {\n   ...(ownerState.orientation === 'horizontal' && {\n     paddingLeft: 8,\n     paddingRight: 8,\n+    position: 'relative',\n   }),\n   ...(ownerState.alternativeLabel && {\n     flex: 1,\n@@ -98,21 +99,14 @@ const Step = React.forwardRef(function Step(inProps, ref) {\n       ownerState={ownerState}\n       {...other}\n     >\n-      {connector && alternativeLabel && index !== 0 ? connector : null}\n+      {connector && index !== 0 ? connector : null}\n       {children}\n     </StepRoot>\n   );\n \n   return (\n     <StepContext.Provider value={contextValue}>\n-      {connector && !alternativeLabel && index !== 0 ? (\n-        <React.Fragment>\n-          {connector}\n-          {newChildren}\n-        </React.Fragment>\n-      ) : (\n-        newChildren\n-      )}\n+      {newChildren}\n     </StepContext.Provider>\n   );\n });\ndiff --git a/packages/mui-material/src/StepConnector/StepConnector.js b/packages/mui-material/src/StepConnector/StepConnector.js\nindex e849dba428..acd75a2838 100644\n--- a/packages/mui-material/src/StepConnector/StepConnector.js\n+++ b/packages/mui-material/src/StepConnector/StepConnector.js\n@@ -41,7 +41,6 @@ const StepConnectorRoot = styled('div', {\n     ];\n   },\n })(({ ownerState }) => ({\n-  flex: '1 1 auto',\n   ...(ownerState.orientation === 'vertical' && {\n     marginLeft: 12, // half icon\n   }),\n@@ -51,6 +50,12 @@ const StepConnectorRoot = styled('div', {\n     left: 'calc(-50% + 20px)',\n     right: 'calc(50% + 20px)',\n   }),\n+  ...(ownerState.orientation === 'horizontal' && !ownerState.alternativeLabel && {\n+    position: 'absolute',\n+    top: 8 + 4,\n+    left: 0,\n+    right: 0,\n+  }),\n }));\n \n const StepConnectorLine = styled('span', {\ndiff --git a/packages/mui-material/src/Stepper/Stepper.js b/packages/mui-material/src/Stepper/Stepper.js\nindex 8776ff6d3f..2dd518c252 100644\n--- a/packages/mui-material/src/Stepper/Stepper.js\n+++ b/packages/mui-material/src/Stepper/Stepper.js\n@@ -18,7 +18,7 @@ const useUtilityClasses = (ownerState) => {\n   return composeClasses(slots, getStepperUtilityClass, classes);\n };\n \n-const StepperRoot = styled('div', {\n+const StepperRoot = styled('ol', {\n   name: 'MuiStepper',\n   slot: 'Root',\n   overridesResolver: (props, styles) => {\n@@ -31,6 +31,9 @@ const StepperRoot = styled('div', {\n   },\n })(({ ownerState }) => ({\n   display: 'flex',\n+  listStyle: 'none',\n+  margin: 0,\n+  padding: 0,\n   ...(ownerState.orientation === 'horizontal' && {\n     flexDirection: 'row',\n     alignItems: 'center',\n"}
{"instance_id": "mui__material-ui-34158", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-base/src/ListboxUnstyled/useControllableReducer.ts b/packages/mui-base/src/ListboxUnstyled/useControllableReducer.ts\nindex 305c5d9f9a..fea504a9d0 100644\n--- a/packages/mui-base/src/ListboxUnstyled/useControllableReducer.ts\n+++ b/packages/mui-base/src/ListboxUnstyled/useControllableReducer.ts\n@@ -46,6 +46,7 @@ function useStateChangeDetection<TOption>(\n   internalPreviousState: ListboxState<TOption>,\n   propsRef: React.RefObject<UseListboxPropsWithDefaults<TOption>>,\n   hasDispatchedActionRef: React.MutableRefObject<boolean>,\n+  lastActionRef: React.MutableRefObject<ListboxAction<TOption> | null>,\n ) {\n   React.useEffect(() => {\n     if (!propsRef.current || !hasDispatchedActionRef.current) {\n@@ -58,24 +59,31 @@ function useStateChangeDetection<TOption>(\n     const previousState = getControlledState(internalPreviousState, propsRef.current);\n     const { multiple, optionComparer } = propsRef.current;\n \n+    const event: React.SyntheticEvent | null =\n+      (lastActionRef.current && (lastActionRef.current as any).event) || null;\n+\n     if (multiple) {\n       const previousSelectedValues = (previousState?.selectedValue ?? []) as TOption[];\n       const nextSelectedValues = nextState.selectedValue as TOption[];\n-      const onChange = propsRef.current.onChange as ((value: TOption[]) => void) | undefined;\n+      const onChange = propsRef.current.onChange as\n+        | ((value: TOption[], event: React.SyntheticEvent | null) => void)\n+        | undefined;\n \n       if (!areArraysEqual(nextSelectedValues, previousSelectedValues, optionComparer)) {\n-        onChange?.(nextSelectedValues);\n+        onChange?.(nextSelectedValues, event);\n       }\n     } else {\n       const previousSelectedValue = previousState?.selectedValue as TOption | null;\n       const nextSelectedValue = nextState.selectedValue as TOption | null;\n-      const onChange = propsRef.current.onChange as ((value: TOption | null) => void) | undefined;\n+      const onChange = propsRef.current.onChange as\n+        | ((value: TOption | null, event: React.SyntheticEvent | null) => void)\n+        | undefined;\n \n       if (!areOptionsEqual(nextSelectedValue, previousSelectedValue, optionComparer)) {\n-        onChange?.(nextSelectedValue);\n+        onChange?.(nextSelectedValue, event);\n       }\n     }\n-  }, [nextState.selectedValue, internalPreviousState, propsRef, hasDispatchedActionRef]);\n+  }, [nextState.selectedValue, internalPreviousState, propsRef, hasDispatchedActionRef, lastActionRef]);\n \n   React.useEffect(() => {\n     if (!propsRef.current) {\n@@ -106,6 +114,7 @@ export default function useControllableReducer<TOption>(\n   propsRef.current = props;\n \n   const hasDispatchedActionRef = React.useRef(false);\n+  const lastActionRef = React.useRef<ListboxAction<TOption> | null>(null);\n \n   const initialSelectedValue =\n     (value === undefined ? defaultValue : value) ?? (props.multiple ? [] : null);\n@@ -118,6 +127,7 @@ export default function useControllableReducer<TOption>(\n   const combinedReducer = React.useCallback(\n     (state: ListboxState<TOption>, action: ListboxAction<TOption>) => {\n       hasDispatchedActionRef.current = true;\n+      lastActionRef.current = action;\n \n       if (externalReducer) {\n         return externalReducer(getControlledState(state, propsRef.current), action);\n@@ -140,6 +150,7 @@ export default function useControllableReducer<TOption>(\n     previousState.current,\n     propsRef,\n     hasDispatchedActionRef,\n+    lastActionRef,\n   );\n   return [getControlledState(nextState, propsRef.current), dispatch];\n }\ndiff --git a/packages/mui-base/src/ListboxUnstyled/useListbox.types.ts b/packages/mui-base/src/ListboxUnstyled/useListbox.types.ts\nindex 8239f94810..2b43092f9e 100644\n--- a/packages/mui-base/src/ListboxUnstyled/useListbox.types.ts\n+++ b/packages/mui-base/src/ListboxUnstyled/useListbox.types.ts\n@@ -178,7 +178,7 @@ interface UseSingleSelectListboxParameters<TOption> extends UseListboxCommonProp\n   /**\n    * Callback fired when the value changes.\n    */\n-  onChange?: (value: TOption) => void;\n+  onChange?: (value: TOption | null, event: React.SyntheticEvent | null) => void;\n }\n \n interface UseMultiSelectListboxParameters<TOption> extends UseListboxCommonProps<TOption> {\n@@ -198,7 +198,7 @@ interface UseMultiSelectListboxParameters<TOption> extends UseListboxCommonProps\n   /**\n    * Callback fired when the value changes.\n    */\n-  onChange?: (value: TOption[]) => void;\n+  onChange?: (value: TOption[], event: React.SyntheticEvent | null) => void;\n }\n \n export type UseListboxParameters<TOption> =\ndiff --git a/packages/mui-base/src/MultiSelectUnstyled/MultiSelectUnstyled.types.ts b/packages/mui-base/src/MultiSelectUnstyled/MultiSelectUnstyled.types.ts\nindex e03a97af79..af115465df 100644\n--- a/packages/mui-base/src/MultiSelectUnstyled/MultiSelectUnstyled.types.ts\n+++ b/packages/mui-base/src/MultiSelectUnstyled/MultiSelectUnstyled.types.ts\n@@ -59,7 +59,7 @@ export interface MultiSelectUnstyledOwnProps<TValue extends {}> extends SelectUn\n   /**\n    * Callback fired when an option is selected.\n    */\n-  onChange?: (value: TValue[]) => void;\n+  onChange?: (event: React.SyntheticEvent | null, value: TValue[]) => void;\n   /**\n    * A function used to convert the option label to a string.\n    * It's useful when labels are elements and need to be converted to plain text\ndiff --git a/packages/mui-base/src/SelectUnstyled/SelectUnstyled.types.ts b/packages/mui-base/src/SelectUnstyled/SelectUnstyled.types.ts\nindex 26833cf66c..cc0e9ee607 100644\n--- a/packages/mui-base/src/SelectUnstyled/SelectUnstyled.types.ts\n+++ b/packages/mui-base/src/SelectUnstyled/SelectUnstyled.types.ts\n@@ -97,7 +97,7 @@ export interface SelectUnstyledOwnProps<TValue extends {}> extends SelectUnstyle\n   /**\n    * Callback fired when an option is selected.\n    */\n-  onChange?: (value: TValue | null) => void;\n+  onChange?: (event: React.SyntheticEvent | null, value: TValue | null) => void;\n   /**\n    * A function used to convert the option label to a string.\n    * It's useful when labels are elements and need to be converted to plain text\ndiff --git a/packages/mui-base/src/SelectUnstyled/useSelect.ts b/packages/mui-base/src/SelectUnstyled/useSelect.ts\nindex a87c4977c9..ece6d2637b 100644\n--- a/packages/mui-base/src/SelectUnstyled/useSelect.ts\n+++ b/packages/mui-base/src/SelectUnstyled/useSelect.ts\n@@ -214,10 +214,13 @@ function useSelect<TValue>(props: UseSelectParameters<TValue>) {\n       optionComparer: (o, v) => o?.value === v?.value,\n       listboxRef: handleListboxRef,\n       multiple: true,\n-      onChange: (newOptions) => {\n+      onChange: (newOptions, event) => {\n         const newValues = newOptions.map((o) => o.value);\n         setValue(newValues);\n-        (onChange as (value: TValue[]) => void)?.(newValues);\n+        (onChange as (event: React.SyntheticEvent | null, value: TValue[]) => void)?.(\n+          event ?? null,\n+          newValues,\n+        );\n       },\n       options,\n       optionStringifier,\n@@ -230,9 +233,12 @@ function useSelect<TValue>(props: UseSelectParameters<TValue>) {\n       optionComparer: (o, v) => o?.value === v?.value,\n       listboxRef: handleListboxRef,\n       multiple: false,\n-      onChange: (option: SelectOption<TValue> | null) => {\n+      onChange: (option: SelectOption<TValue> | null, event) => {\n         setValue(option?.value ?? null);\n-        (onChange as (value: TValue | null) => void)?.(option?.value ?? null);\n+        (onChange as (event: React.SyntheticEvent | null, value: TValue | null) => void)?.(\n+          event ?? null,\n+          option?.value ?? null,\n+        );\n       },\n       options,\n       optionStringifier,\ndiff --git a/packages/mui-base/src/SelectUnstyled/useSelect.types.ts b/packages/mui-base/src/SelectUnstyled/useSelect.types.ts\nindex 93c1490cdf..23b5e5a3a2 100644\n--- a/packages/mui-base/src/SelectUnstyled/useSelect.types.ts\n+++ b/packages/mui-base/src/SelectUnstyled/useSelect.types.ts\n@@ -41,14 +41,14 @@ interface UseSelectCommonProps<TValue> {\n export interface UseSelectSingleParameters<TValue> extends UseSelectCommonProps<TValue> {\n   defaultValue?: TValue | null;\n   multiple?: false;\n-  onChange?: (value: TValue | null) => void;\n+  onChange?: (event: React.SyntheticEvent | null, value: TValue | null) => void;\n   value?: TValue | null;\n }\n \n export interface UseSelectMultiParameters<TValue> extends UseSelectCommonProps<TValue> {\n   defaultValue?: TValue[];\n   multiple: true;\n-  onChange?: (value: TValue[]) => void;\n+  onChange?: (event: React.SyntheticEvent | null, value: TValue[]) => void;\n   value?: TValue[];\n }\n \n"}
{"instance_id": "mui__material-ui-34207", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-material/src/FormControlLabel/FormControlLabel.d.ts b/packages/mui-material/src/FormControlLabel/FormControlLabel.d.ts\nindex cf996bf876..bbb6888465 100644\n--- a/packages/mui-material/src/FormControlLabel/FormControlLabel.d.ts\n+++ b/packages/mui-material/src/FormControlLabel/FormControlLabel.d.ts\n@@ -46,6 +46,10 @@ export interface FormControlLabelProps\n    * A text or an element to be used in an enclosing label element.\n    */\n   label: React.ReactNode;\n+  /**\n+   * If `true`, the label will indicate that the input is required.\n+   */\n+  required?: boolean;\n   /**\n    * The position of the label.\n    * @default 'end'\ndiff --git a/packages/mui-material/src/FormControlLabel/FormControlLabel.js b/packages/mui-material/src/FormControlLabel/FormControlLabel.js\nindex 2f4e89c2f3..0ef6d6a9fe 100644\n--- a/packages/mui-material/src/FormControlLabel/FormControlLabel.js\n+++ b/packages/mui-material/src/FormControlLabel/FormControlLabel.js\n@@ -23,6 +23,7 @@ const useUtilityClasses = (ownerState) => {\n       error && 'error',\n     ],\n     label: ['label', disabled && 'disabled'],\n+    asterisk: ['asterisk', error && 'error'],\n   };\n \n   return composeClasses(slots, getFormControlLabelUtilityClasses, classes);\n@@ -36,6 +37,7 @@ export const FormControlLabelRoot = styled('label', {\n \n     return [\n       { [`& .${formControlLabelClasses.label}`]: styles.label },\n+      { [`& .${formControlLabelClasses.asterisk}`]: styles.asterisk },\n       styles.root,\n       styles[`labelPlacement${capitalize(ownerState.labelPlacement)}`],\n     ];\n@@ -70,6 +72,11 @@ export const FormControlLabelRoot = styled('label', {\n       color: (theme.vars || theme).palette.text.disabled,\n     },\n   },\n+  [`& .${formControlLabelClasses.asterisk}`]: {\n+    [`&.${formControlLabelClasses.error}`]: {\n+      color: (theme.vars || theme).palette.error.main,\n+    },\n+  },\n }));\n \n /**\n@@ -118,7 +125,7 @@ const FormControlLabel = React.forwardRef(function FormControlLabel(inProps, ref\n   const fcs = formControlState({\n     props,\n     muiFormControl,\n-    states: ['error'],\n+    states: ['error', 'required'],\n   });\n \n   const ownerState = {\n@@ -141,8 +148,25 @@ const FormControlLabel = React.forwardRef(function FormControlLabel(inProps, ref\n         className={clsx(classes.label, typographySlotProps?.className)}\n       >\n         {label}\n+        {fcs.required && (\n+          <span aria-hidden className={classes.asterisk}>\n+            &thinsp;{'*'}\n+          </span>\n+        )}\n       </Typography>\n     );\n+  } else if (label != null) {\n+    // when Typography is disabled or label is a React node, append asterisk after label\n+    label = (\n+      <React.Fragment>\n+        {label}\n+        {fcs.required && (\n+          <span aria-hidden className={classes.asterisk}>\n+            &thinsp;{'*'}\n+          </span>\n+        )}\n+      </React.Fragment>\n+    );\n   }\n \n   return (\n@@ -202,6 +226,10 @@ FormControlLabel.propTypes /* remove-proptypes */ = {\n    * A text or an element to be used in an enclosing label element.\n    */\n   label: PropTypes.node,\n+  /**\n+   * If `true`, the label will indicate that the `input` is required.\n+   */\n+  required: PropTypes.bool,\n   /**\n    * The position of the label.\n    * @default 'end'\ndiff --git a/packages/mui-material/src/FormControlLabel/formControlLabelClasses.ts b/packages/mui-material/src/FormControlLabel/formControlLabelClasses.ts\nindex 65b25aa6cc..a59eb908c9 100644\n--- a/packages/mui-material/src/FormControlLabel/formControlLabelClasses.ts\n+++ b/packages/mui-material/src/FormControlLabel/formControlLabelClasses.ts\n@@ -16,6 +16,8 @@ export interface FormControlLabelClasses {\n   label: string;\n   /** State class applied to the root element if `error={true}`. */\n   error: string;\n+  /** Styles applied to the asterisk element. */\n+  asterisk: string;\n }\n \n export type FormControlLabelClassKey = keyof FormControlLabelClasses;\n@@ -34,6 +36,7 @@ const formControlLabelClasses: FormControlLabelClasses = generateUtilityClasses(\n     'disabled',\n     'label',\n     'error',\n+    'asterisk',\n   ],\n );\n \n"}
{"instance_id": "mui__material-ui-34610", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-base/src/SliderUnstyled/SliderUnstyled.js b/packages/mui-base/src/SliderUnstyled/SliderUnstyled.js\nindex c5f73e2b24..bc04c5e299 100644\n--- a/packages/mui-base/src/SliderUnstyled/SliderUnstyled.js\n+++ b/packages/mui-base/src/SliderUnstyled/SliderUnstyled.js\n@@ -46,6 +46,7 @@ const SliderUnstyled = React.forwardRef(function SliderUnstyled(props, ref) {\n   const {\n     'aria-label': ariaLabel,\n     'aria-valuetext': ariaValuetext,\n+    'aria-labelledby': ariaLabelledby,\n     className,\n     component,\n     classes: classesProp,\n@@ -106,7 +107,7 @@ const SliderUnstyled = React.forwardRef(function SliderUnstyled(props, ref) {\n     values,\n     trackOffset,\n     trackLeap,\n-  } = useSlider({ ...ownerState, ref });\n+  } = useSlider({ ...ownerState, 'aria-labelledby': ariaLabelledby, ref });\n \n   ownerState.marked = marks.length > 0 && marks.some((mark) => mark.label);\n   ownerState.dragging = dragging;\n"}
{"instance_id": "mui__material-ui-36353", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-material/src/Dialog/Dialog.js b/packages/mui-material/src/Dialog/Dialog.js\nindex eb31fd065a..612d0c487e 100644\n--- a/packages/mui-material/src/Dialog/Dialog.js\n+++ b/packages/mui-material/src/Dialog/Dialog.js\n@@ -226,10 +226,15 @@ const Dialog = React.forwardRef(function Dialog(inProps, ref) {\n     }\n   };\n \n-  const ariaLabelledby = useId(ariaLabelledbyProp);\n+  const generatedTitleId = useId(ariaLabelledbyProp);\n+  const [registeredTitleId, setRegisteredTitleId] = React.useState();\n+  const effectiveTitleId = registeredTitleId != null ? registeredTitleId : generatedTitleId;\n   const dialogContextValue = React.useMemo(() => {\n-    return { titleId: ariaLabelledby };\n-  }, [ariaLabelledby]);\n+    return {\n+      titleId: generatedTitleId,\n+      registerTitleId: setRegisteredTitleId,\n+    };\n+  }, [generatedTitleId]);\n \n   return (\n     <DialogRoot\n@@ -270,7 +275,7 @@ const Dialog = React.forwardRef(function Dialog(inProps, ref) {\n             elevation={24}\n             role=\"dialog\"\n             aria-describedby={ariaDescribedby}\n-            aria-labelledby={ariaLabelledby}\n+            aria-labelledby={ariaLabelledbyProp != null ? ariaLabelledbyProp : effectiveTitleId}\n             {...PaperProps}\n             className={clsx(classes.paper, PaperProps.className)}\n             ownerState={ownerState}\ndiff --git a/packages/mui-material/src/Dialog/DialogContext.ts b/packages/mui-material/src/Dialog/DialogContext.ts\nindex d73b6aa702..556fa7850f 100644\n--- a/packages/mui-material/src/Dialog/DialogContext.ts\n+++ b/packages/mui-material/src/Dialog/DialogContext.ts\n@@ -2,6 +2,7 @@ import * as React from 'react';\n \n interface DialogContextValue {\n   titleId?: string;\n+  registerTitleId?: (id?: string) => void;\n }\n \n const DialogContext = React.createContext<DialogContextValue>({});\ndiff --git a/packages/mui-material/src/DialogTitle/DialogTitle.js b/packages/mui-material/src/DialogTitle/DialogTitle.js\nindex 099b595797..fe533dffb2 100644\n--- a/packages/mui-material/src/DialogTitle/DialogTitle.js\n+++ b/packages/mui-material/src/DialogTitle/DialogTitle.js\n@@ -37,7 +37,18 @@ const DialogTitle = React.forwardRef(function DialogTitle(inProps, ref) {\n   const ownerState = props;\n   const classes = useUtilityClasses(ownerState);\n \n-  const { titleId: id = idProp } = React.useContext(DialogContext);\n+  const { titleId, registerTitleId } = React.useContext(DialogContext);\n+  const id = idProp != null ? idProp : titleId;\n+\n+  React.useEffect(() => {\n+    if (registerTitleId) {\n+      registerTitleId(idProp);\n+      return () => {\n+        registerTitleId(undefined);\n+      };\n+    }\n+    return undefined;\n+  }, [idProp, registerTitleId]);\n \n   return (\n     <DialogTitleRoot\n"}
{"instance_id": "mui__material-ui-36971", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-material/src/Autocomplete/Autocomplete.d.ts b/packages/mui-material/src/Autocomplete/Autocomplete.d.ts\nindex a453c649cc..272de97729 100644\n--- a/packages/mui-material/src/Autocomplete/Autocomplete.d.ts\n+++ b/packages/mui-material/src/Autocomplete/Autocomplete.d.ts\n@@ -244,6 +244,7 @@ export interface AutocompleteProps<\n     props: React.HTMLAttributes<HTMLLIElement>,\n     option: T,\n     state: AutocompleteRenderOptionState,\n+    ownerState?: AutocompleteOwnerState<T, Multiple, DisableClearable, FreeSolo, ChipComponent>,\n   ) => React.ReactNode;\n   /**\n    * Render the selected value.\ndiff --git a/packages/mui-material/src/Autocomplete/Autocomplete.js b/packages/mui-material/src/Autocomplete/Autocomplete.js\nindex 853f3be7e2..35fa47b813 100644\n--- a/packages/mui-material/src/Autocomplete/Autocomplete.js\n+++ b/packages/mui-material/src/Autocomplete/Autocomplete.js\n@@ -556,7 +556,7 @@ const Autocomplete = React.forwardRef(function Autocomplete(inProps, ref) {\n       selected: optionProps['aria-selected'],\n       index,\n       inputValue,\n-    });\n+    }, ownerState);\n   };\n \n   const clearIndicatorSlotProps = slotProps.clearIndicator ?? componentsProps.clearIndicator;\n@@ -1065,6 +1065,7 @@ Autocomplete.propTypes /* remove-proptypes */ = {\n    * @param {object} props The props to apply on the li element.\n    * @param {T} option The option to render.\n    * @param {object} state The state of the component.\n+   * @param {object} ownerState The state of the Autocomplete component.\n    * @returns {ReactNode}\n    */\n   renderOption: PropTypes.func,\n"}
{"instance_id": "tailwindlabs__tailwindcss-116", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/borderStylesReset.js b/src/generators/borderStylesReset.js\nindex 230dfc88..621ac3b7 100644\n--- a/src/generators/borderStylesReset.js\n+++ b/src/generators/borderStylesReset.js\n@@ -2,11 +2,5 @@ import defineClasses from '../util/defineClasses'\n \n export default function() {\n   return defineClasses({\n-    'border-dashed': {\n-      'border-width': '0',\n-    },\n-    'border-dotted': {\n-      'border-width': '0',\n-    },\n   })\n }\ndiff --git a/src/lib/generateUtilities.js b/src/lib/generateUtilities.js\nindex 75dd4e7d..2b6a28c0 100644\n--- a/src/lib/generateUtilities.js\n+++ b/src/lib/generateUtilities.js\n@@ -3,7 +3,6 @@ import backgroundColors from '../generators/backgroundColors'\n import backgroundPositions from '../generators/backgroundPositions'\n import backgroundSize from '../generators/backgroundSize'\n import borderColors from '../generators/borderColors'\n-import borderStylesReset from '../generators/borderStylesReset'\n import borderStyles from '../generators/borderStyles'\n import borderWidths from '../generators/borderWidths'\n import container from '../generators/container'\n@@ -59,7 +58,7 @@ export default function(config) {\n           backgroundColors(options),\n           backgroundPositions(options),\n           backgroundSize(options),\n-          borderStylesReset(options),\n+          \n           borderWidths(options),\n           borderColors(options),\n           borderStyles(options),\n"}
{"instance_id": "mui__material-ui-38544", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/packages/mui-material/src/Tabs/Tabs.js b/packages/mui-material/src/Tabs/Tabs.js\nindex 12a9f9ba9f..530e568311 100644\n--- a/packages/mui-material/src/Tabs/Tabs.js\n+++ b/packages/mui-material/src/Tabs/Tabs.js\n@@ -504,6 +504,7 @@ const Tabs = React.forwardRef(function Tabs(inProps, ref) {\n       <TabsScrollbarSize\n         onChange={handleScrollbarSizeChange}\n         className={clsx(classes.scrollableX, classes.hideScrollbar)}\n+        ownerState={ownerState}\n       />\n     ) : null;\n \n"}
{"instance_id": "tailwindlabs__tailwindcss-550", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/generators/flexbox.js b/src/generators/flexbox.js\nindex 10e26c30..30708613 100644\n--- a/src/generators/flexbox.js\n+++ b/src/generators/flexbox.js\n@@ -90,16 +90,16 @@ export default function() {\n       'align-content': 'space-around',\n     },\n     'flex-1': {\n-      flex: '1',\n+      flex: '1 1 0',\n     },\n     'flex-auto': {\n-      flex: 'auto',\n+      flex: '1 1 auto',\n     },\n     'flex-initial': {\n-      flex: 'initial',\n+      flex: '0 1 auto',\n     },\n     'flex-none': {\n-      flex: 'none',\n+      flex: '0 0 auto',\n     },\n     'flex-grow': {\n       'flex-grow': '1',\n"}
{"instance_id": "coder__code-server-4923", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/node/app.ts b/src/node/app.ts\nindex 13871355..8c4c378c 100644\n--- a/src/node/app.ts\n+++ b/src/node/app.ts\n@@ -10,6 +10,7 @@ import { DefaultedArgs } from \"./cli\"\n import { disposer } from \"./http\"\n import { isNodeJSErrnoException } from \"./util\"\n import { handleUpgrade } from \"./wsRouter\"\n+import { applySocketPermissions, checkAndCleanupStaleSocket, registerSocketCleanup } from \"./unix-socket\"\n \n type ListenOptions = Pick<DefaultedArgs, \"socket\" | \"port\" | \"host\">\n \n@@ -35,11 +36,7 @@ const listen = (server: http.Server, { host, port, socket }: ListenOptions) => {\n     }\n \n     if (socket) {\n-      try {\n-        await fs.unlink(socket)\n-      } catch (error: any) {\n-        handleArgsSocketCatchError(error)\n-      }\n+      await checkAndCleanupStaleSocket(socket)\n \n       server.listen(socket, onListen)\n     } else {\n@@ -70,6 +67,11 @@ export const createApp = async (args: DefaultedArgs): Promise<App> => {\n \n   await listen(server, args)\n \n+  if (args.socket) {\n+    await applySocketPermissions(args.socket, args[\"socket-mode\"], args[\"socket-user\"], args[\"socket-group\"])\n+    registerSocketCleanup(args.socket, server)\n+  }\n+\n   const wsRouter = express()\n   handleUpgrade(wsRouter, server)\n \ndiff --git a/src/node/cli.ts b/src/node/cli.ts\nindex 9928db1c..c4118aa4 100644\n--- a/src/node/cli.ts\n+++ b/src/node/cli.ts\n@@ -4,6 +4,7 @@ import yaml from \"js-yaml\"\n import * as os from \"os\"\n import * as path from \"path\"\n import { canConnect, generateCertificate, generatePassword, humanPath, paths, isNodeJSErrnoException } from \"./util\"\n+import { parseSocketSpec } from \"./unix-socket\"\n \n const DEFAULT_SOCKET_PATH = path.join(os.tmpdir(), \"vscode-ipc\")\n \n@@ -56,6 +57,9 @@ export interface UserProvidedArgs {\n   open?: boolean\n   \"bind-addr\"?: string\n   socket?: string\n+  \"socket-mode\"?: string\n+  \"socket-user\"?: string\n+  \"socket-group\"?: string\n   version?: boolean\n   \"proxy-domain\"?: string[]\n   \"reuse-window\"?: boolean\n@@ -175,6 +179,9 @@ const options: Options<Required<UserProvidedArgs>> = {\n   port: { type: \"number\", description: \"\" },\n \n   socket: { type: \"string\", path: true, description: \"Path to a socket (bind-addr will be ignored).\" },\n+  \"socket-mode\": { type: \"string\", description: \"File mode for the Unix socket (octal like 0770).\" },\n+  \"socket-user\": { type: \"string\", description: \"User name or UID to own the Unix socket.\" },\n+  \"socket-group\": { type: \"string\", description: \"Group name or GID to own the Unix socket.\" },\n   version: { type: \"boolean\", short: \"v\", description: \"Display version information.\" },\n   _: { type: \"string[]\" },\n \n@@ -366,7 +373,21 @@ export const parse = (\n \n       switch (option.type) {\n         case \"string\":\n-          ;(args[key] as string) = value\n+          if (key === \"socket\") {\n+            const parsed = parseSocketSpec(value)\n+            ;(args[\"socket\"] as string) = path.resolve(parsed.path)\n+            if (parsed.mode) {\n+              ;(args[\"socket-mode\"] as string) = parsed.mode\n+            }\n+            if (parsed.user) {\n+              ;(args[\"socket-user\"] as string) = parsed.user\n+            }\n+            if (parsed.group) {\n+              ;(args[\"socket-group\"] as string) = parsed.group\n+            }\n+          } else {\n+            ;(args[key] as string) = value\n+          }\n           break\n         case \"string[]\":\n           if (!args[key]) {\ndiff --git a/src/node/unix-socket.ts b/src/node/unix-socket.ts\nnew file mode 100644\nindex 00000000..ea051435\n--- /dev/null\n+++ b/src/node/unix-socket.ts\n@@ -0,0 +1,202 @@\n+import { logger } from \"@coder/logger\"\n+import { promises as fs } from \"fs\"\n+import * as net from \"net\"\n+import * as path from \"path\"\n+import * as cp from \"child_process\"\n+import http from \"http\"\n+import { canConnect, isNodeJSErrnoException } from \"./util\"\n+\n+export interface ParsedSocketSpec {\n+  path: string\n+  mode?: string\n+  user?: string\n+  group?: string\n+}\n+\n+/**\n+ * Parse extended --socket spec of the form path[,mode][,user][,group].\n+ * Returns the parsed components. Empty components are treated as undefined.\n+ */\n+export function parseSocketSpec(spec: string): ParsedSocketSpec {\n+  const parts = spec.split(\",\")\n+  const p: ParsedSocketSpec = { path: parts[0] }\n+  if (parts.length > 1 && parts[1] !== \"\") {\n+    p.mode = parts[1]\n+  }\n+  if (parts.length > 2 && parts[2] !== \"\") {\n+    p.user = parts[2]\n+  }\n+  if (parts.length > 3 && parts[3] !== \"\") {\n+    p.group = parts[3]\n+  }\n+  return p\n+}\n+\n+function isWindows(): boolean {\n+  return process.platform === \"win32\"\n+}\n+\n+async function resolveUser(user?: string): Promise<number | undefined> {\n+  if (!user) return undefined\n+  if (/^\\d+$/.test(user)) {\n+    return parseInt(user, 10)\n+  }\n+  if (isWindows()) {\n+    logger.warn(\"--socket-user is not supported on Windows\")\n+    return undefined\n+  }\n+  try {\n+    const uid = await execCommand(`id -u ${user}`)\n+    return parseInt(uid.trim(), 10)\n+  } catch (error) {\n+    logger.warn(`Failed to resolve user '${user}': ${error}`)\n+    return undefined\n+  }\n+}\n+\n+async function resolveGroup(group?: string): Promise<number | undefined> {\n+  if (!group) return undefined\n+  if (/^\\d+$/.test(group)) {\n+    return parseInt(group, 10)\n+  }\n+  if (isWindows()) {\n+    logger.warn(\"--socket-group is not supported on Windows\")\n+    return undefined\n+  }\n+  try {\n+    const gidEntry = await execCommand(`getent group ${group}`)\n+    // getent output: name:*:GID:members\n+    const gid = gidEntry.split(\":\")[2]\n+    return gid ? parseInt(gid.trim(), 10) : undefined\n+  } catch (error) {\n+    logger.warn(`Failed to resolve group '${group}': ${error}`)\n+    return undefined\n+  }\n+}\n+\n+function execCommand(cmd: string): Promise<string> {\n+  return new Promise((resolve, reject) => {\n+    cp.exec(cmd, (err, stdout, stderr) => {\n+      if (err) return reject(stderr || err.message)\n+      resolve(stdout)\n+    })\n+  })\n+}\n+\n+/**\n+ * Check existing socket path and clean up if stale. If active, throws an error.\n+ * If the path exists and is not a socket, throws an error.\n+ */\n+export async function checkAndCleanupStaleSocket(socketPath: string): Promise<void> {\n+  if (isWindows()) {\n+    // No-op on Windows for Unix sockets.\n+    return\n+  }\n+  try {\n+    const stat = await fs.lstat(socketPath)\n+    if (!stat.isSocket()) {\n+      throw new Error(`Existing path is not a Unix socket: ${socketPath}`)\n+    }\n+    const active = await canConnect(socketPath)\n+    if (active) {\n+      throw new Error(`Socket already in use: ${socketPath}`)\n+    }\n+    await fs.unlink(socketPath)\n+  } catch (error: any) {\n+    if (isNodeJSErrnoException(error) && error.code === \"ENOENT\") {\n+      // Doesn't exist; fine.\n+      return\n+    }\n+    // If it's a different error, rethrow.\n+    if (error instanceof Error) {\n+      throw error\n+    } else {\n+      throw new Error(String(error))\n+    }\n+  }\n+}\n+\n+/**\n+ * Apply ownership and permission to the Unix socket file.\n+ * mode should be an octal string (e.g., \"0770\"). user/group can be names or IDs.\n+ * Best effort: logs warnings on failure and continues.\n+ */\n+export async function applySocketPermissions(\n+  socketPath: string,\n+  mode?: string,\n+  user?: string,\n+  group?: string,\n+): Promise<void> {\n+  if (isWindows()) {\n+    return\n+  }\n+\n+  try {\n+    const stat = await fs.lstat(socketPath)\n+    if (!stat.isSocket()) {\n+      logger.warn(`Not a socket, skipping permission changes: ${socketPath}`)\n+      return\n+    }\n+  } catch (error) {\n+    logger.warn(`Failed to stat socket for permission changes: ${socketPath} (${error})`)\n+    return\n+  }\n+\n+  // Resolve user and group\n+  const uid = await resolveUser(user)\n+  const gid = await resolveGroup(group)\n+\n+  // Apply chown first so chmod doesn't get blocked by permissions\n+  if (uid !== undefined || gid !== undefined) {\n+    try {\n+      const current = await fs.lstat(socketPath)\n+      await fs.chown(socketPath, uid ?? (current as any).uid ?? process.getuid?.() ?? 0, gid ?? (current as any).gid ?? 0)\n+    } catch (error: any) {\n+      logger.warn(`Failed to chown socket: ${socketPath} (${error?.message || error})`)\n+    }\n+  }\n+\n+  if (mode) {\n+    // Accept both 770 and 0770 inputs\n+    const parsedMode = parseInt(mode, 8)\n+    if (!isNaN(parsedMode)) {\n+      try {\n+        await fs.chmod(socketPath, parsedMode)\n+      } catch (error: any) {\n+        logger.warn(`Failed to chmod socket: ${socketPath} (${error?.message || error})`)\n+      }\n+    } else {\n+      logger.warn(`Invalid socket mode '${mode}', expected octal like 0770`)\n+    }\n+  }\n+}\n+\n+/**\n+ * Register cleanup handlers to remove the socket file on shutdown.\n+ */\n+export function registerSocketCleanup(socketPath: string, server: http.Server): void {\n+  if (isWindows()) return\n+\n+  const cleanup = async () => {\n+    try {\n+      const stat = await fs.lstat(socketPath)\n+      if (stat.isSocket()) {\n+        await fs.unlink(socketPath)\n+      }\n+    } catch (error: any) {\n+      if (!isNodeJSErrnoException(error) || error.code !== \"ENOENT\") {\n+        logger.warn(`Failed to cleanup socket '${socketPath}': ${error?.message || error}`)\n+      }\n+    }\n+  }\n+\n+  server.on(\"close\", () => {\n+    cleanup().catch(() => {})\n+  })\n+  process.on(\"SIGINT\", () => {\n+    cleanup().finally(() => process.exit(130))\n+  })\n+  process.on(\"SIGTERM\", () => {\n+    cleanup().finally(() => process.exit(143))\n+  })\n+}\n"}
{"instance_id": "coder__code-server-6278", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/node/app.ts b/src/node/app.ts\nindex 2cc858f1..52c130a4 100644\n--- a/src/node/app.ts\n+++ b/src/node/app.ts\n@@ -88,7 +88,8 @@ export const createApp = async (args: DefaultedArgs): Promise<App> => {\n   handleUpgrade(wsRouter, server)\n \n   const editorSessionManager = new EditorSessionManager()\n-  const editorSessionManagerServer = await makeEditorSessionManagerServer(DEFAULT_SOCKET_PATH, editorSessionManager)\n+  const editorSocketPath = args[\"ipc-socket\"] || DEFAULT_SOCKET_PATH\n+  const editorSessionManagerServer = await makeEditorSessionManagerServer(editorSocketPath, editorSessionManager)\n   const disposeEditorSessionManagerServer = disposer(editorSessionManagerServer)\n \n   const dispose = async () => {\ndiff --git a/src/node/cli.ts b/src/node/cli.ts\nindex fe7350f5..532c35c8 100644\n--- a/src/node/cli.ts\n+++ b/src/node/cli.ts\n@@ -78,6 +78,7 @@ export interface UserProvidedArgs extends UserProvidedCodeArgs {\n   \"bind-addr\"?: string\n   socket?: string\n   \"socket-mode\"?: string\n+  \"ipc-socket\"?: string\n   version?: boolean\n   \"proxy-domain\"?: string[]\n   \"reuse-window\"?: boolean\n@@ -204,6 +205,7 @@ export const options: Options<Required<UserProvidedArgs>> = {\n \n   socket: { type: \"string\", path: true, description: \"Path to a socket (bind-addr will be ignored).\" },\n   \"socket-mode\": { type: \"string\", description: \"File mode of the socket.\" },\n+  \"ipc-socket\": { type: \"string\", path: true, description: \"Path to the internal IPC socket used for editor session management.\" },\n   version: { type: \"boolean\", short: \"v\", description: \"Display version information.\" },\n   _: { type: \"string[]\" },\n \ndiff --git a/src/node/vscodeSocket.ts b/src/node/vscodeSocket.ts\nindex 1bdb895f..80ae3bdc 100644\n--- a/src/node/vscodeSocket.ts\n+++ b/src/node/vscodeSocket.ts\n@@ -3,12 +3,28 @@ import express from \"express\"\n import * as http from \"http\"\n import * as os from \"os\"\n import * as path from \"path\"\n+import * as fs from \"fs/promises\"\n import { HttpCode } from \"../common/http\"\n import { listen } from \"./app\"\n import { canConnect } from \"./util\"\n \n // Socket path of the daemonized code-server instance.\n-export const DEFAULT_SOCKET_PATH = path.join(os.tmpdir(), \"code-server-ipc.sock\")\n+// Use per-user runtime directory if available to avoid cross-user collisions.\n+// Fall back to a temp directory scoped to code-server with a user-specific subdir.\n+const userRuntimeDir = (() => {\n+  // Prefer XDG_RUNTIME_DIR when available\n+  const xdg = process.env.XDG_RUNTIME_DIR\n+  if (xdg && xdg.length > 0) {\n+    return path.join(xdg, \"code-server\")\n+  }\n+  // On Windows, os.tmpdir is user-specific; on POSIX it is shared (/tmp)\n+  // Create a code-server-specific directory and add UID/username to avoid conflicts.\n+  const base = path.join(os.tmpdir(), \"code-server\")\n+  const uid = process.platform !== \"win32\" ? String(process.getuid && process.getuid()) : process.env.USERNAME || process.env.USER || \"unknown\"\n+  return path.join(base, uid || \"unknown\")\n+})()\n+\n+export const DEFAULT_SOCKET_PATH = path.join(userRuntimeDir, \"code-server-ipc.sock\")\n \n export interface EditorSessionEntry {\n   workspace: {\n@@ -78,6 +94,7 @@ export async function makeEditorSessionManagerServer(\n   })\n \n   const server = http.createServer(router)\n+  await fs.mkdir(path.dirname(codeServerSocketPath), { recursive: true })\n   await listen(server, { socket: codeServerSocketPath })\n   return server\n }\n"}
{"instance_id": "huggingface__transformers-3716", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/modeling_transfo_xl.py b/src/transformers/modeling_transfo_xl.py\nindex 1ed8408966..4acb92d2de 100644\n--- a/src/transformers/modeling_transfo_xl.py\n+++ b/src/transformers/modeling_transfo_xl.py\n@@ -859,7 +859,7 @@ class TransfoXLLMHeadModel(TransfoXLPreTrainedModel):\n \n     Return:\n         :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.TransfoXLConfig`) and inputs:\n-        loss (:obj:`torch.FloatTensor` of shape `(batch_size, sequence_length)`, `optional`, returned when ``labels`` is provided)\n+        loss (:obj:`torch.FloatTensor` of shape `(1,)`, `optional`, returned when ``labels`` is provided)\n             Language modeling loss.\n         prediction_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`):\n             Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n@@ -904,13 +904,17 @@ class TransfoXLLMHeadModel(TransfoXLPreTrainedModel):\n         pred_hid = last_hidden[:, -tgt_len:]\n         outputs = transformer_outputs[1:]\n \n-        softmax_output = self.crit(pred_hid.view(-1, pred_hid.size(-1)), labels)\n         if labels is None:\n+            softmax_output = self.crit(pred_hid.view(-1, pred_hid.size(-1)), labels)\n             softmax_output = softmax_output.view(bsz, tgt_len, -1)\n             outputs = [softmax_output] + outputs\n         else:\n-            softmax_output = softmax_output.view(bsz, tgt_len)\n-            outputs = [softmax_output, None] + outputs\n+            # Shift so that tokens < n predict n\n+            shift_pred_hid = pred_hid[:, :-1, :].contiguous()\n+            shift_labels = labels[:, 1:].contiguous()\n+            per_token_nll = self.crit(shift_pred_hid.view(-1, shift_pred_hid.size(-1)), shift_labels)\n+            loss = per_token_nll.mean()\n+            outputs = [loss, None] + outputs\n \n         return outputs  # (loss), logits or None if labels is not None (speed up adaptive softmax), new_mems, (all hidden states), (all attentions)\n \n"}
{"instance_id": "huggingface__transformers-4759", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/modeling_transfo_xl.py b/src/transformers/modeling_transfo_xl.py\nindex 25c3592999..4dc43384a2 100644\n--- a/src/transformers/modeling_transfo_xl.py\n+++ b/src/transformers/modeling_transfo_xl.py\n@@ -20,6 +20,7 @@\n \n \n import logging\n+from typing import Optional\n \n import torch\n import torch.nn as nn\n@@ -621,6 +622,46 @@ class TransfoXLModel(TransfoXLPreTrainedModel):\n     def set_input_embeddings(self, new_embeddings):\n         self.word_emb = new_embeddings\n \n+    def _resize_token_embeddings(self, new_num_tokens):\n+        old_embeddings = self.get_input_embeddings()\n+        if new_num_tokens is None:\n+            return old_embeddings\n+        old_num_tokens = old_embeddings.n_token\n+        if old_num_tokens == new_num_tokens:\n+            return old_embeddings\n+\n+        # Build new adaptive embeddings and copy weights\n+        config = self.config\n+        new_embeddings = AdaptiveEmbedding(new_num_tokens, config.d_embed, config.d_model, config.cutoffs, div_val=config.div_val)\n+        # Move to same device and dtype\n+        param = next(old_embeddings.parameters())\n+        new_embeddings.to(param.device)\n+\n+        # Initialize new embedding layers\n+        for layer in new_embeddings.emb_layers:\n+            if hasattr(layer, \"weight\") and layer.weight is not None:\n+                self._init_weight(layer.weight)\n+        # Copy projection weights\n+        for i in range(len(new_embeddings.emb_projs)):\n+            if new_embeddings.emb_projs[i] is not None and old_embeddings.emb_projs[i] is not None:\n+                new_embeddings.emb_projs[i].data.copy_(old_embeddings.emb_projs[i].data)\n+\n+        if config.div_val == 1:\n+            num_tokens_to_copy = min(old_num_tokens, new_num_tokens)\n+            new_embeddings.emb_layers[0].weight.data[:num_tokens_to_copy, :] = old_embeddings.emb_layers[0].weight.data[:num_tokens_to_copy, :]\n+        else:\n+            # Copy each shard, expanding the last shard if needed\n+            for i in range(len(new_embeddings.cutoffs)):\n+                l_old, r_old = old_embeddings.cutoff_ends[i], old_embeddings.cutoff_ends[i + 1]\n+                l_new, r_new = new_embeddings.cutoff_ends[i], new_embeddings.cutoff_ends[i + 1]\n+                size_old = r_old - l_old\n+                size_new = r_new - l_new\n+                rows_to_copy = min(size_old, size_new)\n+                new_embeddings.emb_layers[i].weight.data[:rows_to_copy, :] = old_embeddings.emb_layers[i].weight.data[:rows_to_copy, :]\n+\n+        self.set_input_embeddings(new_embeddings)\n+        return self.get_input_embeddings()\n+\n     def backward_compatible(self):\n         self.sample_softmax = -1\n \n@@ -820,6 +861,21 @@ class TransfoXLLMHeadModel(TransfoXLPreTrainedModel):\n \n         self.init_weights()\n \n+    def resize_token_embeddings(self, new_num_tokens: Optional[int] = None):\n+        model_embeds = super().resize_token_embeddings(new_num_tokens)\n+        if new_num_tokens is None:\n+            return model_embeds\n+        # Rebuild output softmax to match new vocabulary size\n+        config = self.config\n+        self.crit = ProjectedAdaptiveLogSoftmax(\n+            new_num_tokens, config.d_embed, config.d_model, config.cutoffs, div_val=config.div_val\n+        )\n+        # Ensure device consistency\n+        self.crit.to(self.transformer.device)\n+        # Tie weights again with new criterion\n+        self.tie_weights()\n+        return model_embeds\n+\n     def tie_weights(self):\n         \"\"\"\n         Run this to be sure output and input (adaptive) softmax weights are tied\ndiff --git a/src/transformers/modeling_utils.py b/src/transformers/modeling_utils.py\nindex b557aaf8d3..53c2c5d76f 100644\n--- a/src/transformers/modeling_utils.py\n+++ b/src/transformers/modeling_utils.py\n@@ -412,6 +412,9 @@ class PreTrainedModel(nn.Module, ModuleUtilsMixin):\n         if new_num_tokens is None:\n             return old_embeddings\n \n+        if not hasattr(old_embeddings, \"weight\"):\n+            raise NotImplementedError(\"Resizing token embeddings is not supported for this embedding type. The model should implement a custom _resize_token_embeddings method.\")\n+\n         old_num_tokens, old_embedding_dim = old_embeddings.weight.size()\n         if old_num_tokens == new_num_tokens:\n             return old_embeddings\n"}
{"instance_id": "huggingface__transformers-5122", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/data/data_collator.py b/src/transformers/data/data_collator.py\nindex 5e014d338b..1abf5f4707 100644\n--- a/src/transformers/data/data_collator.py\n+++ b/src/transformers/data/data_collator.py\n@@ -42,15 +42,21 @@ def default_data_collator(features: List[InputDataClass]) -> Dict[str, torch.Ten\n     # Special handling for labels.\n     # Ensure that tensor is created with the correct type\n     # (it should be automatically the case, but let's make sure of it.)\n-    if \"label\" in first:\n-        dtype = torch.long if type(first[\"label\"]) is int else torch.float\n-        batch[\"labels\"] = torch.tensor([f[\"label\"] for f in features], dtype=dtype)\n-    elif \"label_ids\" in first:\n-        if isinstance(first[\"label_ids\"], torch.Tensor):\n-            batch[\"labels\"] = torch.stack([f[\"label_ids\"] for f in features])\n-        else:\n-            dtype = torch.long if type(first[\"label_ids\"][0]) is int else torch.float\n-            batch[\"labels\"] = torch.tensor([f[\"label_ids\"] for f in features], dtype=dtype)\n+    if \"label\" in first and first[\"label\"] is not None:\n+        # Only add labels if they are present for the whole batch\n+        labels = [f[\"label\"] for f in features]\n+        if all(label is not None for label in labels):\n+            dtype = torch.long if type(first[\"label\"]) is int else torch.float\n+            batch[\"labels\"] = torch.tensor(labels, dtype=dtype)\n+    elif \"label_ids\" in first and first[\"label_ids\"] is not None:\n+        # Only add label_ids if they are present for the whole batch\n+        label_ids = [f[\"label_ids\"] for f in features]\n+        if all(li is not None for li in label_ids):\n+            if isinstance(first[\"label_ids\"], torch.Tensor):\n+                batch[\"labels\"] = torch.stack(label_ids)\n+            else:\n+                dtype = torch.long if type(first[\"label_ids\"][0]) is int else torch.float\n+                batch[\"labels\"] = torch.tensor(label_ids, dtype=dtype)\n \n     # Handling of all other possible keys.\n     # Again, we will use the first element to figure out which key/values are not None for this model.\n"}
{"instance_id": "huggingface__transformers-6098", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/tokenization_bart.py b/src/transformers/tokenization_bart.py\nindex c83ad0d333..d1d1f68011 100644\n--- a/src/transformers/tokenization_bart.py\n+++ b/src/transformers/tokenization_bart.py\n@@ -124,6 +124,8 @@ class MBartTokenizer(XLMRobertaTokenizer):\n         self.cur_lang_code = self.lang_code_to_id[\"en_XX\"]\n \n         self.fairseq_tokens_to_ids.update(self.lang_code_to_id)\n+        # Make sure <mask> token id comes after all language codes as in fairseq\n+        self.fairseq_tokens_to_ids[\"<mask>\"] = self.sp_model_size + self.fairseq_offset + len(FAIRSEQ_LANGUAGE_CODES)\n         self.fairseq_ids_to_tokens = {v: k for k, v in self.fairseq_tokens_to_ids.items()}\n         self._additional_special_tokens = list(self.lang_code_to_id.keys())\n         self.set_src_lang_special_tokens(kwargs.get(\"src_lang\", \"en_XX\"))\n@@ -255,3 +257,8 @@ class MBartTokenizer(XLMRobertaTokenizer):\n         self.cur_lang_code = self.lang_code_to_id[lang]\n         self.prefix_tokens = [self.cur_lang_code]\n         self.suffix_tokens = [self.eos_token_id]\n+\n+    @property\n+    def vocab_size(self):\n+        # Include language codes and the <mask> token\n+        return len(self.sp_model) + self.fairseq_offset + len(FAIRSEQ_LANGUAGE_CODES) + 1\n"}
{"instance_id": "huggingface__transformers-7075", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/benchmarks.rst b/docs/source/benchmarks.rst\nindex 38afce66fb..e1259c2502 100644\n--- a/docs/source/benchmarks.rst\n+++ b/docs/source/benchmarks.rst\n@@ -306,7 +306,7 @@ This section lists a couple of best practices one should be aware of when benchm\n \n - Currently, only single device benchmarking is supported. When benchmarking on GPU, it is recommended that the user \n   specifies on which device the code should be run by setting the ``CUDA_VISIBLE_DEVICES`` environment variable in the shell, `e.g.` ``export CUDA_VISIBLE_DEVICES=0`` before running the code.\n-- The option :obj:`no_multi_processing` should only be set to :obj:`True` for testing and debugging. To ensure accurate memory measurement it is recommended to run each memory benchmark in a separate process by making sure :obj:`no_multi_processing` is set to :obj:`True`.\n+- Multiprocessing is enabled by default for accurate CPU and GPU memory measurements. Disable it only for testing and debugging, or when using TPU, by setting :obj:`multi_process=False` or using the CLI flag ``--no-multi-process``.\n - One should always state the environment information when sharing the results of a model benchmark. Results can vary heavily between different GPU devices, library versions, etc., so that benchmark results on their own are not very useful for the community.\n \n \ndiff --git a/src/transformers/benchmark/benchmark.py b/src/transformers/benchmark/benchmark.py\nindex d36f589ed1..8ad36e1d8b 100644\n--- a/src/transformers/benchmark/benchmark.py\n+++ b/src/transformers/benchmark/benchmark.py\n@@ -229,7 +229,7 @@ class PyTorchBenchmark(Benchmark):\n             if self.args.is_tpu:\n                 # tpu\n                 raise NotImplementedError(\n-                    \"Memory Benchmarking is currently not implemented for TPU. Please disable memory benchmarking with `--no_memory` or `args.no_memory=True`\"\n+                    \"Memory Benchmarking is currently not implemented for TPU. Please disable memory benchmarking with `--no-memory` or `args.memory=False`\"\n                 )\n             elif self.args.is_gpu:\n                 if not is_py3nvml_available():\ndiff --git a/src/transformers/benchmark/benchmark_args.py b/src/transformers/benchmark/benchmark_args.py\nindex aecefd8ba1..d46ba4f733 100644\n--- a/src/transformers/benchmark/benchmark_args.py\n+++ b/src/transformers/benchmark/benchmark_args.py\n@@ -50,7 +50,7 @@ class PyTorchBenchmarkArguments(BenchmarkArguments):\n     @torch_required\n     def _setup_devices(self) -> Tuple[\"torch.device\", int]:\n         logger.info(\"PyTorch: setting up devices\")\n-        if self.no_cuda:\n+        if not self.cuda:\n             device = torch.device(\"cpu\")\n             n_gpu = 0\n         elif is_torch_tpu_available():\n@@ -63,7 +63,7 @@ class PyTorchBenchmarkArguments(BenchmarkArguments):\n \n     @property\n     def is_tpu(self):\n-        return is_torch_tpu_available() and not self.no_tpu\n+        return is_torch_tpu_available() and self.tpu\n \n     @property\n     @torch_required\ndiff --git a/src/transformers/benchmark/benchmark_args_tf.py b/src/transformers/benchmark/benchmark_args_tf.py\nindex 2b005df68b..d92ba78386 100644\n--- a/src/transformers/benchmark/benchmark_args_tf.py\n+++ b/src/transformers/benchmark/benchmark_args_tf.py\n@@ -50,7 +50,7 @@ class TensorFlowBenchmarkArguments(BenchmarkArguments):\n     @cached_property\n     @tf_required\n     def _setup_tpu(self) -> Tuple[\"tf.distribute.cluster_resolver.TPUClusterResolver\"]:\n-        if not self.no_tpu:\n+        if self.tpu:\n             try:\n                 if self.tpu_name:\n                     tpu = tf.distribute.cluster_resolver.TPUClusterResolver(self.tpu_name)\n@@ -98,7 +98,7 @@ class TensorFlowBenchmarkArguments(BenchmarkArguments):\n     @property\n     @tf_required\n     def n_gpu(self) -> int:\n-        if not self.no_cuda:\n+        if self.cuda:\n             return len(self.gpu_list)\n         return 0\n \ndiff --git a/src/transformers/benchmark/benchmark_args_utils.py b/src/transformers/benchmark/benchmark_args_utils.py\nindex afabee2794..b79a35230f 100644\n--- a/src/transformers/benchmark/benchmark_args_utils.py\n+++ b/src/transformers/benchmark/benchmark_args_utils.py\n@@ -18,7 +18,7 @@ import dataclasses\n import json\n from dataclasses import dataclass, field\n from time import time\n-from typing import List\n+from typing import List, Optional\n \n from ..utils import logging\n \n@@ -57,24 +57,54 @@ class BenchmarkArguments:\n         metadata={\"help\": \"List of sequence lengths for which memory and time performance will be evaluated\"},\n     )\n \n-    no_inference: bool = field(default=False, metadata={\"help\": \"Don't benchmark inference of model\"})\n-    no_cuda: bool = field(default=False, metadata={\"help\": \"Whether to run on available cuda devices\"})\n-    no_tpu: bool = field(default=False, metadata={\"help\": \"Whether to run on available tpu devices\"})\n+    # Positive-formulated flags (default True) for enabling features by default\n+    inference: bool = field(default=True, metadata={\"help\": \"Benchmark inference of model\"})\n+    cuda: bool = field(default=True, metadata={\"help\": \"Run on available CUDA devices\"})\n+    tpu: bool = field(default=True, metadata={\"help\": \"Use available TPU devices\"})\n     fp16: bool = field(default=False, metadata={\"help\": \"Use FP16 to accelerate inference.\"})\n     training: bool = field(default=False, metadata={\"help\": \"Benchmark training of model\"})\n     verbose: bool = field(default=False, metadata={\"help\": \"Verbose memory tracing\"})\n-    no_speed: bool = field(default=False, metadata={\"help\": \"Don't perform speed measurements\"})\n-    no_memory: bool = field(default=False, metadata={\"help\": \"Don't perform memory measurements\"})\n+    speed: bool = field(default=True, metadata={\"help\": \"Perform speed measurements\"})\n+    memory: bool = field(default=True, metadata={\"help\": \"Perform memory measurements\"})\n     trace_memory_line_by_line: bool = field(default=False, metadata={\"help\": \"Trace memory line by line\"})\n     save_to_csv: bool = field(default=False, metadata={\"help\": \"Save result to a CSV file\"})\n     log_print: bool = field(default=False, metadata={\"help\": \"Save all print statements in a log file\"})\n-    no_env_print: bool = field(default=False, metadata={\"help\": \"Don't print environment information\"})\n-    no_multi_process: bool = field(\n-        default=False,\n+    env_print: bool = field(default=True, metadata={\"help\": \"Print environment information\"})\n+    multi_process: bool = field(\n+        default=True,\n         metadata={\n-            \"help\": \"Don't use multiprocessing for memory and speed measurement. It is highly recommended to use multiprocessing for accurate CPU and GPU memory measurements. This option should only be used for debugging / testing and on TPU.\"\n+            \"help\": \"Use multiprocessing for memory and speed measurement. It is highly recommended to enable multiprocessing for accurate CPU and GPU memory measurements. Disable only for debugging/testing or on TPU.\"\n         },\n     )\n+    # Deprecated negative-form aliases for backward compatibility\n+    no_inference: Optional[bool] = field(\n+        default=None,\n+        metadata={\"help\": \"Deprecated: use --no-inference to disable or set inference=False\"},\n+    )\n+    no_cuda: Optional[bool] = field(\n+        default=None,\n+        metadata={\"help\": \"Deprecated: use --no-cuda to disable or set cuda=False\"},\n+    )\n+    no_tpu: Optional[bool] = field(\n+        default=None,\n+        metadata={\"help\": \"Deprecated: use --no-tpu to disable or set tpu=False\"},\n+    )\n+    no_speed: Optional[bool] = field(\n+        default=None,\n+        metadata={\"help\": \"Deprecated: use --no-speed to disable or set speed=False\"},\n+    )\n+    no_memory: Optional[bool] = field(\n+        default=None,\n+        metadata={\"help\": \"Deprecated: use --no-memory to disable or set memory=False\"},\n+    )\n+    no_env_print: Optional[bool] = field(\n+        default=None,\n+        metadata={\"help\": \"Deprecated: use --no-env-print to disable or set env_print=False\"},\n+    )\n+    no_multi_process: Optional[bool] = field(\n+        default=None,\n+        metadata={\"help\": \"Deprecated: use --no-multi-process to disable or set multi_process=False\"},\n+    )\n     inference_time_csv_file: str = field(\n         default=f\"inference_time_{round(time())}.csv\",\n         metadata={\"help\": \"CSV filename used if saving time results to csv.\"},\n@@ -113,6 +143,39 @@ class BenchmarkArguments:\n         \"\"\"\n         return json.dumps(dataclasses.asdict(self), indent=2)\n \n+    def __post_init__(self):\n+        # Map deprecated negative-form aliases to new positive flags\n+        def _map_alias(alias_val, set_fn, name):\n+            if alias_val is True:\n+                logger.warning(\n+                    f\"Argument '{name}' is deprecated and will be removed in a future release. Please use the positive flag or its --no-<flag> form.\"\n+                )\n+                set_fn(False)\n+\n+        _map_alias(self.no_inference, lambda v: setattr(self, \"inference\", v), \"no_inference\")\n+        _map_alias(self.no_cuda, lambda v: setattr(self, \"cuda\", v), \"no_cuda\")\n+        _map_alias(self.no_tpu, lambda v: setattr(self, \"tpu\", v), \"no_tpu\")\n+        _map_alias(self.no_speed, lambda v: setattr(self, \"speed\", v), \"no_speed\")\n+        _map_alias(self.no_memory, lambda v: setattr(self, \"memory\", v), \"no_memory\")\n+        _map_alias(self.no_env_print, lambda v: setattr(self, \"env_print\", v), \"no_env_print\")\n+        _map_alias(self.no_multi_process, lambda v: setattr(self, \"multi_process\", v), \"no_multi_process\")\n+\n+        # Keep deprecated aliases in sync if not provided\n+        if self.no_inference is None:\n+            self.no_inference = not self.inference\n+        if self.no_cuda is None:\n+            self.no_cuda = not self.cuda\n+        if self.no_tpu is None:\n+            self.no_tpu = not self.tpu\n+        if self.no_speed is None:\n+            self.no_speed = not self.speed\n+        if self.no_memory is None:\n+            self.no_memory = not self.memory\n+        if self.no_env_print is None:\n+            self.no_env_print = not self.env_print\n+        if self.no_multi_process is None:\n+            self.no_multi_process = not self.multi_process\n+\n     @property\n     def model_names(self):\n         assert (\n@@ -122,7 +185,7 @@ class BenchmarkArguments:\n \n     @property\n     def do_multi_processing(self):\n-        if self.no_multi_process:\n+        if not self.multi_process:\n             return False\n         elif self.is_tpu:\n             logger.info(\"Multiprocessing is currently not possible on TPU.\")\n"}
{"instance_id": "huggingface__transformers-7078", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/modeling_t5.py b/src/transformers/modeling_t5.py\nindex 81f837a3a0..824321209a 100644\n--- a/src/transformers/modeling_t5.py\n+++ b/src/transformers/modeling_t5.py\n@@ -627,9 +627,18 @@ class T5PreTrainedModel(PreTrainedModel):\n             decoder_start_token_id is not None\n         ), \"self.model.config.decoder_start_token_id has to be defined. In T5 it is usually set to the pad_token_id. See T5 docs for more information\"\n \n-        # shift inputs to the right\n+        # shift inputs to the right, avoiding duplicating start token when present\n         shifted_input_ids = input_ids.new_zeros(input_ids.shape)\n-        shifted_input_ids[..., 1:] = input_ids[..., :-1].clone()\n+        if input_ids.dim() == 1:\n+            if input_ids.size(0) > 0 and input_ids[0].item() == decoder_start_token_id:\n+                shifted_input_ids[1:] = input_ids[1:].clone()\n+            else:\n+                shifted_input_ids[1:] = input_ids[:-1].clone()\n+        else:\n+            shifted_input_ids[..., 1:] = input_ids[..., :-1].clone()\n+            mask = input_ids[..., 0] == decoder_start_token_id\n+            if mask.any().item():\n+                shifted_input_ids[mask, 1:] = input_ids[mask, 1:].clone()\n         shifted_input_ids[..., 0] = decoder_start_token_id\n \n         assert pad_token_id is not None, \"self.model.config.pad_token_id has to be defined.\"\n"}
{"instance_id": "huggingface__transformers-7374", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/modeling_funnel.py b/src/transformers/modeling_funnel.py\nindex 8c8810d507..b1d5ea7a2e 100644\n--- a/src/transformers/modeling_funnel.py\n+++ b/src/transformers/modeling_funnel.py\n@@ -360,6 +360,7 @@ class FunnelAttentionStructure(nn.Module):\n             tensor = torch.cat([tensor[:, :1], suffix], dim=1)\n \n         ndim = tensor.ndim\n+        input_dtype = tensor.dtype\n         if ndim == 2:\n             tensor = tensor[:, None, :, None]\n         elif ndim == 3:\n@@ -377,6 +378,7 @@ class FunnelAttentionStructure(nn.Module):\n         else:\n             raise NotImplementedError(\"The supported modes are 'mean', 'max' and 'min'.\")\n \n+        tensor = tensor.to(input_dtype)\n         if ndim == 2:\n             return tensor[:, 0, :, 0]\n         elif ndim == 3:\n@@ -465,28 +467,28 @@ class FunnelRelMultiheadAttention(nn.Module):\n             # phi and pi have shape seq_len x d_model, psi and omega have shape context_len x d_model\n             phi, pi, psi, omega = position_embeds\n             # Shape n_head x d_head\n-            u = self.r_r_bias * self.scale\n+            u = (self.r_r_bias * self.scale).type_as(q_head)\n             # Shape d_model x n_head x d_head\n-            w_r = self.r_kernel\n+            w_r = self.r_kernel.type_as(q_head)\n \n             # Shape batch_size x sea_len x n_head x d_model\n             q_r_attention = torch.einsum(\"binh,dnh->bind\", q_head + u, w_r)\n-            q_r_attention_1 = q_r_attention * phi[:, None]\n-            q_r_attention_2 = q_r_attention * pi[:, None]\n+            q_r_attention_1 = q_r_attention * phi[:, None].type_as(q_head)\n+            q_r_attention_2 = q_r_attention * pi[:, None].type_as(q_head)\n \n             # Shape batch_size x n_head x seq_len x context_len\n-            positional_attn = torch.einsum(\"bind,jd->bnij\", q_r_attention_1, psi) + torch.einsum(\n-                \"bind,jd->bnij\", q_r_attention_2, omega\n+            positional_attn = torch.einsum(\"bind,jd->bnij\", q_r_attention_1, psi.type_as(q_head)) + torch.einsum(\n+                \"bind,jd->bnij\", q_r_attention_2, omega.type_as(q_head)\n             )\n         else:\n             shift = 2 if q_head.shape[1] != context_len else 1\n             # Notations from the paper, appending A.2.1, final formula (https://arxiv.org/abs/2006.03236)\n             # Grab the proper positional encoding, shape max_rel_len x d_model\n-            r = position_embeds[self.block_index][shift - 1]\n+            r = position_embeds[self.block_index][shift - 1].type_as(q_head)\n             # Shape n_head x d_head\n-            v = self.r_r_bias * self.scale\n+            v = (self.r_r_bias * self.scale).type_as(q_head)\n             # Shape d_model x n_head x d_head\n-            w_r = self.r_kernel\n+            w_r = self.r_kernel.type_as(q_head)\n \n             # Shape max_rel_len x n_head x d_model\n             r_head = torch.einsum(\"td,dnh->tnh\", r, w_r)\n@@ -506,10 +508,10 @@ class FunnelRelMultiheadAttention(nn.Module):\n         batch_size, seq_len, context_len = token_type_mat.shape\n         # q_head has shape batch_size x seq_len x n_head x d_head\n         # Shape n_head x d_head\n-        r_s_bias = self.r_s_bias * self.scale\n+        r_s_bias = (self.r_s_bias * self.scale).type_as(q_head)\n \n         # Shape batch_size x n_head x seq_len x 2\n-        token_type_bias = torch.einsum(\"bind,snd->bnis\", q_head + r_s_bias, self.seg_embed)\n+        token_type_bias = torch.einsum(\"bind,snd->bnis\", q_head + r_s_bias, self.seg_embed.type_as(q_head))\n         # Shape batch_size x n_head x seq_len x context_len\n         token_type_mat = token_type_mat[:, None].expand([batch_size, q_head.shape[2], seq_len, context_len])\n         # Shapes batch_size x n_head x seq_len\n@@ -540,7 +542,9 @@ class FunnelRelMultiheadAttention(nn.Module):\n \n         q_head = q_head * self.scale\n         # Shape n_head x d_head\n-        r_w_bias = self.r_w_bias * self.scale\n+        r_w_bias = (self.r_w_bias * self.scale).type_as(q_head)\n+        # Ensure consistent dtype for matmul operands\n+        k_head = k_head.type_as(q_head)\n         # Shapes batch_size x n_head x seq_len x context_len\n         content_score = torch.einsum(\"bind,bjnd->bnij\", q_head + r_w_bias, k_head)\n         positional_attn = self.relative_positional_attention(position_embeds, q_head, context_len, cls_mask)\n@@ -560,6 +564,7 @@ class FunnelRelMultiheadAttention(nn.Module):\n         attn_prob = self.attention_dropout(attn_prob)\n \n         # attention output, shape batch_size x seq_len x n_head x d_head\n+        v_head = v_head.type_as(attn_prob)\n         attn_vec = torch.einsum(\"bnij,bjnd->bind\", attn_prob, v_head)\n \n         # Shape shape batch_size x seq_len x d_model\n"}
{"instance_id": "huggingface__transformers-7562", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/main_classes/output.rst b/docs/source/main_classes/output.rst\nindex f1e8e01b0d..1e4bb4f516 100644\n--- a/docs/source/main_classes/output.rst\n+++ b/docs/source/main_classes/output.rst\n@@ -71,6 +71,24 @@ BaseModelOutputWithPast\n .. autoclass:: transformers.modeling_outputs.BaseModelOutputWithPast\n     :members:\n \n+LongformerBaseModelOutput\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. autoclass:: transformers.modeling_outputs.LongformerBaseModelOutput\n+    :members:\n+\n+LongformerBaseModelOutputWithPooling\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. autoclass:: transformers.modeling_outputs.LongformerBaseModelOutputWithPooling\n+    :members:\n+\n+LongformerBaseModelOutputWithPast\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. autoclass:: transformers.modeling_outputs.LongformerBaseModelOutputWithPast\n+    :members:\n+\n Seq2SeqModelOutput\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n \n@@ -98,6 +116,12 @@ MaskedLMOutput\n .. autoclass:: transformers.modeling_outputs.MaskedLMOutput\n     :members:\n \n+LongformerMaskedLMOutput\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. autoclass:: transformers.modeling_outputs.LongformerMaskedLMOutput\n+    :members:\n+\n \n Seq2SeqLMOutput\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n@@ -119,6 +143,12 @@ SequenceClassifierOutput\n .. autoclass:: transformers.modeling_outputs.SequenceClassifierOutput\n     :members:\n \n+LongformerSequenceClassifierOutput\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. autoclass:: transformers.modeling_outputs.LongformerSequenceClassifierOutput\n+    :members:\n+\n \n Seq2SeqSequenceClassifierOutput\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n@@ -133,6 +163,12 @@ MultipleChoiceModelOutput\n .. autoclass:: transformers.modeling_outputs.MultipleChoiceModelOutput\n     :members:\n \n+LongformerMultipleChoiceModelOutput\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. autoclass:: transformers.modeling_outputs.LongformerMultipleChoiceModelOutput\n+    :members:\n+\n \n TokenClassifierOutput\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n@@ -140,6 +176,12 @@ TokenClassifierOutput\n .. autoclass:: transformers.modeling_outputs.TokenClassifierOutput\n     :members:\n \n+LongformerTokenClassifierOutput\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+.. autoclass:: transformers.modeling_outputs.LongformerTokenClassifierOutput\n+    :members:\n+\n \n QuestionAnsweringModelOutput\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ndiff --git a/docs/source/model_doc/longformer.rst b/docs/source/model_doc/longformer.rst\nindex 792d7fc6a2..98d193660e 100644\n--- a/docs/source/model_doc/longformer.rst\n+++ b/docs/source/model_doc/longformer.rst\n@@ -45,6 +45,13 @@ The user can define which tokens attend \"locally\" and which tokens attend \"globa\n - 0: the token attends \"locally\",\n - 1: the token attends \"globally\".\n \n+When ``output_attentions=True``, Longformer returns two kinds of attention weights per layer:\n+\n+- ``attentions``: local sliding-window attention weights of shape ``(batch_size, num_heads, sequence_length, window_size)``.\n+- ``global_attentions``: global attention weights from globally attending tokens to all tokens of shape ``(batch_size, num_heads, max_num_global_attention_tokens, sequence_length)``. If the number of global tokens varies across batch items, this dimension is padded to the maximum.\n+\n+This mirrors the input masks ``attention_mask`` (local) and ``global_attention_mask`` (global).\n+\n For more information please also refer to :meth:`~transformers.LongformerModel.forward` method.\n \n Using Longformer self attention, the memory and time complexity of the query-key matmul operation, which usually\ndiff --git a/src/transformers/modeling_longformer.py b/src/transformers/modeling_longformer.py\nindex f32d0a2f1d..e973460c15 100755\n--- a/src/transformers/modeling_longformer.py\n+++ b/src/transformers/modeling_longformer.py\n@@ -31,13 +31,13 @@ from .file_utils import (\n     replace_return_docstrings,\n )\n from .modeling_outputs import (\n-    BaseModelOutput,\n-    BaseModelOutputWithPooling,\n-    MaskedLMOutput,\n-    MultipleChoiceModelOutput,\n+    LongformerBaseModelOutput,\n+    LongformerBaseModelOutputWithPooling,\n+    LongformerMaskedLMOutput,\n+    LongformerMultipleChoiceModelOutput,\n     QuestionAnsweringModelOutput,\n-    SequenceClassifierOutput,\n-    TokenClassifierOutput,\n+    LongformerSequenceClassifierOutput,\n+    LongformerTokenClassifierOutput,\n )\n from .modeling_utils import (\n     PreTrainedModel,\n@@ -377,21 +377,22 @@ class LongformerSelfAttention(nn.Module):\n         attn_output = attn_output.transpose(0, 1)\n \n         if output_attentions:\n+            # always return local attentions in `attentions` and global attentions in `global_attentions`\n             if is_global_attn:\n-                # With global attention, return global attention probabilities only\n+                # split global and local portions\n+                local_attn_probs = attn_probs.narrow(\n+                    -1, max_num_global_attn_indices, self.one_sided_attn_window_size * 2 + 1\n+                )\n+                # batch_size x num_heads x sequence_length x window_size\n+                local_attn_probs = local_attn_probs.permute(0, 2, 1, 3)\n                 # batch_size x num_heads x max_num_global_attention_tokens x sequence_length\n-                # which is the attention weights from tokens with global attention to all tokens\n-                # It doesn't not return local attention\n-                # In case of variable number of global attention in the rows of a batch,\n-                # attn_probs are padded with -10000.0 attention scores\n-                attn_probs = attn_probs.view(batch_size, self.num_heads, max_num_global_attn_indices, seq_len)\n+                global_attn_probs = attn_probs.narrow(-1, 0, max_num_global_attn_indices).permute(0, 2, 3, 1)\n             else:\n-                # without global attention, return local attention probabilities\n-                # batch_size x num_heads x sequence_length x window_size\n-                # which is the attention weights of every token attending to its neighbours\n-                attn_probs = attn_probs.permute(0, 2, 1, 3)\n+                # without global attention, return local attention probabilities only\n+                local_attn_probs = attn_probs.permute(0, 2, 1, 3)\n+                global_attn_probs = None\n \n-        outputs = (attn_output, attn_probs) if output_attentions else (attn_output,)\n+        outputs = (attn_output, local_attn_probs, global_attn_probs) if output_attentions else (attn_output,)\n         return outputs\n \n     @staticmethod\n@@ -891,6 +892,7 @@ class LongformerEncoder(nn.Module):\n     ):\n         all_hidden_states = () if output_hidden_states else None\n         all_attentions = () if output_attentions else None\n+        all_global_attentions = () if output_attentions else None\n         for i, layer_module in enumerate(self.layer):\n             if output_hidden_states:\n                 all_hidden_states = all_hidden_states + (hidden_states,)\n@@ -918,15 +920,16 @@ class LongformerEncoder(nn.Module):\n \n             if output_attentions:\n                 all_attentions = all_attentions + (layer_outputs[1],)\n+                all_global_attentions = all_global_attentions + (layer_outputs[2],)\n \n         # Add last layer\n         if output_hidden_states:\n             all_hidden_states = all_hidden_states + (hidden_states,)\n \n         if not return_dict:\n-            return tuple(v for v in [hidden_states, all_hidden_states, all_attentions] if v is not None)\n-        return BaseModelOutput(\n-            last_hidden_state=hidden_states, hidden_states=all_hidden_states, attentions=all_attentions\n+            return tuple(v for v in [hidden_states, all_hidden_states, all_attentions, all_global_attentions] if v is not None)\n+        return LongformerBaseModelOutput(\n+            last_hidden_state=hidden_states, hidden_states=all_hidden_states, attentions=all_attentions, global_attentions=all_global_attentions\n         )\n \n \n@@ -1182,7 +1185,7 @@ class LongformerModel(LongformerPreTrainedModel):\n         return attention_mask\n \n     @add_start_docstrings_to_model_forward(LONGFORMER_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n-    @replace_return_docstrings(output_type=BaseModelOutputWithPooling, config_class=_CONFIG_FOR_DOC)\n+    @replace_return_docstrings(output_type=LongformerBaseModelOutputWithPooling, config_class=_CONFIG_FOR_DOC)\n     def forward(\n         self,\n         input_ids=None,\n@@ -1284,11 +1287,12 @@ class LongformerModel(LongformerPreTrainedModel):\n         if not return_dict:\n             return (sequence_output, pooled_output) + encoder_outputs[1:]\n \n-        return BaseModelOutputWithPooling(\n+        return LongformerBaseModelOutputWithPooling(\n             last_hidden_state=sequence_output,\n             pooler_output=pooled_output,\n             hidden_states=encoder_outputs.hidden_states,\n             attentions=encoder_outputs.attentions,\n+            global_attentions=encoder_outputs.global_attentions if hasattr(encoder_outputs, \"global_attentions\") else None,\n         )\n \n \n@@ -1309,7 +1313,7 @@ class LongformerForMaskedLM(LongformerPreTrainedModel):\n         return self.lm_head.decoder\n \n     @add_start_docstrings_to_model_forward(LONGFORMER_INPUTS_DOCSTRING.format(\"batch_size, sequence_length\"))\n-    @replace_return_docstrings(output_type=MaskedLMOutput, config_class=_CONFIG_FOR_DOC)\n+    @replace_return_docstrings(output_type=LongformerMaskedLMOutput, config_class=_CONFIG_FOR_DOC)\n     def forward(\n         self,\n         input_ids=None,\n@@ -1384,11 +1388,12 @@ class LongformerForMaskedLM(LongformerPreTrainedModel):\n             output = (prediction_scores,) + outputs[2:]\n             return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n \n-        return MaskedLMOutput(\n+        return LongformerMaskedLMOutput(\n             loss=masked_lm_loss,\n             logits=prediction_scores,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=getattr(outputs, \"global_attentions\", None),\n         )\n \n \n@@ -1416,7 +1421,7 @@ class LongformerForSequenceClassification(LongformerPreTrainedModel):\n     @add_code_sample_docstrings(\n         tokenizer_class=_TOKENIZER_FOR_DOC,\n         checkpoint=\"allenai/longformer-base-4096\",\n-        output_type=SequenceClassifierOutput,\n+        output_type=LongformerSequenceClassifierOutput,\n         config_class=_CONFIG_FOR_DOC,\n     )\n     def forward(\n@@ -1474,11 +1479,12 @@ class LongformerForSequenceClassification(LongformerPreTrainedModel):\n             output = (logits,) + outputs[2:]\n             return ((loss,) + output) if loss is not None else output\n \n-        return SequenceClassifierOutput(\n+        return LongformerSequenceClassifierOutput(\n             loss=loss,\n             logits=logits,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=getattr(outputs, \"global_attentions\", None),\n         )\n \n \n@@ -1659,7 +1665,7 @@ class LongformerForTokenClassification(LongformerPreTrainedModel):\n     @add_code_sample_docstrings(\n         tokenizer_class=_TOKENIZER_FOR_DOC,\n         checkpoint=\"allenai/longformer-base-4096\",\n-        output_type=TokenClassifierOutput,\n+        output_type=LongformerTokenClassifierOutput,\n         config_class=_CONFIG_FOR_DOC,\n     )\n     def forward(\n@@ -1717,11 +1723,12 @@ class LongformerForTokenClassification(LongformerPreTrainedModel):\n             output = (logits,) + outputs[2:]\n             return ((loss,) + output) if loss is not None else output\n \n-        return TokenClassifierOutput(\n+        return LongformerTokenClassifierOutput(\n             loss=loss,\n             logits=logits,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=getattr(outputs, \"global_attentions\", None),\n         )\n \n \n@@ -1748,7 +1755,7 @@ class LongformerForMultipleChoice(LongformerPreTrainedModel):\n     @add_code_sample_docstrings(\n         tokenizer_class=_TOKENIZER_FOR_DOC,\n         checkpoint=\"allenai/longformer-base-4096\",\n-        output_type=MultipleChoiceModelOutput,\n+        output_type=LongformerMultipleChoiceModelOutput,\n         config_class=_CONFIG_FOR_DOC,\n     )\n     def forward(\n@@ -1826,9 +1833,10 @@ class LongformerForMultipleChoice(LongformerPreTrainedModel):\n             output = (reshaped_logits,) + outputs[2:]\n             return ((loss,) + output) if loss is not None else output\n \n-        return MultipleChoiceModelOutput(\n+        return LongformerMultipleChoiceModelOutput(\n             loss=loss,\n             logits=reshaped_logits,\n             hidden_states=outputs.hidden_states,\n             attentions=outputs.attentions,\n+            global_attentions=getattr(outputs, \"global_attentions\", None),\n         )\ndiff --git a/src/transformers/modeling_outputs.py b/src/transformers/modeling_outputs.py\nindex 26a41fc9d1..9d2bb42426 100644\n--- a/src/transformers/modeling_outputs.py\n+++ b/src/transformers/modeling_outputs.py\n@@ -99,6 +99,173 @@ class BaseModelOutputWithPast(ModelOutput):\n     attentions: Optional[Tuple[torch.FloatTensor]] = None\n \n \n+# Longformer-specific outputs including global attentions\n+@dataclass\n+class LongformerBaseModelOutput(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer model outputs, with potential hidden states, local attentions and global attentions.\n+\n+    Args:\n+        last_hidden_state (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`):\n+            Sequence of hidden-states at the output of the last layer of the model.\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, window_size)` representing local sliding-window attention weights.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            max_num_global_tokens, sequence_length)` representing global attention weights from globally attending\n+            tokens to all tokens. May be padded when global token count varies across batch items.\n+    \"\"\"\n+\n+    last_hidden_state: torch.FloatTensor\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerBaseModelOutputWithPooling(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer model outputs that also contains a pooling of the last hidden states.\n+\n+    Args:\n+        last_hidden_state (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`):\n+            Sequence of hidden-states at the output of the last layer of the model.\n+        pooler_output (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, hidden_size)`):\n+            Last layer hidden-state of the first token of the sequence further processed by a Linear + Tanh.\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, window_size)` representing local sliding-window attention weights.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            max_num_global_tokens, sequence_length)` representing global attention weights.\n+    \"\"\"\n+\n+    last_hidden_state: torch.FloatTensor\n+    pooler_output: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerBaseModelOutputWithPast(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer model outputs that may also contain past key/values.\n+\n+    Args:\n+        last_hidden_state (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`):\n+            Sequence of hidden-states at the output of the last layer of the model.\n+        past_key_values (:obj:`List[torch.FloatTensor]`, `optional`):\n+            List of :obj:`torch.FloatTensor` of length :obj:`config.n_layers`, with each tensor of shape :obj:`(2,\n+            batch_size, num_heads, sequence_length, embed_size_per_head)`).\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n+            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            sequence_length, window_size)` representing local attention weights.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`):\n+            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n+            max_num_global_tokens, sequence_length)` representing global attention weights.\n+    \"\"\"\n+\n+    last_hidden_state: torch.FloatTensor\n+    past_key_values: Optional[List[torch.FloatTensor]] = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerMaskedLMOutput(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer masked language model outputs.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`): Masked language modeling loss.\n+        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`):\n+            Prediction scores of the language modeling head.\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of hidden states per layer.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of local attention weights per layer of shape\n+            :obj:`(batch_size, num_heads, sequence_length, window_size)`.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of global attention weights per layer of\n+            shape :obj:`(batch_size, num_heads, max_num_global_tokens, sequence_length)`.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerSequenceClassifierOutput(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer sequence classification/regression outputs.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`): Classification (or regression) loss.\n+        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, config.num_labels)`): Classification scores.\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of hidden states per layer.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of local attention weights per layer.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of global attention weights per layer.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerMultipleChoiceModelOutput(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer multiple choice outputs.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape `(1,)`, `optional`): Classification loss.\n+        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, num_choices)`): Classification scores.\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of hidden states per layer.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of local attention weights per layer.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of global attention weights per layer.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n+@dataclass\n+class LongformerTokenClassifierOutput(ModelOutput):\n+    \"\"\"\n+    Base class for Longformer token classification outputs.\n+\n+    Args:\n+        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`): Classification loss.\n+        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.num_labels)`): Scores.\n+        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of hidden states per layer.\n+        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of local attention weights per layer.\n+        global_attentions (:obj:`tuple(torch.FloatTensor)`, `optional`): Tuple of global attention weights per layer.\n+    \"\"\"\n+\n+    loss: Optional[torch.FloatTensor] = None\n+    logits: torch.FloatTensor = None\n+    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n+    attentions: Optional[Tuple[torch.FloatTensor]] = None\n+    global_attentions: Optional[Tuple[torch.FloatTensor]] = None\n+\n+\n @dataclass\n class Seq2SeqModelOutput(ModelOutput):\n     \"\"\"\n"}
{"instance_id": "huggingface__transformers-8554", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/prophetnet/modeling_prophetnet.py b/src/transformers/models/prophetnet/modeling_prophetnet.py\nindex 7117a5c858..de49903452 100644\n--- a/src/transformers/models/prophetnet/modeling_prophetnet.py\n+++ b/src/transformers/models/prophetnet/modeling_prophetnet.py\n@@ -1794,7 +1794,7 @@ class ProphetNetForConditionalGeneration(ProphetNetPreTrainedModel):\n             )\n \n     def _compute_loss(self, logits, labels):\n-        expend_targets = labels.new_zeros(self.config.ngram, labels.size(0), labels.size(1)).fill_(self.padding_idx)\n+        expend_targets = labels.new_zeros(self.config.ngram, labels.size(0), labels.size(1)).fill_(-100)\n \n         for i in range(self.config.ngram):\n             if i > 0 and self.disable_ngram_loss:\n@@ -1807,11 +1807,11 @@ class ProphetNetForConditionalGeneration(ProphetNetPreTrainedModel):\n             dtype=torch.float32,\n         )\n \n-        loss = F.nll_loss(lprobs, expend_targets.view(-1), reduction=\"sum\")\n+        loss = F.nll_loss(lprobs, expend_targets.view(-1), reduction=\"sum\", ignore_index=-100)\n \n         if self.config.eps > 0.0:\n             smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n-            non_pad_mask = expend_targets.ne(self.padding_idx).view(-1)\n+            non_pad_mask = expend_targets.ne(-100).view(-1)\n             smooth_loss = smooth_loss[non_pad_mask]\n             smooth_loss = smooth_loss.sum()\n \n@@ -2011,7 +2011,7 @@ class ProphetNetForCausalLM(ProphetNetPreTrainedModel):\n             )\n \n     def _compute_loss(self, logits, labels):\n-        expend_targets = labels.new_zeros(self.config.ngram, labels.size(0), labels.size(1)).fill_(self.padding_idx)\n+        expend_targets = labels.new_zeros(self.config.ngram, labels.size(0), labels.size(1)).fill_(-100)\n \n         for i in range(self.config.ngram):\n             if i > 0 and self.disable_ngram_loss:\n@@ -2024,11 +2024,11 @@ class ProphetNetForCausalLM(ProphetNetPreTrainedModel):\n             dtype=torch.float32,\n         )\n \n-        loss = F.nll_loss(lprobs, expend_targets.view(-1), reduction=\"sum\")\n+        loss = F.nll_loss(lprobs, expend_targets.view(-1), reduction=\"sum\", ignore_index=-100)\n \n         if self.config.eps > 0.0:\n             smooth_loss = -lprobs.sum(dim=-1, keepdim=True)\n-            non_pad_mask = expend_targets.ne(self.padding_idx).view(-1)\n+            non_pad_mask = expend_targets.ne(-100).view(-1)\n             smooth_loss = smooth_loss[non_pad_mask]\n             smooth_loss = smooth_loss.sum()\n \n"}
{"instance_id": "huggingface__transformers-8435", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/model_doc/t5.rst b/docs/source/model_doc/t5.rst\nindex 6803868b6c..f58dec27c0 100644\n--- a/docs/source/model_doc/t5.rst\n+++ b/docs/source/model_doc/t5.rst\n@@ -45,8 +45,10 @@ T5 is an encoder-decoder model and converts all NLP problems into a text-to-text\n forcing. This means that for training we always need an input sequence and a target sequence. The input sequence is fed\n to the model using :obj:`input_ids``. The target sequence is shifted to the right, i.e., prepended by a start-sequence\n token and fed to the decoder using the :obj:`decoder_input_ids`. In teacher-forcing style, the target sequence is then\n-appended by the EOS token and corresponds to the :obj:`labels`. The PAD token is hereby used as the start-sequence\n-token. T5 can be trained / fine-tuned both in a supervised and unsupervised fashion.\n+appended by the EOS token and corresponds to the :obj:`labels`. The PAD token is used as the start token for decoder inputs.\n+When decoding, special tokens can be skipped by default; to visualize them (e.g., :obj:`'</s>'`, :obj:`'<pad>'`, :obj:`'<unk>'`),\n+set :obj:`skip_special_tokens=False` or use :meth:`~transformers.PreTrainedTokenizer.convert_ids_to_tokens`.\n+T5 can be trained / fine-tuned both in a supervised and unsupervised fashion.\n \n - Unsupervised denoising training\n \ndiff --git a/src/transformers/tokenization_t5.py b/src/transformers/tokenization_t5.py\nindex bc69fc5d56..d49c8c72ca 100644\n--- a/src/transformers/tokenization_t5.py\n+++ b/src/transformers/tokenization_t5.py\n@@ -79,8 +79,8 @@ class T5Tokenizer(PreTrainedTokenizer):\n \n             .. note::\n \n-                When building a sequence using special tokens, this is not the token that is used for the end of\n-                sequence. The token used is the :obj:`sep_token`.\n+                When building sequences using special tokens for T5, the end-of-sequence is marked with the :obj:`eos_token`.\n+                The :obj:`pad_token` is used as the start token for decoder inputs.\n         unk_token (:obj:`str`, `optional`, defaults to :obj:`\"<unk>\"`):\n             The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n             token instead.\n@@ -171,7 +171,7 @@ class T5Tokenizer(PreTrainedTokenizer):\n                     \"You should not supply a second sequence if the provided sequence of \"\n                     \"ids is already formatted with special tokens for the model.\"\n                 )\n-            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n+            return list(map(lambda x: 1 if x in self.all_special_ids else 0, token_ids_0))\n         # normal case: some special tokens\n         if token_ids_1 is None:\n             return ([0] * len(token_ids_0)) + [1]\n@@ -249,7 +249,19 @@ class T5Tokenizer(PreTrainedTokenizer):\n \n     def convert_tokens_to_string(self, tokens):\n         \"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"\n-        out_string = self.sp_model.decode_pieces(tokens)\n+        # Preserve special tokens literally and decode contiguous non-special token sequences with sentencepiece.\n+        out_string = \"\"\n+        current_segment = []\n+        for token in tokens:\n+            if token in self.all_special_tokens:\n+                if current_segment:\n+                    out_string += self.sp_model.decode_pieces(current_segment)\n+                    current_segment = []\n+                out_string += token\n+            else:\n+                current_segment.append(token)\n+        if current_segment:\n+            out_string += self.sp_model.decode_pieces(current_segment)\n         return out_string\n \n     def save_vocabulary(self, save_directory: str, filename_prefix: Optional[str] = None) -> Tuple[str]:\n"}
{"instance_id": "huggingface__transformers-8747", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/bart/modeling_bart.py b/src/transformers/models/bart/modeling_bart.py\nindex afa006a542..15eddd8410 100644\n--- a/src/transformers/models/bart/modeling_bart.py\n+++ b/src/transformers/models/bart/modeling_bart.py\n@@ -377,8 +377,7 @@ class BartEncoder(nn.Module):\n             x = self.layer_norm(x)\n         if output_hidden_states:\n             encoder_states.append(x)\n-            # T x B x C -> B x T x C\n-            encoder_states = tuple(hidden_state.transpose(0, 1) for hidden_state in encoder_states)\n+            encoder_states = tuple(encoder_states)\n \n         # T x B x C -> B x T x C\n         x = x.transpose(0, 1)\n@@ -583,7 +582,7 @@ class BartDecoder(nn.Module):\n         for idx, decoder_layer in enumerate(self.layers):\n             # add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)\n             if output_hidden_states:\n-                all_hidden_states += (x,)\n+                all_hidden_states += (x,)  # store internal layout (seq_len, batch, embed_dim)\n             dropout_probability = random.uniform(0, 1)\n             if self.training and (dropout_probability < self.layerdrop):\n                 continue\n@@ -612,9 +611,9 @@ class BartDecoder(nn.Module):\n \n         # Convert to standard output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)\n         if output_hidden_states:\n-            all_hidden_states = tuple(hidden_state.transpose(0, 1) for hidden_state in all_hidden_states)\n-        x = x.transpose(0, 1)\n-        encoder_hidden_states = encoder_hidden_states.transpose(0, 1)\n+            all_hidden_states = tuple(all_hidden_states)\n+        x = x.transpose(0, 1).contiguous()\n+        encoder_hidden_states = encoder_hidden_states.transpose(0, 1).contiguous()\n \n         next_cache = next_decoder_cache if use_cache else None\n         if not return_dict:\n"}
{"instance_id": "huggingface__transformers-8624", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/trainer.py b/src/transformers/trainer.py\nindex 0e1eef74cc..55abc7aa31 100755\n--- a/src/transformers/trainer.py\n+++ b/src/transformers/trainer.py\n@@ -674,8 +674,13 @@ class Trainer:\n         # Check if continuing training from a checkpoint\n         if model_path and os.path.isfile(os.path.join(model_path, \"trainer_state.json\")):\n             self.state = TrainerState.load_from_json(os.path.join(model_path, \"trainer_state.json\"))\n-            epochs_trained = self.state.global_step // num_update_steps_per_epoch\n-            steps_trained_in_current_epoch = self.state.global_step % (num_update_steps_per_epoch)\n+            if train_dataset_is_sized:\n+                processed_batches = self.state.global_step * self.args.gradient_accumulation_steps\n+                epochs_trained = processed_batches // len(train_dataloader)\n+                steps_trained_in_current_epoch = processed_batches % len(train_dataloader)\n+            else:\n+                epochs_trained = self.state.global_step // num_update_steps_per_epoch\n+                steps_trained_in_current_epoch = self.state.global_step % (num_update_steps_per_epoch)\n \n             logger.info(\"  Continuing training from checkpoint, will skip to saved global_step\")\n             logger.info(\"  Continuing training from epoch %d\", epochs_trained)\n"}
{"instance_id": "huggingface__transformers-23141", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/whisper/modeling_whisper.py b/src/transformers/models/whisper/modeling_whisper.py\nindex ed845febac..d0d9cfbbc1 100644\n--- a/src/transformers/models/whisper/modeling_whisper.py\n+++ b/src/transformers/models/whisper/modeling_whisper.py\n@@ -1513,10 +1513,10 @@ class WhisperForConditionalGeneration(WhisperPreTrainedModel):\n                 Whether to continue running the while loop until max_length (needed for ZeRO stage 3)\n             return_timestamps (`bool`, *optional*):\n                 Whether to return the timestamps with the text. This enables the `WhisperTimestampsLogitsProcessor`.\n-            task (`bool`, *optional*):\n+            task (`str`, *optional*):\n                 Task to use for generation, either \"translate\" or \"transcribe\". The `model.config.forced_decoder_ids`\n                 will be updated accordingly.\n-            language (`bool`, *optional*):\n+            language (`str`, *optional*):\n                 Language token to use for generation, can be either in the form of `<|en|>`, `en` or `english`. You can\n                 find all the possible language tokens in the `model.generation_config.lang_to_id` dictionary.\n             is_multilingual (`bool`, *optional*):\n@@ -1569,14 +1569,17 @@ class WhisperForConditionalGeneration(WhisperPreTrainedModel):\n         forced_decoder_ids = []\n         if task is not None or language is not None:\n             if hasattr(generation_config, \"language\"):\n-                if generation_config.language in generation_config.lang_to_id.keys():\n-                    language_token = generation_config.language\n-                elif generation_config.language in TO_LANGUAGE_CODE.keys():\n-                    language_token = f\"<|{TO_LANGUAGE_CODE[generation_config.language]}|>\"\n+                language_str = generation_config.language.lower()\n+                if language_str in generation_config.lang_to_id.keys():\n+                    language_token = language_str\n+                elif language_str in TO_LANGUAGE_CODE.keys():\n+                    language_token = f\"<|{TO_LANGUAGE_CODE[language_str]}|>\"\n+                elif language_str in TO_LANGUAGE_CODE.values():\n+                    language_token = f\"<|{language_str}|>\"\n                 else:\n                     raise ValueError(\n-                        f\"Unsupported language: {self.language}. Language should be one of:\"\n-                        f\" {list(TO_LANGUAGE_CODE.keys()) if generation_config.language in TO_LANGUAGE_CODE.keys() else list(TO_LANGUAGE_CODE.values())}.\"\n+                        f\"Unsupported language: {generation_config.language}. Language should be one of:\"\n+                        f\" {list(TO_LANGUAGE_CODE.keys()) + list(TO_LANGUAGE_CODE.values())}.\"\n                     )\n                 forced_decoder_ids.append((1, generation_config.lang_to_id[language_token]))\n             else:\n"}
{"instance_id": "huggingface__transformers-28535", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/en/model_doc/esm.md b/docs/source/en/model_doc/esm.md\nindex 46bab860ff..fb7e364dcd 100644\n--- a/docs/source/en/model_doc/esm.md\n+++ b/docs/source/en/model_doc/esm.md\n@@ -107,6 +107,8 @@ help throughout the process!\n     - create_token_type_ids_from_sequences\n     - save_vocabulary\n \n+Note: When adding new tokens with `add_tokens`, the `special_tokens` parameter is respected. To extend the models embeddings after adding non-special tokens, call `model.resize_token_embeddings(len(tokenizer))`. Non-special added tokens are included in the tokenizer vocabulary and length.\n+\n <frameworkcontent>\n <pt>\n \ndiff --git a/src/transformers/models/esm/tokenization_esm.py b/src/transformers/models/esm/tokenization_esm.py\nindex 065eaae1d5..de36efa853 100644\n--- a/src/transformers/models/esm/tokenization_esm.py\n+++ b/src/transformers/models/esm/tokenization_esm.py\n@@ -92,10 +92,18 @@ class EsmTokenizer(PreTrainedTokenizer):\n         return text.split()\n \n     def get_vocab_size(self, with_added_tokens=False):\n-        return len(self._id_to_token)\n+        if with_added_tokens:\n+            return len(set(self.get_vocab().keys()))\n+        else:\n+            return len(self._id_to_token)\n \n     def get_vocab(self):\n-        return {token: i for i, token in enumerate(self.all_tokens)}\n+        vocab = {token: i for i, token in enumerate(self.all_tokens)}\n+        # Merge in added tokens from the encoder to reflect the full vocabulary\n+        if hasattr(self, \"_added_tokens_encoder\"):\n+            for tok, idx in self._added_tokens_encoder.items():\n+                vocab[tok] = idx\n+        return vocab\n \n     def token_to_id(self, token: str) -> int:\n         return self._token_to_id.get(token, self._token_to_id.get(self.unk_token))\n@@ -159,4 +167,30 @@ class EsmTokenizer(PreTrainedTokenizer):\n         return self.get_vocab_size(with_added_tokens=False)\n \n     def _add_tokens(self, new_tokens: Union[List[str], List[AddedToken]], special_tokens: bool = False) -> int:\n-        return super()._add_tokens(new_tokens, special_tokens=True)\n+        # Respect the provided special_tokens flag instead of forcing all tokens to be special.\n+        return super()._add_tokens(new_tokens, special_tokens=special_tokens)\n+\n+    def add_tokens(self, new_tokens: Union[List[str], List[AddedToken]], special_tokens: bool = False) -> int:\n+        \"\"\"\n+        Override public add_tokens to update the no-split trie for non-special added tokens.\n+        \"\"\"\n+        added = super().add_tokens(new_tokens, special_tokens=special_tokens)\n+        if added > 0:\n+            contents = []\n+            for tok in new_tokens:\n+                if isinstance(tok, AddedToken):\n+                    if tok.special:\n+                        continue\n+                    contents.append(str(tok))\n+                else:\n+                    # String token case\n+                    if tok in self.all_special_tokens or special_tokens:\n+                        continue\n+                    contents.append(tok)\n+            if contents:\n+                for c in contents:\n+                    if c not in self.unique_no_split_tokens:\n+                        self.unique_no_split_tokens.append(c)\n+                self._update_trie(self.unique_no_split_tokens)\n+        return added\n+\n"}
{"instance_id": "langchain-ai__langchain-4103", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/document_loaders/csv_loader.py b/langchain/document_loaders/csv_loader.py\nindex 54c0d8f566..f0248430f6 100644\n--- a/langchain/document_loaders/csv_loader.py\n+++ b/langchain/document_loaders/csv_loader.py\n@@ -37,10 +37,8 @@ class CSVLoader(BaseLoader):\n         self.source_column = source_column\n         self.encoding = encoding\n         if csv_args is None:\n-            self.csv_args = {\n-                \"delimiter\": csv.Dialect.delimiter,\n-                \"quotechar\": csv.Dialect.quotechar,\n-            }\n+            # Use default csv.DictReader dialect (excel), which uses comma delimiter and double-quote quotechar.\n+            self.csv_args = {}\n         else:\n             self.csv_args = csv_args\n \n"}
{"instance_id": "langchain-ai__langchain-4579", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/document_loaders/web_base.py b/langchain/document_loaders/web_base.py\nindex f39f361fa2..564adc53b4 100644\n--- a/langchain/document_loaders/web_base.py\n+++ b/langchain/document_loaders/web_base.py\n@@ -68,17 +68,24 @@ class WebBaseLoader(BaseLoader):\n                 \"bs4 package not found, please install it with \" \"`pip install bs4`\"\n             )\n \n+        # Merge default headers with user-provided template; user values take precedence\n+        headers = dict(default_header_template)\n+        if header_template:\n+            headers.update(header_template)\n+\n         try:\n             from fake_useragent import UserAgent\n \n-            headers = header_template or default_header_template\n-            headers[\"User-Agent\"] = UserAgent().random\n-            self.session.headers = dict(headers)\n+            # Only set a random User-Agent if none was provided or it's empty\n+            if not headers.get(\"User-Agent\"):\n+                headers[\"User-Agent\"] = UserAgent().random\n         except ImportError:\n             logger.info(\n-                \"fake_useragent not found, using default user agent. \"\n+                \"fake_useragent not found; using provided header_template/default headers. \"\n                 \"To get a realistic header for requests, `pip install fake_useragent`.\"\n             )\n+        # Always set session headers based on resolved headers\n+        self.session.headers = dict(headers)\n \n     @property\n     def web_path(self) -> str:\n"}
{"instance_id": "langchain-ai__langchain-4646", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/modules/prompts/output_parsers.rst b/docs/modules/prompts/output_parsers.rst\nindex a71bd06707..0f778e735f 100644\n--- a/docs/modules/prompts/output_parsers.rst\n+++ b/docs/modules/prompts/output_parsers.rst\n@@ -16,6 +16,9 @@ And then one optional one:\n \n - ``parse_with_prompt(str) -> Any``: A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so.\n \n+.. note::\n+   When returning long text fields (e.g., email bodies) in JSON, ensure control characters inside strings are properly escaped (newline as ``\\n``, tab as ``\\t``, carriage return as ``\\r``, backslash as ``\\\\`` and quotes as ``\\\"``). The parser tolerates control characters within strings by default, but providing properly escaped JSON improves reliability.\n+\n To start, we recommend familiarizing yourself with the Getting Started section\n \n .. toctree::\ndiff --git a/docs/modules/prompts/output_parsers/how_to_guides.rst b/docs/modules/prompts/output_parsers/how_to_guides.rst\nindex 7a28e36da8..ce563932fe 100644\n--- a/docs/modules/prompts/output_parsers/how_to_guides.rst\n+++ b/docs/modules/prompts/output_parsers/how_to_guides.rst\n@@ -5,4 +5,9 @@ If you're new to the library, you may want to start with the `Quickstart <./gett\n \n The user guide here shows different types of output parsers.\n \n+Best Practices and Troubleshooting\n+----------------------------------\n+\n+- When using ``PydanticOutputParser``, instruct the model to emit valid JSON only. Make sure control characters in string values are escaped (newline as ``\\n``, tab as ``\\t``, carriage return as ``\\r``, backslash as ``\\\\`` and quotes as ``\\\"``). The parser tolerates control characters within strings by default, but properly escaped JSON is preferred.\n+- Prefer wrapping the JSON output in a single `````json`` code block to reduce extraneous text around the object.\n \ndiff --git a/langchain/output_parsers/pydantic.py b/langchain/output_parsers/pydantic.py\nindex 4b0fa53d54..3e8873ceed 100644\n--- a/langchain/output_parsers/pydantic.py\n+++ b/langchain/output_parsers/pydantic.py\n@@ -15,14 +15,22 @@ class PydanticOutputParser(BaseOutputParser[T]):\n \n     def parse(self, text: str) -> T:\n         try:\n-            # Greedy search for 1st json candidate.\n-            match = re.search(\n-                r\"\\{.*\\}\", text.strip(), re.MULTILINE | re.IGNORECASE | re.DOTALL\n-            )\n+            cleaned = text.strip()\n             json_str = \"\"\n-            if match:\n-                json_str = match.group()\n-            json_object = json.loads(json_str)\n+            # Prefer JSON inside a ```json code block if present\n+            codeblock_match = re.search(r\"```json\\s*(.*?)```\", cleaned, re.DOTALL | re.IGNORECASE)\n+            if codeblock_match:\n+                json_str = codeblock_match.group(1).strip()\n+            else:\n+                # Greedy search for 1st json candidate.\n+                match = re.search(r\"\\{.*\\}\", cleaned, re.MULTILINE | re.IGNORECASE | re.DOTALL)\n+                if match:\n+                    json_str = match.group()\n+            # Try strict parsing first, then fall back to non-strict to allow control characters\n+            try:\n+                json_object = json.loads(json_str)\n+            except json.JSONDecodeError:\n+                json_object = json.JSONDecoder(strict=False).decode(json_str)\n             return self.pydantic_object.parse_obj(json_object)\n \n         except (json.JSONDecodeError, ValidationError) as e:\n"}
{"instance_id": "langchain-ai__langchain-4420", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/document_loaders/whatsapp_chat.py b/langchain/document_loaders/whatsapp_chat.py\nindex 4cbac88cce..daa61ea4ac 100644\n--- a/langchain/document_loaders/whatsapp_chat.py\n+++ b/langchain/document_loaders/whatsapp_chat.py\n@@ -27,6 +27,7 @@ class WhatsAppChatLoader(BaseLoader):\n             lines = f.readlines()\n \n         message_line_regex = r\"\"\"\n+            ^\n             \\[?\n             (\n                 \\d{1,2}\n@@ -43,14 +44,18 @@ class WhatsAppChatLoader(BaseLoader):\n                 (?:[ _](?:AM|PM))?\n             )\n             \\]?\n-            [\\s-]*\n-            ([\\w\\s]+)\n+            (?:\\s*[-]\\s*|\\s+)\n+            ([^:]+)\n             [:]+\n             \\s\n             (.+)\n         \"\"\"\n         for line in lines:\n-            result = re.match(message_line_regex, line.strip(), flags=re.VERBOSE)\n+            # Normalize line by removing common invisible Unicode control characters\n+            cleaned = (\n+                line.replace(\"\\u200e\", \"\").replace(\"\\u200f\", \"\").replace(\"\\ufeff\", \"\")\n+            ).strip()\n+            result = re.match(message_line_regex, cleaned, flags=re.VERBOSE)\n             if result:\n                 date, sender, text = result.groups()\n                 text_content += concatenate_rows(date, sender, text)\n"}
{"instance_id": "langchain-ai__langchain-5450", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "keras-team__keras-19775", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/backend/tensorflow/numpy.py b/keras/src/backend/tensorflow/numpy.py\nindex 74920a624..d46f41e14 100644\n--- a/keras/src/backend/tensorflow/numpy.py\n+++ b/keras/src/backend/tensorflow/numpy.py\n@@ -1319,27 +1319,46 @@ def linspace(\n         dtype = dtypes.result_type(*dtypes_to_resolve)\n     else:\n         dtype = standardize_dtype(dtype)\n-    start = convert_to_tensor(start, dtype=dtype)\n-    stop = convert_to_tensor(stop, dtype=dtype)\n-    if num < 0:\n-        raise ValueError(\n-            f\"`num` must be a non-negative integer. Received: num={num}\"\n+    # Use a floating dtype for internal computation. If requested dtype is integer, use default floatx.\n+    step_dtype = dtype if \"int\" not in dtype else config.floatx()\n+    start = convert_to_tensor(start, dtype=step_dtype)\n+    stop = convert_to_tensor(stop, dtype=step_dtype)\n+    # Normalize and validate `num` to support both Python int and tf.Tensor.\n+    num_is_tensor = isinstance(num, tf.Tensor)\n+    if num_is_tensor:\n+        num_dtype = standardize_dtype(num.dtype)\n+        if num_dtype not in [\"int32\", \"int64\"]:\n+            num = tf.cast(num, tf.int32)\n+        tf.debugging.assert_greater_equal(\n+            num, 0, message=\"`num` must be a non-negative integer.\"\n         )\n-    step = tf.convert_to_tensor(np.nan)\n+    else:\n+        if num < 0:\n+            raise ValueError(\n+                f\"`num` must be a non-negative integer. Received: num={num}\"\n+            )\n+    nan = tf.cast(tf.constant(np.nan), step_dtype)\n     if endpoint:\n         result = tf.linspace(start, stop, num, axis=axis)\n-        if num > 1:\n-            step = (stop - start) / (num - 1)\n+        if num_is_tensor:\n+            denom = tf.cast(num - 1, step_dtype)\n+            step = tf.where(num > 1, (stop - start) / denom, nan)\n+        else:\n+            step = (stop - start) / tf.constant(num - 1, dtype=step_dtype) if num > 1 else nan\n     else:\n         # tf.linspace doesn't support endpoint=False, so we manually handle it\n-        if num > 0:\n-            step = (stop - start) / num\n-        if num > 1:\n-            new_stop = tf.cast(stop, step.dtype) - step\n-            start = tf.cast(start, new_stop.dtype)\n+        if num_is_tensor:\n+            denom = tf.cast(num, step_dtype)\n+            step = tf.where(num > 0, (stop - start) / denom, nan)\n+            new_stop = stop - step\n             result = tf.linspace(start, new_stop, num, axis=axis)\n         else:\n-            result = tf.linspace(start, stop, num, axis=axis)\n+            step = (stop - start) / tf.constant(num, dtype=step_dtype) if num > 0 else nan\n+            if num > 1:\n+                new_stop = stop - step\n+                result = tf.linspace(start, new_stop, num, axis=axis)\n+            else:\n+                result = tf.linspace(start, stop, num, axis=axis)\n     if dtype is not None:\n         if \"int\" in dtype:\n             result = tf.floor(result)\n"}
{"instance_id": "langchain-ai__langchain-5609", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/langchain/agents/chat/output_parser.py b/langchain/agents/chat/output_parser.py\nindex 9f143d0769..2c42fb4592 100644\n--- a/langchain/agents/chat/output_parser.py\n+++ b/langchain/agents/chat/output_parser.py\n@@ -13,17 +13,30 @@ class ChatOutputParser(AgentOutputParser):\n         return FORMAT_INSTRUCTIONS\n \n     def parse(self, text: str) -> Union[AgentAction, AgentFinish]:\n-        if FINAL_ANSWER_ACTION in text:\n+        has_final = FINAL_ANSWER_ACTION in text\n+        parsed_action = None\n+        try:\n+            action_block = text.split(\"```\")[1]\n+            response = json.loads(action_block.strip())\n+            parsed_action = AgentAction(response[\"action\"], response[\"action_input\"], text)\n+        except Exception:\n+            parsed_action = None\n+\n+        if has_final and parsed_action is not None:\n+            raise OutputParserException(\n+                f\"Could not parse LLM output: {text}\",\n+                observation=\"Invalid Format: Found both 'Final Answer:' and an 'Action'. Only one should be present.\",\n+                llm_output=text,\n+                send_to_llm=True,\n+            )\n+        if has_final:\n             return AgentFinish(\n                 {\"output\": text.split(FINAL_ANSWER_ACTION)[-1].strip()}, text\n             )\n-        try:\n-            action = text.split(\"```\")[1]\n-            response = json.loads(action.strip())\n-            return AgentAction(response[\"action\"], response[\"action_input\"], text)\n+        if parsed_action is not None:\n+            return parsed_action\n \n-        except Exception:\n-            raise OutputParserException(f\"Could not parse LLM output: {text}\")\n+        raise OutputParserException(f\"Could not parse LLM output: {text}\")\n \n     @property\n     def _type(self) -> str:\n"}
{"instance_id": "keras-team__keras-19826", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/ops/numpy.py b/keras/src/ops/numpy.py\nindex e8289ee2e..ed75451be 100644\n--- a/keras/src/ops/numpy.py\n+++ b/keras/src/ops/numpy.py\n@@ -4350,21 +4350,49 @@ class Repeat(Operation):\n                 return KerasTensor([None], dtype=x.dtype)\n \n             x_flatten_size = int(np.prod(x_shape))\n-            if isinstance(self.repeats, int):\n-                output_shape = [x_flatten_size * self.repeats]\n+            # Normalize repeats: treat scalar-like values and length-1 sequences as scalars\n+            if isinstance(self.repeats, int) or (\n+                np.isscalar(self.repeats) and not isinstance(self.repeats, (list, tuple))\n+            ) or (\n+                isinstance(self.repeats, np.ndarray) and getattr(self.repeats, \"ndim\", None) == 0\n+            ):\n+                output_shape = [x_flatten_size * int(self.repeats)]\n             else:\n-                output_shape = [int(np.sum(self.repeats))]\n+                repeats_len = len(self.repeats)\n+                if repeats_len == 1:\n+                    output_shape = [x_flatten_size * int(self.repeats[0])]\n+                elif repeats_len == x_flatten_size:\n+                    output_shape = [int(np.sum(self.repeats))]\n+                else:\n+                    output_shape = [None]\n             return KerasTensor(output_shape, dtype=x.dtype)\n \n         size_on_ax = x_shape[self.axis]\n         output_shape = x_shape\n-        if isinstance(self.repeats, int):\n+        # Normalize repeats: treat scalar-like values and length-1 sequences as scalars\n+        if isinstance(self.repeats, int) or (\n+            np.isscalar(self.repeats) and not isinstance(self.repeats, (list, tuple))\n+        ) or (\n+            isinstance(self.repeats, np.ndarray) and getattr(self.repeats, \"ndim\", None) == 0\n+        ):\n             if size_on_ax is None:\n                 output_shape[self.axis] = None\n             else:\n-                output_shape[self.axis] = size_on_ax * self.repeats\n+                output_shape[self.axis] = size_on_ax * int(self.repeats)\n         else:\n-            output_shape[self.axis] = int(np.sum(self.repeats))\n+            repeats_len = len(self.repeats)\n+            if repeats_len == 1:\n+                if size_on_ax is None:\n+                    output_shape[self.axis] = None\n+                else:\n+                    output_shape[self.axis] = size_on_ax * int(self.repeats[0])\n+            else:\n+                if size_on_ax is None:\n+                    output_shape[self.axis] = None\n+                elif repeats_len == size_on_ax:\n+                    output_shape[self.axis] = int(np.sum(self.repeats))\n+                else:\n+                    output_shape[self.axis] = None\n         return KerasTensor(output_shape, dtype=x.dtype)\n \n \n@@ -4374,13 +4402,31 @@ def repeat(x, repeats, axis=None):\n \n     Args:\n         x: Input tensor.\n-        repeats: The number of repetitions for each element.\n+        repeats: The number of repetitions for each element. If a scalar\n+            (int or scalar-like), every element is repeated ``repeats`` times.\n+            If a sequence of integers, then:\n+            - If ``axis=None``, its length must be 1 (treated as a scalar\n+              repetition count) or equal to the flattened size of ``x``\n+              (treated as per-element repetition counts). Otherwise, the\n+              resulting length may be considered unknown in symbolic mode and\n+              the backend may raise at runtime.\n+            - If ``axis`` is specified, its length must be 1 (treated as a\n+              scalar repetition count) or equal to the size of the specified\n+              axis (treated as per-element repetition counts). Otherwise, the\n+              resulting size along that axis may be considered unknown in\n+              symbolic mode and the backend may raise at runtime.\n         axis: The axis along which to repeat values. By default, use\n             the flattened input array, and return a flat output array.\n \n     Returns:\n         Output tensor.\n     \"\"\"\n+    # Normalize repeats only for safe scalar coercion to minimize backend divergence.\n+    try:\n+        if np.isscalar(repeats):\n+            repeats = int(repeats)\n+    except Exception:\n+        pass\n     if any_symbolic_tensors((x,)):\n         return Repeat(repeats, axis=axis).symbolic_call(x)\n     return backend.numpy.repeat(x, repeats, axis=axis)\n"}
{"instance_id": "keras-team__keras-19838", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/losses/losses.py b/keras/src/losses/losses.py\nindex 8bb32c21b..9adb10616 100644\n--- a/keras/src/losses/losses.py\n+++ b/keras/src/losses/losses.py\n@@ -1711,12 +1711,15 @@ def sparse_categorical_crossentropy(\n     array([0.0513, 2.303], dtype=float32)\n     \"\"\"\n \n+    y_true, y_pred = squeeze_or_expand_to_same_rank(y_true, y_pred)\n+\n     if ignore_class is not None:\n         res_shape = ops.shape(y_pred)[:-1]\n         valid_mask = ops.not_equal(y_true, ops.cast(ignore_class, y_pred.dtype))\n         y_true = y_true * ops.cast(valid_mask, y_true.dtype)\n+        valid_mask_pred = ops.reshape(valid_mask, res_shape)\n         y_pred = y_pred * ops.cast(\n-            ops.expand_dims(valid_mask, -1), y_pred.dtype\n+            ops.expand_dims(valid_mask_pred, axis), y_pred.dtype\n         )\n \n     res = ops.sparse_categorical_crossentropy(\n"}
{"instance_id": "keras-team__keras-19844", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/initializers/__init__.py b/keras/src/initializers/__init__.py\nindex af46b7ff9..257cf55e7 100644\n--- a/keras/src/initializers/__init__.py\n+++ b/keras/src/initializers/__init__.py\n@@ -49,6 +49,7 @@ ALL_OBJECTS_DICT.update(\n         \"uniform\": RandomUniform,\n         \"normal\": RandomNormal,\n         \"orthogonal\": OrthogonalInitializer,\n+        \"Orthogonal\": OrthogonalInitializer,\n         \"one\": Ones,\n         \"zero\": Zeros,\n     }\ndiff --git a/keras/src/legacy/saving/saving_utils.py b/keras/src/legacy/saving/saving_utils.py\nindex aec107802..bb797dcab 100644\n--- a/keras/src/legacy/saving/saving_utils.py\n+++ b/keras/src/legacy/saving/saving_utils.py\n@@ -66,6 +66,12 @@ def model_from_config(config, custom_objects=None):\n     if axis is not None and isinstance(axis, list) and len(axis) == 1:\n         config[\"config\"][\"axis\"] = int(axis[0])\n \n+    # Handle backwards compatibility for deprecated RNN args\n+    if config[\"class_name\"] in [\"GRU\"]:\n+        # Older Keras versions serialized an `implementation` arg.\n+        # Keras 3 no longer supports it; drop it silently.\n+        _ = config[\"config\"].pop(\"implementation\", None)\n+\n     # Handle backwards compatibility for Keras lambdas\n     if config[\"class_name\"] == \"Lambda\":\n         for dep_arg in LAMBDA_DEP_ARGS:\n"}
{"instance_id": "keras-team__keras-19863", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/layers/layer.py b/keras/src/layers/layer.py\nindex dfff50867..de6f8b2c8 100644\n--- a/keras/src/layers/layer.py\n+++ b/keras/src/layers/layer.py\n@@ -229,6 +229,10 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n             obj._post_build()\n             obj._lock_state()\n \n+        # Preserve default-method marker for override detection.\n+        if getattr(original_build_method, \"_is_default\", False):\n+            build_wrapper._is_default = True\n+\n         obj.build = build_wrapper\n         return obj\n \n@@ -357,15 +361,25 @@ class Layer(BackendLayer, Operation, KerasSaveable):\n     @utils.default\n     def build(self, input_shape):\n         self._check_super_called()\n+        # If the build method is the default and there are unbuilt sublayers,\n+        # attempt to build by symbolically running the layer's call.\n         if utils.is_default(self.build) and might_have_unbuilt_state(self):\n-            warnings.warn(\n-                f\"`build()` was called on layer '{self.name}', however \"\n-                \"the layer does not have a `build()` method implemented \"\n-                \"and it looks like it has unbuilt state. This will cause \"\n-                \"the layer to be marked as built, despite not being \"\n-                \"actually built, which may cause failures down the line. \"\n-                \"Make sure to implement a proper `build()` method.\"\n-            )\n+            try:\n+                # Construct a symbolic input to trigger variable creation\n+                # in sublayers via a symbolic call.\n+                x = KerasTensor(shape=input_shape, dtype=self.compute_dtype)\n+                # Call the layer symbolically. We ignore the output.\n+                self.call(x)\n+            except Exception:\n+                # Fall back to warning if auto-build fails.\n+                warnings.warn(\n+                    f\"`build()` was called on layer '{self.name}', however \"\n+                    \"the layer does not have a `build()` method implemented \"\n+                    \"and it looks like it has unbuilt state. This will cause \"\n+                    \"the layer to be marked as built, despite not being \"\n+                    \"actually built, which may cause failures down the line. \"\n+                    \"Make sure to implement a proper `build()` method.\"\n+                )\n         self.built = True\n \n     def _lock_state(self):\n"}
{"instance_id": "keras-team__keras-19915", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/export/export_lib.py b/keras/src/export/export_lib.py\nindex 02714c55c..15c5e5e4e 100644\n--- a/keras/src/export/export_lib.py\n+++ b/keras/src/export/export_lib.py\n@@ -635,7 +635,7 @@ def export_model(model, filepath):\n         export_archive.add_endpoint(\"serve\", model.__call__, input_signature)\n     else:\n         input_signature = _get_input_signature(model)\n-        if not input_signature or not model._called:\n+        if not input_signature:\n             raise ValueError(\n                 \"The model provided has never called. \"\n                 \"It must be called at least once before export.\"\n@@ -656,8 +656,9 @@ def _get_input_signature(model):\n             return {k: make_tensor_spec(v) for k, v in structure.items()}\n         if isinstance(structure, (list, tuple)):\n             if all(isinstance(d, (int, type(None))) for d in structure):\n+                dims = tuple(structure)\n                 return tf.TensorSpec(\n-                    shape=(None,) + structure[1:], dtype=model.input_dtype\n+                    shape=(None,) + dims[1:], dtype=model.input_dtype\n                 )\n             result = [make_tensor_spec(v) for v in structure]\n             return tuple(result) if isinstance(structure, tuple) else result\n"}
{"instance_id": "keras-team__keras-19937", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/dtype_policies/dtype_policy.py b/keras/src/dtype_policies/dtype_policy.py\nindex 9d37ac49f..8ad82dc90 100644\n--- a/keras/src/dtype_policies/dtype_policy.py\n+++ b/keras/src/dtype_policies/dtype_policy.py\n@@ -57,6 +57,13 @@ class DTypePolicy:\n     to explicitly construct a `DTypePolicy` object.\n     \"\"\"\n \n+    def __new__(cls, name=None):\n+        # Factory: return FloatDTypePolicy for non-quantized names when called via DTypePolicy\n+        if cls is DTypePolicy:\n+            if name is None or not (isinstance(name, str) and name.startswith(QUANTIZATION_MODES)):\n+                return object.__new__(FloatDTypePolicy)\n+        return object.__new__(cls)\n+\n     def __init__(self, name=None):\n         # Use the global dtype policy if `name` is not specified\n         if name is None:\n@@ -196,6 +203,12 @@ class DTypePolicy:\n                 return False\n         return self._name == other._name\n \n+    def __hash__(self):\n+        # Ensure hash is consistent with equality semantics.\n+        # Group DTypePolicy and FloatDTypePolicy together as in __eq__.\n+        cls = DTypePolicy if self.__class__ in (DTypePolicy, FloatDTypePolicy) else self.__class__\n+        return hash((cls, self._name))\n+\n     def _should_cast(self, x, autocast, dtype):\n         x_dtype = backend.standardize_dtype(x.dtype)\n         if autocast and backend.is_float_dtype(x_dtype) and x_dtype != dtype:\n"}
{"instance_id": "keras-team__keras-19924", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/saving/saving_lib.py b/keras/src/saving/saving_lib.py\nindex 6aad62db5..14b49a609 100644\n--- a/keras/src/saving/saving_lib.py\n+++ b/keras/src/saving/saving_lib.py\n@@ -163,10 +163,9 @@ def _save_model_to_fileobj(model, fileobj, weights_format):\n         try:\n             if weights_format == \"h5\":\n                 if isinstance(fileobj, io.BufferedWriter):\n-                    # First, open the .h5 file, then write it to `zf` at the end\n-                    # of the function call.\n-                    working_dir = pathlib.Path(fileobj.name).parent\n-                    weights_file_path = working_dir / _VARS_FNAME_H5\n+                    # First, write the .h5 file to a temporary directory, then add it to `zf` at the end\n+                    tmp_dir = pathlib.Path(tempfile.mkdtemp())\n+                    weights_file_path = tmp_dir / _VARS_FNAME_H5\n                     weights_store = H5IOStore(weights_file_path, mode=\"w\")\n                 else:\n                     # Fall back when `fileobj` is an `io.BytesIO`. Typically,\n@@ -203,6 +202,17 @@ def _save_model_to_fileobj(model, fileobj, weights_format):\n             asset_store.close()\n             if weights_file_path:\n                 zf.write(weights_file_path, weights_file_path.name)\n+                try:\n+                    weights_file_path.unlink()\n+                    # Remove temp directory if empty\n+                    tmp_dir = weights_file_path.parent\n+                    if tmp_dir.exists():\n+                        try:\n+                            tmp_dir.rmdir()\n+                        except Exception:\n+                            pass\n+                except FileNotFoundError:\n+                    pass\n \n \n def load_model(filepath, custom_objects=None, compile=True, safe_mode=True):\n@@ -312,11 +322,10 @@ def _load_model_from_fileobj(fileobj, custom_objects, compile, safe_mode):\n         try:\n             if _VARS_FNAME_H5 in all_filenames:\n                 if isinstance(fileobj, io.BufferedReader):\n-                    # First, extract the model.weights.h5 file, then load it\n-                    # using h5py.\n-                    working_dir = pathlib.Path(fileobj.name).parent\n-                    zf.extract(_VARS_FNAME_H5, working_dir)\n-                    weights_file_path = working_dir / _VARS_FNAME_H5\n+                    # First, extract the model.weights.h5 file to a temporary directory, then load it using h5py.\n+                    tmp_dir = pathlib.Path(tempfile.mkdtemp())\n+                    zf.extract(_VARS_FNAME_H5, tmp_dir)\n+                    weights_file_path = tmp_dir / _VARS_FNAME_H5\n                     weights_store = H5IOStore(weights_file_path, mode=\"r\")\n                 else:\n                     # Fall back when `fileobj` is an `io.BytesIO`. Typically,\n@@ -350,7 +359,17 @@ def _load_model_from_fileobj(fileobj, custom_objects, compile, safe_mode):\n             if asset_store:\n                 asset_store.close()\n             if weights_file_path:\n-                weights_file_path.unlink()\n+                try:\n+                    weights_file_path.unlink()\n+                    # Remove temp directory if empty\n+                    tmp_dir = weights_file_path.parent\n+                    if tmp_dir.exists():\n+                        try:\n+                            tmp_dir.rmdir()\n+                        except Exception:\n+                            pass\n+                except FileNotFoundError:\n+                    pass\n \n         if failed_saveables:\n             _raise_loading_failure(error_msgs)\n"}
{"instance_id": "keras-team__keras-20002", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "keras-team__keras-20008", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/keras/src/backend/tensorflow/nn.py b/keras/src/backend/tensorflow/nn.py\nindex 3eef471f7..67a9d50a7 100644\n--- a/keras/src/backend/tensorflow/nn.py\n+++ b/keras/src/backend/tensorflow/nn.py\n@@ -254,7 +254,18 @@ def conv(\n         return _conv_xla()\n     if data_format == \"channels_first\" and len(inputs.shape) == 5:\n         inputs = convert_to_tensor(inputs)\n-        if inputs.device.split(\":\")[-2] == \"CPU\":\n+        device = getattr(inputs, \"device\", \"\")\n+        is_cpu = False\n+        if device:\n+            try:\n+                spec = tf.DeviceSpec.from_string(device)\n+                is_cpu = spec.device_type == \"CPU\"\n+            except Exception:\n+                is_cpu = \"CPU\" in device.upper()\n+        else:\n+            # If device is unspecified, assume CPU only when no GPUs are available.\n+            is_cpu = len(tf.config.list_logical_devices(\"GPU\")) == 0\n+        if is_cpu:\n             inputs = tf.transpose(inputs, perm=(0, 2, 3, 4, 1))\n             data_format = \"channels_last\"\n             return tf.transpose(_conv(), perm=(0, 4, 1, 2, 3))\n"}
{"instance_id": "coder__code-server-3277", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/browser/register.ts b/src/browser/register.ts\nindex e99d64c6..e61036ea 100644\n--- a/src/browser/register.ts\n+++ b/src/browser/register.ts\n@@ -22,3 +22,20 @@ if (typeof navigator !== \"undefined\" && \"serviceWorker\" in navigator) {\n } else {\n   console.error(`[Service Worker] navigator is undefined`)\n }\n+\n+// Hide the \"Log out\" button when authentication is disabled (handled externally or not used)\n+const options = getOptions()\n+if (options.auth === \"none\") {\n+  const hideLogout = (): void => {\n+    document.querySelectorAll(\"a, button, div, span\").forEach((el) => {\n+      const text = el.textContent ? el.textContent.trim().toLowerCase() : \"\"\n+      if (text === \"log out\") {\n+        ;(el as HTMLElement).style.display = \"none\"\n+      }\n+    })\n+  }\n+  // Attempt to hide immediately and on DOM changes\n+  hideLogout()\n+  const observer = new MutationObserver(() => hideLogout())\n+  observer.observe(document.documentElement, { childList: true, subtree: true })\n+}\ndiff --git a/src/common/util.ts b/src/common/util.ts\nindex 87ca6f59..f27d9c6a 100644\n--- a/src/common/util.ts\n+++ b/src/common/util.ts\n@@ -4,6 +4,7 @@ export interface Options {\n   base: string\n   csStaticBase: string\n   logLevel: number\n+  auth: string\n }\n \n /**\ndiff --git a/src/node/http.ts b/src/node/http.ts\nindex eb8c91f9..d9b6c936 100644\n--- a/src/node/http.ts\n+++ b/src/node/http.ts\n@@ -33,6 +33,7 @@ export const replaceTemplates = <T extends object>(\n     base,\n     csStaticBase: base + \"/static/\" + commit + rootPath,\n     logLevel: logger.level,\n+    auth: req.args.auth,\n     ...extraOpts,\n   }\n   return content\n"}
{"instance_id": "trinodb__trino-4393", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/presto-hive/src/main/java/io/prestosql/plugin/hive/BackgroundHiveSplitLoader.java b/presto-hive/src/main/java/io/prestosql/plugin/hive/BackgroundHiveSplitLoader.java\nindex 5e770f27a52..7c16ac3fe52 100644\n--- a/presto-hive/src/main/java/io/prestosql/plugin/hive/BackgroundHiveSplitLoader.java\n+++ b/presto-hive/src/main/java/io/prestosql/plugin/hive/BackgroundHiveSplitLoader.java\n@@ -567,7 +567,18 @@ public class BackgroundHiveSplitLoader\n             String fileName = file.getPath().getName();\n             OptionalInt bucket = getBucketNumber(fileName);\n             if (bucket.isPresent()) {\n-                bucketFiles.put(bucket.getAsInt(), file);\n+                int bucketNumber = bucket.getAsInt();\n+                if (bucketNumber >= partitionBucketCount) {\n+                    throw new PrestoException(\n+                            HIVE_INVALID_BUCKET_FILES,\n+                            format(\"Hive table '%s' is corrupt. File '%s' has invalid bucket number %s which exceeds the declared bucket count (%s) for partition: %s\",\n+                                    table.getSchemaTableName(),\n+                                    fileName,\n+                                    bucketNumber,\n+                                    partitionBucketCount,\n+                                    splitFactory.getPartitionName()));\n+                }\n+                bucketFiles.put(bucketNumber, file);\n                 continue;\n             }\n \n"}
{"instance_id": "mui__material-ui-38247", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/data/material/components/icons/icons.md b/docs/data/material/components/icons/icons.md\nindex ef0fafe9a5..2c2d8d4202 100644\n--- a/docs/data/material/components/icons/icons.md\n+++ b/docs/data/material/components/icons/icons.md\n@@ -219,6 +219,45 @@ All you need to do is load the font, for instance, via Google Web Fonts:\n />\n ```\n \n+#### Additional Material Icons variants\n+\n+The Icon component defaults to the filled variant using the material-icons base class. To use other variants, include the appropriate Google Fonts family and set baseClassName accordingly:\n+- Outlined: class material-icons-outlined, link family=Material+Icons+Outlined\n+- Rounded: class material-icons-round, link family=Material+Icons+Round\n+- Sharp: class material-icons-sharp, link family=Material+Icons+Sharp\n+- Two Tone: class material-icons-two-tone, link family=Material+Icons+Two+Tone\n+\n+Include the stylesheets in your HTML:\n+```html\n+<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons&display=swap\" />\n+<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons+Outlined&display=swap\" />\n+<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons+Round&display=swap\" />\n+<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons+Sharp&display=swap\" />\n+<link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons+Two+Tone&display=swap\" />\n+```\n+\n+Then render the desired variant:\n+```jsx\n+import Icon from '@mui/material/Icon';\n+\n+// Default filled (baseline)\n+<Icon>star</Icon>\n+\n+// Outlined\n+<Icon baseClassName=\"material-icons-outlined\">home</Icon>\n+\n+// Two tone\n+<Icon baseClassName=\"material-icons-two-tone\">add_circle</Icon>\n+```\n+\n+Troubleshooting: If you see plain text such as \"ad\" or \"add_circle\" instead of an icon, the icon font isnt loaded or the baseClassName doesnt match the loaded font family. Ensure the correct link tags are present and the baseClassName matches one of the Material Icons classes above.\n+\n+#### Why is the icon name passed as children?\n+\n+Font icon ligatures rely on the text content inside the element to substitute the glyph. Passing the icon name as children ensures the ligature mechanism works across icon fonts. If you prefer type-safe, prop-based icons, use the SVG icon components from `@mui/icons-material` (for example `import AddCircleTwoToneIcon from '@mui/icons-material/AddCircleTwoTone'`).\n+\n+For a type-safe and tree-shakable approach, use the SVG icon components from `@mui/icons-material`. See the [Material SVG icons](#material-svg-icons) section and the Icons API for details.\n+\n {{\"demo\": \"Icons.js\"}}\n \n ### Custom font\ndiff --git a/docs/src/modules/sandbox/CreateReactApp.ts b/docs/src/modules/sandbox/CreateReactApp.ts\nindex dedaab0a38..01e207f608 100644\n--- a/docs/src/modules/sandbox/CreateReactApp.ts\n+++ b/docs/src/modules/sandbox/CreateReactApp.ts\n@@ -21,10 +21,11 @@ export const getHtml = ({\n       href=\"https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;600;700&display=swap\"\n     />\n     <!-- Icons to support Material Design -->\n-    <link\n-      rel=\"stylesheet\"\n-      href=\"https://fonts.googleapis.com/icon?family=Material+Icons\"\n-    />${\n+    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons&display=swap\" />\n+    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons+Outlined&display=swap\" />\n+    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons+Round&display=swap\" />\n+    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons+Sharp&display=swap\" />\n+    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons+Two+Tone&display=swap\" />${\n       codeStyling === 'Tailwind'\n         ? `\n     <!-- Check the Tailwind CSS's installation guide for setting up tailwind: https://tailwindcss.com/docs/installation -->\n"}
{"instance_id": "huggingface__transformers-12981", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/trainer.py b/src/transformers/trainer.py\nindex a2c56f8a8b..ad21df39ad 100755\n--- a/src/transformers/trainer.py\n+++ b/src/transformers/trainer.py\n@@ -1030,6 +1030,10 @@ class Trainer:\n         # This might change the seed so needs to run first.\n         self._hp_search_setup(trial)\n \n+        # Normalize resume_from_checkpoint to a string path or None\n+        if isinstance(resume_from_checkpoint, bool) and not resume_from_checkpoint:\n+            resume_from_checkpoint = None\n+\n         # Model re-init\n         model_reloaded = False\n         if self.model_init is not None:\n@@ -1046,7 +1050,7 @@ class Trainer:\n             if resume_from_checkpoint is None:\n                 raise ValueError(f\"No valid checkpoint found in output directory ({args.output_dir})\")\n \n-        if resume_from_checkpoint is not None:\n+        if isinstance(resume_from_checkpoint, str):\n             if not os.path.isfile(os.path.join(resume_from_checkpoint, WEIGHTS_NAME)):\n                 raise ValueError(f\"Can't find a valid checkpoint at {resume_from_checkpoint}\")\n \n@@ -1176,7 +1180,7 @@ class Trainer:\n         steps_trained_progress_bar = None\n \n         # Check if continuing training from a checkpoint\n-        if resume_from_checkpoint is not None and os.path.isfile(\n+        if isinstance(resume_from_checkpoint, str) and os.path.isfile(\n             os.path.join(resume_from_checkpoint, \"trainer_state.json\")\n         ):\n             self.state = TrainerState.load_from_json(os.path.join(resume_from_checkpoint, \"trainer_state.json\"))\n"}
{"instance_id": "huggingface__transformers-13693", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py b/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\nindex 6aa60df560..e07c4fe6ec 100644\n--- a/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\n+++ b/src/transformers/models/wav2vec2/feature_extraction_wav2vec2.py\n@@ -16,7 +16,7 @@\n Feature extractor class for Wav2Vec2\n \"\"\"\n \n-from typing import List, Optional, Union\n+from typing import Dict, List, Optional, Union\n \n import numpy as np\n \n@@ -233,3 +233,60 @@ class Wav2Vec2FeatureExtractor(SequenceFeatureExtractor):\n             padded_inputs = padded_inputs.convert_to_tensors(return_tensors)\n \n         return padded_inputs\n+\n+    def pad(\n+        self,\n+        processed_features: Union[\n+            BatchFeature,\n+            List[BatchFeature],\n+            Dict[str, BatchFeature],\n+            Dict[str, List[BatchFeature]],\n+            List[Dict[str, BatchFeature]],\n+        ],\n+        padding: Union[bool, str, PaddingStrategy] = True,\n+        max_length: Optional[int] = None,\n+        truncation: bool = False,\n+        pad_to_multiple_of: Optional[int] = None,\n+        return_attention_mask: Optional[bool] = None,\n+        return_tensors: Optional[Union[str, TensorType]] = None,\n+    ) -> BatchFeature:\n+        \"\"\"\n+        Override pad to ensure that input_values are float32 even when padding is called directly.\n+        \"\"\"\n+        # Delegate to parent without tensor conversion to control dtype casting here\n+        padded_inputs = super().pad(\n+            processed_features,\n+            padding=padding,\n+            max_length=max_length,\n+            truncation=truncation,\n+            pad_to_multiple_of=pad_to_multiple_of,\n+            return_attention_mask=return_attention_mask,\n+            return_tensors=None,\n+        )\n+\n+        # Ensure input_values are np.float32\n+        input_values = padded_inputs[\"input_values\"]\n+        if isinstance(input_values, list):\n+            if len(input_values) > 0:\n+                if not isinstance(input_values[0], np.ndarray):\n+                    padded_inputs[\"input_values\"] = [np.asarray(array, dtype=np.float32) for array in input_values]\n+                else:\n+                    if input_values[0].dtype is np.dtype(np.float64):\n+                        padded_inputs[\"input_values\"] = [array.astype(np.float32) for array in input_values]\n+        elif isinstance(input_values, np.ndarray):\n+            if input_values.dtype is np.dtype(np.float64):\n+                padded_inputs[\"input_values\"] = input_values.astype(np.float32)\n+\n+        # Ensure attention_mask dtype is np.int32 if present\n+        attention_mask = padded_inputs.get(\"attention_mask\")\n+        if attention_mask is not None:\n+            if isinstance(attention_mask, list):\n+                if len(attention_mask) > 0 and not isinstance(attention_mask[0], np.ndarray):\n+                    padded_inputs[\"attention_mask\"] = [np.asarray(array, dtype=np.int32) for array in attention_mask]\n+            elif isinstance(attention_mask, np.ndarray) and attention_mask.dtype != np.int32:\n+                padded_inputs[\"attention_mask\"] = np.asarray(attention_mask, dtype=np.int32)\n+\n+        if return_tensors is not None:\n+            padded_inputs = padded_inputs.convert_to_tensors(return_tensors)\n+\n+        return padded_inputs\n"}
{"instance_id": "huggingface__transformers-13865", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/examples/README.md b/examples/README.md\nindex 141564c803..c786bcbc7a 100644\n--- a/examples/README.md\n+++ b/examples/README.md\n@@ -17,6 +17,8 @@ limitations under the License.\n \n This folder contains actively maintained examples of use of  Transformers organized along NLP tasks. If you are looking for an example that used to be in this folder, it may have moved to the corresponding framework subfolder (pytorch, tensorflow or flax), our [research projects](https://github.com/huggingface/transformers/tree/master/examples/research_projects) subfolder (which contains frozen snapshots of research projects) or to the [legacy](https://github.com/huggingface/transformers/tree/master/examples/legacy) subfolder.\n \n+Note on boolean CLI flags: examples scripts expose both `--<flag> [True|False]` and `--no_<flag>` for boolean options (via HfArgumentParser). If a flag defaults to True, use `--no_<flag>` to disable it; if it defaults to False, use `--<flag>` (or `--<flag> True`) to enable it.\n+\n While we strive to present as many use cases as possible, the scripts in this folder are just examples. It is expected that they won't work out-of-the box on your specific problem and that you will be required to change a few lines of code to adapt them to your needs. To help you with that, most of the examples fully expose the preprocessing of the data. This way, you can easily tweak them.\n \n This is similar if you want the scripts to report another metric than the one they currently use: look at the `compute_metrics` function inside the script. It takes the full arrays of predictions and labels and has to return a dictionary of string keys and float values. Just change it to add (or replace) your own metric to the ones already reported.\ndiff --git a/examples/pytorch/language-modeling/README.md b/examples/pytorch/language-modeling/README.md\nindex c768f5ec31..0e2533e7c2 100644\n--- a/examples/pytorch/language-modeling/README.md\n+++ b/examples/pytorch/language-modeling/README.md\n@@ -162,6 +162,22 @@ concatenates all texts and then splits them in blocks of the same length).\n **Note:** On TPU, you should use the flag `--pad_to_max_length` in conjunction with the `--line_by_line` flag to make\n sure all your batches have the same length.\n \n+### Boolean flags in CLI\n+\n+Examples scripts use HfArgumentParser to parse dataclass-defined arguments. For each boolean option, the CLI provides both:\n+- an affirmative flag: `--<option> [True|False]`\n+- a negated convenience flag: `--no_<option>` (no value)\n+This is by design to make it easy to flip defaults.\n+\n+Defaults are shown in the help output. Use:\n+- If default is True: pass `--no_<option>` to set it to False.\n+- If default is False: pass `--<option>` (or `--<option> True`) to set it to True.\n+\n+Examples:\n+- Keep line breaks (default True): disable with `--no_keep_linebreaks`\n+- Pin DataLoader memory (default True): disable with `--no_dataloader_pin_memory`\n+- Skip memory metrics (default True): include memory metrics with `--no_skip_memory_metrics`\n+- Alternate explicit assignments also work: `--keep_linebreaks False`, `--dataloader_pin_memory False`, `--skip_memory_metrics False`\n \n ## Creating a model on the fly\n \ndiff --git a/examples/pytorch/language-modeling/run_clm.py b/examples/pytorch/language-modeling/run_clm.py\nindex e0f8dfe354..a2ac38377f 100755\n--- a/examples/pytorch/language-modeling/run_clm.py\n+++ b/examples/pytorch/language-modeling/run_clm.py\n@@ -18,6 +18,17 @@ Fine-tuning the library models for causal language modeling (GPT, GPT-2, CTRL, .\n \n Here is the full list of checkpoints on the hub that can be fine-tuned by this script:\n https://huggingface.co/models?filter=causal-lm\n+\n+Boolean flags in this script are parsed by HfArgumentParser from dataclasses. For each boolean field, the CLI exposes both\n+an affirmative flag (e.g., --keep_linebreaks [True|False]) and a negated convenience flag (e.g., --no_keep_linebreaks) to\n+explicitly set the value to False. Defaults are shown in the help. Preferred usage to disable a default-True option is\n+--no_<flag>; to enable a default-False option use --<flag>.\n+\n+Examples:\n+- Disable line breaks: python run_clm.py ... --no_keep_linebreaks\n+- Disable DataLoader pin memory: python run_clm.py ... --no_dataloader_pin_memory\n+- Include memory metrics (do not skip): python run_clm.py ... --no_skip_memory_metrics\n+- Alternate explicit values also work: python run_clm.py ... --keep_linebreaks False --dataloader_pin_memory False --skip_memory_metrics False\n \"\"\"\n # You can also adapt this script on your own causal language modeling task. Pointers for this are left as comments.\n \n@@ -173,7 +184,7 @@ class DataTrainingArguments:\n         metadata={\"help\": \"The number of processes to use for the preprocessing.\"},\n     )\n     keep_linebreaks: bool = field(\n-        default=True, metadata={\"help\": \"Whether to keep line breaks when using TXT files or not.\"}\n+        default=True, metadata={\"help\": \"Whether to keep line breaks when using TXT files. Default: True. To disable, pass --no_keep_linebreaks. You can also pass --keep_linebreaks False.\"}\n     )\n \n     def __post_init__(self):\ndiff --git a/src/transformers/training_args.py b/src/transformers/training_args.py\nindex 85abc7f890..6ffa53810a 100644\n--- a/src/transformers/training_args.py\n+++ b/src/transformers/training_args.py\n@@ -634,10 +634,10 @@ class TrainingArguments:\n         },\n     )\n     dataloader_pin_memory: bool = field(\n-        default=True, metadata={\"help\": \"Whether or not to pin memory for DataLoader.\"}\n+        default=True, metadata={\"help\": \"Whether to pin memory for the PyTorch DataLoader. Default: True. To disable, pass --no_dataloader_pin_memory. You can also pass --dataloader_pin_memory False.\"}\n     )\n     skip_memory_metrics: bool = field(\n-        default=True, metadata={\"help\": \"Whether or not to skip adding of memory profiler reports to metrics.\"}\n+        default=True, metadata={\"help\": \"Whether to skip adding memory profiler reports to metrics. Default: True (skip). To include memory metrics, pass --no_skip_memory_metrics. You can also pass --skip_memory_metrics False.\"}\n     )\n     use_legacy_prediction_loop: bool = field(\n         default=False, metadata={\"help\": \"Whether or not to use the legacy prediction_loop in the Trainer.\"}\n"}
{"instance_id": "huggingface__transformers-13491", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/gpt_neo/modeling_gpt_neo.py b/src/transformers/models/gpt_neo/modeling_gpt_neo.py\nindex 05e5b1ce28..7aefa213d0 100755\n--- a/src/transformers/models/gpt_neo/modeling_gpt_neo.py\n+++ b/src/transformers/models/gpt_neo/modeling_gpt_neo.py\n@@ -423,26 +423,39 @@ class GPTNeoLocalSelfAttention(nn.Module, GPTNeoAttentionMixin):\n \n         # create buckets\n         if layer_past is not None:\n-            # we just need 1 block with block_length 1 when caching is enabled\n-            query = self._split_seq_length_dim_to(query, 1, 1)\n+            # When using cache, support multiple new tokens by aligning queries to block boundaries.\n+            start_in_block = past_length % block_length\n+            total_new = seq_length + start_in_block\n+            num_new_blocks = (total_new + block_length - 1) // block_length\n+            if start_in_block > 0:\n+                pad_left = torch.zeros(batch_size, start_in_block, query.size(-1), dtype=query.dtype, device=query.device)\n+                query_padded = torch.cat([pad_left, query], dim=1)\n+            else:\n+                query_padded = query\n+            needed = num_new_blocks * block_length\n+            extra = needed - query_padded.size(1)\n+            if extra > 0:\n+                pad_right = torch.zeros(batch_size, extra, query.size(-1), dtype=query.dtype, device=query.device)\n+                query_padded = torch.cat([query_padded, pad_right], dim=1)\n+            query = self._split_seq_length_dim_to(query_padded, num_new_blocks, block_length)\n         else:\n             query = self._split_seq_length_dim_to(query, num_blocks, block_length)\n \n         key = self._look_back(key, block_length, self.window_size)\n         value = self._look_back(value, block_length, self.window_size)\n \n-        # select key/value vectors only for the last block\n+        # select key/value vectors only for the relevant last blocks\n         if layer_past is not None:\n-            key = key[:, -1:, ...]\n-            value = value[:, -1:, ...]\n+            key = key[:, -num_new_blocks:, ...]\n+            value = value[:, -num_new_blocks:, ...]\n \n         query = self._split_heads(query, self.num_heads, self.head_dim)\n         key = self._split_heads(key, self.num_heads, self.head_dim)\n         value = self._split_heads(value, self.num_heads, self.head_dim)\n \n         if layer_past is not None:\n-            # only take the mask for the last block\n-            attention_mask = attention_mask[:, -1:, :, -1:, :]\n+            # take the mask for the last `num_new_blocks` blocks\n+            attention_mask = attention_mask[:, :, -num_new_blocks:, :, :]\n \n         # attn\n         attn_output, attn_weights = self._attn(\n@@ -456,7 +469,12 @@ class GPTNeoLocalSelfAttention(nn.Module, GPTNeoAttentionMixin):\n         )\n \n         attn_output = self._merge_heads(attn_output, self.num_heads, self.head_dim)\n-        attn_output = attn_output.reshape(batch_size, seq_length, self.embed_dim)\n+        if layer_past is not None:\n+            # flatten (blocks, block_length) and drop any padding to keep only new tokens\n+            attn_output = attn_output.reshape(batch_size, -1, self.embed_dim)\n+            attn_output = attn_output[:, -seq_length:, :]\n+        else:\n+            attn_output = attn_output.reshape(batch_size, seq_length, self.embed_dim)\n \n         attn_output = self.out_proj(attn_output)\n         attn_output = self.resid_dropout(attn_output)\n"}
{"instance_id": "huggingface__transformers-15158", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/bert/tokenization_bert_fast.py b/src/transformers/models/bert/tokenization_bert_fast.py\nindex 4fd53be98d..967fefb67c 100644\n--- a/src/transformers/models/bert/tokenization_bert_fast.py\n+++ b/src/transformers/models/bert/tokenization_bert_fast.py\n@@ -192,10 +192,13 @@ class BertTokenizerFast(PreTrainedTokenizerFast):\n         if (\n             pre_tok_state.get(\"lowercase\", do_lower_case) != do_lower_case\n             or pre_tok_state.get(\"strip_accents\", strip_accents) != strip_accents\n+            or pre_tok_state.get(\"handle_chinese_chars\", tokenize_chinese_chars) != tokenize_chinese_chars\n         ):\n             pre_tok_class = getattr(normalizers, pre_tok_state.pop(\"type\"))\n             pre_tok_state[\"lowercase\"] = do_lower_case\n             pre_tok_state[\"strip_accents\"] = strip_accents\n+            if \"handle_chinese_chars\" in pre_tok_state:\n+                pre_tok_state[\"handle_chinese_chars\"] = tokenize_chinese_chars\n             self.backend_tokenizer.normalizer = pre_tok_class(**pre_tok_state)\n \n         self.do_lower_case = do_lower_case\n"}
{"instance_id": "huggingface__transformers-13989", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/docs/source/model_doc/auto.rst b/docs/source/model_doc/auto.rst\nindex 0cc3b21751..734b57a3b6 100644\n--- a/docs/source/model_doc/auto.rst\n+++ b/docs/source/model_doc/auto.rst\n@@ -36,6 +36,35 @@ AutoConfig\n .. autoclass:: transformers.AutoConfig\n     :members:\n \n+Custom registration\n+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n+\n+You can register your own configuration and model classes to be used with the Auto classes at runtime:\n+\n+- Register a custom configuration class with a model type string:\n+\n+  .. code-block:: python\n+\n+      from transformers import AutoConfig\n+\n+      class MyConfig(PretrainedConfig):\n+          model_type = \"my-model\"\n+          # ...\n+\n+      AutoConfig.register(\"my-model\", MyConfig)\n+\n+- Register your custom model classes for a given configuration class (for example, for sequence classification):\n+\n+  .. code-block:: python\n+\n+      from transformers import AutoModelForSequenceClassification\n+\n+      class MySequenceClassificationModel(nn.Module):\n+          # ...\n+\n+      AutoModelForSequenceClassification.register(MyConfig, MySequenceClassificationModel)\n+\n+After registration, you can use AutoConfig.for_model(\"my-model\") and the corresponding AutoModel classes with your custom types. For distributing custom models via the Hub, you can also rely on `config.auto_map` and `trust_remote_code=True`. See security considerations in the AutoModel docstrings.\n \n AutoTokenizer\n ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\ndiff --git a/src/transformers/models/auto/auto_factory.py b/src/transformers/models/auto/auto_factory.py\nindex 516aec52be..b1aacdab5c 100644\n--- a/src/transformers/models/auto/auto_factory.py\n+++ b/src/transformers/models/auto/auto_factory.py\n@@ -376,6 +376,11 @@ class _BaseAutoModelClass:\n             f\"`{self.__class__.__name__}.from_config(config)` methods.\"\n         )\n \n+    @classmethod\n+    def register(cls, config_class, model_class):\n+        \"\"\"Register a custom model class for a given config class at runtime.\"\"\"\n+        cls._model_mapping[config_class] = model_class\n+\n     @classmethod\n     def from_config(cls, config, **kwargs):\n         if type(config) in cls._model_mapping.keys():\n@@ -501,6 +506,9 @@ class _LazyAutoMapping(OrderedDict):\n \n         - config_mapping: The map model type to config class\n         - model_mapping: The map model type to model (or tokenizer) class\n+\n+    Also allows users to register custom mappings at runtime via assignment,\n+    which will be immediately reflected in accesses and keys().\n     \"\"\"\n \n     def __init__(self, config_mapping, model_mapping):\n@@ -508,8 +516,18 @@ class _LazyAutoMapping(OrderedDict):\n         self._reverse_config_mapping = {v: k for k, v in config_mapping.items()}\n         self._model_mapping = model_mapping\n         self._modules = {}\n+        self._extra_content = OrderedDict()\n+\n+    def __setitem__(self, key, value):\n+        # key should be a configuration class type\n+        if not isinstance(key, type) or not issubclass(key, PretrainedConfig):\n+            raise ValueError(\"Key must be a configuration class derived from PretrainedConfig.\")\n+        # value can be a single model class or a tuple/list of model classes\n+        self._extra_content[key] = value\n \n     def __getitem__(self, key):\n+        if key in self._extra_content:\n+            return self._extra_content[key]\n         model_type = self._reverse_config_mapping[key.__name__]\n         if model_type not in self._model_mapping:\n             raise KeyError(key)\n@@ -523,11 +541,14 @@ class _LazyAutoMapping(OrderedDict):\n         return getattribute_from_module(self._modules[module_name], attr)\n \n     def keys(self):\n-        return [\n+        extras = list(self._extra_content.keys())\n+        extras_names = {k.__name__ for k in extras}\n+        builtins = [\n             self._load_attr_from_module(key, name)\n             for key, name in self._config_mapping.items()\n-            if key in self._model_mapping.keys()\n+            if key in self._model_mapping.keys() and name not in extras_names\n         ]\n+        return extras + builtins\n \n     def get(self, key, default):\n         try:\n@@ -539,26 +560,35 @@ class _LazyAutoMapping(OrderedDict):\n         return bool(self.keys())\n \n     def values(self):\n-        return [\n+        extras_vals = list(self._extra_content.values())\n+        extras_names = {k.__name__ for k in self._extra_content.keys()}\n+        builtins_vals = [\n             self._load_attr_from_module(key, name)\n             for key, name in self._model_mapping.items()\n-            if key in self._config_mapping.keys()\n+            if key in self._config_mapping.keys() and self._config_mapping[key] not in extras_names\n         ]\n+        return extras_vals + builtins_vals\n \n     def items(self):\n-        return [\n+        extras_items = list(self._extra_content.items())\n+        extras_names = {k.__name__ for k in self._extra_content.keys()}\n+        builtins_items = [\n             (\n                 self._load_attr_from_module(key, self._config_mapping[key]),\n                 self._load_attr_from_module(key, self._model_mapping[key]),\n             )\n             for key in self._model_mapping.keys()\n-            if key in self._config_mapping.keys()\n+            if key in self._config_mapping.keys() and self._config_mapping[key] not in extras_names\n         ]\n+        return extras_items + builtins_items\n \n     def __iter__(self):\n+        # Iterate over model types (built-ins), extras are config classes so we don't include them here.\n         return iter(self._model_mapping.keys())\n \n     def __contains__(self, item):\n+        if item in self._extra_content:\n+            return True\n         if not hasattr(item, \"__name__\") or item.__name__ not in self._reverse_config_mapping:\n             return False\n         model_type = self._reverse_config_mapping[item.__name__]\ndiff --git a/src/transformers/models/auto/configuration_auto.py b/src/transformers/models/auto/configuration_auto.py\nindex 78a33659a0..6b3d0f6250 100644\n--- a/src/transformers/models/auto/configuration_auto.py\n+++ b/src/transformers/models/auto/configuration_auto.py\n@@ -271,13 +271,28 @@ def config_class_to_model_type(config):\n class _LazyConfigMapping(OrderedDict):\n     \"\"\"\n     A dictionary that lazily load its values when they are requested.\n+\n+    Also allows users to register custom configs at runtime via assignment,\n+    which will be immediately reflected in accesses and keys().\n     \"\"\"\n \n     def __init__(self, mapping):\n         self._mapping = mapping\n         self._modules = {}\n+        self._extra_content = OrderedDict()\n+\n+    def __setitem__(self, key, value):\n+        if not isinstance(key, str):\n+            raise ValueError(\"Model type key must be a string.\")\n+        if not isinstance(value, type) or not issubclass(value, PretrainedConfig):\n+            raise ValueError(\"Config value must be a configuration class derived from PretrainedConfig.\")\n+        if key in self._mapping:\n+            warnings.warn(f\"Overriding built-in config mapping for key '{key}' with a custom class.\", UserWarning)\n+        self._extra_content[key] = value\n \n     def __getitem__(self, key):\n+        if key in self._extra_content:\n+            return self._extra_content[key]\n         if key not in self._mapping:\n             raise KeyError(key)\n         value = self._mapping[key]\n@@ -287,19 +302,19 @@ class _LazyConfigMapping(OrderedDict):\n         return getattr(self._modules[module_name], value)\n \n     def keys(self):\n-        return self._mapping.keys()\n+        return list(self._extra_content.keys()) + [k for k in self._mapping.keys() if k not in self._extra_content]\n \n     def values(self):\n-        return [self[k] for k in self._mapping.keys()]\n+        return [self[k] for k in self.keys()]\n \n     def items(self):\n-        return [(k, self[k]) for k in self._mapping.keys()]\n+        return [(k, self[k]) for k in self.keys()]\n \n     def __iter__(self):\n-        return iter(self._mapping.keys())\n+        return iter(self.keys())\n \n     def __contains__(self, item):\n-        return item in self._mapping\n+        return item in self._extra_content or item in self._mapping\n \n \n CONFIG_MAPPING = _LazyConfigMapping(CONFIG_MAPPING_NAMES)\n@@ -441,6 +456,11 @@ class AutoConfig:\n             \"using the `AutoConfig.from_pretrained(pretrained_model_name_or_path)` method.\"\n         )\n \n+    @classmethod\n+    def register(cls, model_type: str, config_class):\n+        \"\"\"Register a custom configuration class for a given model type at runtime.\"\"\"\n+        CONFIG_MAPPING[model_type] = config_class\n+\n     @classmethod\n     def for_model(cls, model_type: str, *args, **kwargs):\n         if model_type in CONFIG_MAPPING:\n"}
{"instance_id": "huggingface__transformers-15473", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/trainer.py b/src/transformers/trainer.py\nindex 6a68f7d6f4..a801b6873e 100755\n--- a/src/transformers/trainer.py\n+++ b/src/transformers/trainer.py\n@@ -282,6 +282,7 @@ class Trainer:\n         tokenizer: Optional[PreTrainedTokenizerBase] = None,\n         model_init: Callable[[], PreTrainedModel] = None,\n         compute_metrics: Optional[Callable[[EvalPrediction], Dict]] = None,\n+        preprocess_logits_for_metrics: Optional[Callable] = None,\n         callbacks: Optional[List[TrainerCallback]] = None,\n         optimizers: Tuple[torch.optim.Optimizer, torch.optim.lr_scheduler.LambdaLR] = (None, None),\n     ):\n@@ -385,6 +386,7 @@ class Trainer:\n         self.model = model\n \n         self.compute_metrics = compute_metrics\n+        self.preprocess_logits_for_metrics = preprocess_logits_for_metrics\n         self.optimizer, self.lr_scheduler = optimizers\n         if model_init is not None and (self.optimizer is not None or self.lr_scheduler is not None):\n             raise RuntimeError(\n@@ -2412,14 +2414,20 @@ class Trainer:\n             if loss is not None:\n                 losses = self._nested_gather(loss.repeat(batch_size))\n                 losses_host = losses if losses_host is None else torch.cat((losses_host, losses), dim=0)\n-            if logits is not None:\n-                logits = self._pad_across_processes(logits)\n-                logits = self._nested_gather(logits)\n-                preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)\n             if labels is not None:\n                 labels = self._pad_across_processes(labels)\n                 labels = self._nested_gather(labels)\n                 labels_host = labels if labels_host is None else nested_concat(labels_host, labels, padding_index=-100)\n+            if logits is not None:\n+                logits = self._pad_across_processes(logits)\n+                logits = self._nested_gather(logits)\n+                if self.preprocess_logits_for_metrics is not None:\n+                    try:\n+                        logits = self.preprocess_logits_for_metrics(logits, labels)\n+                    except TypeError:\n+                        # Backward compatibility: some preprocess functions might only accept logits\n+                        logits = self.preprocess_logits_for_metrics(logits)\n+                preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)\n             self.control = self.callback_handler.on_prediction_step(args, self.state, self.control)\n \n             # Gather all tensors and put them back on the CPU if we have done enough accumulation steps.\n@@ -2915,6 +2923,11 @@ class Trainer:\n                 losses = loss.repeat(batch_size)\n                 losses_host = losses if losses_host is None else torch.cat((losses_host, losses), dim=0)\n             if logits is not None:\n+                if self.preprocess_logits_for_metrics is not None:\n+                    try:\n+                        logits = self.preprocess_logits_for_metrics(logits, labels)\n+                    except TypeError:\n+                        logits = self.preprocess_logits_for_metrics(logits)\n                 preds_host = logits if preds_host is None else nested_concat(preds_host, logits, padding_index=-100)\n             if labels is not None:\n                 labels_host = labels if labels_host is None else nested_concat(labels_host, labels, padding_index=-100)\n"}
{"instance_id": "huggingface__transformers-15795", "model_name_or_path": "Prometheus", "model_patch": ""}
{"instance_id": "huggingface__transformers-15843", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/pipelines/automatic_speech_recognition.py b/src/transformers/pipelines/automatic_speech_recognition.py\nindex 3552a23ce3..d6dae658b9 100644\n--- a/src/transformers/pipelines/automatic_speech_recognition.py\n+++ b/src/transformers/pipelines/automatic_speech_recognition.py\n@@ -55,19 +55,40 @@ def rescale_stride(tokens_or_logits, stride):\n \n \n def apply_stride(tokens, stride):\n+    \"\"\"\n+    Adjust tokens in-place to remove stride overlaps by compacting the\n+    non-overlapping window to the start of the sequence and padding the\n+    remainder with a special token (CTC blank/pad assumed 0). Returns a\n+    trimmed view corresponding to the non-overlapping window.\n+    \"\"\"\n     new_stride = rescale_stride(tokens, stride)\n+    window_lens = []\n+\n     for i, (input_n, left, right) in enumerate(new_stride):\n         left_token = left\n-        right_token = input_n - right\n-        # This is CTC to preseve decoding, we need to duplicate\n-        # next letter, and last letter\n-\n-        first_letter = tokens[i, left_token]\n-        tokens[i, :left_token] = first_letter\n-\n-        last_letter = tokens[i, right_token - 1]\n-        tokens[i, right_token:] = last_letter\n-\n+        right_token = right\n+        window_len = max(0, right_token - left_token)\n+        window_lens.append(window_len)\n+\n+        if window_len > 0:\n+            # Compact the valid window to the beginning\n+            tokens[i, :window_len] = tokens[i, left_token:right_token]\n+        # Pad the remainder with a special token id (assumed 0)\n+        if tokens.shape[1] > window_len:\n+            tokens[i, window_len:] = 0\n+\n+    # Return a common trimmed view for downstream decoding and resize in-place\n+    if len(window_lens) == 0:\n+        return tokens\n+    common_len = min(window_lens)\n+    # Resize the tensor in-place so external callers decoding the full tensor\n+    # only see the non-overlapping window.\n+    try:\n+        tokens.resize_(tokens.shape[0], common_len)\n+    except Exception:\n+        # Fallback to returning a view if in-place resize fails\n+        return tokens[:, :common_len]\n+    return tokens\n \n def chunk_iter(inputs, feature_extractor, chunk_len, stride_left, stride_right):\n     inputs_len = inputs.shape[0]\n@@ -327,7 +348,7 @@ class AutomaticSpeechRecognitionPipeline(ChunkPipeline):\n                 if isinstance(stride, tuple):\n                     stride = [stride]\n \n-                apply_stride(tokens, stride)\n+                tokens = apply_stride(tokens, stride)\n             out = {\"tokens\": tokens}\n         else:\n             logger.warning(\"This is an unknown class, treating it as CTC.\")\n"}
{"instance_id": "huggingface__transformers-16198", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/configuration_utils.py b/src/transformers/configuration_utils.py\nindex 773721a203..b73218fe7a 100755\n--- a/src/transformers/configuration_utils.py\n+++ b/src/transformers/configuration_utils.py\n@@ -518,11 +518,20 @@ class PretrainedConfig(PushToHubMixin):\n         assert unused_kwargs == {\"foo\": False}\n         ```\"\"\"\n         config_dict, kwargs = cls.get_config_dict(pretrained_model_name_or_path, **kwargs)\n-        if \"model_type\" in config_dict and hasattr(cls, \"model_type\") and config_dict[\"model_type\"] != cls.model_type:\n-            logger.warning(\n-                f\"You are using a model of type {config_dict['model_type']} to instantiate a model of type \"\n-                f\"{cls.model_type}. This is not supported for all configurations of models and can yield errors.\"\n-            )\n+        # Special handling for composite configs when loading a sub-config directly.\n+        if hasattr(cls, \"model_type\"):\n+            loaded_model_type = config_dict.get(\"model_type\", None)\n+            if loaded_model_type is not None and loaded_model_type != cls.model_type:\n+                logger.warning(\n+                    f\"You are using a model of type {config_dict['model_type']} to instantiate a model of type \"\n+                    f\"{cls.model_type}. This is not supported for all configurations of models and can yield errors.\"\n+                )\n+                # If a composite CLIP config is loaded while trying to instantiate a CLIP vision config,\n+                # extract the nested vision_config to correctly initialize CLIPVisionConfig.\n+                if cls.model_type == \"clip_vision_model\" and \"vision_config\" in config_dict:\n+                    nested_vision_config = config_dict.get(\"vision_config\")\n+                    if isinstance(nested_vision_config, dict):\n+                        return cls.from_dict(nested_vision_config, **kwargs)\n \n         return cls.from_dict(config_dict, **kwargs)\n \n"}
{"instance_id": "huggingface__transformers-18851", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/generation_beam_search.py b/src/transformers/generation_beam_search.py\nindex e0514edafb..45dade1944 100644\n--- a/src/transformers/generation_beam_search.py\n+++ b/src/transformers/generation_beam_search.py\n@@ -372,7 +372,9 @@ class BeamSearchScorer(BeamScorer):\n             decoded[i, : sent_lengths[i]] = hypo\n \n             if indices is not None:\n-                indices[i, : len(best_idx)] = torch.tensor(best_idx)\n+                batch_idx_for_row = i // self.num_beam_hyps_to_keep\n+                offset = batch_idx_for_row * self.num_beams\n+                indices[i, : len(best_idx)] = torch.tensor(best_idx, device=input_ids.device) + offset\n \n             if sent_lengths[i] < sent_max_len:\n                 decoded[i, sent_lengths[i]] = eos_token_id\ndiff --git a/src/transformers/generation_utils.py b/src/transformers/generation_utils.py\nindex dcbe6e5946..c923fc206f 100644\n--- a/src/transformers/generation_utils.py\n+++ b/src/transformers/generation_utils.py\n@@ -217,8 +217,8 @@ class BeamSearchDecoderOnlyOutput(ModelOutput):\n             Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for each generated token),\n             with each tensor of shape `(batch_size*num_beams*num_return_sequences, config.vocab_size)`.\n         beam_indices (`tuple(tuple(torch.LongTensor))`, *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`):\n-            Beam indices of generated token id at each generation step. `torch.LongTensor` of shape\n-            `(batch_size*num_return_sequences, input_ids.shape[-1])`.\n+            Absolute beam indices (flattened over `batch_size*num_beams`) of the generated token at each generation step.\n+            `torch.LongTensor` of shape `(batch_size*num_return_sequences, input_ids.shape[-1])`.\n         attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or `config.output_attentions=True`):\n             Tuple (one element for each generated token) of tuples (one element for each layer of the decoder) of\n             `torch.FloatTensor` of shape `(batch_size*num_beams, num_heads, generated_length, sequence_length)`.\n@@ -254,8 +254,8 @@ class BeamSearchEncoderDecoderOutput(ModelOutput):\n             Tuple of `torch.FloatTensor` with up to `max_new_tokens` elements (one element for each generated token),\n             with each tensor of shape `(batch_size*num_beams, config.vocab_size)`.\n         beam_indices (`tuple(tuple(torch.LongTensor))`, *optional*, returned when `output_scores=True` is passed or when `config.output_scores=True`):\n-            Beam indices of generated token id at each generation step. `torch.LongTensor` of shape\n-            `(batch_size*num_return_sequences, max_length-1)`.\n+            Absolute beam indices (flattened over `batch_size*num_beams`) of the generated token at each generation step.\n+            `torch.LongTensor` of shape `(batch_size*num_return_sequences, max_length-1)`.\n         attentions (`tuple(tuple(torch.FloatTensor))`, *optional*, returned when `output_attentions=True` is passed or `config.output_attentions=True`):\n         encoder_attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or `config.output_attentions=True`):\n             Tuple of `torch.FloatTensor` (one for each layer of the decoder) of shape `(batch_size, num_heads,\n"}
{"instance_id": "huggingface__transformers-17082", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/deberta/configuration_deberta.py b/src/transformers/models/deberta/configuration_deberta.py\nindex 3a70a2460d..34035cbb95 100644\n--- a/src/transformers/models/deberta/configuration_deberta.py\n+++ b/src/transformers/models/deberta/configuration_deberta.py\n@@ -63,8 +63,8 @@ class DebertaConfig(PretrainedConfig):\n         max_position_embeddings (`int`, *optional*, defaults to 512):\n             The maximum sequence length that this model might ever be used with. Typically set this to something large\n             just in case (e.g., 512 or 1024 or 2048).\n-        type_vocab_size (`int`, *optional*, defaults to 2):\n-            The vocabulary size of the `token_type_ids` passed when calling [`DebertaModel`] or [`TFDebertaModel`].\n+        type_vocab_size (`int`, *optional*, defaults to 0):\n+            The vocabulary size of the `token_type_ids`. DeBERTa does not use segment/token type embeddings, so the default is 0 and token_type_ids are ignored.\n         initializer_range (`float`, *optional*, defaults to 0.02):\n             The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n         layer_norm_eps (`float`, *optional*, defaults to 1e-12):\ndiff --git a/src/transformers/models/deberta/tokenization_deberta.py b/src/transformers/models/deberta/tokenization_deberta.py\nindex 6bca0ed581..f066d032a1 100644\n--- a/src/transformers/models/deberta/tokenization_deberta.py\n+++ b/src/transformers/models/deberta/tokenization_deberta.py\n@@ -186,13 +186,10 @@ class DebertaTokenizer(GPT2Tokenizer):\n         self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n     ) -> List[int]:\n         \"\"\"\n-        Create a mask from the two sequences passed to be used in a sequence-pair classification task. A DeBERTa\n-        sequence pair mask has the following format:\n-\n-        ```\n-        0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1\n-        | first sequence    | second sequence |\n-        ```\n+        Create a mask from the two sequences passed to be used in a sequence-pair classification task.\n+        \n+        Note: DeBERTa does not use segment/token type embeddings. As a result, this method returns a list of zeros\n+        for both single sequences and pair sequences, and the model ignores token_type_ids.\n \n         If `token_ids_1` is `None`, this method only returns the first portion of the mask (0s).\n \ndiff --git a/src/transformers/models/deberta/tokenization_deberta_fast.py b/src/transformers/models/deberta/tokenization_deberta_fast.py\nindex 74c2e4aca2..f16cef2da0 100644\n--- a/src/transformers/models/deberta/tokenization_deberta_fast.py\n+++ b/src/transformers/models/deberta/tokenization_deberta_fast.py\n@@ -179,13 +179,10 @@ class DebertaTokenizerFast(GPT2TokenizerFast):\n         self, token_ids_0: List[int], token_ids_1: Optional[List[int]] = None\n     ) -> List[int]:\n         \"\"\"\n-        Create a mask from the two sequences passed to be used in a sequence-pair classification task. A DeBERTa\n-        sequence pair mask has the following format:\n+        Create a mask from the two sequences passed to be used in a sequence-pair classification task.\n \n-        ```\n-        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n-        | first sequence    | second sequence |\n-        ```\n+        Note: DeBERTa does not use segment/token type embeddings. As a result, this method returns a list of zeros\n+        for both single sequences and pair sequences, and the model ignores token_type_ids.\n \n         If `token_ids_1` is `None`, this method only returns the first portion of the mask (0s).\n \n"}
{"instance_id": "huggingface__transformers-19590", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/bert/tokenization_bert_tf.py b/src/transformers/models/bert/tokenization_bert_tf.py\nindex 477ba37e0c..79af565cfb 100644\n--- a/src/transformers/models/bert/tokenization_bert_tf.py\n+++ b/src/transformers/models/bert/tokenization_bert_tf.py\n@@ -3,7 +3,7 @@ from typing import List, Union\n \n import tensorflow as tf\n \n-from tensorflow_text import FastBertTokenizer, ShrinkLongestTrimmer, case_fold_utf8, combine_segments, pad_model_inputs\n+from tensorflow_text import FastBertTokenizer, BertTokenizer as TFBertTokenizerLayer, ShrinkLongestTrimmer, case_fold_utf8, combine_segments, pad_model_inputs\n \n from .tokenization_bert import BertTokenizer\n \n@@ -62,11 +62,9 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n         pad_to_multiple_of: int = None,\n         return_token_type_ids: bool = True,\n         return_attention_mask: bool = True,\n+        backend: str = \"fast\",\n     ):\n         super().__init__()\n-        self.tf_tokenizer = FastBertTokenizer(\n-            vocab_list, token_out_type=tf.int64, lower_case_nfd_strip_accents=do_lower_case\n-        )\n         self.vocab_list = vocab_list\n         self.do_lower_case = do_lower_case\n         self.cls_token_id = cls_token_id or vocab_list.index(\"[CLS]\")\n@@ -79,6 +77,24 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n         self.pad_to_multiple_of = pad_to_multiple_of\n         self.return_token_type_ids = return_token_type_ids\n         self.return_attention_mask = return_attention_mask\n+        self.backend = backend\n+        if self.backend == \"fast\":\n+            self.tf_tokenizer = FastBertTokenizer(\n+                vocab_list, token_out_type=tf.int64, lower_case_nfd_strip_accents=do_lower_case\n+            )\n+        elif self.backend == \"bert\":\n+            # Build lookup table mapping vocab tokens to indices, defaulting to [UNK] for OOVs\n+            unk_index = vocab_list.index(\"[UNK]\") if \"[UNK]\" in vocab_list else 0\n+            initializer = tf.lookup.KeyValueTensorInitializer(\n+                keys=vocab_list,\n+                key_dtype=tf.string,\n+                values=tf.range(len(vocab_list), dtype=tf.int64),\n+                value_dtype=tf.int64,\n+            )\n+            lookup_table = tf.lookup.StaticHashTable(initializer, default_value=tf.cast(unk_index, tf.int64))\n+            self.tf_tokenizer = TFBertTokenizerLayer(lookup_table, token_out_type=tf.int64, lower_case=do_lower_case)\n+        else:\n+            raise ValueError(\"backend must be either 'fast' or 'bert'\")\n \n     @classmethod\n     def from_tokenizer(cls, tokenizer: \"PreTrainedTokenizerBase\", **kwargs):  # noqa: F821\n@@ -98,6 +114,7 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n         tf_tokenizer = TFBertTokenizer.from_tokenizer(tokenizer)\n         ```\n         \"\"\"\n+        # backend can be optionally provided in kwargs\n         vocab = tokenizer.get_vocab()\n         vocab = sorted([(wordpiece, idx) for wordpiece, idx in vocab.items()], key=lambda x: x[1])\n         vocab_list = [entry[0] for entry in vocab]\n@@ -127,16 +144,18 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n         tf_tokenizer = TFBertTokenizer.from_pretrained(\"bert-base-uncased\")\n         ```\n         \"\"\"\n+        # Extract backend argument so it's not passed to regular tokenizer constructors\n+        backend = kwargs.pop(\"backend\", \"fast\")\n         try:\n             tokenizer = BertTokenizer.from_pretrained(pretrained_model_name_or_path, *init_inputs, **kwargs)\n         except:  # noqa: E722\n             from .tokenization_bert_fast import BertTokenizerFast\n \n             tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path, *init_inputs, **kwargs)\n-        return cls.from_tokenizer(tokenizer, **kwargs)\n+        return cls.from_tokenizer(tokenizer, backend=backend, **kwargs)\n \n     def unpaired_tokenize(self, texts):\n-        if self.do_lower_case:\n+        if self.backend == \"fast\" and self.do_lower_case:\n             texts = case_fold_utf8(texts)\n         return self.tf_tokenizer.tokenize(texts)\n \n@@ -219,4 +238,5 @@ class TFBertTokenizer(tf.keras.layers.Layer):\n             \"cls_token_id\": self.cls_token_id,\n             \"sep_token_id\": self.sep_token_id,\n             \"pad_token_id\": self.pad_token_id,\n+            \"backend\": self.backend,\n         }\n"}
{"instance_id": "huggingface__transformers-19657", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/pipelines/base.py b/src/transformers/pipelines/base.py\nindex b5e7c9cb58..4205ef2eb2 100644\n--- a/src/transformers/pipelines/base.py\n+++ b/src/transformers/pipelines/base.py\n@@ -836,13 +836,13 @@ class Pipeline(_ScikitCompat):\n         \"\"\"\n         Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n         \"\"\"\n-        return self(X=X)\n+        return self(X)\n \n     def predict(self, X):\n         \"\"\"\n         Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n         \"\"\"\n-        return self(X=X)\n+        return self(X)\n \n     @contextmanager\n     def device_placement(self):\ndiff --git a/src/transformers/pipelines/text_classification.py b/src/transformers/pipelines/text_classification.py\nindex 51eb6b36f5..b3c6c7f9c3 100644\n--- a/src/transformers/pipelines/text_classification.py\n+++ b/src/transformers/pipelines/text_classification.py\n@@ -140,7 +140,7 @@ class TextClassificationPipeline(Pipeline):\n         result = super().__call__(*args, **kwargs)\n         # TODO try and retrieve it in a nicer way from _sanitize_parameters.\n         _legacy = \"top_k\" not in kwargs\n-        if isinstance(args[0], str) and _legacy:\n+        if args and isinstance(args[0], str) and _legacy:\n             # This pipeline is odd, and return a list when single item is run\n             return [result]\n         else:\n"}
{"instance_id": "huggingface__transformers-21345", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/activations.py b/src/transformers/activations.py\nindex d9caf8763e..e275582329 100644\n--- a/src/transformers/activations.py\n+++ b/src/transformers/activations.py\n@@ -66,6 +66,26 @@ class FastGELUActivation(nn.Module):\n         return 0.5 * input * (1.0 + torch.tanh(input * 0.7978845608 * (1.0 + 0.044715 * input * input)))\n \n \n+class TanhGELUActivation(nn.Module):\n+    \"\"\"\n+    Applies the OpenAI GELU approximation using PyTorch's optimized implementation when available.\n+    Equivalent to NewGELUActivation / FastGELUActivation but faster on torch>=1.12 via approximate='tanh'.\n+    \"\"\"\n+\n+    def __init__(self):\n+        super().__init__()\n+        if version.parse(torch.__version__) >= version.parse(\"1.12.0\"):\n+            self.act = lambda input: nn.functional.gelu(input, approximate=\"tanh\")\n+        else:\n+            self.act = self._gelu_tanh_python\n+\n+    def _gelu_tanh_python(self, input: Tensor) -> Tensor:\n+        return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))\n+\n+    def forward(self, input: Tensor) -> Tensor:\n+        return self.act(input)\n+\n+\n class QuickGELUActivation(nn.Module):\n     \"\"\"\n     Applies GELU approximation that is fast but somewhat inaccurate. See: https://github.com/hendrycks/GELUs\n@@ -154,6 +174,7 @@ ACT2CLS = {\n     \"gelu_10\": (ClippedGELUActivation, {\"min\": -10, \"max\": 10}),\n     \"gelu_fast\": FastGELUActivation,\n     \"gelu_new\": NewGELUActivation,\n+    \"gelu_tanh\": TanhGELUActivation,\n     \"gelu_python\": (GELUActivation, {\"use_gelu_python\": True}),\n     \"linear\": LinearActivation,\n     \"mish\": MishActivation,\n@@ -180,6 +201,7 @@ gelu_python = get_activation(\"gelu_python\")\n gelu_new = get_activation(\"gelu_new\")\n gelu = get_activation(\"gelu\")\n gelu_fast = get_activation(\"gelu_fast\")\n+gelu_tanh = get_activation(\"gelu_tanh\")\n quick_gelu = get_activation(\"quick_gelu\")\n silu = get_activation(\"silu\")\n mish = get_activation(\"mish\")\n"}
{"instance_id": "huggingface__transformers-21768", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/optimization.py b/src/transformers/optimization.py\nindex 659b92a59b..7079ea07ac 100644\n--- a/src/transformers/optimization.py\n+++ b/src/transformers/optimization.py\n@@ -17,6 +17,7 @@\n import math\n import warnings\n from typing import Callable, Iterable, Optional, Tuple, Union\n+from functools import partial\n \n import torch\n from torch import nn\n@@ -31,6 +32,10 @@ from .utils.versions import require_version\n logger = logging.get_logger(__name__)\n \n \n+def _constant_lr_lambda(_: int) -> float:\n+    return 1.0\n+\n+\n def get_constant_schedule(optimizer: Optimizer, last_epoch: int = -1):\n     \"\"\"\n     Create a schedule with a constant learning rate, using the learning rate set in optimizer.\n@@ -44,7 +49,13 @@ def get_constant_schedule(optimizer: Optimizer, last_epoch: int = -1):\n     Return:\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n-    return LambdaLR(optimizer, lambda _: 1, last_epoch=last_epoch)\n+    return LambdaLR(optimizer, _constant_lr_lambda, last_epoch=last_epoch)\n+\n+\n+def _constant_with_warmup_lr_lambda(current_step: int, *, num_warmup_steps: int) -> float:\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1.0, num_warmup_steps))\n+    return 1.0\n \n \n def get_constant_schedule_with_warmup(optimizer: Optimizer, num_warmup_steps: int, last_epoch: int = -1):\n@@ -64,12 +75,16 @@ def get_constant_schedule_with_warmup(optimizer: Optimizer, num_warmup_steps: in\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n \n-    def lr_lambda(current_step: int):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1.0, num_warmup_steps))\n-        return 1.0\n+    schedule = partial(_constant_with_warmup_lr_lambda, num_warmup_steps=num_warmup_steps)\n+    return LambdaLR(optimizer, schedule, last_epoch=last_epoch)\n+\n \n-    return LambdaLR(optimizer, lr_lambda, last_epoch=last_epoch)\n+def _linear_with_warmup_lr_lambda(current_step: int, *, num_warmup_steps: int, num_training_steps: int) -> float:\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    return max(\n+        0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n+    )\n \n \n def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps, last_epoch=-1):\n@@ -91,14 +106,15 @@ def get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_st\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n \n-    def lr_lambda(current_step: int):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        return max(\n-            0.0, float(num_training_steps - current_step) / float(max(1, num_training_steps - num_warmup_steps))\n-        )\n+    schedule = partial(_linear_with_warmup_lr_lambda, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)\n+    return LambdaLR(optimizer, schedule, last_epoch)\n \n-    return LambdaLR(optimizer, lr_lambda, last_epoch)\n+\n+def _cosine_with_warmup_lr_lambda(current_step: int, *, num_warmup_steps: int, num_training_steps: int, num_cycles: float) -> float:\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n+    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n \n \n def get_cosine_schedule_with_warmup(\n@@ -126,13 +142,17 @@ def get_cosine_schedule_with_warmup(\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n \n-    def lr_lambda(current_step):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n-        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress)))\n+    schedule = partial(_cosine_with_warmup_lr_lambda, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps, num_cycles=num_cycles)\n+    return LambdaLR(optimizer, schedule, last_epoch)\n+\n \n-    return LambdaLR(optimizer, lr_lambda, last_epoch)\n+def _cosine_hard_restarts_with_warmup_lr_lambda(current_step: int, *, num_warmup_steps: int, num_training_steps: int, num_cycles: int) -> float:\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n+    if progress >= 1.0:\n+        return 0.0\n+    return max(0.0, 0.5 * (1.0 + math.cos(math.pi * ((float(num_cycles) * progress) % 1.0))))\n \n \n def get_cosine_with_hard_restarts_schedule_with_warmup(\n@@ -159,15 +179,21 @@ def get_cosine_with_hard_restarts_schedule_with_warmup(\n         `torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n     \"\"\"\n \n-    def lr_lambda(current_step):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n-        if progress >= 1.0:\n-            return 0.0\n-        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * ((float(num_cycles) * progress) % 1.0))))\n+    schedule = partial(_cosine_hard_restarts_with_warmup_lr_lambda, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps, num_cycles=num_cycles)\n+    return LambdaLR(optimizer, schedule, last_epoch)\n+\n \n-    return LambdaLR(optimizer, lr_lambda, last_epoch)\n+def _polynomial_decay_with_warmup_lr_lambda(current_step: int, *, num_warmup_steps: int, num_training_steps: int, lr_init: float, lr_end: float, power: float) -> float:\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    elif current_step > num_training_steps:\n+        return lr_end / lr_init  # as LambdaLR multiplies by lr_init\n+    else:\n+        lr_range = lr_init - lr_end\n+        decay_steps = num_training_steps - num_warmup_steps\n+        pct_remaining = 1 - (current_step - num_warmup_steps) / decay_steps\n+        decay = lr_range * pct_remaining**power + lr_end\n+        return decay / lr_init  # as LambdaLR multiplies by lr_init\n \n \n def get_polynomial_decay_schedule_with_warmup(\n@@ -205,19 +231,16 @@ def get_polynomial_decay_schedule_with_warmup(\n     if not (lr_init > lr_end):\n         raise ValueError(f\"lr_end ({lr_end}) must be be smaller than initial lr ({lr_init})\")\n \n-    def lr_lambda(current_step: int):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        elif current_step > num_training_steps:\n-            return lr_end / lr_init  # as LambdaLR multiplies by lr_init\n-        else:\n-            lr_range = lr_init - lr_end\n-            decay_steps = num_training_steps - num_warmup_steps\n-            pct_remaining = 1 - (current_step - num_warmup_steps) / decay_steps\n-            decay = lr_range * pct_remaining**power + lr_end\n-            return decay / lr_init  # as LambdaLR multiplies by lr_init\n+    schedule = partial(_polynomial_decay_with_warmup_lr_lambda, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps, lr_init=lr_init, lr_end=lr_end, power=power)\n+    return LambdaLR(optimizer, schedule, last_epoch)\n \n-    return LambdaLR(optimizer, lr_lambda, last_epoch)\n+\n+def _inverse_sqrt_with_warmup_lr_lambda(current_step: int, *, num_warmup_steps: int, timescale: int) -> float:\n+    if current_step < num_warmup_steps:\n+        return float(current_step) / float(max(1, num_warmup_steps))\n+    shift = timescale - num_warmup_steps\n+    decay = 1.0 / math.sqrt((current_step + shift) / timescale)\n+    return decay\n \n \n def get_inverse_sqrt_schedule(\n@@ -246,14 +269,8 @@ def get_inverse_sqrt_schedule(\n     if timescale is None:\n         timescale = num_warmup_steps\n \n-    def lr_lambda(current_step: int):\n-        if current_step < num_warmup_steps:\n-            return float(current_step) / float(max(1, num_warmup_steps))\n-        shift = timescale - num_warmup_steps\n-        decay = 1.0 / math.sqrt((current_step + shift) / timescale)\n-        return decay\n-\n-    return LambdaLR(optimizer, lr_lambda, last_epoch=last_epoch)\n+    schedule = partial(_inverse_sqrt_with_warmup_lr_lambda, num_warmup_steps=num_warmup_steps, timescale=timescale)\n+    return LambdaLR(optimizer, schedule, last_epoch=last_epoch)\n \n \n TYPE_TO_SCHEDULER_FUNCTION = {\n"}
{"instance_id": "huggingface__transformers-22158", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/maskformer/image_processing_maskformer.py b/src/transformers/models/maskformer/image_processing_maskformer.py\nindex ef4314869b..a783310135 100644\n--- a/src/transformers/models/maskformer/image_processing_maskformer.py\n+++ b/src/transformers/models/maskformer/image_processing_maskformer.py\n@@ -637,7 +637,7 @@ class MaskFormerImageProcessor(BaseImageProcessor):\n         # drop segment IDs > 255.\n         segmentation_map = self._preprocess(\n             image=segmentation_map,\n-            do_resize=do_resize,\n+            do_resize=False,\n             resample=PILImageResampling.NEAREST,\n             size=size,\n             size_divisor=size_divisor,\n@@ -896,6 +896,12 @@ class MaskFormerImageProcessor(BaseImageProcessor):\n                 masks, classes = self.convert_segmentation_map_to_binary_masks(\n                     segmentation_map, instance_id, ignore_index=ignore_index, reduce_labels=reduce_labels\n                 )\n+                # Handle case with no valid masks\n+                if masks.shape[0] == 0:\n+                    empty = torch.zeros((0, pad_size[0], pad_size[1]), dtype=torch.float32)\n+                    mask_labels.append(empty)\n+                    class_labels.append(torch.zeros((0,), dtype=torch.int64))\n+                    continue\n                 # We add an axis to make them compatible with the transformations library\n                 # this will be removed in the future\n                 masks = [mask[None, ...] for mask in masks]\ndiff --git a/src/transformers/models/oneformer/image_processing_oneformer.py b/src/transformers/models/oneformer/image_processing_oneformer.py\nindex 67eadd4e84..c0ddfbb504 100644\n--- a/src/transformers/models/oneformer/image_processing_oneformer.py\n+++ b/src/transformers/models/oneformer/image_processing_oneformer.py\n@@ -592,7 +592,7 @@ class OneFormerImageProcessor(BaseImageProcessor):\n         # drop segment IDs > 255.\n         segmentation_map = self._preprocess(\n             image=segmentation_map,\n-            do_resize=do_resize,\n+            do_resize=False,\n             resample=PILImageResampling.NEAREST,\n             size=size,\n             do_rescale=False,\n@@ -985,6 +985,12 @@ class OneFormerImageProcessor(BaseImageProcessor):\n                     raise ValueError(f\"{task} was not expected, expected `semantic`, `instance` or `panoptic`\")\n \n                 # we cannot batch them since they don't share a common class size\n+                if masks.shape[0] == 0:\n+                    empty_masks = torch.zeros((0, pad_size[0], pad_size[1]), dtype=torch.float32)\n+                    mask_labels.append(empty_masks)\n+                    class_labels.append(torch.zeros((0,), dtype=torch.int64))\n+                    text_inputs.append(texts)\n+                    continue\n                 masks = [mask[None, ...] for mask in masks]\n                 masks = [\n                     self._pad_image(image=mask, output_size=pad_size, constant_values=ignore_index) for mask in masks\n"}
{"instance_id": "huggingface__transformers-21969", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/image_transforms.py b/src/transformers/image_transforms.py\nindex 0ae19c43c7..85e1b9d983 100644\n--- a/src/transformers/image_transforms.py\n+++ b/src/transformers/image_transforms.py\n@@ -130,8 +130,8 @@ def to_pil_image(\n         image (`PIL.Image.Image` or `numpy.ndarray` or `torch.Tensor` or `tf.Tensor`):\n             The image to convert to the `PIL.Image` format.\n         do_rescale (`bool`, *optional*):\n-            Whether or not to apply the scaling factor (to make pixel values integers between 0 and 255). Will default\n-            to `True` if the image type is a floating type, `False` otherwise.\n+            Whether or not to apply the scaling factor (to make pixel values integers between 0 and 255).\n+            If unset, floating-point inputs will be rescaled only when their values are in [0, 1], otherwise no rescaling is applied.\n \n     Returns:\n         `PIL.Image.Image`: The converted image.\n@@ -156,9 +156,20 @@ def to_pil_image(\n     image = np.squeeze(image, axis=-1) if image.shape[-1] == 1 else image\n \n     # PIL.Image can only store uint8 values, so we rescale the image to be between 0 and 255 if needed.\n-    do_rescale = isinstance(image.flat[0], (float, np.float32, np.float64)) if do_rescale is None else do_rescale\n+    if do_rescale is None:\n+        is_float = isinstance(image.flat[0], (float, np.float32, np.float64))\n+        if is_float:\n+            # Decide based on value range: rescale only if values are in [0, 1]\n+            # Use min/max to avoid sampling inconsistencies across platforms\n+            img_min = float(np.min(image))\n+            img_max = float(np.max(image))\n+            do_rescale = 0.0 <= img_min and img_max <= 1.0\n+        else:\n+            do_rescale = False\n     if do_rescale:\n         image = rescale(image, 255)\n+        # Clamp to [0, 255] before casting to uint8 to avoid overflow differences across platforms\n+        image = np.clip(image, 0, 255)\n     image = image.astype(np.uint8)\n     return PIL.Image.fromarray(image)\n \n"}
{"instance_id": "huggingface__transformers-22458", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/vit/image_processing_vit.py b/src/transformers/models/vit/image_processing_vit.py\nindex 66d68e7f82..adfeb49281 100644\n--- a/src/transformers/models/vit/image_processing_vit.py\n+++ b/src/transformers/models/vit/image_processing_vit.py\n@@ -262,7 +262,15 @@ class ViTImageProcessor(BaseImageProcessor):\n             images = [self.resize(image=image, size=size_dict, resample=resample) for image in images]\n \n         if do_rescale:\n-            images = [self.rescale(image=image, scale=rescale_factor) for image in images]\n+            # Avoid double rescaling when inputs are already in [0, 1] float range (e.g., torchvision ToTensor).\n+            processed_images = []\n+            for image in images:\n+                if np.issubdtype(image.dtype, np.floating) and np.all(image >= 0) and np.all(image <= 1):\n+                    # Image already in [0, 1]; keep range but cast to float32 for consistency with rescale() output.\n+                    processed_images.append(image.astype(np.float32))\n+                else:\n+                    processed_images.append(self.rescale(image=image, scale=rescale_factor))\n+            images = processed_images\n \n         if do_normalize:\n             images = [self.normalize(image=image, mean=image_mean, std=image_std) for image in images]\n"}
{"instance_id": "huggingface__transformers-22920", "model_name_or_path": "Prometheus", "model_patch": "diff --git a/src/transformers/models/sam/image_processing_sam.py b/src/transformers/models/sam/image_processing_sam.py\nindex 361567f704..5ed67e8b82 100644\n--- a/src/transformers/models/sam/image_processing_sam.py\n+++ b/src/transformers/models/sam/image_processing_sam.py\n@@ -399,10 +399,22 @@ class SamImageProcessor(BaseImageProcessor):\n         pad_size = self.pad_size if pad_size is None else pad_size\n         target_image_size = (pad_size[\"height\"], pad_size[\"width\"])\n \n+        # normalize sizes to tuples of Python ints for PyTorch interpolate and slicing\n+        if isinstance(original_sizes, torch.Tensor):\n+            original_sizes_norm = [(int(h), int(w)) for h, w in original_sizes.tolist()]\n+        else:\n+            original_sizes_norm = [(int(size[0]), int(size[1])) for size in original_sizes]\n+        if isinstance(reshaped_input_sizes, torch.Tensor):\n+            reshaped_input_sizes_norm = [(int(h), int(w)) for h, w in reshaped_input_sizes.tolist()]\n+        else:\n+            reshaped_input_sizes_norm = [(int(size[0]), int(size[1])) for size in reshaped_input_sizes]\n+        target_image_size = (int(pad_size[\"height\"]), int(pad_size[\"width\"]))\n+\n         output_masks = []\n-        for i, original_size in enumerate(original_sizes):\n+        for i, original_size in enumerate(original_sizes_norm):\n             interpolated_mask = F.interpolate(masks[i], target_image_size, mode=\"bilinear\", align_corners=False)\n-            interpolated_mask = interpolated_mask[..., : reshaped_input_sizes[i][0], : reshaped_input_sizes[i][1]]\n+            crop_h, crop_w = reshaped_input_sizes_norm[i]\n+            interpolated_mask = interpolated_mask[..., : crop_h, : crop_w]\n             interpolated_mask = F.interpolate(interpolated_mask, original_size, mode=\"bilinear\", align_corners=False)\n             if binarize:\n                 interpolated_mask = interpolated_mask > mask_threshold\n"}
